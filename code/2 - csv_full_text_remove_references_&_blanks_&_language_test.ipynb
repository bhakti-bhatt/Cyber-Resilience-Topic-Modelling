{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in c:\\users\\bbhat\\anaconda3\\lib\\site-packages (3.3.0)\n",
      "Requirement already satisfied: pathy>=0.3.5 in c:\\users\\bbhat\\anaconda3\\lib\\site-packages (from spacy) (0.6.1)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\bbhat\\anaconda3\\lib\\site-packages (from spacy) (1.0.7)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in c:\\users\\bbhat\\anaconda3\\lib\\site-packages (from spacy) (0.7.7)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\bbhat\\anaconda3\\lib\\site-packages (from spacy) (3.0.6)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.14 in c:\\users\\bbhat\\anaconda3\\lib\\site-packages (from spacy) (8.0.16)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\bbhat\\anaconda3\\lib\\site-packages (from spacy) (1.0.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\bbhat\\anaconda3\\lib\\site-packages (from spacy) (2.4.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\bbhat\\anaconda3\\lib\\site-packages (from spacy) (49.2.0.post20200714)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in c:\\users\\bbhat\\anaconda3\\lib\\site-packages (from spacy) (1.8.2)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in c:\\users\\bbhat\\anaconda3\\lib\\site-packages (from spacy) (0.4.1)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in c:\\users\\bbhat\\anaconda3\\lib\\site-packages (from spacy) (0.9.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\bbhat\\anaconda3\\lib\\site-packages (from spacy) (20.4)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\bbhat\\anaconda3\\lib\\site-packages (from spacy) (3.3.0)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in c:\\users\\bbhat\\anaconda3\\lib\\site-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\bbhat\\anaconda3\\lib\\site-packages (from spacy) (2.0.7)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\bbhat\\anaconda3\\lib\\site-packages (from spacy) (2.11.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\bbhat\\anaconda3\\lib\\site-packages (from spacy) (4.47.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\bbhat\\anaconda3\\lib\\site-packages (from spacy) (1.22.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\bbhat\\anaconda3\\lib\\site-packages (from spacy) (2.24.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\bbhat\\anaconda3\\lib\\site-packages (from spacy) (2.0.6)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in c:\\users\\bbhat\\anaconda3\\lib\\site-packages (from pathy>=0.3.5->spacy) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\bbhat\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy) (4.2.0)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\bbhat\\anaconda3\\lib\\site-packages (from typer<0.5.0,>=0.3.0->spacy) (7.1.2)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\bbhat\\anaconda3\\lib\\site-packages (from packaging>=20.0->spacy) (2.4.7)\n",
      "Requirement already satisfied: six in c:\\users\\bbhat\\anaconda3\\lib\\site-packages (from packaging>=20.0->spacy) (1.15.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\bbhat\\anaconda3\\lib\\site-packages (from jinja2->spacy) (1.1.1)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\bbhat\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\bbhat\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\bbhat\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.25.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\bbhat\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2020.6.20)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy_langdetect in c:\\users\\bbhat\\anaconda3\\lib\\site-packages (0.1.2)\n",
      "Requirement already satisfied: langdetect==1.0.7 in c:\\users\\bbhat\\anaconda3\\lib\\site-packages (from spacy_langdetect) (1.0.7)\n",
      "Requirement already satisfied: pytest in c:\\users\\bbhat\\anaconda3\\lib\\site-packages (from spacy_langdetect) (5.4.3)\n",
      "Requirement already satisfied: six in c:\\users\\bbhat\\anaconda3\\lib\\site-packages (from langdetect==1.0.7->spacy_langdetect) (1.15.0)\n",
      "Requirement already satisfied: py>=1.5.0 in c:\\users\\bbhat\\anaconda3\\lib\\site-packages (from pytest->spacy_langdetect) (1.9.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\bbhat\\anaconda3\\lib\\site-packages (from pytest->spacy_langdetect) (20.4)\n",
      "Requirement already satisfied: attrs>=17.4.0 in c:\\users\\bbhat\\anaconda3\\lib\\site-packages (from pytest->spacy_langdetect) (19.3.0)\n",
      "Requirement already satisfied: more-itertools>=4.0.0 in c:\\users\\bbhat\\anaconda3\\lib\\site-packages (from pytest->spacy_langdetect) (8.4.0)\n",
      "Requirement already satisfied: pluggy<1.0,>=0.12 in c:\\users\\bbhat\\anaconda3\\lib\\site-packages (from pytest->spacy_langdetect) (0.13.1)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\bbhat\\anaconda3\\lib\\site-packages (from pytest->spacy_langdetect) (0.2.5)\n",
      "Requirement already satisfied: atomicwrites>=1.0 in c:\\users\\bbhat\\anaconda3\\lib\\site-packages (from pytest->spacy_langdetect) (1.4.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\bbhat\\anaconda3\\lib\\site-packages (from pytest->spacy_langdetect) (0.4.3)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\bbhat\\anaconda3\\lib\\site-packages (from packaging->pytest->spacy_langdetect) (2.4.7)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install spacy_langdetect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: en-core-web-sm==3.3.0 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.3.0/en_core_web_sm-3.3.0-py3-none-any.whl#egg=en_core_web_sm==3.3.0 in c:\\users\\bbhat\\anaconda3\\lib\\site-packages (3.3.0)\n",
      "Requirement already satisfied: spacy<3.4.0,>=3.3.0.dev0 in c:\\users\\bbhat\\anaconda3\\lib\\site-packages (from en-core-web-sm==3.3.0) (3.3.0)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\bbhat\\anaconda3\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.4.3)\n",
      "Requirement already satisfied: pathy>=0.3.5 in c:\\users\\bbhat\\anaconda3\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (0.6.1)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.14 in c:\\users\\bbhat\\anaconda3\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (8.0.16)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in c:\\users\\bbhat\\anaconda3\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (0.7.7)\n",
      "Requirement already satisfied: setuptools in c:\\users\\bbhat\\anaconda3\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (49.2.0.post20200714)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in c:\\users\\bbhat\\anaconda3\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (0.4.1)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\bbhat\\anaconda3\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.0.6)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\bbhat\\anaconda3\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.0.2)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\bbhat\\anaconda3\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.0.6)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\bbhat\\anaconda3\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.0.7)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in c:\\users\\bbhat\\anaconda3\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.8.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\bbhat\\anaconda3\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (20.4)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in c:\\users\\bbhat\\anaconda3\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.0.9)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in c:\\users\\bbhat\\anaconda3\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (0.9.1)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\bbhat\\anaconda3\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.22.4)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\bbhat\\anaconda3\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.0.7)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\bbhat\\anaconda3\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.24.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\bbhat\\anaconda3\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.3.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\bbhat\\anaconda3\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (4.47.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\bbhat\\anaconda3\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.11.2)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in c:\\users\\bbhat\\anaconda3\\lib\\site-packages (from pathy>=0.3.5->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (5.2.1)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\bbhat\\anaconda3\\lib\\site-packages (from typer<0.5.0,>=0.3.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (7.1.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\bbhat\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (4.2.0)\n",
      "Requirement already satisfied: six in c:\\users\\bbhat\\anaconda3\\lib\\site-packages (from packaging>=20.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.15.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\bbhat\\anaconda3\\lib\\site-packages (from packaging>=20.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.4.7)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\bbhat\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.25.9)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\bbhat\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\bbhat\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\bbhat\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2020.6.20)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\bbhat\\anaconda3\\lib\\site-packages (from jinja2->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.1.1)\n",
      "[+] Download and installation successful\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Code</th>\n",
       "      <th>Full text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Journal of Business Continuity &amp; Emergency Pla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Code:54.6009d \\n\\nCybersecurity Resiliency of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>PERSPECTIVE\\npublished: 29 March 2019\\ndoi: 10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2018 48th Annual IEEE/IFIP International Confe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Received January 25, 2021, accepted February 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1319</th>\n",
       "      <td>1406</td>\n",
       "      <td>HSI 2009 \\n\\nCatania, Italy, May 21-23, 2009 \\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1320</th>\n",
       "      <td>1407</td>\n",
       "      <td>Identity \\n\\nBased Authenticated \\n\\nKey Agree...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1321</th>\n",
       "      <td>1408</td>\n",
       "      <td>Using Operating System Wrappers to Increase th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1322</th>\n",
       "      <td>1409</td>\n",
       "      <td>Intrusion Tolerant Systems (cid:0)\\n\\nPartha P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1323</th>\n",
       "      <td>1411</td>\n",
       "      <td>Journal of Transportation Security (2021) 14:1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1324 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Code                                          Full text\n",
       "0        1  Journal of Business Continuity & Emergency Pla...\n",
       "1        2  Code:54.6009d \\n\\nCybersecurity Resiliency of ...\n",
       "2        3  PERSPECTIVE\\npublished: 29 March 2019\\ndoi: 10...\n",
       "3        4  2018 48th Annual IEEE/IFIP International Confe...\n",
       "4        5  Received January 25, 2021, accepted February 2...\n",
       "...    ...                                                ...\n",
       "1319  1406  HSI 2009 \\n\\nCatania, Italy, May 21-23, 2009 \\...\n",
       "1320  1407  Identity \\n\\nBased Authenticated \\n\\nKey Agree...\n",
       "1321  1408  Using Operating System Wrappers to Increase th...\n",
       "1322  1409  Intrusion Tolerant Systems (cid:0)\\n\\nPartha P...\n",
       "1323  1411  Journal of Transportation Security (2021) 14:1...\n",
       "\n",
       "[1324 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import CSV file containing full texts\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "os.chdir('C:\\\\Users\\\\bbhat\\\\Downloads\\\\MRP\\\\Final Files')\n",
    "os.getcwd()\n",
    "\n",
    "my_df = pd.read_csv('Stage 1 - new papers full text.csv')      \n",
    "my_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Code</th>\n",
       "      <th>Full text</th>\n",
       "      <th>Full text without references</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1108</th>\n",
       "      <td>1180</td>\n",
       "      <td>6G Networks: Is This an Evolution or a Revolut...</td>\n",
       "      <td>6G Networks: Is This an Evolution or a Revolut...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Code                                          Full text  \\\n",
       "1108  1180  6G Networks: Is This an Evolution or a Revolut...   \n",
       "\n",
       "                           Full text without references  \n",
       "1108  6G Networks: Is This an Evolution or a Revolut...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a column for full texts without references\n",
    "import re\n",
    "\n",
    "reference_section_delimiters = '''References\\n|Reference\\n|REFERENCES\\n|REFERENCE\\n|\n",
    "References \\n|Reference \\n|REFERENCES \\n|REFERENCE \\n|R E F E R E N C E S\\n|R E F E R E N C E S \\n|\n",
    "R E F E R E NC E S\\n|APPENDIX\\nRELATED WORK\\n|references\\n|References |Bibliography\\n|R EF E RE N C E S\\n|\n",
    "REFERENCES |REFERENCES: \\n|RE FE R ENC E S\\n|REFRENCES \\n|R EFER ENCES\\n|rEFErEncEs\\n|RE FE RE NC ES\\n|Literature Cited\\n\\n|\n",
    "BIBLIOGRAPHY\\n|\\nBIBLIOGRAPHY\\n|BIBLIOGRAPHY|r e f e r e n c e s\\n|\\nr e f e r e n c e s\\n|r e f e r e n c e s|\\nREFERENCES|REFERENCES|\n",
    "\\nFurther Suggested Readings|\\n\\nNCES \\n\\nREFEREN\\n|\\nR eferences \\n|\\nBibliography |References\\t|bibliography\\n|\\x0cREFERRENCES|\n",
    "\\nFor Further Reading\\n|\\nReferences|R e f e r e n c e s|Reference Text and Citations|Re f e r e n c e s|LITERATURE CITED|\n",
    "R E F E R E N C E S  |\\nEnd Notes|\\nend notes|\\n\\nreFerences'''\n",
    "\n",
    "my_df = my_df.astype({\"Full text\": str}, errors='raise') \n",
    "\n",
    "my_df['Full text without references'] = my_df['Full text'].str.split(reference_section_delimiters).apply(lambda x: x[0])\n",
    "\n",
    "# most of the references which could be automatically removed through regex, are now removed, save the interim file\n",
    "my_df_without_references = my_df\n",
    "my_df_without_references.to_csv('Stage 2.1 - new papers full text without references.csv')\n",
    "my_df_without_references[my_df_without_references['Code'] ==1180]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Code</th>\n",
       "      <th>Full text</th>\n",
       "      <th>Full text without references</th>\n",
       "      <th>blank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>181</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>220</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>611</th>\n",
       "      <td>649</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>633</th>\n",
       "      <td>671</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Code         Full text Full text without references blank\n",
       "17     18  \n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "             \n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "   Yes\n",
       "175   181           \n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "                      \n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "   Yes\n",
       "209   220         \n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "                    \n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "   Yes\n",
       "611   649           \n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "                      \n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "   Yes\n",
       "633   671        \n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "                   \n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "   Yes"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# flag blank records\n",
    "my_df_without_references['blank'] =  np.where(my_df_without_references['Full text'].str.strip()=='', 'Yes', 'No')\n",
    "#print(my_df[my_df['blank'] == 'Yes'])\n",
    "\n",
    "# identify records that are blank/just pictures\n",
    "my_df_without_references[my_df_without_references['blank']=='Yes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# functions to help identify records that are not in the english language\n",
    "import spacy\n",
    "from spacy.language import Language\n",
    "from spacy_langdetect import LanguageDetector\n",
    "\n",
    "def get_lang_detector(nlp, name):\n",
    "    return LanguageDetector()\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "Language.factory(\"language_detector\", func=get_lang_detector)\n",
    "nlp.add_pipe('language_detector', last=True)\n",
    "\n",
    "\n",
    "def get_lang(x):\n",
    "    return nlp(x)._.language['language']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "en         1302\n",
       "es           14\n",
       "UNKNOWN       5\n",
       "ru            1\n",
       "cy            1\n",
       "tl            1\n",
       "Name: english lang, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# identify records that are not in the english language and save in the dataframe \n",
    "\n",
    "my_df_without_references['english lang'] =  my_df_without_references['Full text without references'].apply(lambda x: get_lang(x))\n",
    "my_df_without_references['english lang'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Code</th>\n",
       "      <th>Full text</th>\n",
       "      <th>Full text without references</th>\n",
       "      <th>blank</th>\n",
       "      <th>english lang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Yes</td>\n",
       "      <td>UNKNOWN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>77</td>\n",
       "      <td>(cid:2)(cid:3)(cid:4)(cid:5)(cid:6)(cid:7)(cid...</td>\n",
       "      <td>(cid:2)(cid:3)(cid:4)(cid:5)(cid:6)(cid:7)(cid...</td>\n",
       "      <td>No</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>143</td>\n",
       "      <td>Towards the cyber security paradigm of\\nehealt...</td>\n",
       "      <td>Towards the cyber security paradigm of\\nehealt...</td>\n",
       "      <td>No</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>157</td>\n",
       "      <td>(cid:36)(cid:3)(cid:54)\\n\\n(cid:54)(cid:87)(ci...</td>\n",
       "      <td>(cid:36)(cid:3)(cid:54)\\n\\n(cid:54)(cid:87)(ci...</td>\n",
       "      <td>No</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>166</td>\n",
       "      <td>See discussions, stats, and author profiles fo...</td>\n",
       "      <td>See discussions, stats, and author profiles fo...</td>\n",
       "      <td>No</td>\n",
       "      <td>ru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>181</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Yes</td>\n",
       "      <td>UNKNOWN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>220</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Yes</td>\n",
       "      <td>UNKNOWN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>300</td>\n",
       "      <td>A Unified Cybersecurity Framework for Complex ...</td>\n",
       "      <td>A Unified Cybersecurity Framework for Complex ...</td>\n",
       "      <td>No</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>408</td>\n",
       "      <td>(cid:51)(cid:85)(cid:72)(cid:83)(cid:68)(cid:8...</td>\n",
       "      <td>(cid:51)(cid:85)(cid:72)(cid:83)(cid:68)(cid:8...</td>\n",
       "      <td>No</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>482</td>\n",
       "      <td>2011 IEEE International Conferences on Interne...</td>\n",
       "      <td>2011 IEEE International Conferences on Interne...</td>\n",
       "      <td>No</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>563</th>\n",
       "      <td>594</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>No</td>\n",
       "      <td>tl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>602</th>\n",
       "      <td>638</td>\n",
       "      <td>(cid:2)(cid:3)(cid:4)(cid:5)(cid:6)(cid:3)(cid...</td>\n",
       "      <td>(cid:2)(cid:3)(cid:4)(cid:5)(cid:6)(cid:3)(cid...</td>\n",
       "      <td>No</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>611</th>\n",
       "      <td>649</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Yes</td>\n",
       "      <td>UNKNOWN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>633</th>\n",
       "      <td>671</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Yes</td>\n",
       "      <td>UNKNOWN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>698</th>\n",
       "      <td>741</td>\n",
       "      <td>(cid:0)(cid:1)(cid:2)(cid:3)(cid:4)(cid:5)(cid...</td>\n",
       "      <td>(cid:0)(cid:1)(cid:2)(cid:3)(cid:4)(cid:5)(cid...</td>\n",
       "      <td>No</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752</th>\n",
       "      <td>796</td>\n",
       "      <td>C y b er  S yst e m  R e c o v er y  f or I E ...</td>\n",
       "      <td>C y b er  S yst e m  R e c o v er y  f or I E ...</td>\n",
       "      <td>No</td>\n",
       "      <td>cy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>841</td>\n",
       "      <td>(cid:0)(cid:1)(cid:2)(cid:3)(cid:4)(cid:5)(cid...</td>\n",
       "      <td>(cid:0)(cid:1)(cid:2)(cid:3)(cid:4)(cid:5)(cid...</td>\n",
       "      <td>No</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>844</th>\n",
       "      <td>891</td>\n",
       "      <td>(cid:17)(cid:15)(cid:16)(cid:23)(cid:1)(cid:39...</td>\n",
       "      <td>(cid:17)(cid:15)(cid:16)(cid:23)(cid:1)(cid:39...</td>\n",
       "      <td>No</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1042</th>\n",
       "      <td>1108</td>\n",
       "      <td>(cid:21)(cid:19)(cid:20)(cid:24)(cid:3)(cid:44...</td>\n",
       "      <td>(cid:21)(cid:19)(cid:20)(cid:24)(cid:3)(cid:44...</td>\n",
       "      <td>No</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1115</th>\n",
       "      <td>1187</td>\n",
       "      <td>2021 IEEE 4th 5G World Forum (5GWF)\\n\\n9\\n6\\n0...</td>\n",
       "      <td>2021 IEEE 4th 5G World Forum (5GWF)\\n\\n9\\n6\\n0...</td>\n",
       "      <td>No</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1139</th>\n",
       "      <td>1214</td>\n",
       "      <td>(cid:3)(cid:4)(cid:5)(cid:4)(cid:6)(cid:7)(cid...</td>\n",
       "      <td>(cid:3)(cid:4)(cid:5)(cid:4)(cid:6)(cid:7)(cid...</td>\n",
       "      <td>No</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1170</th>\n",
       "      <td>1248</td>\n",
       "      <td>(cid:1)(cid:2)(cid:3)(cid:4)(cid:5)(cid:6)(cid...</td>\n",
       "      <td>(cid:1)(cid:2)(cid:3)(cid:4)(cid:5)(cid:6)(cid...</td>\n",
       "      <td>No</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Code                                          Full text  \\\n",
       "17      18                                   \n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "   \n",
       "73      77  (cid:2)(cid:3)(cid:4)(cid:5)(cid:6)(cid:7)(cid...   \n",
       "139    143  Towards the cyber security paradigm of\\nehealt...   \n",
       "152    157  (cid:36)(cid:3)(cid:54)\\n\\n(cid:54)(cid:87)(ci...   \n",
       "161    166  See discussions, stats, and author profiles fo...   \n",
       "175    181                                            \n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "   \n",
       "209    220                                          \n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "   \n",
       "286    300  A Unified Cybersecurity Framework for Complex ...   \n",
       "393    408  (cid:51)(cid:85)(cid:72)(cid:83)(cid:68)(cid:8...   \n",
       "464    482  2011 IEEE International Conferences on Interne...   \n",
       "563    594                                                nan   \n",
       "602    638  (cid:2)(cid:3)(cid:4)(cid:5)(cid:6)(cid:3)(cid...   \n",
       "611    649                                            \n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "   \n",
       "633    671                                         \n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "   \n",
       "698    741  (cid:0)(cid:1)(cid:2)(cid:3)(cid:4)(cid:5)(cid...   \n",
       "752    796  C y b er  S yst e m  R e c o v er y  f or I E ...   \n",
       "797    841  (cid:0)(cid:1)(cid:2)(cid:3)(cid:4)(cid:5)(cid...   \n",
       "844    891  (cid:17)(cid:15)(cid:16)(cid:23)(cid:1)(cid:39...   \n",
       "1042  1108  (cid:21)(cid:19)(cid:20)(cid:24)(cid:3)(cid:44...   \n",
       "1115  1187  2021 IEEE 4th 5G World Forum (5GWF)\\n\\n9\\n6\\n0...   \n",
       "1139  1214  (cid:3)(cid:4)(cid:5)(cid:4)(cid:6)(cid:7)(cid...   \n",
       "1170  1248  (cid:1)(cid:2)(cid:3)(cid:4)(cid:5)(cid:6)(cid...   \n",
       "\n",
       "                           Full text without references blank english lang  \n",
       "17                                     \n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "   Yes      UNKNOWN  \n",
       "73    (cid:2)(cid:3)(cid:4)(cid:5)(cid:6)(cid:7)(cid...    No           es  \n",
       "139   Towards the cyber security paradigm of\\nehealt...    No           es  \n",
       "152   (cid:36)(cid:3)(cid:54)\\n\\n(cid:54)(cid:87)(ci...    No           es  \n",
       "161   See discussions, stats, and author profiles fo...    No           ru  \n",
       "175                                             \n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "   Yes      UNKNOWN  \n",
       "209                                           \n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "   Yes      UNKNOWN  \n",
       "286   A Unified Cybersecurity Framework for Complex ...    No           es  \n",
       "393   (cid:51)(cid:85)(cid:72)(cid:83)(cid:68)(cid:8...    No           es  \n",
       "464   2011 IEEE International Conferences on Interne...    No           es  \n",
       "563                                                 nan    No           tl  \n",
       "602   (cid:2)(cid:3)(cid:4)(cid:5)(cid:6)(cid:3)(cid...    No           es  \n",
       "611                                             \n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "   Yes      UNKNOWN  \n",
       "633                                          \n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "   Yes      UNKNOWN  \n",
       "698   (cid:0)(cid:1)(cid:2)(cid:3)(cid:4)(cid:5)(cid...    No           es  \n",
       "752   C y b er  S yst e m  R e c o v er y  f or I E ...    No           cy  \n",
       "797   (cid:0)(cid:1)(cid:2)(cid:3)(cid:4)(cid:5)(cid...    No           es  \n",
       "844   (cid:17)(cid:15)(cid:16)(cid:23)(cid:1)(cid:39...    No           es  \n",
       "1042  (cid:21)(cid:19)(cid:20)(cid:24)(cid:3)(cid:44...    No           es  \n",
       "1115  2021 IEEE 4th 5G World Forum (5GWF)\\n\\n9\\n6\\n0...    No           es  \n",
       "1139  (cid:3)(cid:4)(cid:5)(cid:4)(cid:6)(cid:7)(cid...    No           es  \n",
       "1170  (cid:1)(cid:2)(cid:3)(cid:4)(cid:5)(cid:6)(cid...    No           es  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list records that are not in english\n",
    "\n",
    "my_df_without_references.to_csv('Stage 2.2 - new papers full text with language.csv')\n",
    "my_df_without_references[my_df_without_references['english lang']!= 'en']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0                                                                   1108\n",
       "Code                                                                         1180\n",
       "Full text                       6G Networks: Is This an Evolution or a Revolut...\n",
       "Full text without references    6G Networks: Is This an Evolution or a Revolut...\n",
       "blank                                                                          No\n",
       "english lang                                                                   en\n",
       "Name: 1108, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "my_df_without_references = pd.read_csv('Stage 2.2 - new papers full text with language.csv')\n",
    "my_df_without_references.loc[1108]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Code</th>\n",
       "      <th>Full text</th>\n",
       "      <th>Full text without references</th>\n",
       "      <th>blank</th>\n",
       "      <th>english lang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Code, Full text, Full text without references, blank, english lang]\n",
       "Index: []"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_df_without_references['Full text'][73]\n",
    "my_df_without_references['Full text'][30]\n",
    "my_df_without_references['Full text'][78]\n",
    "my_df_without_references['Full text'][115]\n",
    "my_df_without_references['Full text'][58]\n",
    "my_df_without_references[my_df_without_references['Code']=='220']#['Full text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MANUALLY CHECK THESE FILES AND REMOVE REFERENCES\n",
      "22   >>   23\n",
      "58   >>   62\n",
      "159   >>   164\n",
      "163   >>   168\n",
      "192   >>   198\n",
      "226   >>   239\n",
      "229   >>   242\n",
      "246   >>   259\n",
      "262   >>   275\n",
      "273   >>   287\n",
      "313   >>   327\n",
      "425   >>   440\n",
      "444   >>   461\n",
      "470   >>   490\n",
      "478   >>   498\n",
      "513   >>   538\n",
      "519   >>   544\n",
      "526   >>   551\n",
      "541   >>   567\n",
      "551   >>   579\n",
      "554   >>   583\n",
      "556   >>   586\n",
      "570   >>   601\n",
      "574   >>   607\n",
      "589   >>   624\n",
      "607   >>   644\n",
      "616   >>   654\n",
      "629   >>   667\n",
      "641   >>   679\n",
      "645   >>   683\n",
      "655   >>   693\n",
      "665   >>   703\n",
      "689   >>   729\n",
      "693   >>   735\n",
      "715   >>   758\n",
      "772   >>   816\n",
      "775   >>   819\n",
      "780   >>   824\n",
      "786   >>   830\n",
      "832   >>   878\n",
      "849   >>   897\n",
      "852   >>   900\n",
      "892   >>   942\n",
      "893   >>   943\n",
      "896   >>   946\n",
      "906   >>   957\n",
      "922   >>   976\n",
      "930   >>   984\n",
      "932   >>   987\n",
      "951   >>   1007\n",
      "959   >>   1016\n",
      "963   >>   1020\n",
      "996   >>   1058\n",
      "1091   >>   1159\n",
      "1105   >>   1177\n",
      "1106   >>   1178\n",
      "1108   >>   1180\n",
      "1112   >>   1184\n",
      "1123   >>   1195\n",
      "1137   >>   1211\n",
      "1162   >>   1240\n",
      "1172   >>   1250\n",
      "1175   >>   1253\n",
      "1181   >>   1260\n",
      "1196   >>   1278\n",
      "1197   >>   1279\n",
      "1203   >>   1285\n",
      "1214   >>   1299\n",
      "1217   >>   1304\n",
      "1218   >>   1305\n",
      "1288   >>   1375\n",
      "1300   >>   1387\n",
      "1301   >>   1388\n",
      "73\n"
     ]
    }
   ],
   "source": [
    "# identify those papers that references were not removed from their full text\n",
    "print(\"MANUALLY CHECK THESE FILES AND REMOVE REFERENCES\")\n",
    "count=0\n",
    "\n",
    "unchanged_papers = []\n",
    "\n",
    "# save list of unchanged papers \n",
    "f = open(\"unchanged_papers.txt\",\"a\")\n",
    "\n",
    "for i in my_df_without_references.index:\n",
    "    if (my_df_without_references['Full text'][i] == my_df_without_references['Full text without references'][i]) \\\n",
    "    and (my_df_without_references['blank'][i] != 'Yes')  and (my_df_without_references['english lang'][i] == 'en'):\n",
    "        count+=1 \n",
    "        print(i, '  >>  ', my_df_without_references['Code'][i])\n",
    "        f.write(str(i)+ \"  >>  \" + str(my_df_without_references['Code'][i])+\" >> \\n\")\n",
    "        unchanged_papers.append(i)\n",
    "\n",
    "f.close()\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created file for 23\n",
      "created file for 62\n",
      "created file for 164\n",
      "created file for 168\n",
      "created file for 198\n",
      "created file for 239\n",
      "created file for 242\n",
      "created file for 259\n",
      "created file for 275\n",
      "created file for 287\n",
      "created file for 327\n",
      "created file for 440\n",
      "created file for 461\n",
      "created file for 490\n",
      "created file for 498\n",
      "created file for 538\n",
      "created file for 544\n",
      "created file for 551\n",
      "created file for 567\n",
      "created file for 579\n",
      "created file for 583\n",
      "created file for 586\n",
      "created file for 601\n",
      "created file for 607\n",
      "created file for 624\n",
      "created file for 644\n",
      "created file for 654\n",
      "created file for 667\n",
      "created file for 679\n",
      "created file for 683\n",
      "created file for 693\n",
      "created file for 703\n",
      "created file for 729\n",
      "created file for 735\n",
      "created file for 758\n",
      "created file for 816\n",
      "created file for 819\n",
      "created file for 824\n",
      "created file for 830\n",
      "created file for 878\n",
      "created file for 897\n",
      "created file for 900\n",
      "created file for 942\n",
      "created file for 943\n",
      "created file for 946\n",
      "created file for 957\n",
      "created file for 976\n",
      "created file for 984\n",
      "created file for 987\n",
      "created file for 1007\n",
      "created file for 1016\n",
      "created file for 1020\n",
      "created file for 1058\n",
      "created file for 1159\n",
      "created file for 1177\n",
      "created file for 1178\n",
      "created file for 1180\n",
      "created file for 1184\n",
      "created file for 1195\n",
      "created file for 1211\n",
      "created file for 1240\n",
      "created file for 1250\n",
      "created file for 1253\n",
      "created file for 1260\n",
      "created file for 1278\n",
      "created file for 1279\n",
      "created file for 1285\n",
      "created file for 1299\n",
      "created file for 1304\n",
      "created file for 1305\n",
      "created file for 1375\n",
      "created file for 1387\n",
      "created file for 1388\n"
     ]
    }
   ],
   "source": [
    "# create the files in text format to manually check for references\n",
    "\n",
    "for i in unchanged_papers:\n",
    "    f = open(str(my_df_without_references['Code'][i]) + \".txt\", \"a\", encoding='utf-8')\n",
    "    f.write(my_df_without_references['Full text'][i])\n",
    "    print(\"created file for\", str(my_df_without_references['Code'][i]))\n",
    "\n",
    "\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Complete manual checks on the text files created above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Code': ['0023', '0062', '0164', '0168', '0198', '0239', '0242', '0259', '0461', '0490', '0494', '0498', '0538', '0544', '0567', '0579', '0583', '0586', '0601', '0607', '0624', '0644', '0667', '0679', '0683', '0693', '0729', '0735', '0758', '0816', '0819', '0824', '0830', '0878', '0897', '0900', '0943', '0946', '0948', '0957', '0976', '0987', '1007', '1016', '1020', '1058', '1159', '1177', '1178', '1180', '1184', '1195', '1240', '1250', '1253', '1260', '1278', '1279', '1299', '1304', '1305', '1375', '1387', '1388'], 'Full text': ['IST-153 Workshop on Intelligent Autonomous Agents for Cyber Defence and Resilience \\n\\nCyber security: Risk versus Resilience \\n\\nPosition Paper \\n\\nIgor Linkov, Alexander Ganin, Benjamin D. Trump, Kelsey Poinsatte-Jones \\n\\nUS Army Corps of Engineers, Engineering Research and Development Center, Virginia \\nRoad, Concord, MA 01742. Phone: (617) 233-9869  \\nEmail: Igor.Linkov@usace.army.mil; aag2k@virginia.edu; \\nbenjamin.d.trump@usace.army.mil; Kelsey.M.Poinsatte-Jones@usace.army.mil  \\n\\nRepresentation of world model, missions, objectives and rules of engagement is of crucial \\nimportance in agent-based modelling.  There is a great deal of confusion in the field of \\ncybersecurity on whether reduction or risk or enhancing resilience constitute the ultimate \\nmission with risk and resilience being used interchangeably.  We argue that risk and resilience \\nare fundamentally different but should be used complimentary in dealing with cyber threats. \\nWhile risk assessment is a useful tool to identify and characterize known, quantifiable system \\nthreats, resilience analysis is useful for the preparation, absorption, recovery, and adaptation of \\ninfrastructural, social, and informational systems against unknown, uncharacterized, low-\\nprobability events. The resilience analysis can be used to not only identify and reduce \\nvulnerabilities of individual components but also to return systems back to original functionality \\nand adaptation following an adverse event. Given the complementary nature of these two \\napproaches and complexity of cyber threats, resilience analysis and risk assessment must be \\nconsidered as a dual mission in agent based modeling. \\n\\nTraditionally, cyber threats are approached from the position of risk analysis. For the context of \\ncybersecurity, risk analysis is focused on the evaluation of threats (e.g., deliberate cyber-\\nattacks) that exploit system vulnerabilities that result in economic or political consequences. \\nRisk is the product of various hazards, vulnerabilities, and consequences, whereby risk analysts \\nseek to gain a measure of the damage that could be incurred by a given threat alongside its \\nrelative likelihood of occurrence. These efforts are well described in literature for routine and \\nwell characterized threats, yet generally rely upon robust sources of quantitative data to \\npopulate an assessment. Unfortunately, cybersecurity threats exploit increasingly complex \\ninformation systems and technology networks in a manner that is rarely predictable and is \\ndifficult to quantify. As such, traditional risk assessment may not be able to address \\ncybersecurity concerns in the near term. \\n\\nResilience analysis can serve as a complementary approach to explore threats that are \\ninherently complex in nature, and are difficult to predict or characterize. Resilience practitioners \\nadopt a systems-view of threat, where emphasis is placed upon reviewing a system’s dynamical \\nproperties, such as robustness, recoverability, and adaptability, for a wide range of potential \\nthreats. Where resilience would allow users to review system absorption and recovery for cyber \\nthreats, we use two methods to operationalize resilience in various contexts. This includes (i) \\nresilience matrices, and (ii) network science. For the former, a resilience matrix utilizes a \\ndecision analytical approach to integrate disparate sources of qualitative and semi-quantitative \\n\\n \\n \\n \\n \\n \\n \\n\\x0cinformation to assess system performance across multiple domains, including physical, \\ninformation, and social. For the latter, network science quantitatively assess a system’s topology \\nand interdependencies, where a failure could trigger cascading failures in other connected \\ncomponents of the system. Such approaches can help identify, in real time, the best available \\noptions to mitigate damage from cyber threats, as well as identify those alternatives available to \\nreduce the time, money, and manpower needed to recover from such threats.  \\n\\n \\n \\n \\n\\x0c', '© 2021 World Scientific Publishing Company\\nhttps://doi.org/10.1142/9789811219160_0002\\n\\nChapter 2\\n\\nThe EU’s Cybersecurity Policy: \\nBuilding a Resilient Regulatory \\nFramework\\nAnnegret Bendiek*,‡ and Eva Pander Maat†,§\\n\\n*German Institute for International and Security Affairs — SWP  \\nBerlin, Germany\\n\\n†University of London, London, United Kingdom\\n\\n‡Annegret.Bendiek@swp-berlin.org\\n\\n§Eva.pander-maat@city.ac.uk\\n\\nAbstract\\n\\nThe  European  Union  (EU)  plays  a  coordinating  role  on  cybersecurity \\nand  primarily  aims  to  build  a  cyber-resilient  regulatory  framework. \\nIts  cybersecurity  policy  is  delineated  by  the  foundational Treaties  and \\nhas  been  shaped  by  two  concepts:  the  internal  market  rationale  and \\nresilience.  The  internal  market  rationale  entails  that  the  EU  is  legiti-\\nmized  to  formulate  a  common  policy  and  promote  harmonized  stand-\\nards on cyberissues because the regulation and protection of the internal \\nmarket  require  it  to  do  so.  Resilience  is  the  core  concept  in  the  EU’s \\ncybersecurity  strategy  and  represents  the  capacity  to  resist  and  regen-\\nerate. The EU aims to achieve deterrence by resilience. Following the \\nstrong path dependency of the internal market rationale, cybersecurity \\npolicy  in  all  domains  of  EU  competence  is  eventually  accessory  or \\ncomplementary to the resilience of the internal market. However, cyber-\\nsecurity as a cross-cutting policy concern has also had a significant spill-\\nover effect into domains other than the internal market, namely the Area \\nof  Freedom,  Security  and  Justice,  the  Common  Foreign  and  Security \\nPolicy, and the Common Security and Defence Policy.\\n\\n2.1.   Introduction\\n\\nThe free trade of data has spurred globalization and led to an increasingly \\ninterconnected  world.  Cyberspace  and  the  Internet  were  long  seen  as  a \\nsource of economic growth, a place primarily belonging to businesses and \\ncustomers. The EU, too, has long seen the digital world through an eco-\\nnomic lens with a free trade perspective. Even today, “data transfers are \\nseen  as  crucial  to  revive  the  slowing  European  economy.”1  Over  time, \\nhowever, concerns about the privacy rights and security of individuals in \\ncyberspace  have  grown,  and  cyberthreats  on  the  European  soil  have \\nsurged. According to the European Cybercrime Centre, “cybercrime con-\\ntinues  to  take  new  forms  and  new  directions”2;  “In  a  12-month  period, \\n[…] over 2 billion [[data-]breaches] were reported, all impacting EU citi-\\nzens  to  some  degree”3;  “Malware  attacks  [have  been  taken]  to  a  level \\nwhere they can be an impossible challenge for national law enforcement \\nagencies to handle alone”4; and “Attacks are used not only for financial \\ngains but for ideological, political or purely malicious reasons.”5\\n\\nIn response to these concerns, cybersecurity quickly ascended to the \\ntop of EU’s political and legislative agenda in the past two decades. This \\nstudy sets out how the EU’s approach to cybersecurity, as delineated by \\nthe foundational Treaties, has been shaped by two concepts: the internal \\nmarket  rationale  and  resilience.  The  former  represents  the  regulatory \\npolicy  argument  that  largely  determined  how  the  EU’s  approach  to \\n\\x0cEU’s Cybersecurity Policy  25\\n\\ncybersecurity has been developed in the past three decades. The latter is \\nthe core concept in the EU’s cybersecurity strategy as it has matured in the \\npast years.\\n\\nIn  this  study,  the  term  “cybersecurity”  is  understood  to  entail \\n“the  safeguards  and  actions  that  can  be  used  to  protect  the  [civilian \\nand  military]  cyber  domain  […]  from  those  threats  that  are  associated \\nwith  or  that  may  harm  its  interdependent  networks  and  information \\ninfrastructure.”6 Such threats, referred to as cyberthreats, can be military, \\nhybrid, or (conventionally) criminal in nature. At first sight, cyberthreats \\naffect  the  internal  and  external  security  domains.7  Many  international \\nactors,  therefore,  establish  their  cybersecurity  policy  primarily  in  these \\ndomains.  However,  cyberthreats  also  significantly  affect  the  economic \\nand  (foreign)  political  domain.  Cybersecurity  is  therefore  a  cross- \\nsectional policy challenge, prone to create spillover effects from the secu-\\nrity domain into other domains.\\n\\nThe  EU  is  a  supranational,  multi-level  governance  institution  with \\ncharacteristics of both a federal state and a traditional intergovernmental \\norganization.8  The  foundational  Treaties,  as  per  its  signatories,  transfer \\nsovereign  powers  to  the  EU.9  These  powers  are  exercised  with  direct \\neffect in Member States’ jurisdictions.10 Competences not conferred upon \\n\\nthe EU remain to lie with Member States.11 Because the Treaties do not \\nmention cybersecurity as such, the EU does not have an explicit compe-\\ntence for a common policy on cybersecurity. Moreover, the EU’s compe-\\ntences in the internal and external security domain — as noted, often the \\nprimary  domains  of  cybersecurity  policy  —  are  limited  to  coordinative \\nefforts, such as a finite extent of minimum harmonization, expertise pool-\\ning,  and  the  steering  of  industrial  investment.  Regardless,  the  EU  has \\nfound itself confronted with increasingly salient cybersecurity concerns. \\nCyberthreats on European soil significantly impact the EU’s economy and \\nsociety.  The  elimination  of  internal  borders  makes  the  EU  particularly \\nvulnerable to cyberthreats. Facing these concerns, the EU has grappled to \\nformulate a common cybersecurity policy. The juxtaposition between the \\nstrong intention within EU institutions to regulate cybersecurity and the \\nlimited legal competences to do so lies at the core of this study. Perhaps \\nstrikingly, the EU has incrementally constructed a common cybersecurity \\npolicy  which  currently  stretches  across  four  policy  domains.  This \\nstudy  investigates  the  EU’s  cybersecurity  policy  and  its  creation  within \\nthe context of constitutional constraints.\\n\\nBecause competences for cybersecurity strictly speaking still lie with \\nMember States, the study of the EU’s cybersecurity policy must recognize \\nthe EU as a multi-level governance actor in a policy structure subject to \\nboth intrainstitutional and intergovernmental forces.12 Following an insti-\\ntutionalist method of analysis, institutions do matter, and the Commission \\nstrategies and cases by the European Court of Justice are critical junctures \\nin the development of the EU’s cybersecurity policy.13\\n\\n\\nThis study takes a particular interest in regulatory policies. In political \\nscience terms, regulatory policies can be distinguished from distributive \\nand redistributive policies.14 Both distributive and redistributive policies \\nare limited by the budgetary cap of 1.27% of Union GDP.15 The EU has \\nthus famously been characterized as a “regulatory state.”16 In addition, in \\nthe  EU’s  cybersecurity  policy,  regulatory  policies  are  predominant. \\nConsequently, this study characterizes the EU’s approach to cybersecurity \\nas “regulatory.” The legal analysis allows us to assess regulatory instru-\\nments on their merit, i.e. the extent to which they provide supranational \\nharmonization and build toward an actual EU-wide policy. It has further \\nbeen instrumental to the constitutional analysis and the interpretation of \\nlegal  cases.17  In  legal  terms,  “regulation”  is  taken  to  refer  not  only  to \\n\\n legislation following Article 288 of the TFEU but also to the adoption of \\nsoft law, guidelines, and standards, with or without the involvement of EU \\nagencies.  In  response  to  the  problem  statement,  this  study  answers  the \\nfollowing  questions:  (1)  what  comprises  the  EU’s  current  cybersecurity \\npolicy;  (2)  how  the  EU’s  cybersecurity  policy  has  come  into  being; \\n(3) what strategy the EU pursues with this policy in the context of interna-\\ntional cyber governance; and (4) how the EU’s regulatory approach to the \\nstrongly interrelated digital policy issue of data protection was created.\\n\\nIn  this  chapter,  we  introduce  the  role  of  resilience  in  the  EU’s \\napproach to cybersecurity and discuss the EU’s norm-pushing role on data \\nprotection. Then we pursue an orderly analysis of the EU’s approach to \\ncybersecurity in full, which is categorized by the policy domains of the \\ninternal  market;  the Area  of  Freedom,  Security  and  Justice  (AFSJ);  the \\nCommon Security and Defence Policy (CSDP); and the Common Foreign \\nand Security Policy (CFSP).\\n\\n2.2.   The EU’s Cybersecurity Policy\\n\\nThe EU has been primarily driven by an internal market rationale in the \\ncreation of its cybersecurity policy, which entails that the EU deploy its \\ncompetence  for  the  regulation  of  the  internal  market  to  issue  common \\n(regulatory) policy on cybersecurity. This choice of competence is partly \\npragmatic. Internal market regulation has been at the core of the European \\nproject since its inception, and the corresponding Treaty basis, Article 114 \\nTFEU, is still the most versatile and widely used legal basis. However, the \\nchoice has also been engrained in European policymaking by the argumen-\\ntation which introduced digital policy as a whole within the EU’s mandate. \\nThis argumentation can be traced back to the completion of the internal \\nmarket in 1985.18 The economic opportunities of the emerging global mar-\\nket for digital services and goods led the Commission to identify informa-\\ntion  and  communications  technology  (ICT)  and  the  digital  domain  as  a \\npotential  area  of  Union  action.19  In  the  decades  that  followed,  the  eco-\\nnomic opportunities of the digital market continued to serve as the impetus \\nfor the EU’s digital policymaking and prevailed when it became apparent \\n\\n\\nthat digitalization brought risks as well as benefits.20 These risks are inter-\\npreted in an economic rather than a security discourse: cyberthreats under-\\nmine citizens’ trust in online services and negatively impact the economy.21 \\nIn turn, the EU is legitimized to take measures to improve cybersecurity to \\nprotect  the  internal  market.  This  idea  is  the  core  of  the  internal  market \\nrationale. Three decades and some later, the internal market rationale still \\nfunctions as the primary rationale in the EU’s approach to cybersecurity \\nand determines the legislative, political, and industrial agenda on cyberse-\\ncurity. The internal market rationale is characteristic for the EU’s cyberse-\\ncurity  policy  and  clearly  distinguishes  the  EU  from  other  actors  on  the \\nglobal  stage,  which  generally  take  a  much  more  security-  and  defence-\\noriented approach to cybersecurity.\\n\\nThe EU’s cybersecurity policy is delineated by the foundational Treaties, \\nwhich define and restrict the EU’s competences. When compared to regional \\nand  international  organizations  in  global  cyber  governance  with  narrow, \\nclearly  formulated  mandates  specifically  devoted  to  cybersecurity,22  the \\nEU’s  mandate  for  cybersecurity  is  muddled. The  foundational Treaties  do \\nnot provide a specific, unifying legal basis for the EU to issue legislation on \\ncybersecurity,  which  consequently  remains  a  legal  competence  of  the \\nMember States.23 The EU’s role is therefore primarily coordinative. In this \\nrole,  the  EU  aims  to  create  coherence  in  Member  States’  approaches  and \\nregulate the policy domains affected by cyberthreats in which the Treaties do \\nconfer powers upon the EU. These domains include (1) the internal market; \\n(2) AFSJ;  (3)  CSDP;  and  (4)  CFSP.24  The  EU  has  broad  competences  to \\nregulate the single market.25 In contrast, the EU’s competences in the AFSJ \\n\\nare mainly restricted to matters of law enforcement.26 Moreover, although \\nthe EU’s moderate mandate to formulate cyber defence projects within the \\nCSDP has recently gained somewhat of a political momentum, the CFSP and \\nCSDP are still mostly nationally governed.27 Interestingly, cybersecurity as a \\nnew policy field has proven able to yield relatively broad political support \\nfor common action. Cybersecurity has functioned as a tool for the EU legis-\\nlator to expand the range of Union action in domains outside of the internal \\nmarket, particularly stretching the Treaty provisions for security and foreign \\npolicy  goals.  The  constitutional  restrictions  to  the  EU’s  cybersecurity \\napproach have hence also triggered a deepening of European integration.\\n\\n2.2.1.   The EU’s cybersecurity strategy\\n\\nThe EU’s cybersecurity policy has only been been provided with an over-\\narching strategy in 2013, with the adoption of the Cyber Security Strategy \\n(CSS).28 The CSS not only reflects the internal market rationale but also \\nattests  to  a  spillover  of  cybersecurity  policy  into  domains  other  than  the \\ninternal  market.  The  policy  priorities  set  out  in  2013,  confirmed  by  the \\n2017  review  and  renewal  of  the  CSS,29  entail:  (1)  achieving  cyber  resil-\\nience; (2) reducing cybercrime; (3) developing cyber defence policy and \\ncapabilities related to the CSDP; (4) developing industrial and technologi-\\ncal resources necessary for cybersecurity; and (5) establishing a coherent \\ncyberspace policy.\\n\\nAt the core of the EU’s cybersecurity strategy lies the pursuit of cyber \\nresilience. Resilience is a common thread through all domains of the EU’s \\ncybersecurity policy as well the 2016 Global Strategy.30 The concept, there-\\nfore, deserves special attention. In foreign policy and defence, resilience is \\na  means  of  deterring  potential  attacks.  Deterrence-by-resilience  is  an \\napproach within deterrence-by-denial, and can as such be contrasted with \\n\\ndeterrence-by-retaliation.  Deterrence-by-retaliation  entails  ensuring  that \\nany attack will be met with offensive countermeasures so intolerable that \\nthey will deter future attacks by the same or other attackers.31 Deterrence-\\nby-denial, in contrast, focuses on defensive rather than offensive means, on \\nprotecting rather than avenging. Resilience can be defined as the ability to \\n“resist  and  regenerate”  or  “quickly  restore  the  original  shape  after  an \\nattack.”32 Deterrence-by-resilience in cyberspace thus entails ensuring that \\nICT infrastructures have high levels of in-built  security measures and are \\nable to recover quickly from attacks. ICT infrastructures of public authori-\\nties, providers of essential services, and operators of critical infrastructures \\ndeserve special attention in this regard. However, to the EU, the resilience \\nof  the  private  sector  is  primordial,  as  decreasing  the  potential  financial \\ngains of cyberattacks logically decreases their economic risks. To the EU, \\nresilience implies “security begins internally.”33 In the EU’s cybersecurity \\npolicy, the core strategy is to achieve “resilience through regulation.”34 The \\nregulatory agenda essentially aims to increase the standards for the security \\nof  the  EU’s  ICT  structures  and  their  capacity  to  recover  from  cyberat-\\ntacks.35  The  regulatory  agenda  is  complemented,  first,  by  an  industrial \\nagenda  that  aims  to  improve  the  competitiveness  of  the  EU’s  ICT  and \\ncybersecurity  sectors  and  decrease  the  dependence  on  non-EU  suppliers, \\nwhich is of strategic importance because dependence is a security risk, and \\nsecond, with foreign policy efforts aimed at trust-building, creating global \\ninterdependence, and advocating common norms.36\\n\\nThe  CSS  is  being  implemented  in  a  piecemeal  fashion.  Two  recent \\nmajor  policy  projects  have  been  instrumental  to  this  implementation. \\n\\nFirst, in 2014, the Juncker Commission announced that a Digital Single \\nMarket  (DSM)  strategy  would  be  at  the  top  of  its  political  agenda.37 \\nCybersecurity forms an integral part of the DSM as an essential tool for \\naverting  economic  damage  to  and  conserving  consumer  trust  in  the \\nEuropean markets. Second, in 2015, the Commission employed the con-\\nstitutional bases of the AFSJ for the construction of the so-called Security \\nUnion.38 Where the Security Union serves to protect the European market, \\ncybersecurity — an integral part of the Security Union — serves to protect \\nthe European digital market. The key elements of the EU’s cybersecurity \\napproach today stem from either one of these two projects, notwithstand-\\ning  frequent  mutual  overlaps  which  illustrate  the  cross-sectional  nature \\nof  cybersecurity  as  a  policy  field.  In  sum,  however,  regulatory  and \\n policy  developments  stretch  across  policy  domains  at  varying  speeds. \\nHarmonization has been achieved in some fields, such as the protection of \\ninformation  systems  and  certification,  and  has  lagged  behind  in  others, \\nsuch  as  substantive  and  procedural  criminal  law.  Investments  in  digital \\ninfrastructure  and  technology  have  steadily  increased  but  are  as  of  yet \\ninsufficient to compensate for the deficient competitiveness of the EU’s \\nICT market. As a consequence, the institutional and policy cohesion of the \\nEU’s approach to cybersecurity is subject to criticism.39\\n\\nCybersecurity  efforts  in  all  domains  are  eventually  accessory  or \\n complementary to the internal market and serve to protect the resilience \\nof the internal market rather than the EU’s territory as such. The most con-\\ncrete legislative and political efforts follow the internal market rationale: \\nthe  Union  is  legitimized  to  formulate  a  common  policy  and  promote \\n\\n \\n \\n\\x0charmonized  standards  on  cybersecurity  because  the  regulation  of  the \\ninternal market requires it.\\n\\nEU’s Cybersecurity Policy  33\\n\\n2.2.2.   Data protection regulation\\n\\nThe European Court of Justice (ECJ, the Court) oversees the application \\nof the Treaties in line with the law.40 The Court is therefore essential to the \\neffectiveness  and  resilience  of  the  EU  as  a  regulatory  power.  It  has  not \\nissued  any  rulings  on  cybersecurity  specifically,  which  is  not  surprising \\ngiven the novelty of the most substantial regulatory instruments on cyber-\\nsecurity.41 Nevertheless, its case law on data protection set a clear prece-\\ndent. Data protection and cybersecurity are closely interrelated. In cases \\non  data  protection,  the  Court  confirmed  internal  market  regulation  as  a \\nlegal  basis  for  regulating  cyberspace,  introduced  data  security  into  the \\nEU’s  regulatory  framework,  entrenched  the  fundamental  right  to  data \\nprotection,  and  reinforced  the  extraterritorial  scope  of  the  EU’s  data \\n protection law.\\n\\nThe  Court  in  the  Digital  Rights  Ireland  case  assessed  the  Data \\nRetention Directive by the fundamental rights to private life and privacy.42 \\nIt  set  strict  minimum  standards  for  data  security  and  went  so  far  as  to \\ninvalidate the Data Retention Directive because the general obligation to \\nretain  traffic  data  and  location  data  did  not  meet  those  standards.43 \\nNotably, the Court focused on the Directive’s secondary objective: that of \\nsecurity.44 This focus suggests that the suitability of Article 114 as a legal \\nbasis for data protection legislation can be questioned,45 but not as such \\n\\n\\nby the Court.46 The decision made explicit that the EU legal community \\nprovides a high level of security in cyberspace, even if the constitutional \\nbasis  to  do  so  stems  from  the  internal  market,  thereby  emphasizing  the \\ninterrelation  of  internal  market  regulation  and  security.  Although  data \\nsecurity refers specifically to the security measures needed to protect per-\\nsonal data from cyberthreats, the introduction of security requirements on \\nall data processors — i.e. public as well as private actors — set a clear \\nprecedent on the EU’s forward regulatory policy on digital issues. In the \\nTele2 and Watson case, the Court assessed the general obligation for pro-\\nviders  of  electronic  communications  services  to  retain  data.  The  Court \\nconfirmed that the standards it set out in Digital Rights Ireland are manda-\\ntory and that it is indeed competent to review not only the retention, but \\nalso the access to data.47 The requirements have since been codified in the \\nGeneral Data Protection Regulation (GDPR).48\\n\\nIn  the  Google  Spain  case,  then,  the  Court  famously  established  the \\n“right to be forgotten.”49 This case buttressed the prevalence of the funda-\\nmental right to data protection in the EU, which in the Google Spain case \\nwas  weighed  against  the  right  to  information  and  Google’s  economic \\ninterests.50 The Google Spain case confirms that the EU takes the perspec-\\ntive of the data subject, i.e. the customer or individual, rather than that of \\nthe  data  processor,  i.e.  businesses  or  governments.  This  rights-oriented \\nperspective is diametrically opposite to the market-oriented perspective, \\n\\nwhich  is  predominant  in  the  US.51  The  Google  Spain  case  has  helped \\n create  a  strong  fundamental  right  to  data  protection,52  which  may  well \\nobstruct  free  data  flows.  Following  a  recurrent  pattern  in  EU  law,  the \\nCourt’s rights-oriented interpretation has now been codified in Article 16 \\nTFEU,  which  provides  an  express  legal  basis  for  the  EU  to  protect  the \\nfundamental right to data protection.53 Article 16 TFEU, in addition to the \\ninternal  market  rationale  and  the  security  dimension  of  data  protection, \\nfunctioned as the legal basis for the GDPR.54\\n\\nThe  ECJ  case  law  has  also  reinforced  the  extraterritorial  effect  of \\nthe EU’s data protection law. This effect has both two dimensions. By \\nmeans of the so-called Brussels effect, EU data protection law is adopted \\nby businesses outside of the EU’s physical borders because of the eco-\\nnomic incentive to access the internal market. This extrajudicial effect is \\nremarkably strong and credited to the comprehensive nature of the EU’s \\nregulatory frameworks.55 In addition to the Brussels effect, third coun-\\ntries  are  incentivized  to  adopt  EU-level  data  protection  standards  by \\nadequacy  decisions  and  data  protection  standards  in  bilateral  agree-\\nments. Data transfers to a third country are only categorically allowed if \\nan  “adequate  level  of  protection”  is  ensured.  An  adequacy  decision \\nexempts data controllers or processors established in or processing per-\\nsonal  data  belonging  to  data  subjects  in  the  EU  from  referring  to  any \\n\\nspecific authorization for data transfers.56 In the Schrems case, the Court \\nheightened  the  standards  for  adequacy  decisions  by  establishing  that \\nthird countries need a level of protection which is “essentially equiva-\\nlent”  to  that  in  the  EU.57  Again,  these  heightened  standards  are  now \\ncodified  in  the  GDPR.58  In  its  opinion  on  the  bilateral  agreement \\nbetween  the  EU  and  Canada  on  a  Passenger  Name  Record  (PNR),  the \\nCourt  obliged  the  EU  to  renegotiate  the  agreement  because  it  did  not \\nprovide sufficient rights protection for data subjects. The Court thereby \\nreaffirmed that it does not hesitate to impose high data protection stand-\\nards  in  questions  concerning  the  EU’s  external  relations.  In  the  recent \\nGoogle v. CNIL case, the Court ruled on the territorial scope of the right \\nto be forgotten. In line with the Advocate-General,59 the Court does not \\ngo so far as to order the global application of the right to be forgotten.60 \\nTo  do  so  would  have  been  very  bold  indeed.  Nevertheless,  the  Court \\nrefrains  from  addressing  or  acknowledging  the  much-cited  arguments \\nthat a global application of the right to be forgotten would create serious \\nextraterritorial enforcement issues and lead to the global imposition of \\nthe  EU’s  view  on  the  fundamental  right  to  privacy.61  Moreover,  the \\nCourt emphasizes that European law does not exclude the global appli-\\ncation  of  the  right  to  be  forgotten  and  specifically  enables  national \\ncourts to judge per individual case whether the balance between the right \\n\\nto  privacy  and  the  right  to  information  requires  a  global  scope.62  The \\novert extraterritorial application of EU data protection law thus remains \\nan option.\\n\\nThe  ECJ’s  case  law  on  data  protection  demonstrates  how  the  EU’s \\nregulatory power lies in consistently pushing for minimum standards both \\ninternally and externally. Responding to and entrenching this case law, the \\nGDPR is currently the clearest and most comprehensive legislative frame-\\nwork on data protection globally, and the EU a global norm-setting power. \\nThe EU has the ambition to play a similar role in cybersecurity. It thus \\nconsistently pushes for international norms on cybersecurity at the GGE \\nlevel at the United Nations. However, with EU being the largest internal \\nmarket in the world, the core strength of the EU regulatory policy lies with \\nthe externalization of internal market-related standards. The example of \\ndata protection regulation suggests that adhering to high minimum stand-\\nards in a clear and comprehensive regulatory framework compatible with \\nnorms and values enshrined in the Treaties and the Charter might enable \\nthe EU to act as a global norm-builder on cybersecurity as well.63\\n\\n2.3.   Single Market\\n\\nThe internal market rationale and its persistence in the EU’s approach to \\ncybersecurity has led to a situation in which the core of the EU’s cyberse-\\ncurity policy is founded upon the EU’s mandate for internal market regu-\\nlation, i.e. Article 114 TFEU. This mandate is also the source of most of \\nthe vast body of European law to date. As noted by Wessel, the extensive \\ncompetences  of  the  Union  in  the  internal  market  have  provided  several \\n“hooks” to harmonize or approximate legislation relating to cybersecurity \\nwith the aim of smoothening the functioning of the internal market.64 As \\nthe foundational cornerstone of the EU, internal market regulation gener-\\nally  also  enjoys  the  most  widely  shared  political  support.  Moreover, \\nthe  sheer  size  of  EU  as  the  largest  single  market  in  the  world  has  been \\n\\nidentified as a main cause of the external effects of European law.65 The \\nglobal regulatory potential of internal market regulation is thus consider-\\nable. Moreover, internal market regulation is the path to increase the cyber \\nresilience of the EU’s internal — which lies at the heart of the EU’s cyber-\\nsecurity strategy.\\n\\nA central role in the coordination and governance of EU cybersecurity \\nregulation  has  been  reserved  for  the  European  Union  Agency  for \\nCybersecurity  (ENISA).  ENISA  supports  the  EU’s  market-coordinating \\nrole. It was founded in 2005 on temporary mandates, but its position is \\nsignificantly  solidified  in  2019.  Its  mandate  now  includes  providing \\ncybersecurity  certification,  supporting  capacity-building  and  drafting  of \\ncybersecurity  policies,  and  helping  implement  vulnerability  disclosure \\npolicies.66\\n\\n2.3.1.   DSM\\n\\nThe  DSM  was  presented  in  2015  as  a  key  priority  of  the  Juncker \\nCommission’s political agenda.67 A DSM is defined as “one in which the \\nfree  movement  of  goods,  persons,  services  and  capital  is  ensured  and \\nwhere  individuals  and  businesses  can  seamlessly  access  and  exercise \\nonline activities under conditions of fair competition, and a high level of \\nconsumer and personal data protection, irrespective of their nationality or \\nplace of residence.”68 Essentially, the DSM entails achieving the elimina-\\ntion  of  internal  borders  in  the  digital  economy  by  means  of  regulatory \\nconvergence. Despite the cross-border nature of the Internet itself, digital \\neconomic  activity  in  the  EU  is  still  highly  compartmentalized  across \\nnational borders.69 The DSM strategy includes no less than 30 legislative \\n\\n\\ninitiatives,  28  of  which  have  been  concluded.70  Core  initiatives  have \\naddressed the obstacles formed by geoblocking71; online payments72; the \\nportability  of  online  content73;  and  diverging  regulatory  frameworks \\nregarding data protection,74 copyright,75 and electronic communication.76 \\nStrategic investments complement these regulatory efforts.\\n\\nCybersecurity  is  instrumental  to  the  DSM  strategy.  The  more  con-\\nnected  the  European  digital  economy,  the  more  vulnerable  it  is  to \\ncyberthreats — a network is only as strong as its weakest link.77 The EU \\naims  to  increase  the  resilience  of  internal  market  as  a  whole  as  well  as \\nvitalize the single market for cybersecurity products and services. These \\nobjectives are mutually complementary: a reinforced European market for \\ncybersecurity products will help facilitate greater resilience, whilst busi-\\nnesses abiding by higher cybersecurity standards will rely more heavily \\non  the  European  cybersecurity  market.  Resilience  in  the  CSS  refers  to \\n\\n“the  capacities  of  any  technical  or  natural  system  to  regulate  itself.”78 \\nIn  the  DSM,  a  resilient  regulatory  network  entails  creating  minimum \\nstandards for net security, e.g. by means of cybersecurity standards and \\nmandatory cyber hygiene measures for businesses and service operators.79 \\nMoreover, the EU aims to create a “level playing field” necessary for a \\nsingle  market  for  cybersecurity  and  increase  the  competitiveness  of  the \\nEU’s ICT and cybersecurity sectors. It must be stressed in this regard that \\nrelying on non-European suppliers in ICT has not only economic but also \\nimportant security implications.\\n\\n2.3.2.   Regulation\\n\\nThe 2016 NIS Directive,80 based on Article 114 TFEU, was the first piece \\nof horizontal EU legislation on cybersecurity and aims to install a mini-\\nmum level of security with network and information systems to smoothen \\nthe  functioning  of  the  internal  market.81  The  NIS  directive  prescribes \\nsecurity and notification requirements for operators of essential services \\nand digital service providers.82 Adherence to these requirements is to be \\nsupervised  by  the  competent  authorities  in  Member  States.83  While  the \\nsocietal function of essential services is rather obvious, the prescription of \\nsecurity norms and obligations for digital service providers is justified by \\nthe  internal  market  rationale,  i.e.  the  dependence  of  businesses  and,  in \\nextension,  the  functioning  of  the  internal  market  on  digital  services.84 \\n\\nThe Directive is, however, less rigid in its approach to the much broader \\ncategory of digital service providers than in its approach to operators of \\nessential services,85 the identification of which is entrusted to the Member \\nStates.86 This difference can be justified by the societal function of essen-\\ntial services but becomes more nuanced when essential services or public \\nadministration  are  heavily  dependent  upon  digital  services,  in  which \\ncase  the  Directive  suggests  further  contractual  security  obligations.87 \\nIn addition, Member States must develop a national cybersecurity strate-\\ngy.88  The  implementation  deadline  of  the  NIS  Directive  passed  in  May \\n2018. At the time of writing, the NIS Directive has not yet been (fully) \\ntransposed  in  Belgium,  Bulgaria,  Hungary,  and  Luxembourg.89  This  is \\ndespite considerable efforts of the Commission to aid Member States in \\nthe implementation.90\\n\\nA  core  obligation  introduced  by  the  NIS  Directive  which  deserves \\nspecial  attention  is  the  obligation  to  create  national  Computer  Security \\nIncident  Response  Teams  (CSIRTs).91  A  network  of  CSIRTs  is  created \\nat  the  Union  level.92  National  CSIRTs  voluntarily  exchange  informa-\\ntion  on  cyberincidents  which  are  serious  but  fall  below  the  level  of  a \\n\\n\\nnational  crisis.  The  CSIRTs  play  a  central  role  in  the  Commission’s \\nCommunication  on  a  coordinated  EU  response  in  case  of  a  large-scale \\ncybersecurity incident.93 In the accompanying Blueprint, the Commission \\nsets out in detail the cooperation between the EU institutions and mecha-\\nnisms  in  case  of  a  large-scale  cybersecurity  incident.94  At  the  political \\nlevel, the Interinstitutional Policy for Crises Response (IPCR) may now \\nalso  be  activated  for  cyberincidents.  The  IPCR  enables  the  Council \\nPresidency to call roundtable meetings for the Permanent Representatives \\nCommittee (COREPER) or Political and Security Committee (PSC) and \\nbring in relevant stakeholders from Member States, EU institutions, EU \\nagencies,  and  third  parties  such  as  non-EU  countries  and  international \\norganizations.95 These are crisis meetings to identify bottlenecks and pro-\\nduce  proposals  for  action  for  cross-cutting  issues.  The  IPCR  is  also \\nclosely connected to the activation of the solidarity clause.96 At the techni-\\ncal  level,  the  CSIRTS  are  central  and  cooperate  with,  amongst  others, \\nCERT-EU (the Computer Emergency Response Team of the EU institu-\\ntions) and ENISA. In case of a major incident, the CSIRT Network Chair \\npresents  an  EU  Cybersecurity  Incident  Situation  Report  to  the  Council \\nPresidency,  the  Commission,  and  the  CFSP’s  High  Representative \\n(HRVP).97 The CSIRTs are thus instrumental for the situational awareness \\nrequired for further strategic deliberation at the political level. The instru-\\nmental position of the CSIRTs, an internal market-based information shar-\\ning  network,  for  essentially  intergovernmental  security  deliberations  at \\nthe Council is characteristic for the EU’s regulatory cybersecurity policy.\\nThe  Cybersecurity Act  was  adopted  in  2019  and  presents  a  signifi-\\ncant step toward coherence in the EU’s regulatory framework for cyber-\\nsecurity.98  The  Act  renewed  and  expanded  ENISA’s  now-permanent \\n\\n\\nmandate  and  increased  its  budget  and  capacity.99  Most  importantly,  the \\nregulation finally introduced the legal basis to adopt an EU-wide cyberse-\\ncurity certification scheme for ICT products.100 Rather detailed provisions \\non the adoption of such a scheme and provisions that should be included \\nare  provided.101  ENISA  will  play  a  central  role  and  prepare  a  candidate \\ncertification  scheme,  for  which  an  ad  hoc  working  group  is  currently \\nbeing assembled.102 The relevance of an EU-wide certification scheme is \\nimportant. Certification is not legislation but rather to be regarded as har-\\nmonized standard setting of which the legal status is still ambiguous. Such \\nstandard setting is an increasingly important co-regulatory instrument.103 \\nAs is habitual with standard setting, the certification schemes will not be \\nmandatory,  although  the  option  of  mandatory  standards  is  set  out  to  be \\nexplored.104 It has been noted that mandatory standards have much greater \\npotential to be externalized to non-EU markets.105 Indeed, a clear, compre-\\nhensive, bold, and mandatory cybersecurity certification scheme would be \\na core asset of the EU’s norm-pushing power. However, it can be ques-\\ntioned whether the EU has a sufficient legal mandate for adopting manda-\\ntory  standards  for  cybersecurity.  Co-regulation  might  be  the  highest \\nattainable  strategy  and  a  clear,  comprehensive,  and  bold  certification \\nscheme still has significant policy clout. Internally, certification schemes \\ncan  significantly  increase  the  security  of  IT  products  and  services  and \\nallow  customers  to  make  informed  decisions,  boosting  market  trust  and \\ndecreasing costs — disparities in national certification schemes have so \\nfar  led  to  fragmentation  and  higher  costs.106  Externally,  a  voluntary \\nEU-wide certification scheme would still put the EU in a stronger position \\nurity  of  ICT  products.107  Moreover, \\nincreased regulatory convergence on the EU’s ICT market will increase its \\ncompetitiveness.\\n\\nIn  2018,  the  Commission  put  forward  a  proposal  for  a  Regulation  on \\npreventing the dissemination of terrorist content online.108 The Regulation \\nwould establish a responsibility with Internet platforms to take down terror-\\nist content within one hour and establish a positive obligation to detect con-\\ntent  and  prevent  its  reappearance.109 The  EU  Fundamental  Rights Agency \\n(FRA)  expressed  concern  that  the  definition  of  terrorist  content  in  the \\nProposal is broader than the definition in the Framework Decision on terror-\\nism and is at odds with the freedom of expression.110 The Regulation statedly \\naims to “guarantee the smooth functioning of the Digital Single Market,”111 \\nbut was also presented as a legislative priority of the Security Union in the \\n2018 State of the Union speech by Juncker.112 The Regulation thereby illus-\\ntrates  how  cybersecurity  as  a  cross-sectional   policy  concern  has  extended \\nfrom internal market regulation into the  security domain.\\n\\n2.3.3.   Soft law\\n\\nThe  Commission  aims  to  increase  the  coherence  of  Member  States’ \\napproaches  to  cybersecurity  via  Recommendations.  One  example  is  the \\nsector-specific Recommendations on cybersecurity in the energy sector.113 \\nThe  Commission  also  started  to  aim  for  an  EU-wide  approach  to  the \\n\\ncybersecurity of 5G networks. Following its 2016 Action Plan114 and the \\nensuing heated debate in the European Parliament115 and  concern in the \\nEuropean  Council,116  the  Commission  published  a  Recommendation  on \\nthe cybersecurity of 5G networks.117 Although 5G networks will act as the \\nbuilding blocks of much of the Union’s digital infrastructure of the com-\\ning decade, EU ICT businesses are not the strongest competitors on the \\nmarket for 5G technology. The EU has defied US requests for a blanket \\nban on Chinese companies from participating in the auction to establish \\n5G structures, which would stand at odds with its consistent commitment \\nto  a  free  and  open  trade  policy. The  Commission’s  Recommendation  is \\nclear in stating that not only technical but also other factors can influence \\ncybersecurity  risks  of  5G  networks,  amongst  which  “the  overall  risk  of \\ninfluence by a third country, notably in relation to its model of govern-\\nance,  the  absence  of  cooperation  agreements  on  security,  or  similar \\narrangements, such as adequacy decisions, as regards data protection,”118 \\nhinting at the US and China. The Commission aims to assemble a com-\\nmon EU Toolbox to address the cybersecurity risks connected to 5G net-\\nworks before December 31, 2019, based on risk assessments by Member \\nStates  and  ENISA’s  threat  landscape  mapping.119  The  extent  to  which \\nMember  States  succeed  in  developing  a  common  approach  to  the  5G \\nquestion will prove an important test for the strategic autonomy of the EU \\non the global digital stage.120 For the EU to fulfill its norm-setting ambi-\\ntions  in  global  cyberpolicy  issues,  it  would  be  best  if  the  common  EU \\nToolbox is as clear and bold as possible.\\n\\n2.3.4.   Industrial policy\\n\\nStrategic investments under the EU’s industrial policy form an important \\naddition to the EU’s regulatory approach to cybersecurity. This policy sets \\nout to help develop the industrial and technological resources necessary \\n\\nfor  cybersecurity  by  strategically  investing  in  the  competitiveness  of \\nthe  EU’s  digital  and  cybersecurity  industry  and  pooling  training  and \\nexpertise.121 The urgency thereof was recently addressed by ENISA in the \\npolicy paper announcing a policy consultation with the pressing title “EU \\nICT Industrial Policy: Breaking the Cycle of Failure.”122 ENISA empha-\\nsizes the interlinkage of the ICT industry and cybersecurity and notes that \\nthe EU is an “ICT taker rather than an ICT maker,” “sandwiched” between \\nthe US and China.123 The same diagnosis accounts for the European mar-\\nket for cybersecurity products: the EU is a net importer of cybersecurity \\nproducts and largely dependent upon non-European suppliers.124\\n\\nThe digital market and cybersecurity are prominently featured in the \\nDigital Europe and Horizon Europe programs. Both programs have been \\nprovisionally  agreed  upon  as  part  of  the  EU’s  long-term  (2021–2027) \\nMultiannual  Financial  Framework,  which  is  still  being  negotiated.  The \\nfirst ever Digital Europe program will invest in digital capacity and infra-\\nstructure building and lists cybersecurity and trust as one of its five priori-\\nties. About €2 billion is reserved for “boosting cyber defence and the EU’s \\ncybersecurity industry, financing state-of-the-art cybersecurity equipment \\nand infrastructure as well as supporting the development of the necessary \\nskills and knowledge.”125 Horizon Europe is a renewal of Horizon 2020, \\nthe  broader  research  and  innovation  program  within  the  EU  budget. \\nCybersecurity is not listed as such in the Horizon Europe proposal, but the \\nprogram does set out to reinforce technological and industrial capacities \\nunder  the  Global  Challenges  and  Industrial  Competitiveness  pillar,  for \\nwhich €52.7 billion is reserved.126 Recently, the Commission declared that \\n\\n€135 million will be made available under Horizon Europe for cybersecu-\\nrity  projects  by  citizens  and  small-  and  medium-sized  enterprises \\n(SMEs).127\\n\\nThe  Commission  also  proposed  the  establishment  of  a  European \\nCybersecurity  Industrial,  Technology  and  Research  Competence  Centre \\nand a Network of National Coordination Centers to more specifically steer \\nthe efforts to rejuvenate the European cybersecurity sector.128 The Centre \\nwould  implement  the  allocation  of  funding  for  cybersecurity  provided \\nunder  the  Horizon  Europe  and  Digital  Europe  programs  by  taking  into \\naccount the whole cybersecurity value chain. It will focus on the coopera-\\ntion between cybersecurity supply and demand chains, civilian and mili-\\ntary efforts, Member States and research and industrial communities, and \\nstrive for the deployment of the latest cybersecurity technology.129\\n\\nThe lacking human capital of the EU’s ICT market is a key concern \\nto  the  EU’s  competitiveness  in  cybersecurity  markets.  A  substantial \\nincrease in human development is desired and could be facilitated by har-\\nmonized training and curricula, but the EU’s lack of competences in the \\nfield of education makes this challenging.130 A tentative first step has been \\nmade  within  the  European  Cybersecurity  Industrial,  Technology  and \\nResearch Competence Centre, which sets out to support education policy-\\nmakers  to  create  the  expertise  necessary  for  a  European  cybersecurity \\nmarket.131 Moreover, based on CSDP provisions, a European Security and \\nDefence College brings together, on a voluntary basis, Member States and \\nacademic  expertise  to  train  CSDP  employees  on,  amongst  other  areas, \\ncybersecurity.132\\n\\n\\n2.4.   AFSJ\\n\\nCybercrime is an economic risk to the EU.133 Cybersecurity is a measure \\nto avert this risk and increase the trust of investors and consumers in the \\ninternal  market.134  This  economic  perspective,  which  follows  from  the \\ninternal  market  rationale,  is  characteristic  of  the  EU’s  prioritization  of \\ncybercrime as a threat to be addressed by cybersecurity. Drastically reduc-\\ning cybercrime is the second policy aim in the CSS and has been an objec-\\ntive since 2005.135 The effective EU-wide investigation and prosecution of \\ncybercrime is primordial to the concept of resilience. However, this aim is \\nambitious for the EU as a supranational organization with limited compe-\\ntences for criminal law in a scattered landscape of national jurisdictions.\\n\\nThe EU’s competences for cybercrime fall within the AFSJ.136 Most, \\nbut  not  all137  Member  States  have  joined  the AFSJ,  and  it  provides  no \\n\\n\\nbasis for the harmonization of criminal law, merely for the approximation \\nof national law by prescribing minimum rules on certain areas of serious \\ncrime, including cybercrime.138 Consequently, the center of gravity in the \\nAFSJ  lies  with  judicial  and  law  enforcement  cooperation.139  The  estab-\\nlishment  of  Europol  and  EC3,  Eurojust,  OLAF  and,  since  recently,140 \\nEPPO have helped facilitate this cooperation. Europol, in particular, has \\nmatured into an important point of coordination for law enforcement in \\nthe EU and has functioned as the platform for several cooperative initia-\\ntives  on  cybercrime.141  Recent  legislative  proposals  expand  upon  the \\nlegal basis for judicial and law enforcement cooperation by harmonizing \\nmatters of procedural criminal law.\\n\\n2.4.1.   The Security Union\\n\\nThe Security Union is a policy agenda which fortified the security nar-\\nrative in the EU. Alongside the reinforced economic imperative to com-\\nbat cybercrime presented by the DSM strategy, the Security Union has \\nboosted regulatory developments on cybersecurity within the AFSJ. The \\nJuncker  Commission,  in  2015,  first  presented  a  European  Agenda  on \\nSecurity  (EAS),  which  frames  cross-border  threats,  primary  amongst \\nwhich is cybercrime, as a European task that must be responded to by \\nthe deepening of European cooperation.142 In 2016, the Commission fol-\\nlowed up on the EAS by announcing the creation of “an effective and \\ngenuine” Security Union on the legal basis of the AFSJ.143 The Security \\nUnion  illustrates  the  political  momentum  for  European  security  coop-\\neration after the terror attacks in Brussels, Madrid, London, Copenhagen, \\nand Paris. The Security Union advanced the implementation of the EAS \\n\\n\\nand drew particular attention to its cohesion, identifying and addressing \\nimplementation gaps.144 Speedy and significant process has been made \\non the Security Union agenda so far, primary amongst which has been \\nthe appointment of a European Commissioner for Security specifically \\ntasked  with  the  implementation  of  the  EAS.  The  Security  Union  thus \\ndemonstrates how cybersecurity policy has recently spilled over into the \\nsecurity  domain  and  has  been  an  important  driver  of  European \\nintegration.\\n\\nThe  Security  Union  explicitly  interweaves  domestic  and  foreign \\npolicies and the internal and external dimensions of security.145 This fits \\nthe  distinctly  hybrid  nature  of  the  threats  addressed  by  the  Security \\nUnion agenda (alongside cybercrime, also counter-terrorism and organ-\\nized  crime)  (see  COM  (2015)  185,  https://www.cepol.europa.eu/sites/\\ndefault/files/european-agenda-security.pdf). By significantly expanding \\nthe  external  dimension  of  security  in  the AFSJ,  the  EU  is  effectively \\nequating  the  term  “Security”  in  “Security  and  Defence”  with  that  in \\n“Freedom,  Security  and  Justice,”  thereby  circumventing  the  constitu-\\ntional obstacles to moving forward on the CSDP. The AFSJ was trans-\\nformed  from  an  isolated  domestic  policy  area  on  justice  and  home \\naffairs  to  the  legal  basis  for  a  European  narrative  on  security  in  the \\ncomprehensive sense of the word.146 The Security Union as a political \\nagenda thereby also signals the growing approval of European coopera-\\ntion on security issues.147\\n\\n2.4.2.   Regulation\\n\\nThe  Council  of  Europe  Convention  on  Cybercrime  (also  termed \\nBudapest Convention) is the main point of reference for the EU’s efforts \\ntoward  combating  cybercrime.  The  Convention  continues  to  serve  as \\nthe  primary  source  of  norms  the  Commission  promotes  internally  and \\nexternally.148\\n\\nThe Treaty provision to prescribe minimum rules has been employed \\na number of times for cybersecurity offenses. In principle, the Treaty only \\nallows for the adoption of Directives, which prescribe minimum rules and \\nrequire subsequent adoption into national law.149 The concern of dispari-\\nties  between  Member  States  and  delayed  implementation  is  therefore \\ninevitable, and further harmonization is desired.150 First, a Directive on the \\nsexual exploitation of children online has been in place for some time.151 \\nSecond,  the  2013  Directive  on  Attacks  against  Information  Systems152 \\nexplicitly builds on and largely reproduces the norms and definitions in the \\nBudapest Convention153 and criminalizes a sparse number of basic cyber \\noffences154 and minimum penalties.155 More advanced cybercrimes such as \\nidentity  theft  and,  interestingly,  attacks  against  information  systems,  are \\nexcluded. The  Directive  enables  sanctions  against  natural  and  legal  per-\\nsons.156 The EU has, with the Directive, effectively bypassed the hesitance \\nof  some  Member  States  to  ratify  the  Convention.157  Third,  the  2014 \\n\\nDirective on European Investigative Orders (EIO Directive)158  regulates \\nthe legislative and technical obstacles to effective investigations to some \\nextent but does not eliminate all problems.159 For example, a provision on \\ne-evidence is lacking.\\n\\nIn April 2018, the Commission therefore put forward a proposal for \\nan  “e-evidence”  Regulation.160  Interestingly,  the  Council  had  urged  the \\nCommission to do so — a novelty in the field of criminal justice, signal-\\nling  increasing  willingness  on  the  part  of  Member  States  to  give  in  on \\nsovereignty  concerns  in  the  face  of  cyberthreats.  Another  novelty  is \\nthe  choice  for  a  Regulation,  which  is  a  more  tangible  legal  instrument \\nthan  a  Directive.161  In  addition  to  the  aforementioned  Regulation,  the \\nCommission is pushing for EU participation in the multilateral negotia-\\ntions on a Protocol on e-evidence to the Budapest Convention as well as \\npreparing for the formal launch of a bilateral EU–US agreement on cross-\\nborder access to electronic evidence under the auspices of the Council of \\nEurope  Convention  on  Cybercrime.162  Finally,  legislative  progress  has \\nbeen made on criminal provisions on fraud and forgery in cashless media. \\nThe  Commission  in  2017  proposed  a  Directive  which  would  establish \\nminimum rules on the fraudulent use of ((non-)corporeal) non-cash pay-\\nment  instruments,  which  includes  virtual  currencies  such  as  bitcoin.163 \\n \\n\\x0cThe Directive would also improve the exchange of information and coop-\\neration between criminal justice authorities.164\\n\\nEU’s Cybersecurity Policy  53\\n\\n2.4.3.   Law enforcement cooperation\\n\\nCooperation  between  national  law  enforcement  authorities  is  currently \\nthe most effective answer to tackling cross-border cybercrime in a bor-\\nderless digital market. The effective EU-wide investigation and prosecu-\\ntion  of  cybercrime  builds  is  instrumental  to  cyber  resilience  because  it \\nprovides the strategic insight necessary to design in-built security meas-\\nures and recover quickly from attacks. Moreover, it is vital to the thorny \\nquestion of attributing serious cyberattacks.165 Europol, since 2013, com-\\nposes of a Cybercrime Centre (EC3) specifically dedicated to the inves-\\ntigation of cyber offences. EC3 aims to be the focal point for the criminal \\ninvestigation of cyber offences in the EU. However, the secondary role \\nof  EC3  in  the  IPCR,  which  was  introduced  in  Section  2.3.2,  calls  the \\nsuccess of this ambition into question. EC3 faces challenges in the legis-\\nlative and institutional conditions under which it operates. First, it has to \\nalign its operations with other institutional cybersecurity actors such as \\nEurojust  and  ENISA.166  Second,  and  more  importantly,  several  legisla-\\ntive and technical obstacles formed by the patchwork of national juris-\\ndictions continue to obstruct digital forensic opportunities. EC3 highlights \\nthe fact that investigative leads are lost because joint investigations lack \\ntimely  access  to  communication  data  and  other  e-evidence,  despite  the \\nEIO  Directive.167  Within  EC3,  however,  the  Member-States–led  Joint \\nCybercrime Action  Taskforce  (J-CAT)  has  been  praised  for  effectively \\nenabling joint cross-jurisdictional investigations under flexible adminis-\\ntrative conditions.168\\n\\n\\n2.5.   CFSP\\n\\nThe CFSP includes all matters of foreign policy except for trade, which \\nfalls  under  the  Common  Commercial  Policy.169  The  European  Council, \\nacting unanimously, is the primary actor in the CFSP. In tandem with the \\nCouncil, it identifies strategic interests, assembles common policies, and \\ntakes concrete decisions.170 The option to adopt legislation based on the \\nCFSP  is  legally  excluded,  making  Council  decisions  the  Union’s  most \\ntangible  instrument  on  foreign  affairs.171  However,  foreign  policy  con-\\ncerns  have  increasingly  permeated  other  domains  of  Union  legislation, \\nwhich has led to the adoption of legislative proposals which are in effect \\ninstrumental toward the CFSP. The implementation of the CFSP is over-\\nseen  by  the  HRVP  and  in  practice  realized  by  the  European  External \\nAction  Service  (EEAS),  which  includes  139  European  delegations  in \\nthird states.172  \\n\\nFollowing its declared commitment to multilateralism,173 the EU has \\nconsistently  participated  in  UNGGE  (United  Nations  Group  of \\nGovernmental  Experts)  on  Advancing  responsible  State  behaviour  in \\ncyberspace in the context of international security talks, pushing forward \\nthe standards adopted under the Budapest Convention.174 Since UNGGE \\nnegotiations  were  halted  without  results  in  2017,  some  signal  a  move \\ntoward “coalitions of the willing,” i.e. the acceptance of a more scattered \\napproach in which willing international partners enhance cyber coopera-\\ntion.175  Nevertheless,  several  Member  States  remain  heavily  invested  in \\n\\n\\nUNGGE  talks,  providing  a  counterweight  against  the  “Open-Ended \\nWorking Group” initiated by Russia.176 Like global counterparts, the EU \\nhas  also  maintained   bilateral  cyber  dialogues  with  countries  such  as  the \\nUS, Canada, China, Japan, and South Korea.\\n\\n2.5.1.   Cyber Diplomacy Toolbox\\n\\nThe EU’s approach to cybersecurity under the CFSP has, in 2017, been \\nstreamlined  by  the  adoption  of  the  Cyber  Diplomacy  Toolbox.177  The \\nToolbox  has  the  potential  to  function  as  a  model  for  diplomatic \\nresponses to cybersecurity issues. The EU distinguishes four categories \\nof  responses:  preventative,  cooperative,  stabilizing,  and  restrictive. \\nThese responses are complementary to the lawful responses for Member \\nStates’ self-defence based on national constitutions and the NATO legal \\nframework.\\n\\nPart of the Cyber Diplomacy Toolbox is the Council Regulation on a \\nsanctions regime adopted in May 2019, which prescribes the freezing of \\nfunds  and  economic  resources  of  any  natural  or  legal  person,  entity,  or \\nbody responsible for (attempted) cyberattacks with a (potentially) signifi-\\ncant effect.178 The sanctions regime also codifies the principle of due dili-\\ngence, by making explicit the Member State’s positive obligation to take \\nthe necessary measures to prevent the passing of natural persons involved \\nin cyberattacks through their territories.179\\n\\n2.5.2.   Disinformation\\n\\nDisinformation  has  become  a  key  concern  within  the  CFSP  after  the \\nEuropean  Council  in  2015  asked  the  HRVP  for  a  common  approach. \\nIn  the  run-up  to  the  European  Parliament  elections  of  May  2019,  sev-\\neral  initiatives  were  set  up.  The  HRVP  led  an  Action  Plan  against \\nDisinformation.180 The Code of Practice against Disinformation is a joint \\ncommitment  of  the  Commission,  online  platforms,  and  other  signato-\\nries.181  The  Rapid  Alert  System,  which  was  set  up  to  coordinate  the \\nresponses to disinformation in the EU election campaigns, will be evalu-\\nated  in  Autumn  2019.  A  European  Cooperation  Network  on  Elections, \\nwith participation by the relevant national authorities, will contribute to \\nthis  evaluation.  The  establishment  of  a  cooperative  EU  Internet  Forum \\naims to further complement the cooperation between Member States and \\nonline platforms by enabling dialogue between Home Affairs ministers, \\nthe Internet industry, and other stakeholders.\\n\\n2.5.3.   Dual-use policy\\n\\nOther  than  for  the  CFSP,  the  EU  has  an  exclusive  competence  for  a \\nCommon Commercial Policy (CCP). The CCP is thus an opportune area \\nof  common  action  with  the  potential  to  complement  efforts  under  the \\nCFSP. The comprehensiveness of the EU’s approach to cybersecurity has \\nhence  been  enhanced  by  introducing  cybersecurity  considerations  in \\ntrade. The recently adopted Foreign Direct Investment (FDI) Regulation \\nprovides a first step toward EU cooperation on investment screening.182 It \\nallows the Commission to issue opinions on the security or public order \\nimplications  of  certain  investments  and  promotes  coordination  on  FDI \\nbetween Member States.183 Cybersecurity is one of the factors suggested \\nto  help  determine  whether  FDI  is  likely  to  affect  security  or  the  public \\n\\norder.184  In  addition,  increased  awareness  of  the  strategic  importance  of \\ndual-use  goods  to  cyberthreats  has  led  the  Commission  to  update  the \\nRegulation on expert controls for dual-use goods in 2018.185\\n\\n2.6.   CSDP\\n\\nThe CSDP is a subcategory of the CFSP. CSDP initiatives have to navi-\\ngate  several  constitutional  limitations  and  political  reluctance  due  to \\nnational sovereignty concerns. The Treaties only provide for the “progres-\\nsive  framing”  of  a  CSDP  which  “might  lead”  to  a  common  defence.186 \\nConsequently,  the  EU’s  abilities  in  the  defence  domain  have  so  far \\nremained limited to “exhorting, facilitating, and incentivizing.”187 There \\nare  no  standing  European  military  forces  or  headquarters,  and  NATO \\nremains the main focal point for European defence cooperation.188 A full-\\nfledged political Defence Union can only be established unanimously by \\nthe European Council.189 This decision has not been taken, although it has \\nnotably  been  called  for  by  the  European  Parliament  in  2016.190  The \\nEuropean Defence Agency (EDA) merely plays a coordinating role.191 In \\nextension, cyber defence is not the primary component of cybersecurity to \\nmost Member States or the EU.\\n\\nNevertheless, the development of a cyber defence policy and capabili-\\nties  related  to  the  CSDP  is  one  of  the  strategic  aims  in  the  CSS.  The \\nCommission  has  partly  circumvented  the  constitutional  limitations  of \\nthe CSDP by progressing the Security Union based on AFSJ provisions \\nand  proposing  the  European  Defence  Fund  based  on  internal  market-\\nrelated provisions. The support for the Defence Union has, in recent years, \\ncaused  an  increase  in  initiatives  in  the  cyber  defence  domain.  In  turn, \\ncybersecurity has been one of the drivers of the current political momen-\\ntum for security and defence integration in the EU.192 At their core, how-\\never,  cyber  defence  initiatives  are  mostly  focused  on  the  industrial \\ndevelopment of the European defence market.\\n\\n2.6.1.   Solidarity clause\\n\\nOne key development for cyber defence has been the renewed interpreta-\\ntion  of  the  EU  “solidarity  clause”  (Article  222  TFEU).  The  solidarity \\nclause  legitimizes  a  joint  EU  response  based  on  classical  justice  and \\nHome  Affairs  policies  in  case  of  severe  cyberattacks.  The  solidarity \\nclause legitimizes action by both the Union and Member States. The latter \\nmeans,  following  the  adoption  of  rules  and  procedures  to  enable  the \\noperation of the solidarity clause, “any situation which may have a severe \\nimpact on people, the environment or property.”193 The solidarity clause \\nis  therefore  different  than  the  “Mutual  Defence  Clause”  (Article  42(7) \\nTEU). The latter strongly resembles and is complementary to Article 5 of \\nthe NATO Treaty, which legitimizes military action on behalf of all sig-\\nnatories  in  the  case  of  an  armed  attack  against  just  one.  The  Mutual \\nDefence Clause and Article 5 of the NATO Treaty refer only to national \\nmilitary action in the case of physical, armed attacks. The suitability of \\nthe  solidarity  clause  for  cyberincidents  pleads  for  the  relevance  of  EU \\ndefence  cooperation  alongside  NATO.  Following  the  Commission’s \\nBlueprint,  activation  of  the  solidarity  clause  in  case  of  a  large-scale \\ncybersecurity incident is linked to IPCR, which in turn is based upon the \\nCSIRTs network.194\\n\\n2.6.2.   Common defence cooperation\\n\\nA  common  cyber  defence  policy  has,  in  recent  years,  been  called  for \\nby  the  European  Council,195  EU  military  staff,  EDA,  HRVP,196  the \\nEuropean  Parliament197  and  jointly  by  the  EU  and  NATO.198  In  2014, \\nthe European Council agreed on a Cyber Defence Policy Framework,199 \\nwhich  was  updated  in  2018.200  The  framework  prioritizes  capacity-\\nbuilding.  It  focuses  on  building  cyber  defence  capacities  in  Member \\nStates and providing steering principles for cooperation with the private \\nsector,  as  well  as  enhancing  the  protection  of  CSDP  communication \\nnetworks.201 Within the EDA, a plethora of smaller projects have been \\nset  up  to  improve  cyber  defence,  including  a  Collaboration  Database \\n(CoDaBa) and a Capability Development Plan (CDP).202 Following the \\n2016  Joint  Framework  on  countering  hybrid  threats,203  several  sce-\\nnario-based  policy  discussions  have  taken  place  under  the  Finnish \\nCouncil Presidency.\\n\\n\\nPESCO  is  a  remarkable  development205  and  seen  by  some  as  the  most \\nopportune pathway to promote EU defence integration.206 Within PESCO, \\nMember States can initiate joint defence cooperation projects, which may \\nthen  voluntarily  be  joined  by  interested  Member  States.207  There  are \\n currently  34  PESCO  projects,  out  of  which  12  have  specifically  been \\ndedicated  to  cyber  defence. At  the  same  time,  NATO  remains  the  main \\nfocal  point  for  European  cyber  defence  cooperation  in  Europe.208 \\nCooperation between the EU and NATO has intensified, by introducing a \\nCyber Defence Pledge209 and resulting in joint projects on early-warning \\ncapabilities  for  headquarters  and  a  Multi-Agent  System  for  Advanced \\nPersistent Threat detection (MASFAD).210\\n\\n2.6.3.   Common defence investment\\n\\nThe  Commission  in  2017  proposed  a  European  Defence  Fund. \\nInterestingly,  the  legal  basis  for  the  EDF  were  the  Treaty  articles  for \\nindustry and development, illustrating the close interrelationship of cyber \\ndefence and the internal market — a conclusion which is underlined by \\nthe  fact  that  the  proposal  was  marked  a  “text  with  EEA  relevance.”211 \\nUnder the EDF, the Commission intends to allocate annual budget to joint \\nresearch in defence technologies, as well as enable the joint procurement \\n\\n\\nof  military  materials,  of  which  the  Commission  estimates  that  it  would \\nsave around €100 billion per year.212 Under the 2021–2027 Multiannual \\nFinancial Framework, the EDF is set out to amount to €500 million per \\nyear.213 Within this budget, which is still being negotiated, the most recent \\nCommission proposals include a €182 million investment in cyber situa-\\ntional awareness and a €27 million investment in AI, virtual reality, and \\ncyber technologies.214 In addition, EDA has started cooperating with the \\nEuropean Investment Bank.215 The EDF and other initiatives to stimulate \\ninvestment  in  defence  measures  present  a  much-needed  impulse  to \\nthe EU’s cybersecurity defence industry. However, again, these initiatives \\nare economic at heart. Rather than unifying 28 diverging strategic cultures \\ninto a common defence policy, the EU’s strength lies in the regulation and \\nstimulation of the defence industry.\\n\\n2.7.   Conclusion\\n\\nThe creation of the EU’s cybersecurity policy has been driven by an inter-\\nnal market rationale. Cyberthreats were mainly regarded as an economic \\nrisk — EU action was needed to protect the common market. This ration-\\nale  has  driven  the  most  substantial  elements  of  the  EU’s  approach  to \\ncybersecurity  (the  Cybersecurity Act  and  the  NIS  Directive),  which  are \\nforemost instruments of internal market regulation. Despite the lack of an \\nexpress  legal  basis  for  EU  cybersecurity  policy,  it  has  become  a  view \\nwidely shared that “Member States or individual companies cannot cope \\nwith  this  challenge  alone.  There  is  need  for  coordination  and  strategic \\n\\nvision.”216 Surging cyberthreats and the curtailing competitiveness of the \\nEU’s digital economy have indeed increased the urgency of cybersecurity \\nas a policy concern to EU institutions. “If current trends continue unmiti-\\ngated, the EU may end up being entirely dependent on third countries for \\nkey  technologies.  This  would  leave  our  economy,  security  and  society \\nexposed  and  vulnerable  on  an  unprecedented  scale.  […]  Importantly,  it \\ncan also threaten our democracies.”217 Therefore, internal market regula-\\ntion  and  industrial  policies  are  now  complemented  with  increased  law \\nenforcement cooperation on cybercrime (EC3), a proposal for harmonized \\nstandards on  information sharing (e-evidence), tentative steps toward for-\\nmulating a common foreign policy on cyberthreats (the Cyber Diplomacy \\nToolbox),  and  common  defence  projects  (PESCO).  Cybersecurity  has \\nhence helped to deepen European integration in the politically sensitive \\nareas of security and defence.\\n\\nNevertheless, in spite of the increase in the policy domains in which \\ncybersecurity is addressed, the locus of the EU’s approach to cybersecu-\\nrity  remains  with  the  internal  market.  Even  in  the  defence  domain,  the \\nmost impactful innovation is a stimulus for the European defence market \\n(EDF).  The  EU’s  cybersecurity  policy  aims  to  regulate  and  protect  the \\ninternal  market. A  resilient  regulatory  framework  on  cybersecurity  is  a \\ndouble-edged sword. Internally, it serves to protect European citizens with \\nthe high level of fundamental rights protection that the EU prides itself on. \\nIt  is  also  an  imperative  requirement  for  the  European  single  market  to \\nbenefit from the transition to the digital age — as fragmented regulatory \\nframeworks obstruct intra-EU, cross-border economic activity. Externally, \\nregulation helps secure the public and private sectors to achieve the cyber \\nresilience  the  EU  counts  on  to  create  deterrence  against  cyberthreats. \\nMoreover, as demonstrated by the case of data protection, a large share of \\nthe EU’s geostrategic strength lies in its regulatory power and the exter-\\nnalization of its norms and values.\\n\\n\\nRegulatory  frameworks  are  the  EU’s  forte.  It  remains  to  be  seen \\nexactly how the incoming Von der Leyen Commission will follow up on \\ndigital  and  cybersecurity  policy.  The  European  Commission’s  digital \\ndepartment  has  in  any  case  given  clear  directions  in  its  proposal  for  a \\nDigital  Leadership  Package  in  a  leaked  internal  Commission  document \\ndated  July  2019.218  This  Package  with  a  “strong  geostrategic  aspect” \\nwould revamp the EU’s industrial policy and build toward the much-cited, \\nelusive  term  “strategic  autonomy.”219  It  would  fix  investment  priorities \\nsuch  as  European  high-level  computing  capacities  and  processor  tech-\\nnologies, a research and investment roadmap for technologies such as 5G \\nand  6G,  a  blockchain  infrastructure  for  public  services,  as  well  as  a \\nEuropean  Cybersecurity  Shield  based  on  quantum  technologies.  The \\npackage  is  proposed  alongside  an  Action  plan  to  make  the  ICT  sector \\nmore sustainable and an AI regulatory framework, including a single mar-\\nket legal instrument that “should set a world-standard for AI regulation.” \\nMoreover,  the  Digital  Services  Act,  which  is  expected  to  replace  the \\ne-Commerce Directive, could serve as an important regulatory tool for the \\nICT  sector.  The  leaked  documents  as  well  as  the  new  Commissioner’s \\nportfolios  clearly  indicate  that  digital  competitiveness  and  cyber  resil-\\nience will be top priorities in 2019–2024. A bold regulatory strategy on \\ncybersecurity could thus very well turn out to be the success story of the \\n“geopolitical Commission.”\\n\\nAnnex I\\n\\nCybersecurity in the EU: Areas of Responsibility\\n\\nSingle  \\nmarket\\n\\nAFSJ:  \\nArea of Freedom, \\nSecurity and Justice\\n\\nCSDP:  \\nCyber Defence\\n\\nCFSP:  \\nCyber Diplomacy\\n\\nEU\\n\\nENISA \\n\\nCSIRT \\nnetwork \\nCERT-EU\\n\\nEuropol (EC3) \\nEurojust \\nEU-LISA\\n\\nEDA GSA\\nESDC\\n\\nNational Authorities  \\nin charge  \\nof NIS \\nNational \\nCSIRTs\\n\\nExecutive and data- \\n\\nprotection  \\nauthorities\\n\\nDefence, military,  \\nand security  \\nagencies\\n\\nEEAS \\n\\nSIAC (EU \\nINTCEN,  \\nEUMS INT) \\nEU SITROOM \\nEU Hybrid  \\nFusion Cell \\nERCC\\n\\nForeign ministries\\n\\nNotes:  EC3:  European  Cybercrime  Centre;  CSIRT:  Computer  Security  Incident  Response  Team; \\nCERT:  Computer  Emergency  Response Team;  EDA:  European  Defence Agency;  ESDC:  European \\nSecurity  and  Defence  College;  EEAS:  European  External Action  Service;  ENISA:  European  Union \\nAgency for Network and Information Security; ERCC: Emergency Response Coordination Centre; \\nEU INTCEN: European Union Intelligence and Situation Centre; EU-LISA: European Agency for the \\nOperational Management of Large-scale IT Systems in the Area of Freedom, Security and Justice; \\nEU  SITROOM:  European  Union  Situation  Room;  EUMS  INT:  European  Union  Military  Staff, \\nIntelligence Directorate Mission; GSA: European Global Navigation Satellite Systems Agency; NIS: \\nNetwork and Information Security; SIAC: Single Intelligence Analysis Capacity.\\n', 'Connections: The Quarterly Journal \\nISSN 1812-1098, e-ISSN 1812-2973 \\n\\nResearch Article \\n\\nAndras Hugyik, Connections QJ 19, no. 4 (2020): 25-38 \\nhttps://doi.org/10.11610/Connections.19.4.02  \\n\\nBest Practices in the Application of the Concept  \\nof Resilience: Building Hybrid Warfare  \\nand Cybersecurity Capabilities  \\nin the Hungarian Defense Forces \\n\\nAndras Hugyik \\n\\nAbstract: In its Global Strategy for foreign and security policy, the EU ap-\\nplies resilience as a comprehensive concept of internal and external secu-\\nrity. In parallel, at the 2016 Summit in Warsaw, Allied leaders decided to \\nboost NATO’s resilience to the full spectrum of threats. Each NATO mem-\\nber  needs  to  be  resilient  to  a  major  shock  caused  by a  natural  disaster, \\nfailure of critical infrastructure, a hybrid, or an armed attack. Hybrid war-\\nfare,  including  cyberattacks,  is  recognized  as  a  significant  security  chal-\\nlenge. \\n\\nThe National Security Strategy of Hungary, adopted in 2020, confirms \\nthat  the  primary  international  framework  of  Hungary’s  security  and  de-\\nfense policy is NATO and EU membership and highlights the need to en-\\nhance the country’s resilience against hybrid attacks. This article provides \\nan analysis of the application of the concept of resilience in the Hungarian \\ndefense sector. It introduces the development of the resilience of the Hun-\\ngarian Defense Forces against hybrid threats, including their cyber compo-\\nnent, while generating options for the decision-makers regarding the mili-\\ntary and information instruments of national power. The author identifies \\npotential hybrid threats against Hungary, a possible cyberattack scenario, \\nand lines of effort to achieve a feasible level of resilience to such threats. \\nHe takes account of the political and military environment, as well as wider \\nnational issues in view of hybrid threats and main features and dilemmas \\nof cyber warfare, thus aiming to facilitate the application of the concept of \\nresilience in Hungary. \\n\\nKeywords: resilience, security policy, military, intelligence, hybrid warfare, \\ncyber defense, EU, NATO, Hungary. \\n\\nPartnership for Peace Consortium of Defense \\nAcademies and Security Studies Institutes \\n\\nCreative Commons \\nBY-NC-SA 4.0 \\n\\n \\n \\n \\n \\n \\n \\n \\n \\n\\x0cAndras Hugyik, Connections QJ 19, no. 4 (2020): 25-38 \\n\\nIntroduction: Applying the Concept of Resilience in Hungary \\n\\nThe purpose of applying the concept of resilience is to strengthen the abilities of \\nsystems, organizations, policies, and individuals to respond well to external im-\\npacts. Many experts agree that “the recent enthusiasm for the concept of resili-\\nence across a range of policy literature is the consequence of its fit with neolib-\\neral discourse. This is not to say that the idea of resilience is reducible to neolib-\\neral policy and governance, but it does fit neatly with what it is trying to say and \\ndo.” \\n\\n1 \\nThe  ideology  of  neoliberalism  primarily  sees  the  guarantee  of  economic \\ngrowth, welfare, liberty, and the common good in the ‘liberalization’ of markets. \\nThe  neoliberal  state  radically  departs  from  the  redistribution  of  the  welfare \\nstate,  takes  business-  and market-friendly  measures  to  protect  private  equity \\ngain, and turns citizens into entrepreneurs and consumers. \\n\\nThe  collapse  of  neoliberal  hegemony  after 2008  has  led  to  a  new wave  of \\npopulism. Populist parties and movements include both left- and right-wing ac-\\ntors. One of their few common characteristics is that they all criticize the ruling \\nelite and its ideology, claiming that the people are oppressed by the elites. \\n\\nAccording to the left-wing rhetoric, the social and economic policy of Orbán’s \\npopulist  government  in  Hungary  is  strengthening  the  nation’s  capitalist  class, \\nselling  out  cheap  workforce  for  foreign  industrial  investors  while  disciplining \\nthose workers, and performing centralized control of the poor, primarily living in \\nrural areas. The purpose of its cultural policy is to promote the official Hungarian \\nideology of the era before 1938; a conservative, Christian, nationalist ideology \\nwith historical lies, an unjust social system, hateful atmosphere, and the hidden \\nintention to recover territories lost after World War I. Orbán perceives the ne-\\noliberal European Union, the international capitalists’ secret fraudulent practices \\nrepresented by George Soros, and migrants as enemies to declare his political \\nopponents as the enemy of the nation and to take the role of the rescuer of the \\nnation. \\n\\nWhile the  government  is  attacking  some  of the  EU’s values  in  front  of the \\npolitical audience and is confronted loudly, in terms of economic processes, it is \\na subordinated ally of European capitalists.2 Due to constructivist elements of \\nViktor Orbán’s regime-building politics,3 democracy, the rule of law, and plural-\\n\\n \\n \\n \\n\\x0cHybrid Warfare and Cybersecurity Capabilities in the Hungarian Defense Forces \\n\\nism in Hungary have become limited and resulted in the establishment of a coun-\\ntry with illiberal democracy. In Hungary, those in power suggest that leftists and \\nliberals are not part of the nation, and all that is left or liberal, be it the person, \\nany artwork, or just a point of view or an approach, should be deemed as alien \\nand should be rejected because that goes against the official national Christian \\nconservative course.  \\n\\nPerhaps this political climate also contributes to the fact that in Hungary, only \\nNATO-related defense sciences initiate develops of resilience-based security and \\nlaw enforcement concepts. However, a more plausible explanation is that, as op-\\nposed to the generally accepted, comprehensive security policy and crisis man-\\nagement approach, in the case of resilience, we should focus on national-level \\nsolutions. Many Hungarian experts regard this as evidence of the appropriate-\\nness of the efforts to develop a comprehensive approach at the national level, \\nwhich was launched in our country in 2010. \\n\\nThe majority of Hungarian security policy experts consider that in 2014, dur-\\ning the Ukrainian crisis, both NATO and the EU found the adequate response to \\nhybrid threats in increasing nations’ resilience and in supporting military efforts \\nwith civilian tools (civil preparedness). The very essence of this solution lies in \\nthe coordinated application of military and civilian crisis management compo-\\nnents, which is also a basic principle of the comprehensive approach. \\n\\nTherefore, it can be established that the background, the fundamental prin-\\nciples, and the toolset applied for resilience and civil preparedness are practically \\nthe same as the comprehensive approach itself; they are a mere re-interpreta-\\ntion thereof in a different context. Thus, resilience and civil preparedness did not \\nbring about a different mindset or a set of requirements; yet, these cannot be \\nregarded as identical to any already existing sets of tasks under any legislation. \\nTherefore, it is necessary to statutorily appoint a national coordinator for the \\npurpose of both resilience and civil preparedness and to define the scope of na-\\ntional-level tasks, the bodies and the organizations responsible for their imple-\\nmentation, the cooperating organizations, and the procedural rules of coopera-\\ntion. Given that the task requires close and comprehensive cooperation through-\\nout the government, the effective implementation should fall within the compe-\\ntence and capabilities of the system of defense administration.4 \\n\\nThe  British  Journal of  Politics  and  International Relations  20, no. 3  (2018):  790-808, \\nhttps://doi.org/10.1177/1369148118775043. \\n\\n \\n \\n\\x0cAndras Hugyik, Connections QJ 19, no. 4 (2020): 25-38 \\n\\nBuilding Hybrid and Cyber Warfare Resilience Capabilities in the \\nHungarian Defense Forces \\n\\nIntroduction of the Hungarian Defence Forces \\n\\nThe Hungarian Defense Forces (HDF) is the national defense force of Hungary. \\nSince 2007, the Hungarian Armed Forces is under a unified command structure. \\nThe Ministry of Defense maintains the political and civil control over the army. A \\nsubordinate  Joint  Forces  Command  is  coordinating  and  commanding  the  HDF \\nunits. \\n\\nThe  armed  forces  have  28,000  personnel  on  active  duty.  In  2019,  military \\nspending was 1.904 billion USD, or about 1.2 % of the country’s GDP, well below \\nthe NATO target of 2 %. In 2016, the government adopted a resolution in which \\nit pledged to increase defense spending to 2 % of GDP and the number of active \\npersonnel to 37,650 by 2026. Military service is voluntary, though conscription \\nmay occur in wartime. \\n\\nAccording to the Hungarian Constitution, the three pillars of the nation’s se-\\ncurity are the strength of the HDF, the system of the Alliance, and the citizens.  \\nIn February 2017, the Ministry of Defence disclosed the Zrínyi 2026 develop-\\nment program, which intends to increase the capability of active armed forces, \\nthe manpower of reserve forces, the military communication and  information \\nsystem, and cyber defense. These measures seem to be adequate steps for build-\\ning resilience to hybrid threats. \\n\\nApproach to Improve Resilience to Hybrid Attacks \\n\\nHybrid  warfare  denotes “the  use  of  military  and  non-military tools  in  an  inte-\\ngrated campaign, designed to achieve surprise, seize the initiative and gain psy-\\nchological  as  well  as  physical  advantages  utilizing  diplomatic  means;  sophisti-\\ncated and rapid information, electronic and cyber operations; covert and occa-\\n5 In other \\nsionally overt military and intelligence action; and economic pressure.” \\nwords, hybrid attacks combine military and non-military as well as covert and \\novert means, including disinformation, cyberattacks, economic pressure, and de-\\nployment of irregular armed groups, and use of regular forces. Nowadays, hybrid \\nwarfare  is  considered  a  significant  security  challenge; within this  wider threat \\ncategory are cyberattacks that are perceived as one of the main threats to the \\nmodern society for every country. \\n\\nFigure 1 illustrates a project for the Hungarian Defence Forces in the field of \\nresilience development against hybrid attacks based on  the findings of Adrian \\n\\n \\n \\n\\x0cHybrid Warfare and Cybersecurity Capabilities in the Hungarian Defense Forces \\n\\nFeher.6 Feher followed the steps of Army Design Methodology,7 and hence de-\\nscribes the desired environment, defines the problem, and recommends an op-\\nerational  approach.  Following  a  modification  by  this  author,  the  project  ap-\\nproach consists of six objectives, seven outcomes, and 15 proposed outputs in \\norder to enhance the level of resilience against hybrid threats and thus protect \\nthe country. The figure aligns instruments of national power to each outcome. \\n\\nThe underlying logic of the proposed approach is that Hungary needs a hybrid \\ndefense strategy to combat potential hybrid threats. The military instrument of \\nnational power has to extend its impact and facilitate the improvement of infor-\\nmation power, the development of information deterrence capacity to protect \\nHungary’s sovereignty through citizenry’s involvement. At the same time, there \\nis a need for support from other agencies in establishing an informational deter-\\nrence  capability  to  protect  the  population  against  hostile  propaganda  and \\ncyberattacks. Since the military instrument is highly dependent on other instru-\\nments of national power, HDF must maintain and improve the collaboration with \\nother stakeholders to establish a “whole-of-government” approach. The domain \\nof information and the associated information operations play an important role \\nin hybrid warfare. Historically, military operations have primarily focused on the \\nenemy’s capabilities and only secondarily on the weakening of its determination, \\nwhile information operations target determination and willpower. \\n\\nThe aim of information operations is to achieve leadership supremacy, infor-\\nmation domination, and information supremacy by employing psychological op-\\nerations and operations on operational security, military deception, physical de-\\nstruction,  electronic  warfare,  public  information,  computer  network  warfare, \\nand civil-military cooperation while using military information systems and intel-\\nligence information.8 In the information operations doctrine currently applied by \\nthe Hungarian Defense Forces, the details of the concept of information opera-\\ntions have not yet been developed. The elements of information operations only \\npartially reflect the activities and capabilities to be achieved in the information \\nenvironment. Experts argue that the main challenge faced by the Hungarian De-\\nfense  Forces is  to  attain the  ability to  address  complex  information  issues: to \\nquickly obtain, process, and integrate information into the decision-making cycle \\nand to control the narratives of conflicts in the information space.  \\n\\n\\n \\n \\n \\n\\x0cAndras Hugyik, Connections QJ 19, no. 4 (2020): 25-38 \\n\\nProject aim: Protect the Sovereignty and Independence of Hungary  \\n\\nby Enhancing Resilience to Hybrid Threats \\n\\nObjectives \\nPossess a military deter-\\nrent capability to stop the \\nenemy and support the \\nintervention of NATO \\nforces in Hungary \\n\\nMaintain constitutional \\norder and support the \\ncentral government \\n\\nAssist NATO allies under \\ncollective defense condi-\\ntion \\nDevelop information de-\\nterrence capacity \\n\\nPrevent surprise \\n\\nOutputs \\n\\n1, 2, 3, 4, 5, 7, 9, \\n10, 12, 13, 14, 15 \\n\\n1, 2, 3, 4, 6, 7, 9, \\n10, 12, 13, 14, 15 \\n1, 2, 3, 4, 5, 7, 8, 9, \\n10, 12, 15 \\n\\n1, 2, 3, 5, 6, 7, 8, 9, \\n10, 11, 12, 13, 14, \\n15 \\n1, 2, 3, 5, 6, 7, 9, 10, \\n13, 15 \\n\\n2, 3, 5, 6, 9, 15 \\n\\nOutcomes and Instruments  \\nIncrease the capability of vol-\\nunteer conventional reserve \\nforces (M&I)  \\nand establish volunteer un-\\nconventional reserve forces \\n(M&I) \\nEstablish volunteer civil pre-\\nparedness capability (M&I) \\nAchieve commitment of the \\ncitizenry to the nation’s de-\\nfense (I) \\nIncrease active-duty forces’ \\nexpeditionary capability (M) \\n\\nProtect citizenry against hos-\\ntile influence warfare and na-\\ntional power against cyberat-\\ntack (I) \\nBuild Integrated Intelligence, \\nSurveillance and Reconnais-\\nsance – Provide operational \\nsecurity (I) \\nProvide for interagency coop-\\neration (DIME) \\n\\n1, 2, 3, 4, 5, 6, 7, 8, \\n9, 10, 11, 12, 13, 14, \\n15 \\n\\nFollow “Whole-of-govern-\\nment” approach in de-\\nfense \\nOutputs: (1) Increase patriotism via social and traditional media; (2) Cease false \\nsense of security; (3) Reveal and refute false news; (4) Recruit volunteers; (5) In-\\ncrease cyber warfare capability; (6) Improve counterintelligence to identify and \\ndetect warning signals; (7) Conduct joint and combined rehearsals (exercises); (8) \\nEliminate/ integrate extreme groups and establish the resistance movement; (9) \\nIdentify vulnerabilities and capability gaps; (10) Establish decentralized command \\nand control with secure communications; (11) Enable quick response through the \\nlegal system; (12) Establish a system for readiness and mobilization; (13) Provide \\ntraining and equip forces; (14) Build prepositioned stocks; (15) Ensure coordina-\\ntion of decision makers.  \\n\\nFigure 1: Project to Improve Resilience to Hybrid Attacks. \\nAbbreviations:  DIME  –  instruments  of  Diplomacy,  Information,  Military  and  Econ-\\nomy; M (Military Instrument), I (Information Instrument), M&I (Military and Infor-\\nmation Instrument). \\n\\n30 \\n\\n \\n \\n \\n\\x0cHybrid Warfare and Cybersecurity Capabilities in the Hungarian Defense Forces \\n\\nAt the same time, the operational cyberspace capabilities of HDF should be \\ndeveloped, and their integration into both military planning and operation im-\\nplementation should be established. To that end, the Hungarian Defense Forces \\nmust adopt a new mindset primarily focusing not only on the execution of com-\\nbat activities but also on the desirable outcomes of such military operations, in-\\ncluding the impact of such outcomes. In military doctrine, a broader interpreta-\\ntion of the information tool system is necessary. Treating it as a mere supporting \\nfunction will not suffice. \\n\\nCyber Defense in Hungary \\n\\nThe Main Aspects and Dilemmas of Cyber Warfare \\nGenerally, in cyber warfare, states launch their operations for intelligence pur-\\nposes with disruptive or destructive intentions and do so directly or through the \\ninvolvement of third parties, such as hackers. Attacks may target critical public \\ninfrastructures, specifically the IT, information and communication systems used \\nin the defense sector. In addition, hostile activities using social media and Inter-\\nnet  platforms  to  influence  civil  society are  increasingly common.  In  a  broader \\nsense, cyber warfare covers all attacks realized in cyberspace with a useable re-\\nsult for the attacker in military or political terms.9 Experience has shown that a \\ncyberattack only imposes a substantial burden on a country if it is coordinated \\n(relates military control with a strategic goal, to which each operational activity \\nis subordinated), comes in waves (types and targets of attacks are diverse, un-\\npredictable and consecutive), is multi-sectorial (affects several industries, while \\ndefense coordination generally covers only a small scope of industries), is sup-\\nported by information acquired by intelligence (information required for attacks \\nis not only from open sources but also from intelligence collection and analysis) \\nand is primarily realized to cause damage to the enemy. The aim is to make the \\ncountry and its citizens feel the attack, i.e., such attacks must be very obvious \\nand must involve emotional impacts –characteristics that set them apart from \\ncyber espionage.10 Cyberattacks are generally not used by states for destructive \\npurposes in peace periods, as remaining in the “gray zone” between peace and \\nwar serves their best interests. This does not mean that they would not be able \\nto go beyond this zone if necessary. \\n\\n \\n \\n \\n\\x0cAndras Hugyik, Connections QJ 19, no. 4 (2020): 25-38 \\n\\nThe main dilemma of cyber warfare is the missing international regulation for \\ncyberspace. Although the majority of UN Member States recognize the extension \\nof the scope of international agreements for cyberspace, their applicability is still \\nproblematic.11 This is because there is no internationally accepted definition of \\nwhat we call a cyberattack or a cyber weapon. In addition, in a cyberattack, there \\nis usually no clear declaration of war, attackers remain hidden in cyberspace, and \\nthe impacts to be expected also remain unassessed. Therefore, serious attention \\nis paid to the application of relevant conventions to cyberspace operations.12 \\n\\nThe Paris Call for Trust and Security in Cyberspace Initiative \\n\\n13 was set up to \\nguarantee secure cyberspace on the international level. Hungary joined the ini-\\ntiative,  but  the  largest  cyber-arsenal  owners  (the  United  States,  Israel,  Iran, \\nChina, Great Britain, or Russia) did not consider this necessary. \\nNATO’s Cyber Defense \\nCombating  cyberattacks  is  a  priority  for  NATO.  However,  regarding  the  com-\\nmonly used terms of cyberwar or cyberattack, it should be noted that there is no \\nagreed definition of cyberwar or cyberattack in NATO’s official terminology, and \\nexamples of definitions can only be found at the level of member states. \\n\\nThis is mainly due to the limitless nature of cyberspace and the constant ex-\\npansion of the range of attack types it accommodates, but also to the interests \\nof the Alliance. NATO does not deem the definition of cyberattack necessary be-\\ncause it individually evaluates simultaneous but different types of attacks to de-\\ncide upon the nature of the alliance-level response. \\n\\nSince 2007, NATO has been paying particular attention to cyber defense and \\ncyber warfare. In 2012, the cyber defense was included in the Alliance’s defense \\nplanning, and NATO’s cyber defense guidelines were adopted at the 2014 Wales \\nSummit. In Wales, the Alliance declared that it recognizes the validity of interna-\\ntional law in cyberspace and included cyber defense  among NATO’s collective \\ndefense tasks.14 \\n\\nIn 2016, in the communiqué of the Warsaw Summit, allies extended the area \\nof operational warfare traditionally covering sea, air, and land to include cyber-\\n\\n\\n \\n \\n \\n\\x0cHybrid Warfare and Cybersecurity Capabilities in the Hungarian Defense Forces \\n\\nspace 15 and declared that a cyberattack against a member state could be con-\\nsidered by the Alliance as an attack on NATO as a whole and, if necessary, they \\nmay take collective measures in response. \\n\\nIn Warsaw, the Cyber Defense Pledge was adopted, wherein member states \\nundertook a significant and rapid development of the protection of their national \\nnetworks and infrastructures in line with Article 3 of the Washington Treaty, de-\\nvelopment of comprehensive cyber defense capabilities, and strengthening the \\ncooperation in identifying and understanding threats while enhancing cyberse-\\ncurity education and training. An important step in the development of NATO’s \\ncyber defense capabilities is the establishment of the Cyber Operational Center \\n(CyOC) to coordinate the Alliance cyber operations within the Supreme Head-\\nquarters Allied Powers, Europe (SHAPE), starting in 2018. \\n\\nIn its cyber capabilities, NATO distinguishes passive and active defense capa-\\nbilities:  the  former  consists  mainly  of  preventive,  incident  management,  data \\nand system restoration capabilities within its own network range. The latter is a \\ncapability of an offensive nature to deter and eliminate threats beyond the scope \\nof its own networks.16 \\nCybersecurity within the Hungarian Defense Forces \\nIn Hungary, defense against cyber threats and the definition of cyberspace as a \\ntheater of war appeared in strategic documents as early as 2012. In 2018, cyber-\\nspace as an autonomous theater of operation was incorporated in the Hungarian \\nlegislation (Section 80 of Act CXIII of 2011). The directions and modalities of the \\ndevelopment of Hungarian military cyber capabilities are set out in the National \\nMilitary Strategy (2012), the National Cybersecurity Strategy (2013), the Cyber-\\nsecurity  Concept  of  the  Hungarian  Defense  Forces  (2013),  the  above  Warsaw \\nCommitments, and the Zrínyi Development Program until 2026. \\n\\nThe National Military Strategy has identified “the creation of opportunities \\nfor network-based warfare” as one of the main goals to be attained by the Hun-\\ngarian Defense Forces. On the one hand, computer-network warfare is aimed at \\ninfluencing,  degrading,  and  making  impossible  the  operation  of  the  opposing \\nparty’s networked IT systems and, on the other hand, it seeks to maintain the \\n\\n \\n \\n \\n\\x0cAndras Hugyik, Connections QJ 19, no. 4 (2020): 25-38 \\n\\npabilities was defined in the Hungarian Defense Forces’ Cybersecurity Concept. \\nIn this document, the initial level of cybersecurity capabilities had to be reached \\nuntil 2014, the basic level cybersecurity capabilities between 2014 and 2016, and \\nthe full cybersecurity capabilities – after 2016. The concept aims, inter alia, to \\nprotect  vital  information  system  components,  reduce  their  vulnerability,  and \\neliminate potential damages as soon as possible. \\n\\nCybersecurity developments brought forth by the Hungarian Defense Forces \\nform an integral part of the defense policy program. The HDF Electronic Incident \\nManagement Center was established in the framework of this program. In addi-\\ntion, further organizational and functional changes may be needed in the Hun-\\ngarian Defense Forces to create a unified cybersecurity system. To that end, the \\ntype  of  cybersecurity  organizations  for  the  individual  command  levels  should \\nalso be clarified. The main challenge in cybersecurity is to reduce response times \\nand to enhance the efficiency of intelligence. \\n\\nAs  of  today,  the  majority  of  cybersecurity  tasks  of  the  Hungarian  Defense \\nForces are performed by the Military National Security Service (MNSS). In recent \\nyears, in the implementation of MoD Instruction No. 85/2014, MNSS invested in \\nthe development of intelligence capabilities and capabilities, enabling the man-\\nagement of cyber incidents. \\n\\nAt a parliamentary hearing in 2019, the Chief of General Staff indicated that \\nit had been foreseen to develop the cyber capabilities (non-existent at the time) \\nin the near future. In 2020, the Government specified the areas within the Hun-\\ngarian Defense Forces’ cyber capabilities and operations that need to be applied \\nor  developed,  and  the  Parliament  added  to  the  National  Defense  Act  special \\nrules regarding the military operations in cyberspace.18 \\n\\nAlthough the details are not entirely public, the 2020 defense budget shows \\n\\nthat the cyber development of the military is a priority. \\n\\nA Scenario of a Hybrid Attack against Hungary \\n\\nIt goes without saying that significant progress has been made at the national \\nlevel in the field of cyber defense and security over the last ten years. However, \\nwe  remain  relatively  defenseless  and  vulnerable  to  a  well-structured,  coordi-\\nnated series of cyberattacks. According to Feher, these attacks can lead to  \\n\\nthe enemy’s most dangerous course of action when the aggressor conducts \\nfull-spectrum hybrid operations, and it is able to procure enough supporters \\nto fight against the central power, thus keeping the conflict under Article 5 \\nthreshold. With covert  support  from Special Operation Forces and conven-\\ntional forces, the enemy can achieve fundamental surprise, paralyze the com-\\nmand and control system, successfully fight against Hungarian security forces, \\n\\nand destruction of the program and data content of the target objects, and issues of \\nprotection against similar activities of the opposing party.” \\n\\n \\n \\n\\x0cHybrid Warfare and Cybersecurity Capabilities in the Hungarian Defense Forces \\n\\nand establish functional alternative political power in occupied territories. In \\nthis situation, Hungary has to struggle without official NATO assistance in oc-\\ncupied or unoccupied lands.19  \\n\\nBased on this assumption and the thesis of Dr. László Kovács and Dr. Csaba \\nKrasznay on a cyberattack scenario against Hungary,20 I would like to present an \\nescalation process that is completely conceivable today (Figure 2). \\n\\nFindings \\n\\nOn December 10, 2019, the European Council adopted conclusions that set pri-\\norities and guidelines for EU cooperation to counter hybrid threats and enhance \\nresilience to these threats. The conclusions call for a comprehensive approach \\nto counter hybrid threats, working across all relevant policy sectors in a more \\nstrategic, coordinated, and coherent way. \\n\\nIn the case of Hungary, control over DIME, supportive and involved popula-\\ntion, adequate military strength, effective intelligence and counterintelligence, \\nand improved cyber resilience seem to be the relevant priorities, where resili-\\nence is defined as “the ability to prepare for and adapt to changing conditions \\nand withstand and recover rapidly from disruption… [and] includes the ability to \\nwithstand and recover from deliberate attacks, accidents, or naturally occurring \\nthreats or incidents.” \\n\\n21 \\n\\nCyber resilience is the ability of an actor to resist, respond, and recover from \\ncyber incidents to ensure the actor’s operational continuity.22 Strategic cyberat-\\ntacks could target the nation’s critical infrastructure and utilities, whilst opera-\\ntional cyberattacks are against the adversary’s military. \\n\\nAt the same time, a cyberattack is a type of information operations within the \\ninformation warfare aiming to “corrupt, deny, degrade and exploit adversary in-\\nformation and information systems and processes while protecting the conﬁden-\\ntiality, integrity, and availability of one’s own information.” \\n\\n23  \\n\\nThe power in the information domain is vital for the nation to prepare the \\n\\ncitizens for the negative influence of the enemy, keep or recover interactions  \\n\\n \\n \\n \\n\\x0cAndras Hugyik, Connections QJ 19, no. 4 (2020): 25-38 \\n\\nCyberattack (the first phase of a possible hybrid attack is a cyberat-\\ntack) \\n1. Intimidation: News about the alleged weakness of Hungarian \\ncyber defense appears on a blog supported by a foreign secret ser-\\nvice.  \\n2. Distribution: The news that appeared on the blog are dissemi-\\nnated on social media, reaching tens of thousands of users. \\n3. Sharing: Due to sharing through pseudo-profiles created by for-\\neign intelligence services, the news appears in more news flow and \\nis spread further. \\n4. Highlighting: Due to the large number of sharing, the tabloid \\npress also starts to cover the topic, and soon it becomes a topic in \\nrespected media as well. \\n1. Overload attacks are launched against certain government web-\\nsites, making some services unavailable for hours. \\n2. Some municipal and support agencies’ websites are hacked, and \\nmessages threatening Hungary appear on their home pages. \\n3. Databases containing the personal data of tens of thousands of \\nHungarian citizens appear on the Internet. \\n1. In a Wikileaks-type leak, government emails are published under \\nthe title HunLeaks; the international press begins to analyze them. \\n2. The “Hungarian Snowden” hands over classified documents to \\nan investigative journalist. They are being analyzed by an interna-\\ntional team of journalists. \\n3. An investigation ordered as a result of previous attacks finds so-\\nphisticated malware at the IT system of a public service provider. \\nThe purpose of malware is to obtain data. According to the report \\non the investigation, the malware has been running for at least \\ntwo years. \\n1. Attacks on telecommunications: Most telecommunication ser-\\nvices become inaccessible. Government communication is also \\nhampered. Defense coordination slows down and is blocked. \\n2. Attacks on the finance system: Online banking is paused; inter-\\nnational financial transactions are also suspended. \\n3. Attacks on electricity services and transport: District level power \\noutages occur; transport is paralyzed.  \\nThe aggressor conducts a combination of special and conventional \\nmilitary operations, uses intelligence agents, political provoca-\\nteurs, media influence, economic intimidation, proxies and surro-\\ngates, paramilitaries, terrorists, and criminal elements. \\nThe aggressor can achieve a fundamental surprise, paralyze the \\ncommand and control system, successfully fight against Hungarian \\ndefense and security forces, and establish functional alternative \\n\\nI. \\n\\nI.1. \\nPsycholog-\\nical opera-\\ntions \\n\\nI.2. \\nSpectacu-\\nlar attacks  \\n\\nI.3. \\nInfluencing \\npolitics \\n\\nI.4. \\nInfrastruc-\\nture at-\\ntacks \\n\\nII. \\nAggressor \\nconducts  \\nfull - spec-\\ntrum hy-\\nbrid opera-\\ntions  \\n\\n36 \\n\\n \\n \\n\\x0cHybrid Warfare and Cybersecurity Capabilities in the Hungarian Defense Forces \\n\\npolitical power in occupied territories. In this situation, Hungary \\nhas to struggle without official NATO assistance in occupied or un-\\noccupied lands. \\n\\nI. Hybrid at-\\ntack \\n\\nII.  \\nCyberattack  \\n\\nResilience development at the \\nnational level \\nDesignate a national coordina-\\ntor for resilience and civic pre-\\nparedness, define the national \\ntasks, bodies, and organiza-\\ntions responsible for and coop-\\nerating in their implementa-\\ntion, and procedures for coop-\\neration. Defense administra-\\ntion seems to be the right sys-\\ntem to ensure full-spectrum \\ngovernment cooperation.  \\nRaising information security \\nawareness in society, strength-\\nening cyber defense organiza-\\ntions, creating alternative, \\nemergency infrastructures, \\nstrengthening the toolbox for \\ncoordinated, centralized cyber \\ndefense, strengthening part-\\nnerships between the adminis-\\ntrative, business, and scientific \\nspheres. \\n\\nResilience development at HDF \\nlevel \\nImplement the proposed pro-\\nject (Figure 1) in order to \\nachieve the desired aim (end-\\nstate), to protect the country by \\nimproving resilience against hy-\\nbrid attacks. The figure aligns \\ninstruments of national power \\nto each outcome.  \\n\\nThe main task of HDF is to deal \\nwith information challenges in a \\ncomplex way: both to quickly \\nobtain and process information \\nand integrate it into the deci-\\nsion-making cycle, and to con-\\ntrol the narratives of conflict in \\nthe information space. The op-\\nerational capabilities in cyber-\\nspace and their integration into \\nmilitary planning and execution \\nneed to be established. \\n\\nFigure 2: Possible Hybrid Attack against Hungary and Provision of Resilience. \\n\\nbetween the state and the people, and terminate the citizens’ false sense of se-\\ncurity. \\n\\nOn the basis of NATO’s interpretation, resilience at the national level is the \\ncombination of civilian preparedness and military capability.24 This means that \\nwe should address the following challenges: raising information security aware-\\n\\n37 \\n\\n \\n \\n \\n \\n \\n \\n \\n \\n\\x0cAndras Hugyik, Connections QJ 19, no. 4 (2020): 25-38 \\n\\nness in society; strengthening cyber defense organizations, creating alternative, \\nemergency  infrastructures  (elements);  strengthening  the  toolbox  for  coordi-\\nnated, centralized defense; strengthening partnerships between the administra-\\ntive, business and scientific spheres; improving the resilience of HDF against hy-\\nbrid  warfare,  including  cyberattacks,  by  the  execution  of the  proposals  in  this \\narticle. \\n\\nTo establish resilience against cyber threats, the HDF should be able to deal \\nwith information challenges in a complex way: both to quickly obtain and pro-\\ncess information and integrate it into the decision cycle, and to control the nar-\\nratives on the conflict in the information space. \\n\\nDisclaimer \\nThe views expressed are solely those of the author and do not represent official \\nviews of the PfP Consortium of Defense Academies and Security Studies Insti-\\ntutes, participating organizations, or the Consortium’s editors. \\n\\nAbout the Author \\n\\nAndras Hugyik, PhD in military science, is a retired police colonel, a chief counci-\\nlor of the Hungarian police. He is an engineer, economist, and political expert. \\nHe is a former adviser to GUAM, OSCE, EUBAM, and UN – OPCW Joint Investiga-\\ntion Mechanism. Before joining these international organizations, he served in \\nthe Military Intelligence, the internal security service of the Hungarian law en-\\nforcement agencies, and the counter-terrorism center of Hungary. \\nE-mail: seniorhugyik@gmail.com. \\n\\n38 \\n\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n\\x0cReproduced with permission of copyright owner.\\n\\nFurther reproduction prohibited without permission.\\n\\n\\x0c', \"Connections: The Quarterly Journal \\nISSN 1812-1098, e-ISSN 1812-2973 \\n\\nResearch Article \\n\\nGeorge Sharkov, Connections QJ 19, no. 4 (2020): 5-24 \\nhttps://doi.org/10.11610/Connections.19.4.01  \\n\\nAssessing the Maturity of National Cybersecurity \\nand Resilience \\n\\nGeorge Sharkov \\n\\nMinistry of Defense, Republic of Bulgaria, https://mod.bg/ \\n\\nEuropean Software Institute – Center Eastern Europe, Sofia, Bulgaria, \\nhttps://esicenter.bg/ \\n\\nAbstract: This article provides an overview of maturity levels and assess-\\nment methodologies for the evaluation of cybersecurity and resilience in \\nrelation to their applicability and usefulness at sectoral and national levels. \\nReference maturity models and assessment frameworks, such as CERT Re-\\nsilience Management  Model, Cybersecurity Capacity Maturity Model for \\nNations, C2M2 (Cybersecurity Capability Maturity Model), are compared \\nand analyzed for their applicability in designing and implementing national \\ncybersecurity strategies and programs  to achieve cyber resilience. Cyber \\nreadiness indexes are also outlined in view of their use to indicate possible \\nimprovements. The author explores the development of national cyberse-\\ncurity strategies with a focus on cyber maturity and provides examples. A \\nmaturity-based approach for the Bulgarian cyber resilience roadmap is also \\ndescribed  within  the  context  of  the  evolving  cyber-empowered  hybrid \\nthreats and the need for  an institutionalized collaborative public-private \\nresilience. \\n\\nKeywords: cyber resilience, capability maturity models, cybersecurity ma-\\nturity assessment, maturity indicators, hybrid resilience  \\n\\nIntroduction \\n\\nModern  digitized  societies  and  economies  are  globally  interconnected  and in-\\ncreasingly interdependent as a result of global digital connectivity and depend-\\nency  on  digital  infrastructure,  communications,  and  systems.  The  analysis  of \\nthese interdependencies and emerging complex vulnerabilities and threats re-\\n\\nPartnership for Peace Consortium of Defense \\nAcademies and Security Studies Institutes \\n\\nCreative Commons \\nBY-NC-SA 4.0 \\n\\n \\n \\n \\n \\n \\n \\n \\n \\n\\x0cGeorge Sharkov, Connections QJ 19, no. 4 (2020): 5-24 \\n\\nquires a holistic approach, which goes well beyond the personal, the enterprise, \\nor the sectoral cybersecurity measures. The enhancement of cybersecurity and \\nthe protection of critical infrastructures require coordinated efforts at national, \\nregional, and international levels. In addition, due to the multi-layered “cyber \\nterrain” (a term introduced by the US Department of Defense, DoD, and further \\ndetailed  by  Shawn  Riley 1)  and  complex  systems  interdependencies,  the  new \\nrisks  and threats  become  “unknown  unknowns”  and require  upgrading  of  the \\nestablished since centuries resilience principles of the society to the entirely new \\nmaturity level of “cyber resilience.” \\n\\nAchieving  cybersecurity  and  resilience  at  the  national  level  is  a  shared  re-\\nsponsibility  of  all  stakeholders –  government,  private  sector,  and  civil  society. \\nCoordinated actions and a multi-stakeholder approach are required to develop \\nand execute national cybersecurity strategies and plans. Various methodologies, \\nguidelines,  and  templates  for  defining  well-structured and  comprehensive  na-\\ntional or sectoral cybersecurity strategies are provided by world organizations \\nlike  ITU,  OECD,  EU’s  ENISA,  OSCE,  standardization  bodies,  and  academic  re-\\nsearch. Most of them have already postulated “cyber resiliency” as a new main \\ngoal to upgrade ‘cybersecurity.’ Strategies are also reflected in roadmaps outlin-\\ning the steps and goals to achieve at different phases of the improvement plans. \\nThe challenge is how to evaluate the level of achievements, the efficiency, and \\neffectiveness  of  the  measures,  and  more  generally,  how  to  assess  the  overall \\nlevel of readiness, capacity and objectively evaluate security and resilience ca-\\npabilities  at the  sectoral  and national level.  There  is  also  a  need  for  a  unified \\nmethodology  to  monitor  the  progress  and  to  compare  the  achieved  status \\namong organizations, sectors, countries, and societies. \\n\\nFor decades, the approach based on maturity models has been widely used \\nin IT companies and technology sectors, as well as by public procurement, start-\\ning with defense, to assess the organizations’ readiness and capability to deliver \\nhigh-quality products and services within the required scope, time and budget. \\nOn the other hand, organizations, communities, and nations must live and com-\\nply with a constantly increasing number of regulations, standards, and require-\\nments, such as the NIST Cybersecurity Framework 2 and related NIST standards \\n3 with the expected Cybersecu-\\nand EU Regulations, e.g., the “Cybersecurity Act” \\n4 and others. To cope with all that \\nrity Certification Scheme, the “NIS Directive,” \\n\\n \\n \\n\\x0cAssessing the Maturity of National Cybersecurity and Resilience \\n\\nand yet meet the organization’s specific business goals, the maturity models and \\nassessment methods turned out to be the most efficient and effective way for \\nlarger and smaller organizations.5 \\n\\nIn this survey, we cover several most popular representatives of the huge di-\\nversity of cybersecurity maturity models and give a brief analysis of their suita-\\nbility for application at a higher level for the purposes of community, sectoral or \\nnational  cybersecurity  maturity  evaluation,  and  furnish  national  cybersecurity \\nstrategies  with  well-structured  improvement  programs,  like  “roadmap  to  ma-\\nturity.”  \\n\\nMaturity Models and Digital Society \\n\\nThe Origin and Types of Maturity Models \\n\\nThe concept of maturity models for software/ICT industry was initially sponsored \\nby the US military who wanted to develop a method to objectively evaluate soft-\\nware/ICT  subcontractors’  process  capability  and  maturity.6  Due  to  various \\nemerging technologies, standards, different sizes and capacities of the suppliers, \\nthere was a need to objectively assess in a unified manner the level of reliability, \\ntrust, and associated risks of software/ICT service quality. Maturity models pro-\\nvide a measurable transition as well between different levels (or steps, stages). \\nThey  allow to  compare  organizations  by their  “maturity  levels”  and  provide  a \\nstructured and prioritized approach for improvement plans. \\nThe maturity models can be grouped into three types:  \\n•  Progression Maturity Models, frequently illustrated by a ‘journey,’ repre-\\nsents a simple progression or scaling of an attribute, characteristic, indi-\\ncator, a pattern where the movement up the maturity levels indicates \\nthe progression of attribute’s maturity. Levels describe the next “higher \\nstates”  of  achievement,  advancement,  or  ‘steps’  in  the  evolution  and \\nprovide  a  clear  transformative  roadmap.  In  practice,  however,  they \\nmeasure neither process maturity nor capabilities; \\n\\n•  Capability Maturity Models (CMMs): the dimensions that are evaluated \\nrepresent organizational capabilities around a set of characteristics, indi-\\ncators, or patterns, often expressed as ‘practices.’ They are usually refer-\\n\\nongoing consultations for update in 2021, https://ec.europa.eu/digital-single-market/ \\nen/network-and-information-security-nis-directive.  \\n\\n \\n \\n\\x0cGeorge Sharkov, Connections QJ 19, no. 4 (2020): 5-24 \\n\\nred to as “process models.” The typical levels of CMM models are named \\naround the maturity of the processes, for example:  \\n\\nad-hoc → managed → defined → quantitatively managed → optimized \\n\\n•  Hybrid Maturity Models combine characteristics of progressive models \\nwith  capability  attributes  from  capability  maturity  models  and  reflect \\ntransitions between levels related to capabilities’ maturity while archi-\\ntecturally using the attributes, indicators, and patterns of a progression \\nmodel. They are relatively easy to use and understand, especially in spe-\\ncific subject matter domains. \\n\\nMaturity models, regardless of their type, have a similar structure that en-\\nsures a harmonized linkage between objectives, best practices, and assessments, \\nand also  facilitates the  definition of  improvement roadmaps  between  current \\ncapabilities and target ones within the context of business goals, standards, and \\ndomain-specific characteristics. A typical structure includes: \\n\\n•  Maturity levels: represent transitional states (also steps); in a hybrid ap-\\n\\nproach they could be also mapped to “capability levels”; \\n\\n•  Model domains:  groups  of attributes and  activities  into  areas,  usually \\n\\nreferred to as “process areas”; \\n\\n•  Attributes: the core content of the model, grouped by domain and level, \\n\\nbased on practices, prescriptions, knowledge, standards;  \\n\\n•  Appraisal methods: assessments in a unified manner that produce com-\\nparable and meaningful scoring (more than just checkboxes). The main \\nuse is to objectively evaluate adherence to the model, provide measur-\\nable indicators for achievements and progress, rather than comparing \\norganizations. Appraisals could be formal (expert-led) and informal (in-\\ncluding self-assessment); \\nImprovement plans (roadmaps): appraisal methods provide an evalua-\\ntion of the current state, gap analysis towards target level, identification \\nof improvement scope and priorities, improvement planning, and veri-\\nfying the results (achieving next or maintaining the current level). \\n\\n• \\n\\nMaturity Models for the Digital Society and Economy \\n\\nThe introduction and the early use of maturity models were in software/IT in-\\ndustry. After the first use of a staged maturity model by Richard L. Nolan in 1973, \\nand the following work of Watts Humphrey, initially at IBM and after 1986 at the \\nSoftware Engineering Institute (SEI), Carnegie Mellon University (CMU), the US \\nDepartment  of  Defense  requested  a  formalized  process  maturity  framework \\nfrom SEI by to be able to evaluate software contractors. In the early 1990s, SEI \\nintroduced the formal Capability Maturity Model (CMM) with five maturity lev-\\nels. Subsequently, in 2002, a much more comprehensive and integrated model, \\nCapability  Maturity  Models  Integration  (CMMI)  was  published,  with  the  most \\npopular  version 1.3  of 2010.  It  applies to  software engineering,  systems  engi-\\n\\n8 \\n\\n \\n \\n\\x0cAssessing the Maturity of National Cybersecurity and Resilience \\n\\nneering, software and systems acquisition, and service delivery as different con-\\nstellations  with  a  common  core.  The  CMMI  was  further  administered  by  the \\nCMMI Institute (a spin-off of CMU), which was acquired in 2016 by ISACA. A new \\nversion 2.0 was released in 2018. The five maturity levels defined by CMMI to \\nreflect the maturity of the established and institutionalized processes are:  \\nInitial -> Managed -> Defined -> Quantitatively managed -> Optimizing \\nSince then, capability maturity models have been introduced  widely in do-\\nmains such as ICT infrastructure, all kinds of software engineering, service man-\\nagement, business process management, manufacturing, civil engineering, and \\ncybersecurity. The CMMI Institute published in 2018 the “CMMI Cyber maturity \\nPlatform” to address the cyber resilience assessments.  \\n\\nCapability Maturity Models for Cybersecurity and Cyber Resilience \\n\\nDuring the past decade, multiple cybersecurity and resilience frameworks have \\nbeen proposed. A recent study 7 identified more than 25 research activities in 36 \\ndifferent  industries  attempting  to  achieve  increased  clarity  about  the  scope, \\ncharacteristics, synergies, and gaps that would facilitate scientific research ad-\\nvancement in this area. A 2017 technical mapping comparing maturity models \\nused in various sectors, including education and awareness, provided another \\nsource for our survey.8 The study classifies frameworks as either strategic or op-\\nerational, by the hierarchy of their decision influence, by the attacks addressed, \\nthrough the methods used and implementation area.  As an exercise to deter-\\nmine  the  popularity  of  the  terms,  we  conducted  a  simple  search  in  Google \\nScholar,  which  brought  more  than  10,000  results  for  “cybersecurity  maturity \\nmodel,” and around 12,000 hits for “cyber resilience maturity assessment.” For \\nour survey, we selected a few of the frameworks identified in previous research \\nand added more recent work, as we aim at identifying the applicability at higher \\nthan organizational level (like sectors, community, nations), the similarity of as-\\nsessment results, and possibilities for interdisciplinary, cross-sectoral and cross-\\nborder  application.  In  the  sub-sections  below,  we  comment  on  some  popular \\ncybersecurity indexes. \\n\\nCERT Resilience Management Model (CERT-RMM) \\n\\nCERT-RMM became the reference model for cyber resilience developed by the \\nCERT  Division  of  SEI,  Carnegie  Mellon  University.  It  had  a  strong  influence  on \\n\\n \\n \\n \\n\\x0cGeorge Sharkov, Connections QJ 19, no. 4 (2020): 5-24 \\n\\nmost  of  the  contemporary  cybersecurity  maturity  assessment  methods  and \\nframeworks. Although not explicitly stated in the title, the model is dedicated to \\nachieving  an  operational  resilience  of  organizations  in  a  digitized  society  and \\neconomy, i.e., what we currently mean by cyber resilience. A stable version 1.1 \\nof the model was published in 2011,9 with an update to the last published version \\n1.2 in 2016.10 The model is based on the “Operationally Critical Threat, Asset, \\nand  Vulnerability  Evaluation”  (OCTAVE)  method  for  information  security  risk \\nmanagement and the experience of application in the financial and other sec-\\ntors. The cyber risk management aspects have been combined with the process-\\noriented approach and common CMMI-related taxonomy, with terms like “pro-\\ncess areas” and generic goals and practices, introduced along with mapping to \\nthe engineering and service delivery and continuity process areas from CMMI for \\nservices and development. \\n\\nThe model defines the following 26 process areas grouped in 4 categories: \\n•  Category “Enterprise Management”: Communications; Compliance; En-\\nterprise focus; Financial Resource Management; Human Resource Man-\\nagement; Organizational Training & Awareness; Risk Management; \\n•  Category  “Operations  Management”:  Access  Management;  Environ-\\nmental Control; External Dependencies Management; Identity Manage-\\nment; Incident Management & Control; Knowledge & Information Man-\\nagement; People Management; Technology Management; Vulnerability \\nAnalysis & Resolution; \\n\\n•  Category  “Engineering”:  Asset  Definition  and  Management;  Controls \\nManagement;  Resilience  Requirements  Development;  Resilience  Re-\\nquirements  Management;  Resilience  Technical  Solutions  Engineering; \\nService Continuity; \\n\\n•  Category “Process Management”: Measurement and Analysis; Monitor-\\ning; Organizational Process Development; Organizational Process Focus. \\n\\nThe “resilience strategy” is based on achieving resilience of the four basic as-\\nsets: people, information, technology, and facilities. Thus, ‘resilience’ is ‘trans-\\nlated’ to protect and sustain measures for the assets. The structure of the model \\nfollows the classical CMMI architecture. For each of the 26 process areas, a set \\nof specific goals (total of 94) are defined and must be fulfilled by implementing \\nspecific  practices  (251,  typically  with  several  sub-practices).  The  model  pre-\\nscribes the use of three generic goals and 13 generic practices to measure the \\nlevel of maturity. To facilitate assessments, some more granulated Maturity In-\\n\\n\\n \\n \\n \\n\\x0cAssessing the Maturity of National Cybersecurity and Resilience \\n\\ndicator Levels (MIL) were subsequently introduced. The mapping of capabilities \\nlevels to maturity indicator levels is shown below: \\n\\n•  Capability Level 0: Incomplete – MIL0: Incomplete; \\n•  Capability Level 1: Performed – MIL1: Performed; \\n•  Capability Level 2: Managed – with MIL2: Planned; MIL3: Managed; \\n\\nMIL4: Measured; \\n\\n•  Capability Level 3: Defined – MIL5: Defined and new MIL6: Shared (ad-\\ndressing the maturity for overall improvements of the community). \\n\\nCybersecurity Capability Maturity Model (C2M2) for Critical Infrastructures \\n\\nThe Cybersecurity Capability Maturity Model (C2M2) 11 was introduced in 2014 \\nby the Department of Energy (US DOE) as an upgrade of an earlier version of \\nC2M2 for the Electricity Subsector (ES-C2M2) by removing sector-specific refer-\\nences and making it applicable more widely to Critical Infrastructures. It was sup-\\nported by the White House initiative led by the DOE, the Department of Home-\\nland Security (DHS), and SEI, CMU. C2M2 is structured in 10 domains (listed in \\nTable 1) and a set of practices per domain, which represent the capability in the \\ndomain. The practices are grouped by objectives and ordered by four maturity \\nindicator levels (MIL0 to MIL3). \\n\\nThe ‘objectives’ are of two types – approach objectives (one or more per do-\\nmain, unique for domains), supported by a progression of specific practices, and \\nmanagement  objectives  (one  per domain),  supported  by  a  progression  of  ‘ge-\\nneric’ practices that describe institutionalized activities. The progression is meas-\\nured by a set of practices characterizing maturity indicators levels, applied to ap-\\nproach progression and institutionalization progression. Like in CMMI and CERT-\\nRMM models, the MILs are ‘cumulative.’ The model is mapped to most of the \\nknown models and frameworks in information security and cybersecurity, like \\nISO/IEC 27001/2, NIST frameworks on cybersecurity, critical infrastructures, sup-\\nply chains. Remarkably, all 10 domains with objectives and practices meet a sub-\\nset of the CERT-RMM.12 A new version 2.0 is currently under consultation.13 \\n\\n3-D Community Cybersecurity Maturity Model (CCSMM) \\n\\nTo face the problem that most government agencies, industry partners, crit-\\nical infrastructure operators, school systems, nonprofit and other organiza-\\ntions exist and operate at the local level and are not equally prepared to de-\\nfend against cyber threats that could affect the entire community, the Center \\n\\n \\n \\n \\n\\x0cGeorge Sharkov, Connections QJ 19, no. 4 (2020): 5-24 \\n\\nTable 1. The Domains in C2M2, New Version 2.0 (under Consultation).  \\n\\nDomains \\nRisk Management  \\n\\nAsset, Change, and \\nConfiguration Man-\\nagement  \\nIdentity and Access \\nManagement  \\n\\nThreat and Vulnera-\\nbility Management  \\n\\nSituational Aware-\\nness  \\n\\nEvent and Incident \\nResponse  \\n\\nSupply Chain and \\nExternal Dependen-\\ncies Management  \\n\\nWorkforce Manage-\\nment  \\n\\nCybersecurity Archi-\\ntecture  \\n\\nCybersecurity Pro-\\ngram Management  \\n\\nPurpose statement \\n\\nEstablish, operate, and maintain an enterprise cybersecurity risk \\nmanagement program to identify, analyze, and mitigate cyber-\\nsecurity risk \\n\\nManage the organization’s IT and OT assets, including both \\nhardware and software, commensurate with the risk to critical \\ninfrastructure and organizational objectives \\nCreate and manage identities for entities that may be granted \\nlogical or physical access to the organization’s assets. Control \\naccess to the organization’s assets \\nEstablish and maintain plans, procedures, and technologies to \\ndetect, identify, analyze, manage, and respond to cybersecurity \\nthreats and vulnerabilities \\nEstablish and maintain activities and technologies to collect, an-\\nalyze, alarm, present, and use operational and cybersecurity in-\\nformation, status and summary information from other do-\\nmains, to establish situational awareness for operational state \\nand cybersecurity state \\nEstablish and maintain plans, procedures, and technologies to \\ndetect, analyze, mitigate, respond to, and recover from cyberse-\\ncurity events and incidents \\nEstablish and maintain controls to manage the cybersecurity \\nrisks associated with services and assets that are dependent on \\nexternal entities, commensurate with the risk to critical infra-\\nstructure and organizational objectives \\nEstablish and maintain plans, procedures, technologies, and \\ncontrols to create a culture of cybersecurity and to ensure the \\nongoing suitability and competence of personnel \\nEstablish and maintain the structure and behavior of the organi-\\nzation’s cybersecurity controls, processes, and other elements \\n\\nEstablish and maintain an enterprise cybersecurity program \\nthat provides governance, strategic planning, and sponsorship \\nfor the organization’s cybersecurity activities in a manner that \\naligns cybersecurity objectives with the organization’s strategic \\nobjectives and the risk to critical infrastructure \\n\\nfor Infrastructure Assurance and Security (CIAS) at The University of Texas at \\nSan Antonio (UTSA) created the Community Cyber Security Maturity Model \\n(CCSMM).14 A program was developed to help communities (and states) im-\\n\\n \\n \\n \\n \\n \\n\\x0cAssessing the Maturity of National Cybersecurity and Resilience \\n\\nplement the model and piloted in seven states helping them begin the devel-\\nopment of their own programs,15 as the community cybersecurity is arguably \\nthe weak link in the nation’s cybersecurity chain. The ‘levels’ in CCSMM are less \\nformal and defined as ‘levels of improvement’: \\n\\n• \\n\\n• \\n\\n• \\n\\n• \\n\\n• \\n\\nLevel 1 – Initial: some processes or programs may be in place, but a com-\\nmunity does not have all the program elements for a basic program; \\nLevel  2  –  Established: a  basic  program  has  been  established  with ele-\\nments and processes in place for all four dimensions; \\nLevel 3 – Self-Assessed: a minimal viable and sustainable program has \\nbeen implemented; \\nLevel 4 – Integrated: cybersecurity is integrated across the community, \\nincludes all citizens and organizations, the community is working with \\nthe state and other communities within the state; \\nLevel 5 – Vanguard: the community is maintaining a fully-vigilant cyber-\\nsecurity posture. \\n\\nThese levels of improvement are focused on four areas called dimensions, \\n\\nshown in Table 2. \\n\\nTable 2. Dimensions in the Community Cybersecurity Maturity Model (CCSMM). \\n\\nDimensions \\nAwareness \\n\\nInformation \\nSharing \\n\\nPolicy \\n\\nPlans \\n\\nDescription \\n\\nMost people understand that cyber threats exist. However, not \\nas many understand the extent of the threat, the current attack \\ntrends, how a cyber incident can impact a community, which \\nvulnerabilities should be addressed, what the cascading effects \\nmay be if a community was under a cyberattack  \\nAddresses what to do with information on a cyber incident and \\nwhere the information should be reported. In addition, how \\none sector can share information with another, allowing the \\nsecond sector to potentially prevent the incident from occurring \\nAddresses the need to integrate cyber elements into the policies or \\nguiding principles and includes all guiding regulations, laws, rules, and \\ndocuments that govern the community's daily operation. Policies \\nshould be evaluated to ensure cybersecurity principles are reflected in \\neverything we do and will establish expectations and limitations \\nCommunities have established plans to address many different haz-\\nards and this dimension ensures cybersecurity elements are included \\nin those plans enabling the community to address cyber incidents \\nthat could impact the operations of the community \\n\\n \\n \\n \\n \\n\\x0cGeorge Sharkov, Connections QJ 19, no. 4 (2020): 5-24 \\n\\nThis model’s distinguishing point is that it is 3-dimensional, with ‘geography’ \\nadded  as  a third  coordinate,  with  three  values:  organization, community,  and \\nstate. This 3-D Community Cybersecurity Model can serve to define a roadmap \\nfor individuals, organizations, communities, states, and the nation, and as: \\n\\n• \\n\\n• \\n\\na ‘yardstick’ to measure the present status of a community’s cybersecu-\\nrity program and attitudes; \\na  roadmap  to  help  a  community  understand  the  steps  needed  to  im-\\nprove its security posture; \\n\\n•  a common point of reference allowing individuals from different states \\n\\nand communities to compare and relate to individual programs. \\n\\nIt is declared to be compliant with other known frameworks, like the NIST \\nCyber Security Framework, the DoD’s CMMC, and to support the Cybersecurity \\nWorkforce Framework from the National Initiative for Cybersecurity Education \\n(NICE). \\n\\nCybersecurity Capacity Maturity Model for Nations (CMM-GCSCC 16) \\n\\nCMM-GCSCC 17 is a methodical framework designed to review the maturity of a \\ncountry’s cybersecurity capacity. It was developed by the Global Cyber Security \\nCapacity  Centre  (GCSCC)  through  a  global  collaborative  exercise  launched  in \\n2014. For each of its five dimensions (shown in Table 3), the model provides fac-\\ntors (24 in total for this version), which define criteria to demonstrate the re-\\nspective cybersecurity capacity. Most factors are examined from several view-\\npoints, and composed of a series of indicators within the five stages of maturity \\nfor each dimension, named as follows: start-up; formative; established; strate-\\ngic; dynamic.  \\n\\nCMM-GCSCC  is  among  the  most  popular  assessment  tools  applicable  to \\ncountries and regions, used by international organizations like ITU, Organization \\nof American States (OAS), the World Bank, Oceania Cyber Security Centre, Cy-\\nbersecurity Capacity Centre for Southern Africa, RAND Corporation, etc. It has \\nbeen deployed to over 80 nations with more than 110 assessments and two re-\\ngional  studies  by  OAS.  Many  country  profiles  are  publicly  available  and  levels \\nachieved could be reviewed, along with recommended improvements.18 A new \\nversion is planned for publication in the second half of 2020. It should be noted \\nthat ‘capacity’ is not equivalent to ‘capability,’ and the model is less formal than \\nmaturity assessments, although dimensions and factors may match. \\n\\n \\n \\n \\n\\x0cAssessing the Maturity of National Cybersecurity and Resilience \\n\\nTable 3. Cybersecurity Capacity Maturity Model for Nations (CMM of GCSCC).  \\n\\nDimensions \\n\\nCybersecurity Policy \\nand Strategy  \\n\\nCyber Culture and \\nSociety  \\n\\nCybersecurity Edu-\\ncation, Training and \\nSkills  \\nLegal and Regula-\\ntory Frameworks  \\nStandards, Organi-\\nzations, and Tech-\\nnologies  \\n\\nFactors \\nNational Cybersecurity Strategy; Incident Response; Critical In-\\nfrastructure (CI) Protection; Crisis Management; Cyber Defense; \\nCommunications Redundancy  \\nCybersecurity Mindset; Trust and Confidence on the Internet; \\nUser Understanding of Personal Information Protection Online; \\nReporting Mechanisms; Media and Social Media  \\nAwareness Raising; Framework for Education; Framework for \\nProfessional Training  \\n\\nLegal Frameworks; Criminal Justice System; Formal and Informal \\nCooperation Frameworks to Combat Cybercrime  \\n\\nAdherence to Standards; Internet Infrastructure Resilience; \\nSoftware Quality; Technical Security Controls; Cryptographic \\nControls; Cybersecurity Marketplace; Responsible Disclosure  \\n\\nCybersecurity Assessment for Financial Institutions – CAT FFIEC Tool \\n\\nIn 2015, the US Federal Financial Institutions Examination Council (FFIEC) intro-\\nduced  the  maturity-model-based  Cybersecurity  Assessment  Tool  (CAT) 19  for \\nbanking  institutions  to  evaluate  bank’s  risks  and  cybersecurity  readiness  by \\nmeasuring  levels  of  risk  and  corresponding  controls.  Five  maturity  levels  are \\nused: Baseline, Evolving, Intermediate, Advanced, and Innovative, based on five \\ndomains characterizing the institution’s behaviors, practices, and processes that \\nsupport  cybersecurity  preparedness. The five  domains  consist  of  a total  of 15 \\n“assessment factors” with 497 “declarative statements” used to assess the ma-\\nturity level achieved per domain. The five domains are: \\n\\n•  Cyber Risk Management and Oversight \\n•  Threat Intelligence and Collaboration \\n•  Cybersecurity Controls \\n•  External Dependency Management \\n•  Cyber Incident Management and Resilience. \\n\\nFor each domain, the assessment determines a maturity level on the following \\nscale: \\n\\n•  Baseline: The management reviews and evaluates guidelines;  \\n\\n \\n \\n \\n \\n \\n\\x0cGeorge Sharkov, Connections QJ 19, no. 4 (2020): 5-24 \\n\\n•  Evolving: Additional procedures and policies are set. Cybersecurity is in-\\n\\n• \\n\\ncreased to include information assets and systems; \\nIntermediate: Detailed processes occur, controls remain consistent, risk-\\nmanagement is integrated into business strategies;   \\n\\n•  Advanced: Cybersecurity practices and analytics are included in all busi-\\n\\n• \\n\\nnesses; continuous improvement in risk management processes; \\nInnovative: There  is  driving  innovation  in  the  people,  processes,  and \\ntechnology (new tools, new controls, new information-sharing groups). \\n\\nCAT  FFIEC  is  meant to  be  completed  periodically,  but also  after  significant \\ntechnological or operational changes. It is a self-assessment, which could be val-\\nidated by an auditor. After disputes on the “voluntary assessment,” the tool has \\nevolved to map better to the NIST Cybersecurity Framework (revision in progress \\nsince 2019). Auditors also increasingly require that companies complete an as-\\nsessment to demonstrate CAT FFIEC compliance. \\n\\nCyber Resilience Review (CRR) by DHS \\n\\nThe self-assessment package was designed by the Department of Homeland Se-\\ncurity (DHS) in partnership with the CERT Division of SEI, Carnegie Mellon Uni-\\nversity, as a derivative of the CERT-RMM tailored to the needs of critical infra-\\nstructure owners and operators.20 \\n\\nAs in CERT-RMM, CRR considers that an organization deploys its assets (peo-\\nple, information, technology, facilities) to support specific operational missions \\nor critical services. Then the assessment of capabilities in performing, planning, \\nmanaging, measuring, and defining operational resilience practices and behav-\\niors  is  performed  in  the  following  ten  domains:  Asset  Management;  Controls \\nManagement;  Configuration  and Change  Management;  Vulnerability  Manage-\\nment;  Incident  Management;  Service  Continuity  Management;  Risk  Manage-\\nment; External Dependency Management; Training and Awareness; Situational \\nAwareness. The domains are derived from CERT-RMM and are similar to the ten \\ndomains of C2M2. The assessment is based on the CERT-RMM method and could \\nbe performed in two ways: self-assessment or in a facilitated session. \\n\\nCybersecurity Maturity Model Assessment (CMMC) by US DoD \\n\\nCMMC is the new Cybersecurity Maturity Model Assessment requirement for all \\nDefense  Industrial  Base  (DIB)  members  that  are  suppliers  to  the  DoD.  All  DIB \\ncompanies will be required to get third-party certification to meet one of five \\nmaturity levels required to submit proposals on government contracts.21 We in-\\nclude this model in the review as it contains the most detailed up-to-date re-\\nquirements and assessment criteria not only for the organization’s resilience but \\n\\n \\n\\x0cAssessing the Maturity of National Cybersecurity and Resilience \\n\\nfor  the  entire  ecosystem  (such  as  national  security  and  defense).  The  model \\nspecifies 17 capability domains with 43 capabilities and 171 practices across five \\nmaturity levels to measure technical capabilities: Performed, Documented, Man-\\naged, Reviewed, Optimizing (somewhat different from the levels in CMMI and \\nCERT-RMM). The logic of the CMMC levels is different, as it provides a means of \\nimproving the alignment of maturity processes and cybersecurity practices with \\nthe sensitivity of the information to be protected and the range of threats. Ac-\\ncordingly, the levels are defined as: \\n\\nLevel 1: Safeguard Federal Contract Information (FCI) \\nLevel 2: Serve as a transition step in the progression to protect CUI \\nLevel 3: Protect Controlled Unclassified Information (CUI) \\nLevels 4-5: Protect CUI and reduce the risk of Advanced Persistent Threats. \\n\\nThe domains correspond to the security-related areas in Federal Information \\nProcessing  Standards  (FIPS)  and  the  related  security  requirements  from  NIST \\nframeworks. The 17 domains are: Access Control; Asset Management; Audit and \\nAccountability; Awareness and Training; Configuration Management; Identifica-\\ntion  and  Authentication;  Incident  Response;  Maintenance;  Media  Protection; \\nPersonnel  Security;  Physical  Protection;  Recovery;  Risk  Management;  Security \\nAssessment;  Situational  Awareness;  System  and  Communications  Protection; \\nSystem and Information Integrity. \\n\\nCyber Resilience Metrics of MITRE  \\n\\nWe briefly cover one more systematic and architectural view of the MITRE meth-\\nodology for assessing cyber resiliency which is based on the Systems-of-Systems \\n(SOS) 22 approach and allows to define and assess the cyber resilience metrics at \\ndifferent levels and scope, going up to national and transnational enterprises: \\n•  At the systems level, including directed systems-of-systems (SoS); \\n•  Missions, including acknowledged SoS within an organization; \\n•  Organizations where the CERT-RMM or the DHS CRR could be applied; \\n• \\nSectors (e.g., critical infrastructure sectors or sub-sectors), regions, and \\nmissions supported by multiple organizations, via collaborative SoS; \\n\\n•  Nations and transnational enterprises supported by virtual SoS. \\n\\nThe proposed metrics can facilitate the development of technical indicators \\nto assess the risks and dependability (thus the possible cascading effects, esca-\\nlating impact) of systems and then prioritize improvement programs.  \\n\\n \\n \\n\\x0cGeorge Sharkov, Connections QJ 19, no. 4 (2020): 5-24 \\n\\nCybersecurity Indexes and Maturity \\n\\nWith the increasing interest and ambition of nations to accelerate improvement \\nprograms and promote their achievements internationally, another instrument \\nof evaluation and ranking countries’ status is the international/global indexes. \\nThere are many indexes established already for decades in areas like information \\nsociety development, digital readiness, internet connectivity, computer literacy, \\netc. ITU published in 2017 an “Index of cybersecurity indices” 23 with the most \\npopular international cybersecurity indexes. We will comment on three of them \\nwith a focus on assessing countries. \\n\\nGlobal Cybersecurity Index (GCI), ITU 24: An assessment framework based on \\nthe Global Cybersecurity Agenda (GCA) of ITU. The GCI measures the commit-\\nment of countries to cybersecurity at a global level. The assessment measures a \\ncountry’s level of development or engagement through a question-based online \\nsurvey  structured  along  five  pillars—Legal  Measures,  Technical  Measures,  Or-\\nganizational Measures, Capacity Building, and Cooperation—using 25 indicators \\nand additional  sub-indicators,  and  then  calculating  an  overall  score.  Since the \\nfirst survey in 2013, GCI promotes cybersecurity initiatives through comparison. \\nThe third issue of GCI (in 2018), covering more than 193 countries and producing \\nthree  regional  reports,  shows  considerable  improvements  in  cybersecurity \\nworldwide, as more countries have cybersecurity strategies, national plans, re-\\nsponse teams, and specific legislation. However, a significant gap between re-\\ngions is still observed. \\n\\nNational Cybersecurity Index (NCSI) 25: Global index, measuring the prepared-\\nness of countries to prevent cyber threats and manage cyber incidents, crime, \\nand crises on a large scale. The Estonian e-Governance Academy develops it in \\ncooperation with the Estonian Foreign Ministry. The index emphasizes the public \\naspects of national cybersecurity implemented by the central government. The \\nindex has 12 main indicators with sub-indicators, divided into three groups: Gen-\\neral  Cyber  Security,  Baseline  Cyber  Security,  Incident  and  Crisis  Management. \\nThe  indicators  have  been tied  to  information society  and  cybersecurity  issues \\nsuch as e-identity, digital signature, and the existence of a secure environment \\nfor e-services. NCSI provides publicly available evidence materials and a tool for \\nnational cybersecurity capacity building. The country ranking is compared to GCI \\n(ITU), the ICT Development Index, and the Networked Readiness Index. \\n\\n \\n \\n\\x0cAssessing the Maturity of National Cybersecurity and Resilience \\n\\nCyber Readiness Index 2.0 (CRI 2.0) 26: Evaluates a nation state’s cyber ma-\\nturity as well as its overall commitment to cyber issues, defines the meaning of \\nbeing “cyber ready” while proposing actionable blueprints to follow. The index \\nuses a set of seven indicators: national strategy, incident response, e-crime and \\nlaw enforcement, information sharing, investment in R&D, diplomacy and trade, \\ndefense, and crisis response. One hundred twenty-five countries were studied, \\nand the methodology is based on similar pillars as those of the ITU’s Global Cy-\\nbersecurity Agenda. Each country is assigned a score, while the addition of mili-\\ntary capabilities goes beyond that covered by the ITU GCI. However, CRI 2.0 does \\nnot offer any ranking despite its scoring mechanism. \\n\\nAlthough  these  and  other  known  indexes  (Kaspersky  Cybersecurity  Index, \\nCyber Maturity in the Asia-Pacific Region, etc.) are quite popular and easy to pro-\\nmote countries, their use as cyber maturity assessment indicators is  doubtful. \\nThe areas and indicators look similar to those of the maturity models, but they \\nlack the rigor and granularity of the maturity levels and the assessments. There \\nare  no  levels,  and improvement  plans  could  not  be  prioritized  and structured \\nwith clear stages and targets. A higher rank in the index could be a success indi-\\ncator, but it is unlikely to be set as a target. The question-based scores depend \\nlargely on the engagement and motivation of local bodies to provide evidence.  \\n\\nFocus on Maturity in National Cybersecurity Strategies \\n\\nThe  focus  on  cybersecurity maturity  is  already  incorporated,  and  maturity  as-\\nsessments are recommended in most of the updated manuals and guidelines for \\nthe development of national cybersecurity strategies. In ENISA’s National Cyber \\nSecurity Strategy (NCSS) Good Practice Guide (updated in 2016) 27 , there are two \\nreferences to maturity and assessments during the lifecycle of strategy develop-\\nment and implementation. To establish baseline security measures, several com-\\nplex aspects should be considered: different levels of maturity among the stake-\\nholders, differences in terms of the operational capacity of each organization, \\nand the different standards existing in each critical sector. Among the actions \\nrecommended is to “Create maturity self-assessment tools and encourage the \\nstakeholder to use them.” According to Recommendation 9: “Enhance capabili-\\nties of the public and private sector,” after baseline requirements have been de-\\nfined, existing capabilities need to be evaluated to identify gaps and deviations. \\nTo develop improvement plans and assess results, governments are advised to \\n“actively support capacity building by publishing national standards,  designing \\ncyber security capability maturity models, promote and encourage the exchange \\nof knowledge…..”  \\n\\n \\n \\n\\x0cGeorge Sharkov, Connections QJ 19, no. 4 (2020): 5-24 \\n\\nNevertheless, a quick review of the national cybersecurity strategies (listed \\non ENISA’s website) shows that the word “maturity” is barely mentioned, and \\n“maturity levels” or models are not referred to. This observation might be in-\\ncomplete, as the issue might be addressed in plans and roadmaps. Some of the \\nmentions of cyber maturity and maturity models are: \\n\\n• \\n\\n•  The UK strategy adopted in 2016 states that the UK Government’s level \\nof support for each sector is defined “taking into account its cyber ma-\\nturity.” A Cyber Assessment Framework (CAF) by NCSC is introduced to \\nguide organizations from vitally important services;28 \\nin the third Cybersecurity  Strategy  of  Estonia  (2019)  a “tested  level  of \\nmaturity” is considered among the main strengths of Estonia. Various ar-\\neas of capabilities and maturity type of indicators are defined, with a de-\\ntailed description of ‘start’ and ‘target’ levels, clear objectives and activ-\\nity areas (which indeed makes it a good example of an actionable strat-\\negy), but no further elaboration on the eventual introduction of “cyber \\nmaturity models” or assessments are covered; \\nthe Cybersecurity Strategy of Lithuania (2018) specifies as its first target \\n“to strengthen cybersecurity in the country and to develop cyber defense \\ncapabilities”; \\nthe strategy of Finland (updated in 2019) recommends that “each admin-\\nistrative branch make its risk assessment and maturity analysis...,” which \\nis further developed in the Implementation Program, where the Secre-\\ntariat of the Security Committee will “carry out a research project to cre-\\nate an updated maturity model and instrumentation for the purpose of \\nmonitoring the status of Finland’s cyber security and the achievement of \\nthe goals … The maturity model and the instruments will be used to pro-\\nvide regular reports on the status …” \\n\\n• \\n\\n• \\n\\nCase Study: Resilience and Maturity in Bulgarian National Cybersecurity \\nStrategy  \\n\\nA maturity-based approach, encouraged mainly by the experience in implement-\\ning the CERT-RMM, was selected in the development of the National Cybersecu-\\n29 Cyber re-\\nrity Strategy in Bulgaria, targeting “Cyber Resilient Bulgaria in 2020.” \\nsilience was defined as a target state upon implementing the strategy. According \\nto the strategy, “the achievement of cyber resilience at national level necessi-\\ntates coordinated activities regarding the security and reliability of all cyberspace \\ncomponents  and  assets:  information, technology,  people  and  facilities,  of  the \\n\\n\\n \\n \\n \\n\\x0cAssessing the Maturity of National Cybersecurity and Resilience \\n\\ndesign and deployment of communication channels and services, their interde-\\npendency and interoperability.” \\n\\nThe strategy has an “actionable architecture” and defines nine domains (ar-\\neas) with several goals per domain and sets of measures (practices) with capa-\\nbilities’ indicators. For the description of ‘maturity,’ a three-layered definition of \\nsecurity in cyberspace is used, based on two well-established aspects30: \\n\\n• \\n\\n• \\n\\nthe implementation of the fundamental ‘triad’ from information secu-\\nrity of Confidentiality, Integrity, and Availability (CIA); \\nthe extent of our knowledge on risks and threats – adapting the “known \\nunknowns”  classification,  coming  from  the  finances  and  structured  in \\nNassim Taleb’s “Black Swan” theory, but also used in other fields, includ-\\ning for national security and cyberspace. \\n\\nThese two aspects helped to structure goals and measures at three levels and \\nintroduce them as a generalized ‘label’ to express the kind of maturity levels not \\nonly of the organizations, but also of the state, ecosystems, community and na-\\ntion. These ‘nested’ levels are briefly outlined as follows: \\n\\n• \\n\\n• \\n\\n• \\n\\nLevel 1 – Information/IT Security (“known knowns”): protect and defend \\ninformation assets and infrastructure against known “CIA threats”;  \\nLevel  2  –  Cybersecurity  (“known  unknowns”):  dealing  with  combined \\nthreats, various advanced persistent threats (APTs), attacks against the \\nreputation of people and organizations, disinformation campaigns, and \\nother unpredictable consequences of the mass migration of activities to \\ncyberspace,  large-scale  information  breaches  (on  a  national, regional, \\nand global scale) requiring enhanced and systematic application of the \\nCIA  concept  to  all  assets  of  the  digital  ecosystem  –  people,  facilities, \\ntechnologies, and information (informal description of the cyber secu-\\nrity); \\nLevel 3 – Cyber Resilience (“unknown unknowns”): preparing for the un-\\nknown: unexpected, unforeseeable threats in cyberspace, dynamically \\nchanging risks and complex impacts with unpredictable implications ne-\\ncessitating flexibility and resilience of systems, processes, and organiza-\\ntions, as well as introducing appropriate requirements when developing \\nand deploying systems and processes – the essential characteristics of \\nthe status of cyber resilience. \\n\\nFurthermore, the strategy implementation phases are defined as achieving \\nthe “maturity levels” and a transition from cybersecurity to cyber resilience for \\nthe entire country, namely: \\n\\n\\n \\n \\n \\n\\x0cGeorge Sharkov, Connections QJ 19, no. 4 (2020): 5-24 \\n\\nPhase 1 – Initiation (“Cyber secure institutions”): Common agreement on the \\npriorities of the National Cybersecurity Strategy and the Roadmap. Adopt a co-\\nordinated  approach  and  establish  a  common  national  cybersecurity  system \\nframework.  Define  the  main  structures  and  core  capacity,  development  pro-\\ncesses, and principles in coordination with key stakeholders. Catch up with NATO \\nand the EU and ensure baseline cybersecurity. Focus on the required basic level \\nof information security and build upon it to achieve cybersecurity at the level of \\nthe individual organizations. Define “cyber crisis” in the National Cybersecurity \\nCoordination  Network.  Conduct  sector-specific  and  cross-sector  exercises  in-\\nvolving entities such as state bodies, businesses, and academia. \\n\\nPhase 2 – Development (“From capacity to capabilities”): Focus on cyber-re-\\nsilient organizations and cyber-secure society, develop a coordinated response \\nto cyber crises at the national level. Continue the prevention activities, institu-\\ntionalize a robust mechanism of interaction and collaboration in case of incidents \\nand  crises.  Monitor  the  overall  “cyber  picture”  (situational  awareness).  Build \\nbasic capabilities for operational and strategic analysis and assessment, opera-\\ntional and technical collaboration with NATO, EU, and other international net-\\nworks. \\n\\nPhase 3 – Maturity (“Cyber resilient society”): Effectively collaborate at the \\noperational and strategic levels on a national and international scale. Based on \\nthe engagement and commitment of all stakeholders, develop advanced joint \\ncapabilities in public, private, and research sectors. Identify niches, and work for \\nleading positions and specialization in the region, EU, and NATO. \\n\\nSubsequently, the national Cybersecurity Act (2018) utilized the “capability \\nlevels” approach to define requirements for essential services and critical infra-\\nstructures. Target capability levels are defined as follows: ‘Baseline’ (correspond-\\ning to cyber hygiene from the NIS Directive), ‘Cybersecure’ (or ‘performed,’ as \\ndefined by the State Agency for National Security), and ‘resilient’ (defined by the \\nMinistry  Defense  in  accordance  to  civil  resilience  plans  and  engagements  to \\nNATO and EU collective defense). \\n\\nAs seen, hybrid threats (like disinformation) have been addressed already in \\n“Level 2 – Cybersecurity,” but a more systematic coverage of the “hybrid influ-\\nence,” especially in the context of increased specific interest in Eastern Europe, \\nis  ongoing  for  the  current  update  of  the  National  Resilience  Strategy  and  a \\nRoadmap, incorporating the new cyber/hybrid influence (also known as ‘cybrid’) \\nto both areas – peoples’ minds and critical infrastructures.31 \\n\\n \\n \\n\\x0cAssessing the Maturity of National Cybersecurity and Resilience \\n\\nCyber Maturity and EU, NATO Strategies \\n\\nThe maturity levels approach was recommended for the incorporation of cyber-\\nsecurity in the “EU Common Security and Defence Policy” (CSDP). In a study per-\\nformed by ENISA and the Science and Technology Options Assessment Panel of \\nthe European Parliament, three aspects of a safer cyber domain in the context \\nof  CSDP  are  considered.32  In  the  area  of  Capacity  Building,  it  is  stated  that to \\nfacilitate capacity building, one has to be able to measure it. The study recom-\\nmends  using  cybersecurity  capacity  models  that  allow  the  development  and \\nmonitoring of cyber capacities and their maturity. The Cybersecurity Capability \\nMaturity Model (CMM of GCSCC) is mentioned. \\n\\nAnother study on EU Financial services discusses the “…degree of digital op-\\nerational  resilience  and  cybersecurity  maturity”  that  needs  to  be  consid-\\nered.33 \\n\\nA novel maturity assessment framework, Cybersecurity Maturity Assessment \\nFramework  (CMAF),  was  recently  proposed  and  implemented  as  a  pilot  in \\nGreece, dedicated to assessing the compliance with the requirements of the NIS \\nDirective. Two main applications of CMAF are foreseen: for self-assessment from \\noperators of essential services and digital service providers (identified according \\nto the  NIS  Directive  as  adopted  by  the Member  States)  or  as  an  auditing tool \\nfrom the competent national authorities for cybersecurity. \\n\\nENISA also provided a CSIRT Maturity Self-assessment Tool 34 to assist the ca-\\n\\npacity and capabilities development of national and sectoral CERTs. \\n\\nIn addition to the highly demanding maturity models introduced for defense \\nacquisitions and military supply chain (like the US DoD CMMC, presented above), \\nNATO uses the maturity levels approach to plan and assess the nations’ cyber \\ndefense  capabilities  development  according  to  the  ongoing  Cyber  Defense \\nPledge.35  \\n\\n\\n \\n \\n \\n\\x0cGeorge Sharkov, Connections QJ 19, no. 4 (2020): 5-24 \\n\\nConclusion \\n\\nTo assess the cybersecurity and cyber resilience of a sector, community, country, \\nor  region,  a  unified  approach  to  define  goals  and  measurement  indicators  is \\nneeded. Capability maturity models provide such a mechanism since they imple-\\nment a similar architecture and regardless of possible differences in scope and \\ndefinitions of domains, they produce comparable scoring of achievements and \\nfacilitate the aggregation of target states. As shown, most of the popular models \\ncould naturally map, which allows organizations to choose the most suitable for \\ntheir  profile  and  business  goals.  At  the  national  level,  assessments  and  plans \\ncould still be effectively developed, as maturity and capability levels have iden-\\ntical meaning. However, this challenges the ‘maturity’ of the maturity models. \\nSince ‘cybersecurity’ covers mainly the ‘protection’ side, resilience must be in-\\ntroduced to complete the protect-sustain cycle. Besides, new areas like cyber-\\nempowered  hybrid threats (named  ‘cybrid’)  should  be introduced, as  none  of \\nthe models studied cover yet these aspects, and “people’s minds are not a sector \\nthat  we  know  how  to  protect.”  Same  for  new  disrupting  technologies  like  AI, \\nQuantum, 5G – the ‘innovation’ capability at higher maturity levels is not suffi-\\ncient, and new domains and indicators will certainly be needed. Maturity models \\nare helpful to align ambition and programs at  a higher level (like EU Member \\nStates, US States, or regions). They are also recommended to attract and involve \\nthe SMEs in the “roadmap to maturity.”  \\n\\nDisclaimer \\nThe views expressed are solely those of the author and do not represent official \\nviews of the PfP Consortium of Defense Academies and Security Studies Insti-\\ntutes, participating organizations, or the Consortium’s editors. \\n\\nAbout the Author \\n\\nGeorge Sharkov is an Adviser to the Minister of Defense and served as a National \\nCybersecurity Coordinator in the period 2014-2017. He led the development of \\nthe National Cybersecurity Strategy of Bulgaria, adopted in 2016. He holds a PhD \\nin Artificial Intelligence and specialization in applied informatics, thermography, \\ngenetics, intelligent financial and security systems. Since 2003, he is the CEO of \\nthe European Software Institute – Center Eastern Europe, Head of the Cyber Re-\\nsilience Lab (CyResLab), and since 2014 leads the Cybersecurity Lab at Sofia Tech \\nPark. E-mail: gesha@esicenter.bg \\n\\n24 \\n\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n\\x0cReproduced with permission of copyright owner.\\n\\nFurther reproduction prohibited without permission.\\n\\n\\x0c\", 'Enabling\\xa0Distributed\\xa0\\nSecurity\\xa0in\\xa0Cyberspace\\xa0\\n\\nBuilding\\xa0a\\xa0Healthy\\xa0and\\xa0Resilient\\xa0Cyber\\xa0\\nEcosystem\\xa0with\\xa0Automated\\xa0Collective\\xa0Action\\xa0\\n\\nMarch\\xa023,\\xa02011\\xa0\\n\\n\\xa0\\n\\xa0\\n\\xa0\\n\\xa0\\n\\xa0\\n\\x0cEnabling\\xa0Distributed\\xa0Security\\xa0in\\xa0Cyberspace\\xa0\\n\\nBuilding\\xa0a\\xa0Healthy\\xa0and\\xa0Resilient\\xa0Cyber\\xa0Ecosystem\\xa0with\\xa0Automated\\xa0Collective\\xa0\\nAction\\xa0\\n\\nExecutive\\xa0Summary\\xa0\\n\\nLike\\xa0natural\\xa0ecosystems,\\xa0the\\xa0cyber\\xa0ecosystem\\xa0comprises\\xa0a\\xa0variety\\xa0of\\xa0diverse\\xa0participants\\xa0–\\xa0\\nprivate\\xa0firms,\\xa0non‐profits,\\xa0governments,\\xa0individuals,\\xa0processes,\\xa0and\\xa0cyber\\xa0devices\\xa0(computers,\\xa0\\nsoftware,\\xa0and\\xa0communications\\xa0technologies)\\xa0–\\xa0that\\xa0interact\\xa0for\\xa0multiple\\xa0purposes.\\xa0\\xa0Today\\xa0in\\xa0\\ncyberspace,\\xa0intelligent\\xa0adversaries\\xa0exploit\\xa0vulnerabilities\\xa0and\\xa0create\\xa0incidents\\xa0that\\xa0propagate\\xa0at\\xa0\\nmachine\\xa0speeds\\xa0to\\xa0steal\\xa0identities,\\xa0resources,\\xa0and\\xa0advantage.\\xa0\\xa0The\\xa0rising\\xa0volume\\xa0and\\xa0virulence\\xa0\\nof\\xa0these\\xa0attacks\\xa0have\\xa0the\\xa0potential\\xa0to\\xa0degrade\\xa0our\\xa0economic\\xa0capacity\\xa0and\\xa0threaten\\xa0basic\\xa0\\nservices\\xa0that\\xa0underpin\\xa0our\\xa0modern\\xa0way\\xa0of\\xa0life.\\xa0\\n\\nThis\\xa0discussion\\xa0paper\\xa0explores\\xa0the\\xa0idea\\xa0of\\xa0a\\xa0healthy,\\xa0resilient\\xa0–\\xa0and\\xa0fundamentally\\xa0more\\xa0secure\\xa0\\n–\\xa0cyber\\xa0ecosystem\\xa0of\\xa0the\\xa0future,\\xa0in\\xa0which\\xa0cyber\\xa0participants,\\xa0including\\xa0cyber\\xa0devices,\\xa0are\\xa0able\\xa0\\nto\\xa0work\\xa0together\\xa0in\\xa0near‐real\\xa0time\\xa0to\\xa0anticipate\\xa0and\\xa0prevent\\xa0cyber\\xa0attacks,\\xa0limit\\xa0the\\xa0spread\\xa0of\\xa0\\nattacks\\xa0across\\xa0participating\\xa0devices,\\xa0minimize\\xa0the\\xa0consequences\\xa0of\\xa0attacks,\\xa0and\\xa0recover\\xa0to\\xa0a\\xa0\\ntrusted\\xa0state.\\xa0\\xa0In\\xa0this\\xa0future\\xa0cyber\\xa0ecosystem,\\xa0security\\xa0capabilities\\xa0are\\xa0built\\xa0into\\xa0cyber\\xa0devices\\xa0in\\xa0\\na\\xa0way\\xa0that\\xa0allows\\xa0preventive\\xa0and\\xa0defensive\\xa0courses\\xa0of\\xa0action\\xa0to\\xa0be\\xa0coordinated\\xa0within\\xa0and\\xa0\\namong\\xa0communities\\xa0of\\xa0devices.\\xa0\\xa0Power\\xa0is\\xa0distributed\\xa0among\\xa0participants,\\xa0and\\xa0near‐real\\xa0time\\xa0\\ncoordination\\xa0is\\xa0enabled\\xa0by\\xa0combining\\xa0the\\xa0innate\\xa0and\\xa0interoperable\\xa0capabilities\\xa0of\\xa0individual\\xa0\\ndevices\\xa0with\\xa0trusted\\xa0information\\xa0exchanges\\xa0and\\xa0shared,\\xa0configurable\\xa0policies.\\xa0\\n\\nTo\\xa0illuminate\\xa0such\\xa0a\\xa0cyber\\xa0ecosystem\\xa0in\\xa0action,\\xa0one\\xa0might\\xa0look\\xa0at\\xa0today’s\\xa0practice\\xa0known\\xa0as\\xa0\\xa0\\xa0\\n“continuous\\xa0monitoring,”\\xa0in\\xa0which\\xa0system\\xa0managers\\xa0use\\xa0a\\xa0variety\\xa0of\\xa0software\\xa0products\\xa0to\\xa0\\nautomatically\\xa0detect\\xa0and\\xa0report\\xa0known\\xa0security\\xa0vulnerabilities\\xa0in\\xa0network\\xa0nodes.\\xa0\\xa0In\\xa0some\\xa0\\ncases,\\xa0system\\xa0managers\\xa0further\\xa0configure\\xa0their\\xa0systems\\xa0to\\xa0automatically\\xa0remediate\\xa0detected\\xa0\\nsecurity\\xa0deficiencies.\\xa0\\xa0To\\xa0offer\\xa0an\\xa0analogy,\\xa0continuous\\xa0monitoring\\xa0is\\xa0to\\xa0a\\xa0healthy\\xa0cyber\\xa0\\necosystem\\xa0as\\xa0smoke\\xa0detectors\\xa0and\\xa0sprinkler\\xa0systems\\xa0are\\xa0to\\xa0a\\xa0“smart”\\xa0building.\\xa0\\n\\nAt\\xa0the\\xa0other\\xa0end\\xa0of\\xa0sophistication\\xa0in\\xa0the\\xa0orderly\\xa0management\\xa0of\\xa0a\\xa0complex\\xa0system,\\xa0we\\xa0draw\\xa0\\ninspiration\\xa0from\\xa0the\\xa0human\\xa0body’s\\xa0immune\\xa0system.\\xa0\\xa0To\\xa0paint\\xa0a\\xa0picture\\xa0that\\xa0mirrors\\xa0the\\xa0body’s\\xa0\\nability\\xa0to\\xa0defend\\xa0itself\\xa0is\\xa0complex.\\xa0\\xa0It\\xa0might\\xa0include\\xa0layered\\xa0defenses\\xa0and\\xa0countermeasures\\xa0that\\xa0\\nwork\\xa0in\\xa0tandem;\\xa0specialized\\xa0roles;\\xa0powerful\\xa0methods\\xa0for\\xa0rapidly\\xa0identifying\\xa0attackers;\\xa0surge\\xa0\\ncapabilities;\\xa0and\\xa0the\\xa0ability\\xa0to\\xa0learn\\xa0and\\xa0rapidly\\xa0adapt.\\xa0\\xa0A\\xa0companion\\xa0analogy\\xa0may\\xa0be\\xa0made\\xa0to\\xa0\\nthe\\xa0public\\xa0health\\xa0system\\xa0and\\xa0the\\xa0Centers\\xa0for\\xa0Disease\\xa0Control\\xa0and\\xa0Prevention\\xa0(CDC).\\xa0\\xa0Here,\\xa0cyber\\xa0\\nequivalent\\xa0functions\\xa0might\\xa0include\\xa0threat\\xa0and\\xa0incident\\xa0watch,\\xa0data\\xa0dissemination,\\xa0threat\\xa0\\nanalysis,\\xa0intervention\\xa0recommendations,\\xa0and\\xa0coordination\\xa0of\\xa0preventive\\xa0actions.\\xa0\\n\\nAutomation\\xa0is\\xa0one\\xa0of\\xa0three\\xa0interdependent\\xa0building\\xa0blocks\\xa0of\\xa0a\\xa0healthy\\xa0cyber\\xa0ecosystem,\\xa0along\\xa0\\nwith\\xa0interoperability\\xa0and\\xa0authentication.\\xa0\\xa0Automation\\xa0can\\xa0increase\\xa0speed\\xa0of\\xa0action,\\xa0optimize\\xa0\\ndecision\\xa0making,\\xa0and\\xa0ease\\xa0adoption\\xa0of\\xa0new\\xa0security\\xa0solutions.\\xa0\\xa0A\\xa0healthy\\xa0cyber\\xa0ecosystem\\xa0\\nmight\\xa0employ\\xa0an\\xa0automation\\xa0strategy\\xa0of\\xa0fixed,\\xa0local\\xa0defenses\\xa0supported\\xa0by\\xa0mobile\\xa0and\\xa0global\\xa0\\ndefenses\\xa0at\\xa0multiple\\xa0levels.\\xa0\\xa0Such\\xa0a\\xa0strategy\\xa0could\\xa0enable\\xa0the\\xa0cyber\\xa0ecosystem\\xa0to\\xa0sustain\\xa0itself\\xa0\\n\\nMarch\\xa023,\\xa02011\\xa0\\n\\n\\xa02\\xa0\\n\\n\\x0cand\\xa0supported\\xa0missions\\xa0while\\xa0fighting\\xa0through\\xa0attacks.\\xa0\\xa0Further,\\xa0it\\xa0could\\xa0enable\\xa0the\\xa0ecosystem\\xa0\\nto\\xa0continuously\\xa0strengthen\\xa0itself\\xa0against\\xa0the\\xa0cyber\\xa0equivalent\\xa0of\\xa0autoimmune\\xa0disorders.\\xa0\\n\\nInteroperability\\xa0can\\xa0broaden\\xa0and\\xa0strengthen\\xa0collaboration,\\xa0create\\xa0new\\xa0intelligence,\\xa0hasten\\xa0and\\xa0\\nspread\\xa0learning,\\xa0and\\xa0improve\\xa0situational\\xa0awareness.\\xa0\\xa0This\\xa0paper\\xa0posits\\xa0three\\xa0types\\xa0of\\xa0\\ninteroperability\\xa0–\\xa0semantic\\xa0(i.e.,\\xa0shared\\xa0lexicon\\xa0based\\xa0on\\xa0common\\xa0understanding),\\xa0technical,\\xa0\\nand\\xa0policy\\xa0–\\xa0as\\xa0fundamental\\xa0to\\xa0integrating\\xa0disparate\\xa0cyber\\xa0participants\\xa0into\\xa0a\\xa0comprehensive\\xa0\\ncyber\\xa0defense\\xa0system.\\xa0\\xa0It\\xa0examines\\xa0how\\xa0the\\xa0cybersecurity\\xa0community\\xa0has\\xa0achieved\\xa0some\\xa0early\\xa0\\nsuccesses\\xa0by\\xa0explicitly\\xa0separating\\xa0the\\xa0management\\xa0of\\xa0security\\xa0information\\xa0from\\xa0the\\xa0\\nmanagement\\xa0of\\xa0security\\xa0functions\\xa0in\\xa0an\\xa0approach\\xa0called\\xa0security\\xa0content\\xa0automation.\\xa0\\xa0Such\\xa0\\nsuccesses\\xa0include:\\xa0developing\\xa0naming\\xa0conventions\\xa0and\\xa0shared\\xa0lists\\xa0and\\xa0catalogs\\xa0of\\xa0the\\xa0\\nfundamental\\xa0elements\\xa0that\\xa0we\\xa0identify\\xa0here\\xa0as\\xa0the\\xa0ecosystem;\\xa0creating\\xa0and\\xa0using\\xa0machine\\xa0\\nreadable\\xa0languages\\xa0and\\xa0formats\\xa0for\\xa0expressing\\xa0security\\xa0policies\\xa0or\\xa0encoding\\xa0security\\xa0\\ntransactions;\\xa0and\\xa0developing\\xa0and\\xa0using\\xa0knowledge\\xa0repositories\\xa0for\\xa0best\\xa0practices,\\xa0benchmarks,\\xa0\\nprofiles,\\xa0standards,\\xa0templates,\\xa0checklists,\\xa0tools,\\xa0guidelines,\\xa0rules\\xa0and\\xa0principles,\\xa0among\\xa0others.\\xa0\\xa0\\nThe\\xa0paper\\xa0also\\xa0looks\\xa0at\\xa0some\\xa0challenges\\xa0associated\\xa0with\\xa0expanding\\xa0this\\xa0approach\\xa0to\\xa0ensure\\xa0a\\xa0\\nwidely\\xa0distributed,\\xa0automated,\\xa0collective\\xa0defense.\\xa0\\xa0\\n\\nAuthentication\\xa0can\\xa0improve\\xa0trust\\xa0in\\xa0ways\\xa0that\\xa0enhance\\xa0privacy\\xa0and\\xa0decision\\xa0making.\\xa0\\xa0It\\xa0is\\xa0\\nintegral\\xa0to\\xa0many\\xa0capabilities\\xa0beyond\\xa0cyber\\xa0defense,\\xa0and\\xa0the\\xa0paper\\xa0looks\\xa0to\\xa0the\\xa0emerging\\xa0\\nNational\\xa0Strategy\\xa0for\\xa0Trusted\\xa0Identities\\xa0in\\xa0Cyberspace\\xa0(NSTIC),\\xa0detailed\\xa0below,\\xa0to\\xa0build\\xa0a\\xa0shared\\xa0\\nfoundation.\\xa0\\xa0The\\xa0paper\\xa0calls\\xa0for\\xa0identification\\xa0and\\xa0authentication\\xa0technologies\\xa0that\\xa0deliver\\xa0\\nacross\\xa0five\\xa0operational\\xa0objectives:\\xa0security,\\xa0affordability,\\xa0ease\\xa0of\\xa0use\\xa0and\\xa0administration,\\xa0\\nscalability,\\xa0and\\xa0interoperability.\\xa0\\xa0Additionally,\\xa0the\\xa0paper\\xa0calls\\xa0for\\xa0consumer\\xa0guides\\xa0that\\xa0rate\\xa0\\ntechnologies\\xa0across\\xa0all\\xa0five\\xa0objectives\\xa0and\\xa0assist\\xa0system\\xa0developers\\xa0and\\xa0owners\\xa0in\\xa0making\\xa0\\nphased\\xa0improvements\\xa0and\\xa0selections.\\xa0\\xa0For\\xa0automated\\xa0cyber\\xa0defense,\\xa0it\\xa0calls\\xa0for\\xa0strong\\xa0\\nstandards‐based\\xa0device\\xa0authentication,\\xa0including\\xa0for\\xa0software,\\xa0handheld\\xa0devices,\\xa0and\\xa0small,\\xa0\\noften\\xa0wireless,\\xa0devices\\xa0composing\\xa0massively\\xa0scalable\\xa0grids.\\xa0\\n\\nThe\\xa0paper\\xa0also\\xa0draws\\xa0on\\xa0current\\xa0research\\xa0on\\xa0network‐enabled\\xa0enterprises\\xa0that\\xa0is\\xa0recasting\\xa0\\ntraditional\\xa0notions\\xa0of\\xa0command\\xa0and\\xa0control\\xa0in\\xa0the\\xa0direction\\xa0of\\xa0focus\\xa0and\\xa0convergence.\\xa0\\xa0Focus\\xa0\\nprovides\\xa0the\\xa0context\\xa0and\\xa0defines\\xa0the\\xa0purposes\\xa0of\\xa0an\\xa0endeavor,\\xa0but\\xa0is\\xa0agnostic\\xa0regarding\\xa0who\\xa0\\nmight\\xa0be\\xa0in\\xa0charge\\xa0or\\xa0particular\\xa0lines\\xa0of\\xa0authority.\\xa0\\xa0Convergence\\xa0refers\\xa0to\\xa0the\\xa0goal‐seeking\\xa0\\nprocess\\xa0that\\xa0guides\\xa0actions\\xa0and\\xa0effects,\\xa0but\\xa0recognizes\\xa0that\\xa0control\\xa0works\\xa0in\\xa0an\\xa0unconventional\\xa0\\nmanner\\xa0in\\xa0highly\\xa0distributed\\xa0systems.\\xa0\\xa0The\\xa0paper\\xa0presents\\xa0a\\xa0five‐level\\xa0maturity\\xa0model\\xa0for\\xa0\\necosystem\\xa0focus\\xa0and\\xa0convergence\\xa0that\\xa0is\\xa0associated\\xa0with\\xa0increasing\\xa0agility\\xa0and\\xa0provides\\xa0an\\xa0\\napproach\\xa0for\\xa0defining\\xa0how\\xa0to\\xa0achieve\\xa0and\\xa0employ\\xa0these\\xa0various\\xa0levels.\\xa0\\xa0Ecosystem\\xa0maturity\\xa0is\\xa0\\nfurther\\xa0explored\\xa0through\\xa0a\\xa0discussion\\xa0of\\xa0healthy\\xa0attributes—eight\\xa0for\\xa0the\\xa0ecosystem\\xa0and\\xa0\\neighteen\\xa0for\\xa0participants\\xa0and\\xa0exchanges.\\xa0\\n\\nThe\\xa0paper\\xa0concludes\\xa0with\\xa0a\\xa0brief\\xa0discussion\\xa0of\\xa0incentives\\xa0and\\xa0recommendations\\xa0for\\xa0the\\xa0way\\xa0\\nahead.\\xa0\\xa0It\\xa0posits\\xa0that\\xa0the\\xa0slow\\xa0adoption\\xa0of\\xa0available\\xa0best\\xa0practices\\xa0and\\xa0technologies\\xa0in\\xa0the\\xa0face\\xa0\\nof\\xa0increasing\\xa0cyber\\xa0attacks\\xa0indicates\\xa0an\\xa0imbalance\\xa0of\\xa0incentives\\xa0and\\xa0proposes\\xa0that\\xa0better\\xa0and\\xa0\\nmore\\xa0widely\\xa0disseminated\\xa0aggregated\\xa0and\\xa0anonymized\\xa0information\\xa0about\\xa0the\\xa0frequency\\xa0and\\xa0\\nactual\\xa0harm\\xa0of\\xa0cyber\\xa0attacks\\xa0is\\xa0needed.\\xa0\\xa0Despite\\xa0the\\xa0many\\xa0open\\xa0questions\\xa0remaining,\\xa0the\\xa0field\\xa0\\nis\\xa0ripe\\xa0for\\xa0planning\\xa0and\\xa0action.\\xa0\\xa0Feedback\\xa0on\\xa0this\\xa0paper\\xa0and\\xa0comment\\xa0on\\xa0all\\xa0aspects\\xa0of\\xa0the\\xa0\\nproblem\\xa0are\\xa0welcome\\xa0at\\xa0cyberfeedback@dhs.gov.\\xa0\\n\\nMarch\\xa023,\\xa02011\\xa0\\n\\n\\xa03\\xa0\\n\\n\\x0cTable\\xa0of\\xa0Contents\\xa0\\n\\nExecutive\\xa0Summary............................................................................................................................... 2\\xa0\\n\\nBackground\\xa0and\\xa0Purpose ...................................................................................................................... 5\\xa0\\n\\nThe\\xa0Case\\xa0for\\xa0a\\xa0More\\xa0Secure\\xa0Cyber\\xa0Ecosystem ..................................................................................... 5\\xa0\\n\\nBuilding\\xa0Blocks\\xa0for\\xa0a\\xa0Healthy\\xa0Cyber\\xa0Ecosystem.................................................................................... 8\\xa0\\n\\nBuilding\\xa0Block\\xa01:\\xa0\\xa0Automation........................................................................................................... 8\\xa0\\n\\nBuilding\\xa0Block\\xa02:\\xa0\\xa0Interoperability................................................................................................... 11\\xa0\\n\\nBuilding\\xa0Block\\xa03:\\xa0\\xa0Authentication.................................................................................................... 17\\xa0\\n\\nKey\\xa0Concepts....................................................................................................................................... 18\\xa0\\n\\nFocus,\\xa0Convergence,\\xa0and\\xa0Maturity ................................................................................................. 18\\xa0\\n\\nAttributes\\xa0of\\xa0a\\xa0Healthy\\xa0Cyber\\xa0Ecosystem ....................................................................................... 22\\xa0\\n\\nAttributes\\xa0of\\xa0Healthy\\xa0Participants .................................................................................................. 24\\xa0\\n\\nIncentives\\xa0and\\xa0Adoption ..................................................................................................................... 26\\xa0\\n\\nWay\\xa0Ahead.......................................................................................................................................... 27\\xa0\\n\\nGlossary............................................................................................................................................... 28\\xa0\\n\\nMarch\\xa023,\\xa02011\\xa0\\n\\n\\xa04\\xa0\\n\\n\\xa0\\n\\xa0\\n\\xa0\\n\\x0cBackground\\xa0and\\xa0Purpose\\xa0\\n\\nThis\\xa0paper\\xa0was\\xa0prepared\\xa0under\\xa0the\\xa0direction\\xa0of\\xa0Philip\\xa0Reitinger,\\xa0Deputy\\xa0Under\\xa0Secretary\\xa0for\\xa0the\\xa0\\nNational\\xa0Protection\\xa0and\\xa0Programs\\xa0Directorate\\xa0(NPPD),\\xa0U.S.\\xa0Department\\xa0of\\xa0Homeland\\xa0Security,\\xa0\\nwith\\xa0support\\xa0from\\xa0the\\xa0NPPD\\xa0Cyber+Strategy\\xa0Staff,\\xa0the\\xa0federally\\xa0funded\\xa0Homeland\\xa0Security\\xa0\\nSystems\\xa0Engineering\\xa0and\\xa0Development\\xa0Institute\\xa0(HS\\xa0SEDI),\\xa0and\\xa0the\\xa0NPPD\\xa0Office\\xa0of\\xa0\\nCybersecurity\\xa0and\\xa0Communications\\xa0(CS&C).\\xa0\\xa0In\\xa02010,\\xa0NPPD\\xa0sponsored\\xa0a\\xa0government\\xa0workshop\\xa0\\nto\\xa0discuss\\xa0a\\xa0draft\\xa0of\\xa0this\\xa0paper.\\xa0\\xa0Recommendations\\xa0from\\xa0that\\xa0workshop\\xa0have\\xa0been\\xa0\\nincorporated.\\xa0\\n\\nThis\\xa0paper\\xa0explores\\xa0a\\xa0future\\xa0–\\xa0a\\xa0“healthy\\xa0cyber\\xa0ecosystem”\\xa0–\\xa0where\\xa0cyber\\xa0devices\\xa0collaborate\\xa0in\\xa0\\nnear‐real\\xa0time\\xa0in\\xa0their\\xa0own\\xa0defense.\\xa0\\xa0In\\xa0this\\xa0future,\\xa0cyber\\xa0devices\\xa0have\\xa0innate\\xa0capabilities\\xa0that\\xa0\\nenable\\xa0them\\xa0to\\xa0work\\xa0together\\xa0to\\xa0anticipate\\xa0and\\xa0prevent\\xa0cyber\\xa0attacks,\\xa0limit\\xa0the\\xa0spread\\xa0of\\xa0\\nattacks\\xa0across\\xa0participating\\xa0devices,\\xa0minimize\\xa0the\\xa0consequences\\xa0of\\xa0attacks,\\xa0and\\xa0recover\\xa0to\\xa0a\\xa0\\ntrusted\\xa0state.\\xa0\\n\\nThis\\xa0paper\\xa0presents\\xa0three\\xa0building\\xa0blocks\\xa0as\\xa0foundational\\xa0for\\xa0a\\xa0healthy\\xa0cyber\\xa0ecosystem:\\xa0\\nautomation,\\xa0interoperability,\\xa0and\\xa0authentication.\\xa0\\xa0The\\xa0paper\\xa0then\\xa0considers\\xa0how\\xa0these\\xa0building\\xa0\\nblocks\\xa0contribute\\xa0to\\xa0ecosystem\\xa0maturity\\xa0and\\xa0explores\\xa0incentives\\xa0for\\xa0creating\\xa0such\\xa0a\\xa0system.\\xa0\\xa0It\\xa0\\nconcludes\\xa0with\\xa0thoughts\\xa0on\\xa0the\\xa0way\\xa0ahead.\\xa0\\n\\nThe\\xa0envisioned\\xa0end‐state\\xa0is\\xa0focused\\xa0specifically\\xa0on\\xa0capabilities\\xa0that\\xa0can\\xa0be\\xa0achieved\\xa0in\\xa0the\\xa0near‐\\xa0\\nand\\xa0mid‐term\\xa0by\\xa0utilizing\\xa0standards‐based\\xa0software\\xa0and\\xa0information\\xa0to\\xa0strengthen\\xa0self‐defense\\xa0\\nthrough\\xa0automated\\xa0collective\\xa0action.\\xa0This\\xa0paper\\xa0is\\xa0meant\\xa0to\\xa0provoke\\xa0discussion\\xa0and\\xa0further\\xa0\\nexploration\\xa0of\\xa0the\\xa0topic.\\xa0\\n\\nThis\\xa0paper\\xa0is\\xa0available\\xa0online\\xa0at\\xa0http://www.dhs.gov/xlibrary/assets/nppd-healthy-cyber-ecosystem.pdf.  \\nComments\\xa0and\\xa0feedback\\xa0are\\xa0welcome,\\xa0and\\xa0may\\xa0be\\xa0directed\\xa0to\\xa0cyberfeedback@dhs.gov.\\xa0\\xa0You\\xa0\\nmay\\xa0also\\xa0contact\\xa0cyberfeedback@dhs.gov\\xa0if\\xa0you\\xa0are\\xa0interested\\xa0in\\xa0hosting\\xa0a\\xa0discussion\\xa0on\\xa0this\\xa0\\ntopic.\\xa0\\n\\nThe\\xa0Case\\xa0for\\xa0a\\xa0More\\xa0Secure\\xa0Cyber\\xa0Ecosystem\\xa0\\n\\nCyber\\xa0attacks\\xa0have\\xa0become\\xa0more\\xa0frequent,\\xa0more\\xa0widespread,\\xa0and\\xa0more\\xa0consequential.\\xa0\\xa0\\nForecasts\\xa0for\\xa02011\\xa0and\\xa0beyond\\xa0project\\xa0continued\\xa0increases\\xa0in\\xa0both\\xa0the\\xa0volume\\xa0and\\xa0virulence\\xa0of\\xa0\\ncyber\\xa0attacks.\\xa0\\xa0These\\xa0mostly\\xa0unattributed\\xa0incidents\\xa0reduce\\xa0the\\xa0availability\\xa0of\\xa0this\\xa0vital\\xa0medium\\xa0\\nfor\\xa0information\\xa0exchange\\xa0and\\xa0impair\\xa0the\\xa0ability\\xa0of\\xa0the\\xa0information\\xa0environment\\xa0to\\xa0be\\xa0a\\xa0mission\\xa0\\nmultiplier\\xa0and\\xa0support\\xa0more\\xa0effective\\xa0and\\xa0efficient\\xa0business\\xa0processes.\\xa0\\xa0Needless\\xa0to\\xa0say,\\xa0an\\xa0\\ninsecure\\xa0environment\\xa0also\\xa0weakens\\xa0the\\xa0privacy\\xa0of\\xa0cyber\\xa0ecosystem\\xa0participants.\\xa0\\n\\nMarch\\xa023,\\xa02011\\xa0\\n\\n\\xa05\\xa0\\n\\n\\xa0\\n\\xa0\\n\\x0cAt\\xa0the\\xa0same\\xa0time,\\xa0the\\xa0Nation\\xa0is\\xa0significantly\\xa0\\nexpanding\\xa0the\\xa0cyber\\xa0capabilities\\xa0that\\xa0power\\xa0\\nits\\xa0economy\\xa0and\\xa0support\\xa0its\\xa0homeland\\xa0and\\xa0\\nnational\\xa0security.\\xa0\\xa0The\\xa0transformations\\xa0being\\xa0\\nundertaken\\xa0in\\xa0the\\xa0financial,\\xa0health\\xa0care,\\xa0\\nenergy,\\xa0transportation,\\xa0homeland\\xa0security,\\xa0\\ndefense,\\xa0and\\xa0intelligence\\xa0sectors\\xa0are\\xa0\\npredicated\\xa0on\\xa0an\\xa0expectation\\xa0that\\xa0cyber\\xa0\\ndevices\\xa0(computers,\\xa0software,\\xa0and\\xa0\\ncommunications\\xa0technologies),\\xa0\\ncommunications\\xa0networks,\\xa0and\\xa0embedded\\xa0\\ncontrol\\xa0systems\\xa0for\\xa0critical\\xa0infrastructures\\xa0will\\xa0\\nbe\\xa0available\\xa0and\\xa0perform\\xa0as\\xa0expected.\\xa0\\xa0(As\\xa0\\nexamples,\\xa0see\\xa0Figures\\xa01\\xa0and\\xa02\\xa0for\\xa0profiles\\xa0of\\xa0\\nThe\\xa0Next\\xa0Generation\\xa0Air\\xa0Transportation\\xa0\\nSystem\\xa0and\\xa0Smart\\xa0Grid.)\\xa0\\n\\nCyber\\xa0defense\\xa0today\\xa0is\\xa0founded\\xa0on\\xa0ad\\xa0hoc,\\xa0\\nmanual\\xa0processes;\\xa0yet\\xa0cyber\\xa0attacks\\xa0often\\xa0\\nfollow\\xa0a\\xa0well\\xa0known,\\xa0systematic\\xa0escalation\\xa0\\npath\\xa0beginning\\xa0with\\xa0reconnaissance\\xa0activities\\xa0\\nand\\xa0extending\\xa0to\\xa0gaining\\xa0entry,\\xa0establishing\\xa0\\npersistence,\\xa0setting\\xa0up\\xa0external\\xa0\\ncommunications\\xa0pathways,\\xa0and\\xa0conducting\\xa0\\nattack\\xa0operations.\\xa0\\xa0If\\xa0cyber\\xa0devices\\xa0\\ncommunicated\\xa0in\\xa0near\\xa0real‐time\\xa0with\\xa0each\\xa0\\nother\\xa0about\\xa0attacks,\\xa0and\\xa0took\\xa0coordinated\\xa0\\nsecurity‐hardening\\xa0response\\xa0actions\\xa0\\nconsistent\\xa0with\\xa0a\\xa0defined\\xa0policy\\xa0framework,\\xa0\\nthen\\xa0critical\\xa0business,\\xa0mission\\xa0and\\xa0privacy\\xa0\\nobjectives\\xa0could\\xa0be\\xa0better\\xa0supported,\\xa0and\\xa0\\nmany\\xa0security\\xa0risks\\xa0could\\xa0be\\xa0managed\\xa0\\nproactively\\xa0and\\xa0dynamically.\\xa0\\xa0Automated\\xa0\\ndefenses\\xa0could\\xa0be\\xa0effective\\xa0at\\xa0the\\xa0earliest,\\xa0\\nleast\\xa0costly\\xa0stage\\xa0of\\xa0the\\xa0lifecycle\\xa0as\\xa0well\\xa0as\\xa0at\\xa0\\nthe\\xa0later\\xa0stages\\xa0of\\xa0an\\xa0attack\\xa0when\\xa0malicious\\xa0\\ncode\\xa0and\\xa0other\\xa0attack\\xa0elements\\xa0propagate\\xa0at\\xa0\\nmachine\\xa0speed.\\xa0\\xa0These\\xa0defenses\\xa0could\\xa0be\\xa0\\neffective\\xa0against\\xa0all\\xa0threats\\xa0including\\xa0financial\\xa0\\nfraud,\\xa0identity\\xa0theft,\\xa0and\\xa0advanced,\\xa0persistent\\xa0\\nthreats\\xa0that\\xa0exploit\\xa0unauthorized\\xa0access\\xa0to\\xa0\\nintellectual\\xa0property\\xa0and\\xa0sensitive\\xa0\\ninformation.\\xa0\\n\\nIn\\xa0January\\xa02003,\\xa0the\\xa0Slammer\\xa0worm\\xa0infected\\xa0\\nsome\\xa0247,000\\xa0Internet\\xa0hosts.\\xa0\\xa0Over\\xa090\\xa0\\n\\nFigure\\xa01:\\xa0\\xa0Next\\xa0Generation\\xa0Air\\xa0Transportation\\xa0System\\xa0\\n\\n(NextGen)\\xa0\\n\\nNextGen\\xa0is\\xa0a\\xa0comprehensive\\xa0overhaul\\xa0of\\xa0U.S.\\xa0national\\xa0airspace\\xa0\\nsystem\\xa0from\\xa0air\\xa0traffic\\xa0control\\xa0to\\xa0air\\xa0traffic\\xa0management\\xa0and\\xa0\\nfrom\\xa0ground‐based\\xa0to\\xa0satellite‐based\\xa0capabilities.\\xa0\\xa0It\\xa0is\\xa0\\nemploying\\xa0continuous\\xa0roll‐out\\xa0of\\xa0improvements\\xa0and\\xa0upgrades\\xa0\\nto\\xa0make\\xa0air\\xa0travel\\xa0more\\xa0convenient\\xa0and\\xa0dependable,\\xa0more\\xa0\\neconomical,\\xa0and\\xa0more\\xa0environmentally\\xa0friendly,\\xa0while\\xa0\\nensuring\\xa0flights\\xa0are\\xa0as\\xa0safe,\\xa0secure\\xa0and\\xa0hassle‐free\\xa0as\\xa0possible.\\xa0\\n\\nNextGen\\xa0offers\\xa0advantages\\xa0to\\xa0all\\xa0stakeholders:\\xa0consumers,\\xa0\\nservice\\xa0providers,\\xa0neighbors\\xa0(e.g.,\\xa0noise\\xa0reduction),\\xa0and\\xa0the\\xa0\\nenvironment.\\xa0\\n\\nThe\\xa0NextGen\\xa0portfolio\\xa0is\\xa0organized\\xa0into\\xa0seven\\xa0solution\\xa0sets,\\xa0\\neach\\xa0focusing\\xa0on\\xa0a\\xa0series\\xa0of\\xa0related\\xa0operational\\xa0changes\\xa0that\\xa0\\ntogether\\xa0will\\xa0bring\\xa0about\\xa0the\\xa0mid‐term\\xa0system.\\xa0\\n\\nThe\\xa0NextGen\\xa0Information\\xa0Systems\\xa0Security\\xa0Architecture\\xa0\\naddresses\\xa0how\\xa0to:\\xa0\\n\\n\\uf0b7 \\n\\nKeep\\xa0the\\xa0Bad\\xa0Stuff\\xa0Out\\xa0(external\\xa0boundary\\xa0\\nprotection\\xa0and\\xa0certified\\xa0software\\xa0management\\xa0\\n\\uf0b7  Make\\xa0Sure\\xa0You\\xa0Know\\xa0To\\xa0Whom\\xa0You\\xa0Are\\xa0Talking\\xa0\\n\\n\\uf0b7 \\n\\n(identity\\xa0and\\xa0key\\xa0management)\\xa0\\nIf\\xa0They\\xa0Get\\xa0In,\\xa0Make\\xa0Sure\\xa0You\\xa0Find\\xa0Them\\xa0and\\xa0Deal\\xa0\\nWith\\xa0the\\xa0Problem\\xa0(intrusion\\xa0detection\\xa0and\\xa0response)\\xa0\\n\\n\\uf0b7  Minimize\\xa0Damage\\xa0Once\\xa0In;\\xa0Don’t\\xa0Let\\xa0it\\xa0Spread\\xa0\\n\\n(internal\\xa0policy\\xa0enforcement)\\xa0\\n\\nhttp://www.faa.gov/nextgen/\\xa0\\n\\nFigure\\xa02:\\xa0Smart\\xa0Grid\\xa0\\n\\nSmart\\xa0Grid\\xa0comprises\\xa0the\\xa0electric\\xa0transmission\\xa0and\\xa0\\ndistribution\\xa0systems\\xa0and\\xa0myriads\\xa0of\\xa0local\\xa0area\\xa0networks\\xa0that\\xa0\\nuse\\xa0distributed\\xa0energy\\xa0resources\\xa0to\\xa0serve\\xa0local\\xa0loads\\xa0and/or\\xa0to\\xa0\\nmeet\\xa0specific\\xa0application\\xa0requirements\\xa0for\\xa0remote\\xa0power,\\xa0\\nvillage\\xa0or\\xa0district\\xa0power,\\xa0premium\\xa0power,\\xa0and\\xa0critical\\xa0loads\\xa0\\nprotection.\\xa0\\n\\nElectric\\xa0grid\\xa0stakeholders\\xa0representing\\xa0utilities,\\xa0technology\\xa0\\nproviders,\\xa0researchers,\\xa0policymakers,\\xa0and\\xa0consumers\\xa0have\\xa0\\nworked\\xa0together\\xa0to\\xa0define\\xa0the\\xa0functions\\xa0of\\xa0a\\xa0smart\\xa0grid,\\xa0and\\xa0\\nthey\\xa0have\\xa0identified\\xa0the\\xa0following\\xa0characteristics\\xa0or\\xa0\\nperformance\\xa0features:\\xa0\\n\\uf0b7 \\n\\uf0b7 \\n\\nSelf‐healing\\xa0from\\xa0power\\xa0disturbance\\xa0events\\xa0\\xa0\\nEnabling\\xa0active\\xa0participation\\xa0by\\xa0consumers\\xa0in\\xa0demand\\xa0\\nresponse\\xa0\\xa0\\n\\n\\uf0b7  Operating\\xa0resiliently\\xa0against\\xa0physical\\xa0and\\xa0cyber\\xa0attack\\xa0\\xa0\\nProviding\\xa0power\\xa0quality\\xa0for\\xa021st\\xa0century\\xa0needs\\xa0\\xa0\\n\\uf0b7 \\n\\uf0b7 \\nAccommodating\\xa0all\\xa0generation\\xa0and\\xa0storage\\xa0options\\xa0\\xa0\\n\\uf0b7 \\nEnabling\\xa0new\\xa0products,\\xa0services,\\xa0and\\xa0markets\\xa0\\xa0\\n\\uf0b7  Optimizing\\xa0assets\\xa0and\\xa0operating\\xa0efficiently\\xa0\\n\\nhttp://www.oe.energy.gov/smartgrid.htm\\xa0\\xa0\\n\\nMarch\\xa023,\\xa02011\\xa0\\n\\n\\xa06\\xa0\\n\\n\\x0cpercent\\xa0of\\xa0the\\xa0infections\\xa0occurred\\xa0within\\xa010\\xa0minutes\\xa0of\\xa0release,\\xa0and\\xa0the\\xa0worm\\xa0achieved\\xa0its\\xa0full\\xa0\\nscanning\\xa0rate\\xa0(over\\xa055\\xa0million\\xa0scans\\xa0per\\xa0second)\\xa0in\\xa0approximately\\xa03\\xa0minutes.\\xa0\\xa0While\\xa0Slammer\\xa0\\ndid\\xa0not\\xa0carry\\xa0a\\xa0malicious\\xa0payload,\\xa0the\\xa0volume\\xa0of\\xa0traffic\\xa0it\\xa0produced\\xa0swamped\\xa0networks,\\xa0causing\\xa0\\ndisconnected\\xa0ATMs\\xa0(over\\xa013,000\\xa0reported\\xa0by\\xa0a\\xa0single\\xa0bank),\\xa0cancelled\\xa0airline\\xa0flights,\\xa0and\\xa0\\ndisrupted\\xa0elections\\xa0and\\xa0911\\xa0services.\\xa0\\xa0Clean\\xa0up\\xa0costs\\xa0world‐wide\\xa0were\\xa0estimated\\xa0at\\xa0between\\xa0\\n$750\\xa0million\\xa0and\\xa0$1.2\\xa0billion1 2\\xa0.\\xa0\\xa0Recently,\\xa0more\\xa0highly\\xa0sophisticated\\xa0and\\xa0targeted\\xa0attacks\\xa0have\\xa0\\nbeen\\xa0regularly\\xa0reported.\\xa0\\n\\nImagine\\xa0a\\xa0future\\xa0where\\xa0cyber\\xa0devices\\xa0have\\xa0an\\xa0innate\\xa0ability\\xa0to\\xa0correlate\\xa0operational\\xa0\\ninformation\\xa0and\\xa0to\\xa0deduce\\xa0that\\xa0a\\xa0device\\xa0in\\xa0their\\xa0domain\\xa0has\\xa0been\\xa0infected\\xa0with\\xa0possible\\xa0\\nmalware.\\xa0\\xa0One\\xa0indicator\\xa0might\\xa0be\\xa0an\\xa0unusually\\xa0high\\xa0number\\xa0of\\xa0random\\xa0connection\\xa0requests\\xa0\\nand\\xa0a\\xa0corresponding\\xa0high\\xa0failure\\xa0rate.\\xa0\\xa0The\\xa0scenario:\\xa0\\xa0\\xa0\\n\\n\\uf0b7  A\\xa0healthy\\xa0device\\xa0detects\\xa0an\\xa0infection\\xa0in\\xa0another\\xa0device.\\xa0\\xa0(A\\xa0discussion\\xa0of\\xa0healthy\\xa0\\nparticipants\\xa0–\\xa0persons,\\xa0devices,\\xa0and\\xa0processes\\xa0–\\xa0is\\xa0provided\\xa0later\\xa0in\\xa0\\xa0this\\xa0paper);\\xa0\\n\\uf0b7  The\\xa0device\\xa0stops\\xa0receiving\\xa0and\\xa0forwarding\\xa0messages\\xa0from\\xa0the\\xa0infected\\xa0source\\xa0and\\xa0\\ninforms\\xa0surrounding\\xa0healthy\\xa0devices\\xa0about\\xa0the\\xa0identity\\xa0of\\xa0the\\xa0suspected\\xa0threat;\\xa0\\xa0\\xa0\\n\\uf0b7  Healthy\\xa0devices\\xa0receiving\\xa0the\\xa0threat\\xa0alert\\xa0employ\\xa0a\\xa0threshold\\xa0defense\\xa0to\\xa0minimize\\xa0the\\xa0\\nrisk\\xa0of\\xa0false\\xa0alarms\\xa0–\\xa0that\\xa0is,\\xa0they\\xa0defer\\xa0action\\xa0until\\xa0alerts\\xa0are\\xa0received\\xa0from\\xa0some\\xa0pre‐\\ndetermined\\xa0number\\xa0of\\xa0independent\\xa0devices;\\xa0\\n\\n\\uf0b7  The\\xa0alert\\xa0threshold\\xa0is\\xa0reached,\\xa0and\\xa0participating\\xa0healthy\\xa0devices\\xa0stop\\xa0receiving\\xa0and\\xa0\\nforwarding\\xa0messages\\xa0from\\xa0the\\xa0infected\\xa0device,\\xa0effectively\\xa0neutralizing\\xa0its\\xa0ability\\xa0to\\xa0\\nspread\\xa0the\\xa0infection;\\xa0and\\xa0finally\\xa0\\n\\n\\uf0b7  Communications\\xa0are\\xa0re‐established\\xa0when\\xa0the\\xa0infected\\xa0devices\\xa0are\\xa0cleaned.\\xa0\\n\\nSome\\xa0simulations3\\xa04\\xa0indicate\\xa0that\\xa0about\\xa030\\xa0to\\xa035\\xa0percent\\xa0of\\xa0devices\\xa0would\\xa0need\\xa0to\\xa0cooperate\\xa0in\\xa0\\norder\\xa0for\\xa0such\\xa0a\\xa0course\\xa0of\\xa0action\\xa0to\\xa0work.\\xa0\\xa0These\\xa0numbers\\xa0are\\xa0important,\\xa0because\\xa0they\\xa0indicate\\xa0\\nthat\\xa0success\\xa0is\\xa0not\\xa0dependent\\xa0on\\xa0the\\xa0participation\\xa0of\\xa0all\\xa0or\\xa0even\\xa0a\\xa0majority\\xa0of\\xa0devices;\\xa0\\ntherefore,\\xa0large‐scale\\xa0infrastructure\\xa0modification\\xa0is\\xa0not\\xa0required\\xa0to\\xa0make\\xa0the\\xa0ecosystem\\xa0\\nfundamentally\\xa0more\\xa0secure.\\xa05\\xa0\\n\\nThe\\xa0defenses\\xa0present\\xa0in\\xa0a\\xa0healthy\\xa0cyber\\xa0ecosystem\\xa0could\\xa0intervene\\xa0at\\xa0essentially\\xa0any\\xa0point\\xa0\\nduring\\xa0complex\\xa0attacks.\\xa0\\xa0For\\xa0example,\\xa0an\\xa0alert\\xa0could\\xa0come\\xa0from\\xa0trusted\\xa0and\\xa0authenticated\\xa0\\nsources\\xa0such\\xa0as\\xa0other\\xa0devices\\xa0inside\\xa0the\\xa0infrastructure\\xa0that\\xa0detect\\xa0anomalous\\xa0behavior,\\xa0\\nanother\\xa0company\\xa0or\\xa0entity\\xa0under\\xa0attack,\\xa0a\\xa0monitoring\\xa0service,\\xa0or\\xa0the\\xa0United\\xa0States\\xa0Computer\\xa0\\n\\n\\n\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\n\\xa0\\n\\x0cEmergency\\xa0Readiness\\xa0Team\\xa0(US‐CERT).\\xa0\\xa0If\\xa0from\\xa0an\\xa0external\\xa0source,\\xa0the\\xa0alert\\xa0could\\xa0come\\xa0directly\\xa0\\ninto\\xa0an\\xa0entity’s\\xa0systems\\xa0and\\xa0in\\xa0a\\xa0format\\xa0such\\xa0as\\xa0eXtended\\xa0Markup\\xa0Language\\xa0(XML)\\xa0that\\xa0cyber\\xa0\\ndevices\\xa0could\\xa0read.\\xa0\\xa0In\\xa0response\\xa0to\\xa0the\\xa0alert,\\xa0the\\xa0infrastructure\\xa0could\\xa0automatically\\xa0check\\xa0itself\\xa0\\nthen\\xa0notify\\xa0officials\\xa0of\\xa0the\\xa0exact\\xa0location\\xa0and\\xa0extent\\xa0of\\xa0compromise\\xa0or\\xa0of\\xa0susceptibility\\xa0to\\xa0a\\xa0\\npotential\\xa0attack.\\xa0\\xa0In\\xa0response,\\xa0a\\xa0digital\\xa0policy\\xa0(i.e.,\\xa0machine\\xa0instructions)\\xa0could\\xa0be\\xa0deployed\\xa0to\\xa0\\ntake\\xa0infected\\xa0devices\\xa0offline,\\xa0change\\xa0the\\xa0configuration\\xa0of\\xa0healthy\\xa0devices\\xa0to\\xa0harden\\xa0them\\xa0\\nagainst\\xa0potential\\xa0attack,\\xa0block\\xa0the\\xa0incoming\\xa0malware,\\xa0or\\xa0block\\xa0outbound\\xa0traffic\\xa0to\\xa0the\\xa0receiving\\xa0\\nsite(s).\\xa0\\xa0Immediately\\xa0upon\\xa0detection\\xa0of\\xa0a\\xa0compromise,\\xa0a\\xa0digital\\xa0policy\\xa0could\\xa0be\\xa0deployed\\xa0to\\xa0alert\\xa0\\nothers\\xa0of\\xa0the\\xa0situation\\xa0and\\xa0begin\\xa0sharing\\xa0discoveries\\xa0in\\xa0an\\xa0information\\xa0exchange\\xa0format\\xa0that\\xa0\\ncould\\xa0be\\xa0authenticated\\xa0and\\xa0automatically\\xa0fed\\xa0into\\xa0cyber\\xa0devices\\xa0in\\xa0other\\xa0cyber\\xa0infrastructures.\\xa0\\n\\nA\\xa0healthy\\xa0cyber\\xa0ecosystem\\xa0would\\xa0interoperate\\xa0broadly,\\xa0collaborate\\xa0effectively\\xa0in\\xa0a\\xa0distributed\\xa0\\nenvironment,\\xa0respond\\xa0with\\xa0agility,\\xa0and\\xa0recover\\xa0rapidly.\\xa0\\xa0With\\xa0a\\xa0rich\\xa0web\\xa0of\\xa0security\\xa0\\npartnerships,\\xa0shared\\xa0strategies,\\xa0preapproved\\xa0and\\xa0prepositioned\\xa0digital\\xa0policies,\\xa0interoperable\\xa0\\ninformation\\xa0exchanges,\\xa0and\\xa0“healthy”\\xa0participants\\xa0–\\xa0persons,\\xa0devices,\\xa0and\\xa0processes\\xa0–\\xa0a\\xa0\\nhealthy\\xa0cyber\\xa0ecosystem\\xa0could\\xa0defend\\xa0against\\xa0a\\xa0full\\xa0spectrum\\xa0of\\xa0known\\xa0and\\xa0emerging\\xa0threats,\\xa0\\nincluding\\xa0attacks\\xa0against\\xa0the\\xa0supply\\xa0chain,\\xa0remote\\xa0network‐based\\xa0attacks,\\xa0proximate\\xa0or\\xa0physical\\xa0\\nattacks,\\xa0and\\xa0insider\\xa0attacks;\\xa0\\xa0improve\\xa0the\\xa0reliability\\xa0and\\xa0resilience\\xa0of\\xa0critical\\xa0infrastructures;\\xa0and\\xa0\\nbetter\\xa0assure\\xa0privacy,\\xa0business\\xa0processes,\\xa0and\\xa0missions.\\xa0\\xa0\\n\\nBuilding\\xa0Blocks\\xa0for\\xa0a\\xa0Healthy\\xa0Cyber\\xa0Ecosystem\\xa0\\n\\nBuilding\\xa0Block\\xa01:\\xa0\\xa0Automation\\xa0\\n\\nAutomated\\xa0Courses\\xa0of\\xa0Action\\xa0(ACOAs)\\xa0are\\xa0strategies\\xa0that\\xa0incorporate\\xa0decisions\\xa0made\\xa0and\\xa0\\nactions\\xa0taken\\xa0in\\xa0response\\xa0to\\xa0cyber\\xa0situations.\\xa0\\xa0Automation\\xa0frees\\xa0humans\\xa0to\\xa0do\\xa0what\\xa0they\\xa0do\\xa0\\nwell\\xa0–\\xa0think,\\xa0ask\\xa0questions,\\xa0and\\xa0make\\xa0judgments\\xa0about\\xa0complex\\xa0situations.\\xa0\\xa0Automation\\xa0allows\\xa0\\nthe\\xa0speed\\xa0of\\xa0response\\xa0to\\xa0approach\\xa0the\\xa0speed\\xa0of\\xa0attack,\\xa0rather\\xa0than\\xa0relying\\xa0on\\xa0human\\xa0responses\\xa0\\nto\\xa0attacks\\xa0that\\xa0are\\xa0occurring\\xa0at\\xa0machine\\xa0speed.\\xa0\\xa0With\\xa0the\\xa0ability\\xa0to\\xa0execute\\xa0at\\xa0machine\\xa0speed,\\xa0\\ndefenders\\xa0could\\xa0get\\xa0inside\\xa0the\\xa0turning\\xa0circles\\xa0or\\xa0decision\\xa0cycles\\xa0of\\xa0attackers.\\xa0\\xa0Further,\\xa0\\nautomation\\xa0could\\xa0make\\xa0it\\xa0easier\\xa0to\\xa0adopt\\xa0and\\xa0adapt\\xa0new\\xa0or\\xa0proven\\xa0security\\xa0solutions.\\xa0\\nOne\\xa0potential\\xa0inspiration\\xa0for\\xa0ACOAs\\xa0is\\xa0the\\xa0human\\xa0immune\\xa0system,\\xa0illustrated\\xa0in\\xa0Figure\\xa03.6\\xa0\\n\\n\\n\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\n\\xa0\\n\\x0cFigure\\xa03:\\xa0\\xa0Overview\\xa0of\\xa0Human\\xa0Immune\\xa0System\\xa0\\n\\nEntry\\xa0Points\\xa0(e.g.,\\xa0eyes,\\xa0mouth,\\xa0\\nnose)\\n1. Traps\\xa0and\\xa0filters\\xa0(e.g.,\\xa0mucus,\\xa0\\n\\n2\\n\\nmast\\xa0cells)\\n\\n2. Detection\\xa0and\\xa0early\\xa0warning\\xa0\\n\\n(smell,\\xa0taste)\\n\\n3. Anti‐pathogenic\\xa0properties\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\n\\n(\\xa0e.g.,\\xa0tears,\\xa0saliva)\\n\\nSkin\\n1. Encapsulating\\xa0physical\\xa0barrier\\n2. Detection\\xa0and\\xa0early\\xa0warning\\xa0\\n\\n1\\n\\n(touch)\\n\\n3. Anti‐bacterial\\xa0\\xa0and\\xa0anti‐fungal\\xa0\\n\\nproperties\\xa0(e.g.,\\xa0acids)\\n\\n3\\n\\nInternal\\xa0System\\xa0(defenders\\xa0and\\xa0signaling)\\n1. Defenders\\xa0are\\xa0specialists:\\xa0patrollers,\\xa0killers,\\xa0\\n\\ncleaners,\\xa0or\\xa0helpers\\n\\n2. All\\xa0cells\\xa0that\\xa0are\\xa0part\\xa0of\\xa0the\\xa0body\\xa0(self)\\xa0present\\xa0\\n\\nan\\xa0identifier\\xa0that\\xa0is\\xa0known\\xa0to\\xa0defenders\\n\\n3. Patrollers\\xa0detect\\xa0and\\xa0counter\\xa0invaders\\xa0‐‐ cells\\xa0\\nthat\\xa0don’t\\xa0present\\xa0a\\xa0known\\xa0good\\xa0identifier\\xa0or\\xa0\\nthat\\xa0have\\xa0a\\xa0known\\xa0bad\\xa0identifier\\xa0(antigen)\\n4. Countermeasures\\xa0may\\xa0disable\\xa0toxic\\xa0chemical\\xa0\\naction,\\xa0prevent\\xa0movement\\xa0across\\xa0cell\\xa0walls,\\xa0or\\xa0\\ndestroy\\xa0the\\xa0invader\\n\\n5. Helpers\\xa0sound\\xa0the\\xa0alert\\xa0and\\xa0activate\\xa0rapid\\xa0\\nproduction\\xa0of\\xa0more\\xa0patrollers\\xa0and\\xa0killers\\n6. Helpers\\xa0guide\\xa0killers\\xa0and\\xa0cleaners\\xa0to\\xa0the\\xa0\\n\\ndetection\\xa0site\\n\\n7. Patrollers,\\xa0killers,\\xa0and\\xa0cleaners\\xa0also\\xa0flood\\xa0the\\xa0\\nbloodstream,\\xa0looking\\xa0for\\xa0any\\xa0other\\xa0antigens\\n\\n8. Helpers\\xa0may\\xa0activate\\xa0supplementary\\xa0kill\\xa0\\n\\nmechanisms\\xa0(e.g.\\xa0fever)\\n\\n9. Killers\\xa0cause\\xa0invaders\\xa0and\\xa0infected\\xa0cells\\xa0to\\xa0die\\xa0\\n\\nand\\xa0cleaners\\xa0engulf\\xa0them\\n\\n10.Specialized\\xa0patrollers\\xa0and\\xa0killers\\xa0that\\xa0are\\xa0\\nprimed\\xa0with\\xa0the\\xa0invader’s\\xa0identifier\\xa0are\\xa0\\nproduced\\xa0to\\xa0“remember”\\xa0and\\xa0protect\\xa0against\\xa0\\nfuture\\xa0invasions\\n\\nThe\\xa0internal\\xa0system\\xa0is\\xa0actually\\xa0two\\xa0interrelated\\xa0systems:\\xa0one\\xa0that\\xa0is\\xa0stationary\\xa0and\\xa0local\\xa0to\\xa0cells\\xa0\\n(cell\\xa0mediated)\\xa0and\\xa0one\\xa0that\\xa0is\\xa0global\\xa0to\\xa0the\\xa0entire\\xa0body,\\xa0moving\\xa0throughout\\xa0it\\xa0via\\xa0the\\xa0\\nbloodstream\\xa0and\\xa0lymph\\xa0systems\\xa0(humoral).\\xa0\\xa0Each\\xa0of\\xa0these\\xa0interrelated\\xa0systems\\xa0has\\xa0its\\xa0own\\xa0locus\\xa0\\nfor\\xa0sustainment\\xa0(e.g.,\\xa0thymus,\\xa0bone\\xa0marrow)\\xa0and\\xa0sophisticated\\xa0mechanisms\\xa0for\\xa0synchronized\\xa0\\nactivity.7\\xa08\\xa0\\n\\nA\\xa0healthy\\xa0cyber\\xa0ecosystem\\xa0might\\xa0employ\\xa0an\\xa0automation\\xa0strategy\\xa0of\\xa0fixed\\xa0local\\xa0defenses\\xa0\\nsupported\\xa0by\\xa0mobile\\xa0and\\xa0global\\xa0defenses\\xa0at\\xa0multiple\\xa0levels.\\xa0\\xa0Such\\xa0a\\xa0strategy\\xa0could\\xa0enable\\xa0the\\xa0\\ncyber\\xa0ecosystem\\xa0to\\xa0sustain\\xa0itself\\xa0and\\xa0supported\\xa0missions\\xa0while\\xa0fighting\\xa0through\\xa0attacks.\\xa0\\xa0\\nFurther\\xa0it\\xa0could\\xa0enable\\xa0the\\xa0ecosystem\\xa0to\\xa0continuously\\xa0strengthen\\xa0itself\\xa0against\\xa0the\\xa0cyber\\xa0\\nequivalent\\xa0of\\xa0autoimmune\\xa0disorders.\\xa0\\xa0For\\xa0example,\\xa0within\\xa0an\\xa0organization,\\xa0cyber\\xa0devices\\xa0that\\xa0\\ndirectly\\xa0provide\\xa0end\\xa0user,\\xa0mission,\\xa0or\\xa0business\\xa0functionality\\xa0might\\xa0maintain\\xa0a\\xa0high\\xa0awareness\\xa0of\\xa0\\nuser\\xa0behavior,\\xa0expectations,\\xa0and\\xa0service\\xa0level\\xa0agreements,\\xa0be\\xa0tuned\\xa0to\\xa0sense\\xa0and\\xa0respond\\xa0to\\xa0\\nuser\\xa0situations,\\xa0signal\\xa0local\\xa0or\\xa0user\\xa0level\\xa0status\\xa0to\\xa0organizational\\xa0devices,\\xa0and\\xa0correlate\\xa0\\ndiscoveries\\xa0and\\xa0synchronize\\xa0responses\\xa0with\\xa0organizational\\xa0devices.\\xa0\\n\\n\\xa0\\n\\xa0\\n\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\n\\x0cCyber\\xa0devices\\xa0that\\xa0provide\\xa0or\\xa0manage\\xa0organization‐wide\\xa0connectivity\\xa0and\\xa0services\\xa0might\\xa0be\\xa0\\ntuned\\xa0to\\xa0sense\\xa0and\\xa0respond\\xa0to\\xa0organizational\\xa0situations,\\xa0signal\\xa0organizational\\xa0status\\xa0to\\xa0user\\xa0\\nlevel\\xa0devices,\\xa0correlate\\xa0discoveries\\xa0and\\xa0synchronize\\xa0responses\\xa0with\\xa0user\\xa0level\\xa0devices,\\xa0and\\xa0\\nprovide\\xa0support\\xa0or\\xa0augmentation\\xa0to\\xa0user\\xa0situations.\\xa0\\xa0Enforcement\\xa0of\\xa0organizational\\xa0policies\\xa0\\nsuch\\xa0as\\xa0privacy\\xa0protection\\xa0could\\xa0be\\xa0synchronized\\xa0across\\xa0user\\xa0and\\xa0organizational\\xa0levels.\\xa0\\n\\nIn\\xa0addition\\xa0to\\xa0the\\xa0ability\\xa0to\\xa0signal\\xa0and\\xa0synchronize\\xa0across\\xa0levels,\\xa0each\\xa0level\\xa0could\\xa0have\\xa0internal\\xa0\\nsynchronization\\xa0and\\xa0analysis\\xa0capabilities.\\xa0\\xa0For\\xa0example,\\xa0all\\xa0devices\\xa0supporting\\xa0users,\\xa0or\\xa0classes\\xa0\\nof\\xa0users,\\xa0could\\xa0share\\xa0a\\xa0focus\\xa0and\\xa0convergence\\xa0approach\\xa0that\\xa0would\\xa0include\\xa0security\\xa0policies\\xa0\\nand\\xa0pooled\\xa0analytic\\xa0resources,\\xa0as\\xa0could\\xa0all\\xa0devices\\xa0supporting\\xa0organizational\\xa0services\\xa0or\\xa0classes\\xa0\\nof\\xa0services.\\xa0\\xa0In\\xa0turn,\\xa0an\\xa0organization\\xa0could\\xa0share\\xa0information\\xa0and\\xa0coordinate\\xa0activities\\xa0or\\xa0\\nsynchronize\\xa0ACOAs\\xa0with\\xa0a\\xa0larger\\xa0business,\\xa0political,\\xa0or\\xa0geographic\\xa0domain,\\xa0or\\xa0with\\xa0the\\xa0world‐\\nwide\\xa0cyber\\xa0environment.\\xa0\\n\\nCyber\\xa0devices\\xa0endowed\\xa0with\\xa0strong\\xa0feed\\xa0forward\\xa0and\\xa0feedback\\xa0signaling\\xa0mechanisms\\xa0that\\xa0\\nassume\\xa0and\\xa0can\\xa0accommodate\\xa0communications\\xa0failures\\xa0and\\xa0operating\\xa0in\\xa0an\\xa0environment\\xa0with\\xa0\\ntrusted\\xa0end‐to‐end\\xa0identification\\xa0and\\xa0authentication\\xa0of\\xa0all\\xa0participants\\xa0would\\xa0enjoy\\xa0a\\xa0\\nheightened\\xa0ability\\xa0to\\xa0observe,\\xa0record,\\xa0and\\xa0share\\xa0what\\xa0is\\xa0happening\\xa0to\\xa0and\\xa0around\\xa0them.\\xa0\\xa0In\\xa0\\nturn,\\xa0they\\xa0could:\\xa0\\n\\n\\uf0b7  Proactively\\xa0take\\xa0preventive\\xa0measures;\\xa0\\n\\n\\uf0b7  Reject\\xa0requests\\xa0that\\xa0do\\xa0not\\xa0fit\\xa0the\\xa0profile\\xa0of\\xa0what\\xa0is\\xa0good,\\xa0a\\xa0priori,\\xa0for\\xa0themselves\\xa0or\\xa0the\\xa0\\n\\nlarger\\xa0cyber\\xa0environment;\\xa0\\n\\n\\uf0b7  Sense\\xa0malicious\\xa0actors\\xa0and\\xa0autonomously\\xa0refine\\xa0the\\xa0evidence\\xa0captured\\xa0for\\xa0diagnosis\\xa0or\\xa0\\n\\nin\\xa0support\\xa0of\\xa0the\\xa0development\\xa0of\\xa0future\\xa0prevention\\xa0methods;\\xa0and\\xa0\\n\\n\\uf0b7  Autonomously\\xa0enact\\xa0defensive\\xa0responses\\xa0or\\xa0even\\xa0build\\xa0such\\xa0responses\\xa0in\\xa0real\\xa0time.9\\xa0\\xa0\\n\\nA\\xa0companion\\xa0source\\xa0of\\xa0inspiration\\xa0for\\xa0ACOAs\\xa0comes\\xa0from\\xa0the\\xa0public\\xa0health\\xa0sector,\\xa0although\\xa0for\\xa0\\nmany\\xa0processes\\xa0in\\xa0this\\xa0domain,\\xa0automation\\xa0is\\xa0some\\xa0distance\\xa0away.\\xa0\\xa0Public\\xa0health\\xa0services\\xa0\\nconduct\\xa0population\\xa0health\\xa0surveillance\\xa0and\\xa0react\\xa0to\\xa0threats\\xa0to\\xa0the\\xa0overall\\xa0health\\xa0of\\xa0\\ncommunities.\\xa0\\xa0The\\xa0stated\\xa0mission\\xa0of\\xa0the\\xa0Centers\\xa0for\\xa0Disease\\xa0Prevention\\xa0and\\xa0Control\\xa0(CDC)\\xa0is:\\xa0\\n“to\\xa0collaborate\\xa0to\\xa0create\\xa0the\\xa0expertise,\\xa0information,\\xa0and\\xa0tools\\xa0that\\xa0people\\xa0and\\xa0communities\\xa0\\nneed\\xa0to\\xa0protect\\xa0their\\xa0health\\xa0–\\xa0through\\xa0health\\xa0promotion,\\xa0prevention\\xa0of\\xa0disease,\\xa0injury\\xa0and\\xa0\\ndisability,\\xa0and\\xa0preparedness\\xa0for\\xa0new\\xa0health\\xa0threats.”10\\xa0\\xa0The\\xa0cyber\\xa0equivalent\\xa0of\\xa0a\\xa0CDC\\xa0might\\xa0\\nperform\\xa0functions\\xa0such\\xa0as\\xa0the\\xa0following:\\xa0\\n\\n\\uf0b7  Watch:\\xa0Gather\\xa0data\\xa0on\\xa0cyber\\xa0threats\\xa0and\\xa0cybersecurity\\xa0outbreaks\\xa0that\\xa0are\\xa0analogous\\xa0to\\xa0\\n\\nthe\\xa0information\\xa0about\\xa0diseases\\xa0reported\\xa0by\\xa0health\\xa0care\\xa0providers.\\xa0\\xa0\\n\\n\\uf0b7  Data\\xa0dissemination:\\xa0Provide\\xa0data\\xa0about\\xa0the\\xa0spread\\xa0and\\xa0danger\\xa0of\\xa0threats\\xa0to\\xa0help\\xa0\\n\\ncommunities\\xa0and\\xa0organizations\\xa0plan\\xa0protective\\xa0measures\\xa0and\\xa0responses.\\xa0\\n\\n\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\n\\xa0\\n\\x0c\\uf0b7  Cyber\\xa0threat\\xa0analysis:\\xa0Investigate\\xa0and\\xa0diagnose\\xa0cyber\\xa0threats\\xa0in\\xa0the\\xa0community.\\xa0\\xa0Where\\xa0\\npossible,\\xa0verify\\xa0outbreaks\\xa0of\\xa0new\\xa0cyber‐threats\\xa0and\\xa0understand\\xa0the\\xa0causes,\\xa0extent\\xa0and\\xa0\\nimpact\\xa0of\\xa0these\\xa0outbreaks.\\xa0\\xa0\\n\\n\\uf0b7 \\n\\nIntervention\\xa0analysis\\xa0and\\xa0recommendations:\\xa0Provide\\xa0a\\xa0cost/benefit\\xa0analysis\\xa0of\\xa0potential\\xa0\\ninterventions\\xa0and\\xa0make\\xa0recommendations.\\xa0\\xa0\\n\\n\\uf0b7  Coordination\\xa0of\\xa0preventive\\xa0actions:\\xa0Coordinate\\xa0response\\xa0strategies\\xa0and\\xa0their\\xa0execution,\\xa0\\n\\nfor\\xa0example,\\xa0the\\xa0equivalent\\xa0of\\xa0quarantining\\xa0and\\xa0vaccination\\xa0strategies\\xa0or\\xa0cyber\\xa0\\npatrolling\\xa0for\\xa0fraud.11\\xa0\\n\\nBuilding\\xa0Block\\xa02:\\xa0\\xa0Interoperability\\xa0\\n\\nInteroperability\\xa0allows\\xa0cyber\\xa0communities\\xa0to\\xa0be\\xa0defined\\xa0by\\xa0policies\\xa0rather\\xa0than\\xa0by\\xa0technical\\xa0\\nconstraints\\xa0and\\xa0permits\\xa0cyber\\xa0participants\\xa0to\\xa0collaborate\\xa0seamlessly\\xa0and\\xa0dynamically\\xa0in\\xa0\\nautomated\\xa0community\\xa0defense.\\xa0\\xa0Interoperability\\xa0enables\\xa0common\\xa0operational\\xa0pictures\\xa0and\\xa0\\nshared\\xa0situational\\xa0awareness\\xa0to\\xa0emerge\\xa0and\\xa0disseminate\\xa0rapidly.\\xa0\\xa0The\\xa0creation\\xa0of\\xa0new\\xa0kinds\\xa0of\\xa0\\nintelligence\\xa0(such\\xa0as\\xa0fused\\xa0sensor\\xa0inputs),\\xa0coupled\\xa0with\\xa0rapid\\xa0learning\\xa0at\\xa0both\\xa0the\\xa0machine\\xa0and\\xa0\\nthe\\xa0human\\xa0levels,\\xa0could\\xa0fundamentally\\xa0change\\xa0the\\xa0ecosystem.\\xa0\\n\\nUnfortunately,\\xa0within\\xa0cybersecurity\\xa0today,\\xa0many\\xa0available\\xa0devices\\xa0(e.g.,\\xa0firewalls,\\xa0file\\xa0integrity\\xa0\\ncheckers,\\xa0virus\\xa0scanners,\\xa0intrusion\\xa0detection\\xa0systems,\\xa0anti‐malware\\xa0software)\\xa0operate\\xa0\\nindependently\\xa0and\\xa0neither\\xa0exchange\\xa0data\\xa0nor\\xa0have\\xa0consistent\\xa0security\\xa0policies.\\xa0\\xa0Each\\xa0of\\xa0them\\xa0\\nmay\\xa0have\\xa0been\\xa0developed\\xa0by\\xa0a\\xa0different\\xa0vendor,\\xa0perhaps\\xa0even\\xa0competitors,\\xa0without\\xa0adherence\\xa0\\nto\\xa0internationally\\xa0accepted\\xa0open\\xa0standards.\\xa0\\xa0In\\xa0other\\xa0cases,\\xa0the\\xa0standards\\xa0are\\xa0not\\xa0yet\\xa0mature.\\xa0\\xa0\\nThus,\\xa0in\\xa0today’s\\xa0ecosystem,\\xa0collaboration\\xa0is\\xa0possible\\xa0but\\xa0difficult.\\xa0\\xa0We\\xa0must\\xa0reach\\xa0a\\xa0point\\xa0where\\xa0\\nthe\\xa0only\\xa0barriers\\xa0to\\xa0collaboration\\xa0across\\xa0devices,\\xa0people,\\xa0and\\xa0organizations\\xa0are\\xa0those\\xa0we\\xa0\\nchoose\\xa0to\\xa0impose\\xa0by\\xa0policy,\\xa0not\\xa0those\\xa0that\\xa0are\\xa0imposed\\xa0on\\xa0us\\xa0by\\xa0technology.\\xa0\\nThree\\xa0types\\xa0of\\xa0interoperability12\\xa0are\\xa0fundamental\\xa0to\\xa0integrating\\xa0the\\xa0many\\xa0disparate\\xa0\\nparticipants\\xa0into\\xa0a\\xa0comprehensive\\xa0cyber\\xa0defense\\xa0system\\xa0that\\xa0can\\xa0create\\xa0new\\xa0intelligence\\xa0and\\xa0\\nmake\\xa0and\\xa0implement\\xa0decisions\\xa0at\\xa0machine\\xa0speed:\\xa0\\n\\n\\uf0b7  Semantic\\xa0Interoperability.\\xa0The\\xa0ability\\xa0of\\xa0each\\xa0sending\\xa0party\\xa0to\\xa0communicate\\xa0data\\xa0and\\xa0\\nhave\\xa0receiving\\xa0parties\\xa0understand\\xa0the\\xa0message\\xa0in\\xa0the\\xa0sense\\xa0intended\\xa0by\\xa0the\\xa0sending\\xa0\\nparty.\\xa0\\n\\n\\n\\n\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\n\\xa0\\n\\x0c\\uf0b7  Technical\\xa0Interoperability.\\xa0The\\xa0ability\\xa0for\\xa0different\\xa0technologies\\xa0to\\xa0communicate\\xa0and\\xa0\\nexchange\\xa0data\\xa0based\\xa0upon\\xa0well\\xa0defined\\xa0and\\xa0widely\\xa0adopted\\xa0interface\\xa0standards.\\xa0\\n\\n\\uf0b7  Policy\\xa0Interoperability.\\xa0Common\\xa0business\\xa0processes\\xa0related\\xa0to\\xa0the\\xa0transmission,\\xa0\\n\\nreceipt,\\xa0and\\xa0acceptance\\xa0of\\xa0data\\xa0among\\xa0participants.\\xa0\\n\\nWithin\\xa0cybersecurity,\\xa0all\\xa0three\\xa0types\\xa0of\\xa0interoperability\\xa0are\\xa0being\\xa0enabled\\xa0through\\xa0an\\xa0approach\\xa0\\nthat\\xa0has\\xa0been\\xa0refined\\xa0over\\xa0the\\xa0past\\xa0decade\\xa0by\\xa0many\\xa0in\\xa0industry,\\xa0academia,\\xa0and\\xa0government.\\xa0\\xa0It\\xa0\\nis\\xa0an\\xa0information‐oriented\\xa0approach,\\xa0generally\\xa0referred\\xa0to\\xa0as\\xa0[cyber]\\xa0security\\xa0content\\xa0\\nautomation\\xa0and\\xa0comprises\\xa0the\\xa0following\\xa0elements.13\\xa0\\xa0\\xa0\\n\\n\\uf0b7  Enumerations.\\xa0\\xa0These\\xa0are\\xa0lists\\xa0or\\xa0catalogs\\xa0of\\xa0the\\xa0fundamental\\xa0entities\\xa0of\\xa0cybersecurity,\\xa0\\n\\nfor\\xa0example,\\xa0cyber\\xa0devices\\xa0and\\xa0software\\xa0items\\xa0(CPE);\\xa0device\\xa0and\\xa0software\\xa0\\nconfigurations\\xa0(CCE);\\xa0publicly\\xa0known\\xa0weaknesses\\xa0in\\xa0architecture,\\xa0design,\\xa0or\\xa0code\\xa0(CWE);\\xa0\\npublicly\\xa0known\\xa0flaws\\xa0or\\xa0vulnerabilities\\xa0(CVE);\\xa0or\\xa0publicly\\xa0known\\xa0attack\\xa0patterns\\xa0(CAPEC).\\xa0\\xa0\\nEnumerations\\xa0enable\\xa0semantic\\xa0interoperability.\\xa0\\n\\n\\uf0b7  Languages\\xa0and\\xa0Formats.\\xa0\\xa0These\\xa0incorporate\\xa0enumerations\\xa0and\\xa0support\\xa0the\\xa0creation\\xa0of\\xa0\\nmachine‐readable\\xa0security\\xa0state\\xa0assertions,\\xa0assessment\\xa0results,\\xa0audit\\xa0logs,\\xa0messages,\\xa0\\nand\\xa0reports.\\xa0\\xa0Examples\\xa0include\\xa0patterns\\xa0associated\\xa0with\\xa0assets,\\xa0configurations,\\xa0\\nvulnerabilities,\\xa0and\\xa0software\\xa0patches\\xa0(XCCDF\\xa0&\\xa0OVAL);\\xa0security\\xa0announcements\\xa0(CAIF),\\xa0\\nevents\\xa0(CEE),\\xa0malware\\xa0(MAEC);\\xa0risk\\xa0associated\\xa0with\\xa0vulnerability\\xa0(CVSS),\\xa0sensor\\xa0\\ncollection\\xa0and\\xa0correlation\\xa0(ARF),\\xa0and\\xa0US‐CERT\\xa0security\\xa0bulletins\\xa0and\\xa0incident\\xa0reports\\xa0\\n(NIEM).\\xa0\\xa0Languages\\xa0and\\xa0formats\\xa0enable\\xa0technical\\xa0interoperability.\\xa0\\n\\n\\uf0b7  Knowledge\\xa0Repositories.\\xa0\\xa0These\\xa0contain\\xa0a\\xa0broad\\xa0collection\\xa0of\\xa0best\\xa0practices,\\xa0\\n\\nbenchmarks,\\xa0profiles,\\xa0standards,\\xa0templates,\\xa0checklists,\\xa0tools,\\xa0guidelines,\\xa0rules,\\xa0and\\xa0\\nprinciples,\\xa0among\\xa0others.\\xa0In\\xa0many\\xa0respects,\\xa0knowledge\\xa0repositories\\xa0serve\\xa0as\\xa0the\\xa0\\ncybersecurity\\xa0community\\xa0“memory”\\xa0and\\xa0enable\\xa0policy\\xa0interoperability.\\xa0\\xa0Examples\\xa0\\ninclude\\xa0Information\\xa0Assurance\\xa0Checklists\\xa0housed\\xa0on\\xa0the\\xa0National\\xa0Checklist\\xa0Program\\xa0\\nwebsite\\xa0(http://checklists.nist.gov/),\\xa0Department\\xa0of\\xa0Defense\\xa0Security\\xa0Technical\\xa0\\nImplementation\\xa0Guides\\xa0(STIGs),\\xa0and\\xa0vendor\\xa0guides.\"\\xa0\\n\\nFigure\\xa04\\xa0presents\\xa0a\\xa0history\\xa0of\\xa0U.S.\\xa0Government\\xa0supported\\xa0security\\xa0content\\xa0automation\\xa0efforts\\xa0\\nalong\\xa0with\\xa0projected\\xa0achievements\\xa0through\\xa02014.\\xa0\\xa0Projections\\xa0are\\xa0based\\xa0on\\xa0current\\xa0resourcing\\xa0\\nand\\xa0the\\xa0interests\\xa0of\\xa0a\\xa0largely\\xa0volunteer\\xa0and\\xa0self‐directed\\xa0community.\\xa0\\xa0Figure\\xa04\\xa0also\\xa0illustrates\\xa0\\nhow\\xa0standards\\xa0build\\xa0upon\\xa0themselves\\xa0to\\xa0expand\\xa0functionality\\xa0over\\xa0time\\xa0(e.g.,\\xa0the\\xa0expansion\\xa0of\\xa0\\nconfiguration\\xa0management\\xa0capabilities\\xa0from\\xa0desktops\\xa0to\\xa0networks).\\n\\n\\xa0\\n\\xa0\\n\\x0cAnother\\xa0way\\xa0to\\xa0approach\\xa0the\\xa0evolution\\xa0of\\xa0cyber\\xa0security\\xa0content\\xa0automation\\xa0is\\xa0through\\xa0a\\xa0strategic\\xa0\\nconsideration\\xa0of\\xa0what\\xa0is\\xa0needed\\xa0and\\xa0possible.\\xa0\\xa0Figure\\xa05\\xa0presents\\xa0an\\xa0array\\xa0of\\xa0security\\xa0functions\\xa0that\\xa0\\ncan\\xa0be\\xa0transformed\\xa0by\\xa0content\\xa0automation\\xa0and\\xa0exchange.\\xa0\\xa0Standards\\xa0supporting\\xa0the\\xa0first\\xa0wave\\xa0\\nare\\xa0extant\\xa0and\\xa0documented\\xa0in\\xa0NIST\\xa0SP\\xa0800‐126,\\xa0The\\xa0Technical\\xa0Specification\\xa0for\\xa0the\\xa0Security\\xa0\\nContent\\xa0Automation\\xa0Protocol14.\\xa0\\xa0Many\\xa0of\\xa0the\\xa0standards\\xa0necessary\\xa0to\\xa0support\\xa0the\\xa0second\\xa0wave\\xa0are\\xa0\\nin\\xa0development\\xa0now,\\xa0and\\xa0some\\xa0of\\xa0the\\xa0challenges\\xa0associated\\xa0with\\xa0bridging\\xa0the\\xa0two\\xa0waves\\xa0are\\xa0\\ndiscussed\\xa0later\\xa0in\\xa0this\\xa0section.\\xa0\\xa0The\\xa0third\\xa0wave\\xa0identifies\\xa0a\\xa0logical\\xa0progression.\\xa0\\xa0As\\xa0with\\xa0the\\xa0\\nhistorical\\xa0transition\\xa0from\\xa0e‐commerce\\xa0to\\xa0e‐business,\\xa0succeeding\\xa0waves\\xa0build\\xa0in\\xa0capability\\xa0and\\xa0\\nbecome\\xa0more\\xa0strategic\\xa0in\\xa0focus.\\xa0\\n\\nFigure\\xa05:\\xa0Strategic\\xa0Consideration\\xa0of\\xa0Cyber\\xa0Security\\xa0Content\\xa0Automation\\xa0\\n\\nTesting,\\xa0\\nattestation,\\xa0\\n\\nand\\xa0\\nassurance\\xa0\\n\\nSoftware\\xa0\\nAssurance\\n\\nCollaborative\\xa0\\nthreat\\xa0\\nintelligence\\xa0\\n\\nMalware\\xa0\\nAnalysis\\n\\nSensing\\xa0and\\xa0\\nWarning\\n\\nEngineering\\n\\nDesign\\n\\nRemote\\xa0\\nAssessment\\n\\nVulnerability\\xa0\\nAssessment\\n\\nAsset\\xa0\\nInventory\\n\\nNetwork\\xa0\\nDevice\\xa0\\nAssessment\\n\\nArchitecture\\n\\nConfiguration\\xa0\\nAssessment\\n\\nCompliance\\xa0\\nManagement\\n\\nRemediation\\n\\nEvent\\xa0\\nManagement\\n\\nSupply\\xa0Chain\\xa0\\nAssurance\\n\\nEnterprise\\nReporting\\n\\nRecovery\\n\\nStructured\\xa0\\nThreat\\xa0\\nInformation\\n\\nIncident\\xa0\\nReporting\\n\\nResponse\\n\\nForensics\\nand\\nDamage\\n\\nAssessment\\xa0\\n\\nModeling\\xa0and\\xa0 Simulation\\n\\nReconstitution\\n\\nThe\\xa0success\\xa0of\\xa0any\\xa0single\\xa0function\\xa0and\\xa0the\\xa0integration\\xa0of\\xa0functions\\xa0within\\xa0and\\xa0across\\xa0waves\\xa0\\ndepend\\xa0on\\xa0semantic,\\xa0technical,\\xa0and\\xa0policy\\xa0interoperability.\\xa0\\xa0These\\xa0three\\xa0types\\xa0of\\xa0interoperability\\xa0\\nare\\xa0themselves\\xa0interdependent,\\xa0and\\xa0they\\xa0mature\\xa0as\\xa0each\\xa0adapts\\xa0to\\xa0changes\\xa0in\\xa0the\\xa0other.\\xa0\\xa0Some\\xa0\\nlevel\\xa0of\\xa0semantic\\xa0interoperability\\xa0must\\xa0be\\xa0achieved\\xa0and\\xa0some\\xa0vision\\xa0of\\xa0policy\\xa0(or\\xa0process)\\xa0\\ninteroperability\\xa0is\\xa0necessary\\xa0in\\xa0order\\xa0to\\xa0successfully\\xa0develop\\xa0and\\xa0employ\\xa0technical\\xa0interoperability.\\xa0\\xa0\\nA\\xa0simple\\xa0example\\xa0would\\xa0be\\xa0the\\xa0publication\\xa0of\\xa0US‐CERT\\xa0bulletins\\xa0in\\xa0XML\\xa0blobs.\\xa0\\xa0The\\xa0technical\\xa0\\nstandards\\xa0must\\xa0be\\xa0underpinned\\xa0by\\xa0sender/receiver\\xa0agreement\\xa0on\\xa0the\\xa0meaning\\xa0of\\xa0the\\xa0content\\xa0and\\xa0\\nby\\xa0agreement\\xa0on\\xa0how\\xa0the\\xa0XML‐structured\\xa0bulletins\\xa0are\\xa0to\\xa0be\\xa0received\\xa0and\\xa0processed.\\xa0\\xa0In\\xa0turn,\\xa0\\nachievements\\xa0in\\xa0technical\\xa0interoperability\\xa0enable\\xa0advances\\xa0in\\xa0semantic\\xa0and\\xa0policy\\xa0interoperability,\\xa0\\nand\\xa0these\\xa0advances\\xa0trigger\\xa0further\\xa0advances\\xa0in\\xa0technical\\xa0interoperability.\\xa0\\n\\n\\n\\xa0\\n\\xa0\\n\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\n\\x0cAdvances\\xa0in\\xa0semantic\\xa0and\\xa0policy\\xa0interoperability\\xa0almost\\xa0always\\xa0start\\xa0with\\xa0persons\\xa0and\\xa0progress\\xa0to\\xa0\\ndevices.\\xa0\\xa0Further,\\xa0advances\\xa0in\\xa0interoperability\\xa0have\\xa0short‐term\\xa0advantages.\\xa0\\xa0For\\xa0example,\\xa0the\\xa0first\\xa0\\nwave\\xa0of\\xa0security\\xa0content\\xa0automation\\xa0is\\xa0enabling\\xa0the\\xa0recent\\xa0federal\\xa0commitment\\xa0to\\xa0continuous\\xa0\\nmonitoring,\\xa0and\\xa0progress\\xa0in\\xa0the\\xa0second\\xa0wave,\\xa0combined\\xa0with\\xa0gains\\xa0achieved\\xa0during\\xa0the\\xa0first\\xa0wave,\\xa0\\nis\\xa0enabling\\xa0XML‐based\\xa0incident\\xa0reporting\\xa0to\\xa0the\\xa0US‐CERT.\\xa0\\n\\nThe\\xa0three\\xa0waves\\xa0of\\xa0automated\\xa0security\\xa0functions\\xa0depicted\\xa0in\\xa0Figure\\xa05\\xa0can\\xa0be\\xa0summarized\\xa0as\\xa0\\nprogress\\xa0along\\xa0three\\xa0axes:\\xa0\\n\\nFigure\\xa06:\\xa0\\xa0Axes\\xa0of\\xa0Progress\\xa0\\n\\nAxis\\xa0\\n\\nSpace\\xa0\\n\\nTime\\xa0\\n\\nProgression\\xa0\\n\\nFrom\\xa0hosts\\xa0to\\xa0networks\\xa0and\\xa0applications\\xa0\\n\\nFrom\\xa0static\\xa0to\\xa0dynamic\\xa0\\n\\nCapability\\xa0\\n\\nFrom\\xa0configuration\\xa0to\\xa0integrated\\xa0policy\\xa0and\\xa0audit\\xa0\\n\\nA\\xa0third\\xa0way\\xa0to\\xa0examine\\xa0cyber\\xa0security\\xa0content\\xa0automation\\xa0is\\xa0through\\xa0the\\xa0generalized\\xa0functional\\xa0\\nmodel\\xa0in\\xa0use\\xa0by\\xa0the\\xa0standards\\xa0community.\\xa0\\xa0As\\xa0illustrated\\xa0in\\xa0Figure\\xa07\\xa0below,\\xa0the\\xa0security\\xa0functions\\xa0\\ncontained\\xa0in\\xa0this\\xa0model\\xa0generally\\xa0represent\\xa0the\\xa0first\\xa0wave\\xa0plus\\xa0a\\xa0portion\\xa0of\\xa0the\\xa0second\\xa0wave.\\xa0\\xa0\\nSecurity\\xa0content\\xa0automation\\xa0standards\\xa0that\\xa0can\\xa0facilitate\\xa0the\\xa0exchange\\xa0of\\xa0information\\xa0with\\xa0and\\xa0\\namong\\xa0functions\\xa0are\\xa0annotated\\xa0adjacent\\xa0to\\xa0each\\xa0function,\\xa0input,\\xa0or\\xa0output.\\xa0\\n\\nMarch\\xa023,\\xa02011\\xa0\\n\\n\\xa015\\xa0\\n\\n\\x0cFigure\\xa07:\\xa0\\xa0Generalized\\xa0Functional\\xa0Model\\xa0Informing\\xa0Standards\\xa0Development\\xa0\\n\\nThis\\xa0model\\xa0is\\xa0lifecycle‐oriented\\xa0and\\xa0enterprise‐\\xa0or\\xa0organization‐focused.\\xa0\\xa0Capabilities\\xa0are\\xa0\\nexpected\\xa0to\\xa0build\\xa0on\\xa0one\\xa0another\\xa0(from\\xa0left\\xa0to\\xa0right).\\xa0\\xa0Each\\xa0function\\xa0(e.g.,\\xa0asset\\xa0inventory,\\xa0\\nconfiguration\\xa0guidance\\xa0analysis,\\xa0vulnerability\\xa0analysis)\\xa0is\\xa0viewed\\xa0as\\xa0a\\xa0black\\xa0box\\xa0and\\xa0assumed\\xa0to\\xa0\\nbe\\xa0provided\\xa0by\\xa0current\\xa0or\\xa0future\\xa0commercial\\xa0products.\\xa0\\xa0Integration\\xa0across\\xa0functions\\xa0is\\xa0also\\xa0\\nassumed.\\xa0\\xa0The\\xa0current\\xa0model\\xa0does\\xa0not\\xa0address\\xa0formulation\\xa0or\\xa0dynamic\\xa0evolution\\xa0of\\xa0ACOAs;\\xa0\\nhowever,\\xa0it\\xa0does\\xa0provide\\xa0a\\xa0reasonable\\xa0foundation\\xa0for\\xa0ACOA\\xa0execution.\\xa0\\n\\nIn\\xa0general,\\xa0the\\xa0functions\\xa0can\\xa0be\\xa0organized\\xa0into\\xa0“pre‐incident\\xa0detection”\\xa0(asset\\xa0inventory,\\xa0\\nconfiguration\\xa0guidance\\xa0analysis,\\xa0and\\xa0vulnerability\\xa0analysis\\xa0plus\\xa0threat\\xa0analysis)\\xa0and\\xa0“post‐\\nincident\\xa0detection”\\xa0(intrusion\\xa0detection\\xa0and\\xa0incident\\xa0management\\xa0plus\\xa0threat\\xa0analysis).\\xa0\\xa0This\\xa0\\norganizing\\xa0construct\\xa0aligns\\xa0with\\xa0the\\xa0waves\\xa0presented\\xa0in\\xa0Figure\\xa05\\xa0above.\\xa0\\xa0As\\xa0illustrated,\\xa0the\\xa0\\nstructuring\\xa0of\\xa0threat\\xa0information\\xa0is\\xa0a\\xa0second\\xa0wave\\xa0activity.\\xa0\\xa0The\\xa0effort\\xa0to\\xa0standardize\\xa0threat\\xa0\\nalerts\\xa0and\\xa0automate\\xa0threat\\xa0analysis\\xa0may\\xa0prove\\xa0more\\xa0complex\\xa0than\\xa0previous\\xa0security\\xa0content\\xa0\\nautomation\\xa0efforts\\xa0because\\xa0standardization\\xa0must:\\xa0\\n\\n\\uf0b7  Bridge\\xa0these\\xa0two\\xa0operational\\xa0dimensions\\xa0(pre‐\\xa0and\\xa0post‐\\xa0incident\\xa0detection);\\xa0and\\xa0\\n\\n\\uf0b7  Add\\xa0value\\xa0for\\xa0enterprises\\xa0that\\xa0lack\\xa0automated\\xa0capabilities\\xa0on\\xa0one\\xa0side\\xa0or\\xa0the\\xa0other.\\xa0\\n\\nIn\\xa0addition,\\xa0on\\xa0the\\xa0whole,\\xa0the\\xa0“post‐incident\\xa0detection”\\xa0space\\xa0is\\xa0less\\xa0standards‐based\\xa0than\\xa0the\\xa0\\n“pre‐incident\\xa0detection”\\xa0space.\\xa0\\xa0Advances\\xa0in\\xa0semantic\\xa0and\\xa0policy\\xa0interoperability\\xa0regarding\\xa0\\n\\nMarch\\xa023,\\xa02011\\xa0\\n\\n\\xa016\\xa0\\n\\n\\xa0\\n\\xa0\\n\\xa0\\n \\n\\x0cwhat\\xa0constitutes\\xa0a\\xa0reportable\\xa0incident,\\xa0what\\xa0attributes\\xa0best\\xa0support\\xa0incident\\xa0management,\\xa0and\\xa0\\nhow\\xa0these\\xa0attributes\\xa0are\\xa0to\\xa0be\\xa0sourced\\xa0and\\xa0shared\\xa0are\\xa0needed\\xa0to\\xa0advance\\xa0technical\\xa0standards\\xa0\\nand\\xa0interoperability.\\xa0\\xa0\\n\\nBuilding\\xa0Block\\xa03:\\xa0\\xa0Authentication\\xa0\\n\\nAuthentication\\xa0should\\xa0enable\\xa0trusted\\xa0online\\xa0decisions.\\xa0\\xa0Nearly\\xa0every\\xa0decision\\xa0in\\xa0an\\xa0online\\xa0\\nenvironment\\xa0involves\\xa0resources\\xa0and\\xa0actors\\xa0at\\xa0a\\xa0distance.\\xa0\\xa0When\\xa0needed\\xa0for\\xa0a\\xa0decision,\\xa0\\nauthentication\\xa0provides\\xa0appropriate\\xa0assurance\\xa0that\\xa0the\\xa0participants\\xa0are\\xa0authentic\\xa0or\\xa0genuine,\\xa0\\nand\\xa0it\\xa0should\\xa0do\\xa0so\\xa0in\\xa0a\\xa0way\\xa0that\\xa0enhances\\xa0individual\\xa0privacy.\\xa0\\xa0In\\xa0a\\xa0healthy\\xa0ecosystem,\\xa0\\nauthentication\\xa0could\\xa0extend\\xa0beyond\\xa0persons\\xa0to\\xa0include\\xa0cyber\\xa0devices\\xa0(e.g.,\\xa0computers;\\xa0\\nsoftware,\\xa0or\\xa0information).\\xa0\\n\\nAuthentication\\xa0is\\xa0critical\\xa0to\\xa0cyber\\xa0defense\\xa0because\\xa0communications\\xa0and\\xa0content\\xa0attribution\\xa0are\\xa0\\nessential\\xa0factors\\xa0in\\xa0security\\xa0decisions.\\xa0\\xa0Authentication\\xa0is\\xa0also\\xa0foundational\\xa0to\\xa0many\\xa0capabilities\\xa0\\nbeyond\\xa0cyber\\xa0defense.15\\xa0\\n\\nIn\\xa0a\\xa0healthy\\xa0cyber\\xa0ecosystem,\\xa0sending\\xa0and\\xa0receiving\\xa0parties\\xa0could\\xa0be\\xa0known\\xa0and\\xa0accountable\\xa0\\nfor\\xa0their\\xa0actions,\\xa0but\\xa0protect\\xa0anonymity\\xa0where\\xa0it\\xa0may\\xa0be\\xa0needed\\xa0to\\xa0preserve\\xa0the\\xa0purpose\\xa0of\\xa0the\\xa0\\nexchange.\\xa0\\xa0Consumers\\xa0of\\xa0shared\\xa0cyber\\xa0awareness\\xa0could\\xa0judge\\xa0the\\xa0trustworthiness\\xa0of\\xa0providers\\xa0\\nand\\xa0their\\xa0contributions,\\xa0and\\xa0providers\\xa0could\\xa0confirm\\xa0that\\xa0requesters\\xa0are\\xa0authorized\\xa0access\\xa0to\\xa0\\nsuch\\xa0information.\\xa0\\xa0Authentication\\xa0mechanisms\\xa0could\\xa0be\\xa0strong\\xa0enough\\xa0to\\xa0protect\\xa0against\\xa0\\nidentity\\xa0theft\\xa0and\\xa0spoofing,\\xa0while\\xa0at\\xa0the\\xa0same\\xa0time\\xa0remain\\xa0affordable,\\xa0easy\\xa0to\\xa0use\\xa0and\\xa0\\nadminister,\\xa0scalable,\\xa0and\\xa0interoperable.\\xa0\\xa0They\\xa0could\\xa0also\\xa0be\\xa0designed\\xa0to\\xa0enhance\\xa0individual\\xa0\\nprivacy\\xa0by\\xa0allowing\\xa0voluntary,\\xa0opt‐in\\xa0regimes.\\xa0\\n\\nCommon\\xa0authentication\\xa0technologies\\xa0rely\\xa0on\\xa0(1)\\xa0something\\xa0you\\xa0know\\xa0(e.g.,\\xa0passwords),\\xa0(2)\\xa0\\nsomething\\xa0you\\xa0have\\xa0(e.g.,\\xa0digital\\xa0credential),\\xa0or\\xa0(3)\\xa0something\\xa0you\\xa0are\\xa0(e.g.,\\xa0biometrics).\\xa0\\xa0Each\\xa0\\nof\\xa0these\\xa0technologies\\xa0has\\xa0characteristics\\xa0that\\xa0impact\\xa0security\\xa0strength,\\xa0affordability,\\xa0ease\\xa0of\\xa0use\\xa0\\nand\\xa0administration,\\xa0scalability,\\xa0and\\xa0interoperability.\\xa0\\xa0Significant\\xa0considerations\\xa0include\\xa0ease\\xa0of\\xa0\\nintegration\\xa0into\\xa0emerging\\xa0and\\xa0deployed\\xa0devices\\xa0and\\xa0software\\xa0applications\\xa0and\\xa0ease\\xa0of\\xa0\\nexchange\\xa0or\\xa0federation\\xa0across\\xa0networks\\xa0and\\xa0organizations.\\xa0\\n\\nUnfortunately,\\xa0in\\xa0today’s\\xa0market,\\xa0system\\xa0developers\\xa0and\\xa0owners\\xa0find\\xa0few\\xa0if\\xa0any\\xa0technologies\\xa0\\nthat\\xa0deliver\\xa0on\\xa0all\\xa0five\\xa0operational\\xa0objectives:\\xa0security,\\xa0affordability,\\xa0ease\\xa0of\\xa0use\\xa0and\\xa0\\nadministration,\\xa0scalability,\\xa0and\\xa0interoperability.\\xa0\\xa0The\\xa0usual\\xa0approach\\xa0is\\xa0to\\xa0divide\\xa0up\\xa0enterprises\\xa0\\nand\\xa0use\\xa0populations\\xa0to\\xa0control\\xa0and\\xa0vary\\xa0the\\xa0objective\\xa0that\\xa0gets\\xa0optimized.\\xa0\\xa0This\\xa0creates\\xa0a\\xa0\\ncomplex\\xa0landscape\\xa0of\\xa0multiple\\xa0authentication\\xa0technologies\\xa0with\\xa0limited\\xa0interoperability,\\xa0\\nvulnerable\\xa0security\\xa0seams,\\xa0and\\xa0barriers\\xa0to\\xa0business\\xa0or\\xa0organizational\\xa0change.\\xa0\\n\\nA\\xa0healthy\\xa0cyber\\xa0ecosystem\\xa0could\\xa0have\\xa0standards‐based\\xa0authentication\\xa0technologies\\xa0that\\xa0deliver\\xa0\\nmore\\xa0comprehensively\\xa0across\\xa0all\\xa0five\\xa0operational\\xa0objectives.\\xa0\\xa0To\\xa0support\\xa0near‐term\\xa0decisions,\\xa0\\nconsumer\\xa0guides\\xa0that\\xa0rate\\xa0technologies\\xa0across\\xa0all\\xa0five\\xa0objectives\\xa0and\\xa0assist\\xa0system\\xa0developers\\xa0\\nand\\xa0owners\\xa0in\\xa0making\\xa0phased\\xa0improvements\\xa0and\\xa0selections\\xa0could\\xa0be\\xa0available.\\xa0\\xa0For\\xa0automated\\xa0\\n\\n\\n\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\n\\x0ccyber\\xa0defense,\\xa0a\\xa0healthy\\xa0cyber\\xa0ecosystem\\xa0could\\xa0have\\xa0strong\\xa0standards‐based\\xa0device\\xa0\\nauthentication,\\xa0including\\xa0small\\xa0and\\xa0usually\\xa0wireless\\xa0devices\\xa0composing\\xa0massively\\xa0scalable\\xa0grids.\\xa0\\xa0\\nFinally,\\xa0a\\xa0healthy\\xa0ecosystem\\xa0could\\xa0have\\xa0broad\\xa0ways\\xa0to\\xa0express\\xa0and\\xa0manage\\xa0trust\\xa0that\\xa0combine\\xa0\\ntrust\\xa0attributes\\xa0about\\xa0people,\\xa0transactions,\\xa0technology,\\xa0and\\xa0information\\xa0into\\xa0new\\xa0decision\\xa0\\nframeworks\\xa0and\\xa0metrics.\\xa0\\xa0Such\\xa0frameworks\\xa0could\\xa0recognize\\xa0that\\xa0trust\\xa0is\\xa0not\\xa0a\\xa0binary\\xa0or\\xa0static\\xa0\\nstate,\\xa0but\\xa0is\\xa0fluid\\xa0and\\xa0conditioned\\xa0upon\\xa0evolving\\xa0operational\\xa0and\\xa0environmental\\xa0factors.\\xa0\\n\\nKey\\xa0Concepts\\xa0\\n\\nFocus,\\xa0Convergence,\\xa0and\\xa0Maturity\\xa0\\n\\nFigure\\xa08.\\xa0\\xa0Prevailing\\xa0Cybersecurity\\xa0Construct\\xa0\\n\\nThe\\xa0prevailing\\xa0construct\\xa0for\\xa0cybersecurity\\xa0is\\xa0illustrated\\xa0in\\xa0Figure\\xa08.\\xa0\\xa0Cybersecurity\\xa0processes\\xa0are\\xa0\\na\\xa0combination\\xa0of\\xa0local\\xa0and\\xa0global\\xa0activities.\\xa0The\\xa0\\ndistribution\\xa0 of\\xa0 activities\\xa0 between\\xa0 local\\xa0 and\\xa0\\nglobal\\xa0 may\\xa0 differ\\xa0 from\\xa0 process\\xa0 to\\xa0 process,\\xa0\\nactivity\\xa0to\\xa0activity,\\xa0participant\\xa0to\\xa0participant,\\xa0or\\xa0\\nevent\\xa0 to\\xa0 event.\\xa0 \\xa0The \\xa0 range\\xa0 of\\xa0 local‐to‐global\\xa0\\nextends\\xa0from\\xa0the\\xa0circuitry\\xa0within\\xa0a\\xa0single\\xa0cyber\\xa0\\ndevice\\xa0\\n(e.g.,\\xa0 a\\xa0 mobile\\xa0 phone,\\xa0 personal\\xa0\\ncomputer,\\xa0 medical\\xa0 device,\\xa0 or\\xa0 electric\\xa0 grid\\xa0\\nsoftware\\xa0\\ncomponent)\\xa0\\napplications,\\xa0 data\\xa0 centers,\\xa0 networks,\\xa0 and\\xa0\\nclouds.\\xa0 To\\xa0 successfully\\xa0 defend\\xa0 against\\xa0 active\\xa0\\nand\\xa0intelligent\\xa0adversaries\\xa0in\\xa0such\\xa0complex\\xa0and\\xa0\\nuncertain\\xa0 networked\\xa0 environments,\\xa0 current\\xa0\\nthinking\\xa0 suggests\\xa0 the\\xa0 need\\xa0 for\\xa0 a\\xa0 new\\xa0 view\\xa0 of\\xa0\\ncommand\\xa0 and\\xa0 control,\\xa0 one\\xa0 that\\xa0 emphasizes\\xa0\\nagility,\\xa0focus,\\xa0and\\xa0convergence:\\xa0\\n\\ndistributed\\xa0\\n\\nto\\xa0\\n\\nIn\\xa0brief,\\xa0agility\\xa0is\\xa0the\\xa0critical\\xa0capability\\xa0that\\xa0organizations\\xa0need\\xa0to\\xa0meet\\xa0the\\xa0\\nchallenges\\xa0of\\xa0complexity\\xa0and\\xa0uncertainty;\\xa0focus\\xa0provides\\xa0the\\xa0context\\xa0and\\xa0defines\\xa0\\nthe\\xa0purposes\\xa0of\\xa0the\\xa0endeavor;\\xa0convergence\\xa0is\\xa0the\\xa0goal‐seeking\\xa0process\\xa0that\\xa0guides\\xa0\\nactions\\xa0and\\xa0effects.\\xa0....\\xa0Focus\\xa0as\\xa0a\\xa0replacement\\xa0for\\xa0command\\xa0speaks\\xa0directly\\xa0to\\xa0\\nwhat\\xa0command\\xa0is\\xa0meant\\xa0to\\xa0accomplish\\xa0while\\xa0being\\xa0agnostic\\xa0with\\xa0respect\\xa0to\\xa0the\\xa0\\nexistence\\xa0of\\xa0someone\\xa0in\\xa0charge\\xa0or\\xa0particular\\xa0lines\\xa0of\\xa0authority.\\xa0Similarly,\\xa0\\nconvergence\\xa0speaks\\xa0directly\\xa0to\\xa0what\\xa0control\\xa0(the\\xa0verb)\\xa0is\\xa0meant\\xa0to\\xa0achieve\\xa0without\\xa0\\nasserting\\xa0that\\xa0control\\xa0as\\xa0a\\xa0verb\\xa0is\\xa0possible\\xa0or\\xa0desirable.16\\xa0\\xa0\\xa0\\n\\nAs\\xa0suggested\\xa0earlier,\\xa0this\\xa0paper\\xa0focuses\\xa0primarily\\xa0on\\xa0how\\xa0networked\\xa0devices\\xa0can\\xa0become\\xa0actors\\xa0\\nin\\xa0their\\xa0own\\xa0and\\xa0the\\xa0network’s\\xa0defense.\\xa0To\\xa0illustrate\\xa0a\\xa0range\\xa0of\\xa0capabilities\\xa0that\\xa0such\\xa0devices\\xa0\\n\\n\\n\\xa0\\n\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\n\\x0cwill\\xa0begin\\xa0to\\xa0embody,\\xa0we\\xa0present\\xa0a\\xa0five‐level\\xa0maturity\\xa0model\\xa0in\\xa0Figure\\xa09.17\\xa0The\\xa0model\\xa0considers\\xa0\\nFocus\\xa0and\\xa0Convergence\\xa0(F&C)\\xa0in\\xa0terms\\xa0of\\xa0increasing\\xa0agility,\\xa0that\\xa0is,\\xa0effectiveness\\xa0in\\xa0dealing\\xa0with\\xa0\\nchange\\xa0over\\xa0time.\\xa0\\xa0As\\xa0with\\xa0other\\xa0maturity\\xa0models,\\xa0Level\\xa05\\xa0represents\\xa0the\\xa0highest\\xa0level\\xa0of\\xa0focus\\xa0\\nand\\xa0convergence,\\xa0while\\xa0Level\\xa01\\xa0represents\\xa0the\\xa0lowest.\\xa0\\xa0The\\xa0five‐level\\xa0model\\xa0is\\xa0not\\xa0a\\xa0normative\\xa0\\nscale.\\xa0\\xa0That\\xa0is,\\xa0Level\\xa05\\xa0is\\xa0not\\xa0always\\xa0better\\xa0than\\xa0Level\\xa03.\\xa0\\xa0Communities\\xa0may\\xa0opt\\xa0to\\xa0operate\\xa0at\\xa0\\nlower\\xa0levels\\xa0for\\xa0reasons\\xa0of\\xa0cost,\\xa0efficiency,\\xa0or\\xa0other\\xa0reasons.\\xa0\\xa0Describing\\xa0the\\xa0ecosystem\\xa0in\\xa0terms\\xa0\\nof\\xa0multiple\\xa0levels\\xa0helps\\xa0illustrate\\xa0and\\xa0demonstrate\\xa0a\\xa0system’s\\xa0high\\xa0tolerance\\xa0for\\xa0diversity,\\xa0as\\xa0\\ndifferent\\xa0communities\\xa0will\\xa0inevitably\\xa0have\\xa0different\\xa0needs\\xa0and\\xa0be\\xa0in\\xa0different\\xa0stages\\xa0of\\xa0\\nevolution\\xa0at\\xa0any\\xa0given\\xa0point\\xa0in\\xa0time.\\xa0\\xa0For\\xa0example,\\xa0there\\xa0are\\xa0a\\xa0number\\xa0of\\xa0outdated\\xa0system\\xa0\\ncomponents\\xa0within\\xa0the\\xa0nation’s\\xa0critical\\xa0infrastructure\\xa0that\\xa0are\\xa0not\\xa0able\\xa0to\\xa0interface\\xa0with\\xa0\\nmodern\\xa0systems\\xa0but\\xa0will\\xa0remain\\xa0an\\xa0important\\xa0part\\xa0of\\xa0the\\xa0ecosystem\\xa0in\\xa0the\\xa0near\\xa0term.\\xa0\\xa0The\\xa0\\nability\\xa0to\\xa0leap‐frog\\xa0from\\xa0this\\xa0legacy\\xa0technology\\xa0to\\xa0a\\xa0modern\\xa0cyber\\xa0infrastructure\\xa0is\\xa0something\\xa0\\nthat\\xa0should\\xa0be\\xa0explored.\\xa0\\n\\nFigure\\xa09:\\xa0Focus\\xa0and\\xa0Convergence\\xa0Maturity\\xa0Model\\xa0for\\xa0Networked\\xa0Environments\\xa0\\n\\nLevel\\xa05\\xa0 Edge\\xa0F&C\\xa0\\n\\nLevel\\xa04\\xa0 Collaborative\\xa0\\nF&C\\xa0\\n\\nF&C\\xa0Maturity\\xa0Levels\\xa0\\n\\nCharacterized\\xa0by\\xa0a\\xa0robustly‐networked\\xa0collection\\xa0of\\xa0devices\\xa0\\nhaving\\xa0widespread\\xa0and\\xa0easy\\xa0access\\xa0to\\xa0information,\\xa0sharing\\xa0\\ninformation\\xa0extensively,\\xa0interacting\\xa0in\\xa0a\\xa0rich\\xa0and\\xa0continuous\\xa0\\nfashion,\\xa0and\\xa0having\\xa0the\\xa0broadest\\xa0possible\\xa0distribution\\xa0of\\xa0\\ndecision\\xa0rights.\\xa0\\xa0The\\xa0objective\\xa0of\\xa0Edge\\xa0F&C\\xa0is\\xa0to\\xa0enable\\xa0the\\xa0\\ncommunity\\xa0to\\xa0self‐synchronize\\xa0in\\xa0an\\xa0agile\\xa0and\\xa0adaptable\\xa0\\nmanner.\\xa0\\n\\nCharacterized\\xa0by\\xa0multiple\\xa0devices\\xa0working\\xa0together\\xa0toward\\xa0a\\xa0\\ncommon\\xa0purpose\\xa0and\\xa0under\\xa0a\\xa0single,\\xa0shared\\xa0plan.\\xa0\\xa0Involves\\xa0a\\xa0\\nconsiderable\\xa0delegation\\xa0of\\xa0decision\\xa0rights\\xa0to\\xa0the\\xa0community.\\xa0\\xa0\\nAims\\xa0to\\xa0develop\\xa0synergies\\xa0by\\xa0negotiating\\xa0and\\xa0establishing\\xa0\\nshared\\xa0intent\\xa0as\\xa0well\\xa0as\\xa0a\\xa0shared\\xa0security\\xa0policy,\\xa0establishing\\xa0\\nor\\xa0reconfiguring\\xa0roles,\\xa0coupling\\xa0actions,\\xa0and\\xa0by\\xa0engendering\\xa0\\na\\xa0rich\\xa0sharing\\xa0of\\xa0resources\\xa0and\\xa0awareness.\\xa0\\n\\nLevel\\xa03\\xa0 Coordinated\\xa0\\nF&C\\xa0\\n\\nCharacterized\\xa0by\\xa0multiple\\xa0devices\\xa0related\\xa0by\\xa0mutual\\xa0support\\xa0\\nfor\\xa0intent,\\xa0expressed\\xa0as\\xa0links\\xa0between\\xa0and\\xa0among\\xa0security\\xa0\\npolicies\\xa0and\\xa0actions\\xa0that\\xa0reinforce\\xa0and\\xa0enhance\\xa0effects\\xa0along\\xa0\\nwith\\xa0some\\xa0pooling\\xa0of\\xa0resources\\xa0for\\xa0specified\\xa0activities.\\xa0\\n\\nLevel\\xa02\\xa0 De‐conflicted\\xa0\\nF&C\\xa0\\n\\nCharacterized\\xa0by\\xa0a\\xa0partitioning\\xa0of\\xa0the\\xa0problem\\xa0space\\xa0among\\xa0\\ndevices\\xa0to\\xa0avoid\\xa0adverse\\xa0cross‐effects.\\xa0\\xa0Establishment\\xa0and\\xa0\\nmaintenance\\xa0of\\xa0the\\xa0partitions\\xa0requires\\xa0limited\\xa0information\\xa0\\n\\n\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\n\\x0cF&C\\xa0Maturity\\xa0Levels\\xa0\\n\\nsharing\\xa0and\\xa0interaction\\xa0among\\xa0devices.\\xa0\\n\\nLevel\\xa01\\xa0\\n\\nIsolated\\xa0\\xa0F&C\\xa0\\n\\nCharacterized\\xa0by\\xa0individual\\xa0devices\\xa0exercising\\xa0focus\\xa0and\\xa0\\nconvergence\\xa0only\\xa0over\\xa0their\\xa0own\\xa0resources.\\xa0\\xa0Hence,\\xa0there\\xa0is\\xa0\\nno\\xa0shared\\xa0objective;\\xa0neither\\xa0is\\xa0there\\xa0information\\xa0distribution\\xa0\\nnor\\xa0any\\xa0other\\xa0interaction\\xa0among\\xa0devices.\\xa0\\n\\nTo\\xa0consider\\xa0how\\xa0such\\xa0a\\xa0model\\xa0might\\xa0be\\xa0applied,\\xa0a\\xa0framework\\xa0for\\xa0defining\\xa0and\\xa0thinking\\xa0about\\xa0\\nthe\\xa0space\\xa0of\\xa0all\\xa0possible\\xa0F&C\\xa0approaches\\xa0is\\xa0helpful.\\xa0Three\\xa0variables\\xa0define\\xa0the\\xa0essence\\xa0of\\xa0F&C,\\xa0\\nand\\xa0thus\\xa0the\\xa0F&C\\xa0Approach\\xa0Space\\xa0is\\xa0illustrated\\xa0in\\xa0Figure\\xa010\\xa0below.\\xa0\\xa0\\n\\nFigure\\xa010:\\xa0\\xa0Focus\\xa0and\\xa0Convergence\\xa0(F&C)\\xa0Approach\\xa0Space18\\xa0\\n\\nAs\\xa0Figure\\xa010\\xa0illustrates,\\xa0any\\xa0focus\\xa0and\\xa0convergence\\xa0approach\\xa0may\\xa0be\\xa0viewed\\xa0as\\xa0a\\xa0function\\xa0of\\xa0\\nthree\\xa0interrelated\\xa0dimensions:\\xa0\\n\\n1.  The\\xa0allocation\\xa0of\\xa0decision\\xa0rights\\xa0to\\xa0the\\xa0community;\\xa0\\n\\n\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\n\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\n\\x0c2.  The\\xa0patterns\\xa0of\\xa0interaction\\xa0that\\xa0take\\xa0place\\xa0between\\xa0and\\xa0among\\xa0devices;\\xa0and\\xa0\\n\\n3.  The\\xa0distribution\\xa0of\\xa0information\\xa0among\\xa0devices.\\xa0\\n\\nFigure\\xa011\\xa0summarizes\\xa0how\\xa0these\\xa0three\\xa0dimensions\\xa0vary\\xa0among\\xa0the\\xa0F&C\\xa0levels.\\xa0\\n\\nFigure\\xa011:\\xa0Dimensions\\xa0of\\xa0Focus\\xa0and\\xa0Convergence19\\xa0\\n\\nIncreased\\xa0agility\\xa0(moving\\xa0from\\xa0the\\xa0bottom\\xa0left\\xa0to\\xa0top\\xa0right\\xa0within\\xa0the\\xa0F&C\\xa0approach\\xa0space\\xa0in\\xa0\\nFigure\\xa010)\\xa0can\\xa0be\\xa0viewed\\xa0as:\\xa0\\n\\n\\uf0b7  The\\xa0ability\\xa0of\\xa0devices\\xa0to\\xa0adopt\\xa0ever\\xa0wider\\xa0ranges\\xa0of\\xa0approaches;\\xa0\\n\\n\\uf0b7  The\\xa0ability\\xa0of\\xa0devices\\xa0to\\xa0recognize\\xa0and\\xa0adopt\\xa0an\\xa0appropriate\\xa0approach,\\xa0which\\xa0is\\xa0\\ndetermined\\xa0by\\xa0the\\xa0nature\\xa0of\\xa0the\\xa0situation\\xa0and\\xa0how\\xa0it\\xa0is\\xa0likely\\xa0to\\xa0evolve;\\xa0and\\xa0\\n\\n\\uf0b7  The\\xa0ability\\xa0of\\xa0devices\\xa0to\\xa0change\\xa0approaches\\xa0if\\xa0necessary\\xa0in\\xa0a\\xa0timely\\xa0manner.\\xa0\\n\\nConsidering\\xa0F&C\\xa0within\\xa0an\\xa0approach\\xa0space\\xa0also\\xa0supports\\xa0a\\xa0growing\\xa0recognition\\xa0that\\xa0there\\xa0may\\xa0\\nbe\\xa0no\\xa0single\\xa0best\\xa0system\\xa0design\\xa0or\\xa0configuration,\\xa0no\\xa0best\\xa0process\\xa0for\\xa0all\\xa0situations\\xa0and\\xa0\\ncircumstances.\\xa0\\xa0Rather\\xa0than\\xa0optimization,\\xa0the\\xa0uncertainty\\xa0in\\xa0the\\xa0mission\\xa0space\\xa0combined\\xa0with\\xa0\\nthe\\xa0diverse\\xa0and\\xa0interacting\\xa0effects\\xa0of\\xa0countermeasures\\xa0and\\xa0the\\xa0complexity\\xa0inherent\\xa0in\\xa0\\ncollective\\xa0action\\xa0lead\\xa0to\\xa0a\\xa0need\\xa0for\\xa0agility.\\xa0\\xa0This\\xa0might\\xa0mean\\xa0that\\xa0devices\\xa0routinely\\xa0operate\\xa0at\\xa0\\nlower\\xa0levels\\xa0of\\xa0F&C\\xa0for\\xa0economy\\xa0but\\xa0have\\xa0the\\xa0ability\\xa0to\\xa0switch\\xa0to\\xa0higher\\xa0levels\\xa0of\\xa0F&C\\xa0for\\xa0\\nselected\\xa0situations.\\xa0\\xa0It\\xa0might\\xa0also\\xa0mean\\xa0that\\xa0routine\\xa0F&C\\xa0levels\\xa0vary\\xa0by\\xa0devices’\\xa0roles\\xa0or\\xa0\\nlocations\\xa0within\\xa0the\\xa0ecosystem.\\xa0\\n\\n\\n\\xa0\\n\\xa0\\xa0\\xa0\\n\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\n\\x0cIncreased\\xa0agility\\xa0among\\xa0cyber\\xa0devices\\xa0is\\xa0necessarily\\xa0dependent\\xa0upon\\xa0and\\xa0exists\\xa0in\\xa0synchrony\\xa0\\nwith\\xa0the\\xa0agility\\xa0of\\xa0the\\xa0organizations\\xa0that\\xa0own\\xa0and\\xa0operate\\xa0them\\xa0and\\xa0the\\xa0business\\xa0or\\xa0mission\\xa0\\nprocesses\\xa0that\\xa0consume\\xa0their\\xa0services.\\xa0\\xa0The\\xa0three\\xa0building\\xa0blocks\\xa0described\\xa0earlier\\xa0–\\xa0\\nautomation,\\xa0authentication\\xa0and\\xa0interoperability\\xa0–\\xa0increase\\xa0agility\\xa0and\\xa0enable\\xa0collective\\xa0cyber\\xa0\\ndefense.\\xa0\\xa0Decision\\xa0rights\\xa0originate\\xa0with\\xa0persons,\\xa0organizations\\xa0and\\xa0business\\xa0processes;\\xa0and\\xa0\\ninteroperability\\xa0ensures\\xa0that\\xa0any\\xa0delegation\\xa0to\\xa0cyber\\xa0devices\\xa0is\\xa0communicated\\xa0in\\xa0a\\xa0way\\xa0that\\xa0\\nboth\\xa0humans\\xa0and\\xa0machines\\xa0can\\xa0understand.\\xa0\\xa0Automation\\xa0provides\\xa0the\\xa0ability\\xa0to\\xa0act\\xa0upon\\xa0\\ndelegated\\xa0decision\\xa0rights\\xa0at\\xa0machine\\xa0speed,\\xa0and\\xa0authentication\\xa0allows\\xa0the\\xa0data\\xa0necessary\\xa0for\\xa0a\\xa0\\ngiven\\xa0decision\\xa0to\\xa0be\\xa0trusted.\\xa0\\n\\nAttributes\\xa0of\\xa0a\\xa0Healthy\\xa0Cyber\\xa0Ecosystem\\xa0\\n\\nLooking\\xa0at\\xa0the\\xa0ecosystem\\xa0through\\xa0building\\xa0blocks\\xa0and\\xa0maturity\\xa0levels\\xa0helps\\xa0envision\\xa0how\\xa0a\\xa0\\nhealthy\\xa0ecosystem\\xa0might\\xa0work\\xa0and\\xa0how\\xa0it\\xa0might\\xa0self‐defend\\xa0through\\xa0automated\\xa0collective\\xa0\\naction.\\xa0\\xa0This\\xa0section\\xa0begins\\xa0to\\xa0examine\\xa0the\\xa0desired\\xa0end‐state.\\xa0\\xa0What\\xa0might\\xa0be\\xa0different\\xa0in\\xa0a\\xa0\\nhealthy\\xa0ecosystem?\\xa0\\xa0What\\xa0might\\xa0be\\xa0the\\xa0value\\xa0added?\\xa0\\n\\nIn\\xa0a\\xa0healthy\\xa0cyber\\xa0ecosystem,\\xa0we\\xa0might\\xa0find:\\xa0\\n\\n\\uf0a7 \\n\\nInformation\\xa0connected\\xa0across\\xa0space\\xa0and\\xa0time.\\xa0\\xa0Information\\xa0discovered\\xa0or\\xa0created\\xa0\\nin\\xa0one\\xa0part\\xa0of\\xa0the\\xa0ecosystem\\xa0conveys\\xa0rapidly\\xa0to\\xa0others\\xa0rather\\xa0than\\xa0being\\xa0siloed,\\xa0e.g.,\\xa0\\ninformation\\xa0is\\xa0preserved\\xa0in\\xa0ways\\xa0that\\xa0help\\xa0discover\\xa0patterns\\xa0over\\xa0time\\xa0and\\xa0can\\xa0be\\xa0\\nconfigured\\xa0to\\xa0protect\\xa0Personally\\xa0Identifiable\\xa0Information\\xa0(PII)\\xa0and\\xa0other\\xa0sensitive\\xa0\\ndata.\\xa0\\n\\n\\uf0a7  Rapid\\xa0and\\xa0essentially\\xa0universal\\xa0learning.\\xa0\\xa0Machines\\xa0learn\\xa0from\\xa0each\\xa0other\\xa0and\\xa0\\n\\npeople\\xa0learn\\xa0from\\xa0machines.\\xa0\\n\\n\\uf0a7  Greater\\xa0attribution.\\xa0\\xa0Machines\\xa0and\\xa0humans\\xa0work\\xa0together\\xa0to\\xa0improve\\xa0attribution\\xa0\\n\\nwhere\\xa0needed\\xa0while\\xa0enhancing\\xa0privacy.\\xa0\\n\\n\\uf0a7  New\\xa0analytics.\\xa0\\xa0Data\\xa0from\\xa0multiple,\\xa0otherwise\\xa0discrete\\xa0sources\\xa0(e.g.,\\xa0sensors,\\xa0red\\xa0\\nteams,\\xa0trouble\\xa0tickets)\\xa0are\\xa0fused,\\xa0aggregated\\xa0or\\xa0otherwise\\xa0transformed\\xa0to\\xa0create\\xa0\\nnew\\xa0intelligence.\\xa0\\n\\n\\uf0a7  Greater\\xa0network\\xa0reach.\\xa0\\xa0Security\\xa0content\\xa0is\\xa0separated\\xa0from\\xa0delivery\\xa0mechanisms\\xa0\\nand\\xa0managed\\xa0as\\xa0an\\xa0ecosystem\\xa0asset.\\xa0\\xa0Earlier\\xa0research\\xa0in\\xa0Tailored\\xa0Trustworthy\\xa0\\nSpaces20\\xa0results\\xa0in\\xa0powerful\\xa0new\\xa0ways\\xa0to\\xa0work\\xa0across\\xa0multiple\\xa0trust\\xa0or\\xa0classification\\xa0\\nlevels.\\xa0\\n\\n\\uf0a7  New\\xa0defensive\\xa0tactics.\\xa0\\xa0Earlier\\xa0research\\xa0in\\xa0Moving\\xa0Target\\xa0Defense21,\\xa0combined\\xa0with\\xa0\\nshared\\xa0security\\xa0policies\\xa0and\\xa0new\\xa0intelligence,\\xa0enables\\xa0new\\xa0courses\\xa0of\\xa0action\\xa0such\\xa0as\\xa0\\ndynamic\\xa0networking\\xa0or\\xa0uncertainty.\\xa0\\xa0In\\xa0other\\xa0words,\\xa0attacks\\xa0only\\xa0work\\xa0once\\xa0(i.e.\\xa0one\\xa0\\nvictim\\xa0or\\xa0one\\xa0device)\\xa0if\\xa0at\\xa0all.\\xa0\\n\\n\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\n\\x0c\\uf0a7  Lifecycle\\xa0Feedback.\\xa0\\xa0Rich\\xa0feedback\\xa0loops\\xa0from\\xa0operations\\xa0into\\xa0the\\xa0front\\xa0end\\xa0of\\xa0\\nsystem\\xa0and\\xa0technology\\xa0life\\xa0cycles\\xa0reduce\\xa0costs,\\xa0shorten\\xa0adoption\\xa0cycles,\\xa0and\\xa0\\nimprove\\xa0ecosystem\\xa0health.\\xa0\\n\\nAnother\\xa0way\\xa0to\\xa0examine\\xa0the\\xa0desired\\xa0end\\xa0state\\xa0is\\xa0through\\xa0the\\xa0qualities\\xa0or\\xa0attributes\\xa0the\\xa0building\\xa0\\nblocks\\xa0might\\xa0help\\xa0create.\\xa0\\xa0A\\xa0healthy\\xa0cyber\\xa0ecosystem\\xa0might\\xa0be:\\xa0\\xa0\\n\\n\\uf0a7 \\n\\nInclusive.\\xa0\\xa0Encompassing\\xa0capabilities\\xa0embedded\\xa0in\\xa0an\\xa0ever‐widening\\xa0web\\xa0that\\xa0\\nextends\\xa0far\\xa0beyond\\xa0traditional\\xa0notions\\xa0of\\xa0the\\xa0public\\xa0Internet\\xa0or\\xa0of\\xa0information\\xa0\\ntechnology\\xa0(IT)\\xa0and\\xa0services.\\xa0\\xa0A\\xa0healthy\\xa0cyber\\xa0ecosystem\\xa0would\\xa0include\\xa0the\\xa0Smart\\xa0\\nGrid\\xa0with\\xa0its\\xa0energy‐controlled\\xa0home\\xa0networks\\xa0and\\xa0IP\\xa0addressable\\xa0appliances,\\xa0the\\xa0\\nnext\\xa0generation\\xa0of\\xa0the\\xa0National\\xa0Airspace\\xa0System\\xa0which\\xa0takes\\xa0advantage\\xa0of\\xa0satellite\\xa0\\ncapabilities,\\xa0and\\xa0the\\xa0large\\xa0number\\xa0of\\xa0legacy\\xa0devices\\xa0and\\xa0control\\xa0systems\\xa0which\\xa0must\\xa0\\ninteroperate\\xa0with\\xa0the\\xa0newest\\xa0technologies.\\xa0\\xa0\\n\\n\\uf0a7  Effective.\\xa0\\xa0Able\\xa0to\\xa0defend\\xa0against\\xa0all\\xa0types\\xa0of\\xa0cyber\\xa0threats,\\xa0including\\xa0supply\\xa0chain\\xa0\\n\\nattacks;\\xa0remote\\xa0or\\xa0network‐based\\xa0attacks,\\xa0including\\xa0those\\xa0launched\\xa0by\\xa0sophisticated\\xa0\\nand\\xa0well‐resourced\\xa0attackers\\xa0using\\xa0persistent\\xa0methods;\\xa0\\xa0proximate\\xa0or\\xa0physical\\xa0\\nattacks\\xa0or\\xa0adverse\\xa0events;\\xa0and\\xa0insider\\xa0or\\xa0disgruntled\\xa0employee\\xa0attacks.\\xa0\\n\\n\\uf0a7  Smart.\\xa0\\xa0Able\\xa0to\\xa0sense\\xa0the\\xa0environment,\\xa0recognize\\xa0patterns,\\xa0and\\xa0share\\xa0information\\xa0in\\xa0\\nnear‐real\\xa0time\\xa0across\\xa0sectors\\xa0and\\xa0communities\\xa0at\\xa0both\\xa0the\\xa0human\\xa0and\\xa0machine\\xa0\\nlevels\\xa0in\\xa0order\\xa0to\\xa0assure\\xa0authorized\\xa0transactions,\\xa0prevent\\xa0the\\xa0most\\xa0serious\\xa0security\\xa0\\nbreaches\\xa0and\\xa0increase\\xa0response\\xa0effectiveness\\xa0when\\xa0breaches\\xa0or\\xa0other\\xa0adverse\\xa0\\nevents\\xa0do\\xa0occur.\\xa0\\xa0\\xa0\\n\\n\\uf0a7  Barrier‐free.\\xa0\\xa0Having\\xa0security\\xa0choices\\xa0instantiated\\xa0in\\xa0configurable\\xa0digital\\xa0policies\\xa0\\nrather\\xa0than\\xa0being\\xa0“hardwired”\\xa0in\\xa0network\\xa0or\\xa0system\\xa0designs\\xa0or\\xa0imposed\\xa0by\\xa0\\ntechnology\\xa0limitations\\xa0or\\xa0shortfalls.\\xa0\\xa0Designers\\xa0would\\xa0design\\xa0with\\xa0the\\xa0assumption\\xa0\\nthat\\xa0everything\\xa0will\\xa0be\\xa0shared\\xa0with\\xa0everyone,\\xa0and\\xa0the\\xa0only\\xa0barriers\\xa0to\\xa0collaboration\\xa0\\nwould\\xa0be\\xa0those\\xa0imposed\\xa0by\\xa0policy.\\xa0\\n\\n\\uf0a7  Optimized.\\xa0\\xa0Having\\xa0capabilities\\xa0and\\xa0decision\\xa0making\\xa0allocated\\xa0among\\xa0humans\\xa0and\\xa0\\nmachines\\xa0so\\xa0as\\xa0to\\xa0best\\xa0leverage\\xa0the\\xa0strengths\\xa0and\\xa0cycle‐times\\xa0of\\xa0each,\\xa0consistent\\xa0\\nwith\\xa0maintaining\\xa0agility.\\xa0\\xa0Further,\\xa0having\\xa0cyber\\xa0defense\\xa0organized\\xa0so\\xa0that\\xa0machines\\xa0\\ndefend\\xa0against\\xa0machines\\xa0and\\xa0people\\xa0defend\\xa0against\\xa0people.\\xa0\\n\\n\\uf0a7  Understandable.\\xa0\\xa0Having\\xa0security\\xa0expressed\\xa0in\\xa0user\\xa0or\\xa0stakeholder\\xa0terms\\xa0rather\\xa0than\\xa0\\nin\\xa0specialized\\xa0security\\xa0“jargon”\\xa0and\\xa0recognizing\\xa0that\\xa0everyone\\xa0is\\xa0a\\xa0cybersecurity\\xa0\\nstakeholder.\\xa0\\xa0For\\xa0example,\\xa0stakeholders\\xa0might\\xa0want\\xa0global\\xa0visibility\\xa0into\\xa0the\\xa0cyber\\xa0\\nenvironment,\\xa0the\\xa0ability\\xa0to\\xa0query\\xa0the\\xa0environment\\xa0and\\xa0get\\xa0back\\xa0a\\xa0high\\xa0fidelity\\xa0\\nanswer,\\xa0and\\xa0the\\xa0ability\\xa0to\\xa0rationalize\\xa0security\\xa0costs.\\xa0\\n\\n\\uf0a7  Assured.\\xa0\\xa0Able\\xa0to\\xa0sustain\\xa0consumer\\xa0confidence\\xa0over\\xa0time.\\xa0\\xa0This\\xa0might\\xa0mean\\xa0moving\\xa0\\nbeyond\\xa0traditional\\xa0security\\xa0notions\\xa0of\\xa0“preventing\\xa0unwanted\\xa0transactions”\\xa0to\\xa0\\n“ensuring\\xa0the\\xa0right\\xa0transactions\\xa0occur,”\\xa0which\\xa0could\\xa0contribute\\xa0more\\xa0broadly\\xa0to\\xa0a\\xa0\\nsense\\xa0of\\xa0consumer\\xa0safety\\xa0and\\xa0trust\\xa0in\\xa0sector\\xa0operations\\xa0for\\xa0transportation,\\xa0energy,\\xa0\\nhealth,\\xa0etc.\\xa0\\n\\nMarch\\xa023,\\xa02011\\xa0\\n\\n\\xa023\\xa0\\n\\n\\x0c\\uf0a7  Usable.\\xa0\\xa0Having\\xa0assembly,\\xa0configuration,\\xa0operational,\\xa0and\\xa0performance\\xa0properties\\xa0\\n\\nthat\\xa0are\\xa0straightforward\\xa0and\\xa0well‐behaving,\\xa0rather\\xa0than\\xa0overwhelmingly\\xa0\\ncomplicated,\\xa0brittle,\\xa0and\\xa0error‐prone.\\xa0\\n\\nAttributes\\xa0of\\xa0Healthy\\xa0Participants\\xa0\\xa0\\n\\nJust\\xa0as\\xa0healthy\\xa0individuals\\xa0are\\xa0essential\\xa0to\\xa0healthy\\xa0communities,\\xa0healthy\\xa0participants\\xa0are\\xa0\\nessential\\xa0to\\xa0a\\xa0healthy\\xa0cyber\\xa0ecosystem.\\xa0\\xa0Cyber\\xa0ecosystem\\xa0participants\\xa0include\\xa0persons\\xa0(both\\xa0\\nindividuals\\xa0and\\xa0entities),\\xa0devices,\\xa0and\\xa0processes.\\xa0\\n\\nPersons\\xa0who\\xa0are\\xa0“unhealthy”\\xa0cyber\\xa0participants\\xa0might\\xa0lack\\xa0awareness\\xa0or\\xa0skills,\\xa0or\\xa0they\\xa0may\\xa0not\\xa0\\nbe\\xa0who\\xa0they\\xa0claim.\\xa0\\xa0Persons\\xa0who\\xa0are\\xa0“healthy”\\xa0cyber\\xa0participants\\xa0might\\xa0have\\xa0continuing\\xa0access\\xa0\\nto\\xa0a\\xa0range\\xa0of\\xa0education,\\xa0training\\xa0and\\xa0awareness\\xa0opportunities,\\xa0including\\xa0but\\xa0not\\xa0limited\\xa0to\\xa0\\nexercises,\\xa0simulations,\\xa0and\\xa0fully‐immersive\\xa0learning\\xa0environments.\\xa0\\xa0Further,\\xa0they\\xa0might\\xa0have\\xa0\\nvalidated\\xa0skills\\xa0that\\xa0have\\xa0been\\xa0codified\\xa0for\\xa0their\\xa0occupations\\xa0or\\xa0positions\\xa0and\\xa0strongly\\xa0proofed\\xa0\\ncyber\\xa0identities.\\xa0\\n\\n“Unhealthy”\\xa0cyber\\xa0devices\\xa0(computers,\\xa0software,\\xa0and\\xa0communications\\xa0technologies)\\xa0lack\\xa0\\nawareness,\\xa0functionality,\\xa0or\\xa0capacity\\xa0or\\xa0feature\\xa0purposeful\\xa0deceptions.\\xa0\\xa0“Healthy”\\xa0cyber\\xa0devices\\xa0\\nare:\\xa0\\n\\n\\uf0b7  Self\\xa0Aware.\\xa0\\xa0Having\\xa0the\\xa0ability\\xa0to\\xa0collect\\xa0information\\xa0about\\xa0security\\xa0properties,\\xa0draw\\xa0\\n\\nconclusions,\\xa0and\\xa0report\\xa0or\\xa0act\\xa0upon\\xa0the\\xa0conclusions.\\xa0\\n\\n\\uf0b7  User\\xa0Aware.\\xa0\\xa0Having\\xa0the\\xa0ability\\xa0to\\xa0collect\\xa0or\\xa0receive\\xa0and\\xa0process\\xa0information\\xa0about\\xa0\\nsupported\\xa0users,\\xa0missions,\\xa0or\\xa0business\\xa0processes\\xa0or\\xa0assigned\\xa0role\\xa0in\\xa0a\\xa0larger\\xa0cyber\\xa0\\ninfrastructure\\xa0plus\\xa0ability\\xa0to\\xa0draw\\xa0conclusions,\\xa0report\\xa0or\\xa0act\\xa0upon\\xa0the\\xa0conclusions,\\xa0and\\xa0\\nimplement\\xa0policies\\xa0that\\xa0assure\\xa0user\\xa0privacy.\\xa0\\n\\n\\uf0b7  Environmentally\\xa0Aware.\\xa0\\xa0Having\\xa0the\\xa0ability\\xa0to\\xa0collect\\xa0or\\xa0receive\\xa0and\\xa0process\\xa0information\\xa0\\nabout\\xa0the\\xa0security\\xa0of\\xa0surrounding\\xa0cyber\\xa0devices\\xa0of\\xa0interest\\xa0or\\xa0the\\xa0cyber\\xa0environment,\\xa0\\ndraw\\xa0conclusions,\\xa0and\\xa0report\\xa0or\\xa0act\\xa0upon\\xa0the\\xa0conclusions.\\xa0\\n\\n\\uf0b7  Smart.\\xa0\\xa0Having\\xa0the\\xa0ability\\xa0to\\xa0retrospectively\\xa0examine\\xa0events\\xa0and\\xa0associated\\xa0responses,\\xa0\\ncorrelate\\xa0historical\\xa0patterns\\xa0with\\xa0current\\xa0status\\xa0data,\\xa0and\\xa0either\\xa0select\\xa0from\\xa0a\\xa0range\\xa0of\\xa0\\nACOAs\\xa0or\\xa0formulate\\xa0a\\xa0new\\xa0ACOA.\\xa0\\xa0Examples\\xa0of\\xa0ACOAs\\xa0that\\xa0may\\xa0be\\xa0deployed\\xa0in\\xa0near‐real\\xa0\\ntime\\xa0include\\xa0filtering\\xa0or\\xa0re‐routing\\xa0traffic,\\xa0cordoning\\xa0off\\xa0portions\\xa0of\\xa0the\\xa0network\\xa0or\\xa0\\napplications,\\xa0changing\\xa0access\\xa0levels,\\xa0reconfiguring\\xa0assets,\\xa0and\\xa0quarantining\\xa0users.\\xa0\\n\\n\\uf0b7  Autonomously\\xa0Reacting.\\xa0\\xa0Having\\xa0the\\xa0ability\\xa0to\\xa0initiate\\xa0an\\xa0ACOA.\\xa0\\n\\n\\uf0b7  Dynamic.\\xa0\\xa0Having\\xa0the\\xa0ability\\xa0to\\xa0alter\\xa0appearance\\xa0or\\xa0persona.\\xa0\\xa0Ideally,\\xa0alterations\\xa0are\\xa0\\nenacted\\xa0on\\xa0cycle\\xa0times\\xa0that\\xa0are\\xa0shorter\\xa0than\\xa0target\\xa0acquisition\\xa0and\\xa0attack\\xa0execution\\xa0\\ntimes.\\xa0\\xa0For\\xa0example,\\xa0today’s\\xa0systems\\xa0tend\\xa0to\\xa0rely\\xa0on\\xa0selected\\xa0system\\xa0parameters\\xa0for\\xa0\\nsecurity,\\xa0such\\xa0as\\xa0duration\\xa0of\\xa0timeouts\\xa0or\\xa0corruption\\xa0thresholds.\\xa0\\xa0Typically,\\xa0these\\xa0\\nparameters\\xa0are\\xa0chosen\\xa0in\\xa0advance\\xa0and\\xa0fixed\\xa0for\\xa0the\\xa0lifetime\\xa0of\\xa0the\\xa0system.\\xa0\\xa0Future\\xa0\\ndevices\\xa0could\\xa0make\\xa0these\\xa0parameters\\xa0variable.\\xa0\\xa0Additionally\\xa0or\\xa0alternatively,\\xa0\\nvirtualization\\xa0could\\xa0be\\xa0employed\\xa0to\\xa0project\\xa0multiple\\xa0decoy\\xa0systems\\xa0to\\xa0confuse\\xa0attackers\\xa0\\nand\\xa0to\\xa0frequently\\xa0roll\\xa0back\\xa0actual\\xa0systems\\xa0to\\xa0a\\xa0known\\xa0good\\xa0state\\xa0in\\xa0order\\xa0to\\xa0obviate\\xa0\\n\\nMarch\\xa023,\\xa02011\\xa0\\n\\n\\xa024\\xa0\\n\\n\\x0c\\uf0b7  Collaborative.\\xa0Having\\xa0the\\xa0ability\\xa0to\\xa0work\\xa0in\\xa0partnership\\xa0with\\xa0other\\xa0participants\\xa0to\\xa0collect\\xa0\\nand\\xa0assess\\xa0security\\xa0information,\\xa0and\\xa0select,\\xa0formulate,\\xa0or\\xa0alter\\xa0an\\xa0ACOA\\xa0intended\\xa0to\\xa0\\ncounter\\xa0an\\xa0attack\\xa0or\\xa0sustain\\xa0priority\\xa0services.\\xa0\\n\\n\\uf0b7  Heterogeneous.\\xa0\\xa0Having\\xa0the\\xa0ability\\xa0to\\xa0collaborate\\xa0with\\xa0other\\xa0participants\\xa0using\\xa0a\\xa0\\n\\ncommon\\xa0communications\\xa0channel\\xa0despite\\xa0differences\\xa0in\\xa0affiliation,\\xa0security\\xa0policies\\xa0or\\xa0\\nservice\\xa0level\\xa0agreements.\\xa0\\n\\n\\uf0b7  Diversifying.\\xa0\\xa0Having\\xa0the\\xa0ability\\xa0to\\xa0sense\\xa0the\\xa0appearance\\xa0or\\xa0persona\\xa0of\\xa0surrounding\\xa0\\n\\ndevices\\xa0and\\xa0to\\xa0make\\xa0oneself\\xa0different\\xa0from\\xa0other\\xa0devices.\\xa0\\n\\n\\uf0b7  Resilient.\\xa0\\xa0For\\xa0cyber\\xa0defense\\xa0purposes,\\xa0having\\xa0sufficient\\xa0capacity\\xa0to\\xa0simultaneously\\xa0\\n\\ncollect\\xa0or\\xa0receive\\xa0and\\xa0assess\\xa0security\\xa0information,\\xa0execute\\xa0any\\xa0ACOA,\\xa0make\\xa0alterations\\xa0\\nto\\xa0the\\xa0ACOA\\xa0as\\xa0needed,\\xa0and\\xa0sustain\\xa0agreed\\xa0upon\\xa0service\\xa0levels.\\xa0\\n\\n\\uf0b7  Trustworthy.\\xa0\\xa0Performing\\xa0as\\xa0expected\\xa0–\\xa0and\\xa0only\\xa0as\\xa0expected\\xa0–\\xa0despite\\xa0environmental\\xa0\\ndisruption,\\xa0user\\xa0and\\xa0operator\\xa0errors,\\xa0and\\xa0attacks\\xa0by\\xa0hostile\\xa0parties.\\xa0\\xa0Three\\xa0approaches\\xa0\\nfor\\xa0achieving\\xa0trustworthiness\\xa0are\\xa0software\\xa0assurance22,\\xa0hardware\\xa0enabled\\xa0trust\\xa0(e.g.,\\xa0\\nTrusted\\xa0Computing\\xa0Group‐based\\xa0technologies,\\xa0associated\\xa0system\\xa0architectures\\xa0such\\xa0as\\xa0\\nNetwork\\xa0Admission\\xa0Control\\xa0or\\xa0Trusted\\xa0Network\\xa0Connection\\xa0and\\xa0trusted\\xa0virtualization)\\xa0\\nand\\xa0data\\xa0provenance\\xa0(e.g.,\\xa0metadata\\xa0tags\\xa0and\\xa0labels\\xa0containing\\xa0identity,\\xa0origin,\\xa0and\\xa0\\ntransformation\\xa0history).\\xa0\\n\\n“Unhealthy”\\xa0information\\xa0exchanges\\xa0should\\xa0be\\xa0expensive\\xa0or\\xa0difficult\\xa0to\\xa0adapt.\\xa0\\xa0Or\\xa0they\\xa0might\\xa0be\\xa0\\neasily\\xa0compromised,\\xa0disrupted,\\xa0or\\xa0corrupted.\\xa0\\xa0“Healthy”\\xa0information\\xa0exchanges\\xa0are:\\xa0\\n\\n\\uf0b7  Secure.\\xa0\\xa0Secure\\xa0exchanges\\xa0are\\xa0those\\xa0in\\xa0which\\xa0the\\xa0identities\\xa0of\\xa0all\\xa0participants\\xa0in\\xa0an\\xa0\\n\\nexchange\\xa0are\\xa0authenticated,\\xa0appropriate\\xa0digital\\xa0identities\\xa0and\\xa0minimum\\xa0attribute\\xa0data\\xa0\\nare\\xa0asserted,\\xa0and\\xa0the\\xa0vulnerability\\xa0of\\xa0any\\xa0communications\\xa0in\\xa0the\\xa0exchange\\xa0to\\xa0\\nunauthorized\\xa0interception,\\xa0diversion,\\xa0access,\\xa0use,\\xa0modification\\xa0or\\xa0disclosure\\xa0is\\xa0\\nminimized23.\\xa0\\xa0 \\n\\n\\uf0b7  Environmentally\\xa0Sustainable.\\xa0\\xa0Environmentally‐sustainable\\xa0exchanges\\xa0are\\xa0structured\\xa0\\nfor\\xa0the\\xa0most\\xa0rational\\xa0use\\xa0of\\xa0cyber\\xa0resources\\xa0(least\\xa0effort),\\xa0are\\xa0bandwidth\\xa0friendly,\\xa0easy\\xa0\\nto\\xa0administer,\\xa0and\\xa0easy\\xa0to\\xa0achieve\\xa0(for\\xa0example,\\xa0are\\xa0broadly\\xa0incorporated\\xa0into\\xa0\\ncommercial\\xa0solutions).\\xa0\\n\\n\\uf0b7  Rapidly\\xa0customizable.\\xa0\\xa0Rapidly‐customizable\\xa0exchanges\\xa0are\\xa0enabled\\xa0by\\xa0user‐\\n\\nconfigurable\\xa0profiles,\\xa0parameters\\xa0and\\xa0rules\\xa0and\\xa0by\\xa0open\\xa0application\\xa0programming\\xa0\\ninterfaces\\xa0(APIs).\\xa0\\n\\n\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\n\\x0c\\uf0b7  Lightweight\\xa0and\\xa0loosely\\xa0coupled.\\xa0\\xa0Lightweight\\xa0and\\xa0loosely‐coupled\\xa0exchanges\\xa0are\\xa0those\\xa0\\nthat\\xa0are\\xa0achievable\\xa0with\\xa0existing\\xa0infrastructure\\xa0and\\xa0with\\xa0minor\\xa0upgrades\\xa0to\\xa0existing\\xa0\\ntools\\xa0and\\xa0services,\\xa0rather\\xa0than\\xa0through\\xa0approaches\\xa0that\\xa0require\\xa0extensive\\xa0redesign.\\xa0\\n\\nEcosystem‐generated\\xa0value,\\xa0desired\\xa0ecosystem\\xa0and\\xa0participant\\xa0attributes,\\xa0and\\xa0ecosystem\\xa0\\nbuilding\\xa0blocks\\xa0all\\xa0work\\xa0together.\\xa0\\xa0For\\xa0example,\\xa0an\\xa0ecosystem\\xa0with\\xa0the\\xa0ability\\xa0to\\xa0make\\xa0\\nautomated\\xa0adjustments\\xa0to\\xa0configuration\\xa0in\\xa0response\\xa0to\\xa0trust\\xa0choices\\xa0would\\xa0offer\\xa0increased\\xa0\\nreliability\\xa0and\\xa0resilience\\xa0for\\xa0supported\\xa0business,\\xa0social\\xa0and\\xa0civic\\xa0processes\\xa0while\\xa0improving\\xa0the\\xa0\\nprivacy\\xa0and\\xa0civil\\xa0liberties\\xa0of\\xa0users.\\xa0\\xa0An\\xa0ecosystem\\xa0with\\xa0such\\xa0abilities\\xa0would\\xa0also\\xa0be\\xa0self‐\\ndefending.\\xa0\\xa0A\\xa0self‐defending\\xa0ecosystem\\xa0with\\xa0human\\xa0involvement\\xa0could\\xa0force\\xa0attackers\\xa0to\\xa0take\\xa0\\nmore\\xa0risks\\xa0and\\xa0be\\xa0more\\xa0exposed.\\xa0\\xa0These\\xa0activities,\\xa0combined\\xa0with\\xa0greater\\xa0attribution,\\xa0could\\xa0\\nenable\\xa0law\\xa0enforcement\\xa0or\\xa0other\\xa0deterrence\\xa0to\\xa0be\\xa0more\\xa0effective.\\xa0\\xa0A\\xa0healthy\\xa0ecosystem,\\xa0in\\xa0\\nother\\xa0words,\\xa0mutually\\xa0reinforces\\xa0security,\\xa0usability,\\xa0reliability,\\xa0and\\xa0the\\xa0protection\\xa0of\\xa0privacy\\xa0and\\xa0\\ncivil\\xa0liberties.\\xa0\\n\\nIncentives\\xa0and\\xa0Adoption\\xa0\\n\\nWe\\xa0know\\xa0today\\xa0that\\xa0users\\xa0are\\xa0not\\xa0routinely\\xa0complying\\xa0with\\xa0cyber\\xa0best\\xa0practices\\xa0and\\xa0\\nconfiguration\\xa0guidelines.\\xa0\\xa0Adoption\\xa0of\\xa0security\\xa0standards\\xa0is\\xa0decidedly\\xa0slow,\\xa0and\\xa0early\\xa0indications\\xa0\\nare\\xa0that\\xa0cybersecurity\\xa0continuous\\xa0monitoring\\xa0will\\xa0face\\xa0impediments\\xa0to\\xa0adoption.\\xa0This\\xa0indicates\\xa0\\nan\\xa0imbalance\\xa0of\\xa0incentives,\\xa0whereby\\xa0defenders\\xa0are\\xa0not\\xa0incented,\\xa0but\\xa0attackers\\xa0are.\\xa0\\xa0\\xa0\\n\\nA\\xa0persistent\\xa0challenge\\xa0in\\xa0today’s\\xa0ecosystem\\xa0is\\xa0the\\xa0inability\\xa0to\\xa0establish\\xa0level\\xa0of\\xa0harm\\xa0as\\xa0a\\xa0result\\xa0\\nof\\xa0a\\xa0cyber\\xa0incident\\xa0–\\xa0be\\xa0it\\xa0loss\\xa0of\\xa0intellectual\\xa0property,\\xa0privacy,\\xa0consumer\\xa0confidence,\\xa0business\\xa0\\nopportunity,\\xa0or\\xa0essential\\xa0services.\\xa0\\xa0Such\\xa0inability\\xa0may\\xa0be\\xa0due\\xa0in\\xa0part\\xa0to\\xa0a\\xa0lack\\xa0of\\xa0agreement\\xa0on\\xa0\\nhow\\xa0to\\xa0establish\\xa0extent\\xa0in\\xa0a\\xa0highly‐interconnected\\xa0environment\\xa0as\\xa0well\\xa0as\\xa0how\\xa0to\\xa0measure,\\xa0\\nvalidate,\\xa0and\\xa0communicate\\xa0effects.\\xa0\\xa0It\\xa0may\\xa0also\\xa0be\\xa0due\\xa0in\\xa0part\\xa0to\\xa0a\\xa0lack\\xa0of\\xa0trust,\\xa0which\\xa0impedes\\xa0\\ninformation\\xa0sharing\\xa0and\\xa0collaboration.\\xa0\\xa0 \\n\\nEarlier,\\xa0this\\xa0paper\\xa0proposed\\xa0types\\xa0of\\xa0activities\\xa0that\\xa0might\\xa0be\\xa0associated\\xa0with\\xa0an\\xa0appropriately\\xa0\\nautomated\\xa0and\\xa0distributed\\xa0“Cyber\\xa0CDC”\\xa0that\\xa0performs\\xa0threat\\xa0and\\xa0incident\\xa0watch,\\xa0data\\xa0\\ndissemination,\\xa0threat\\xa0analysis,\\xa0intervention\\xa0analysis\\xa0and\\xa0recommendations,\\xa0and\\xa0coordination\\xa0of\\xa0\\npreventive\\xa0actions.\\xa0\\xa0In\\xa0addition\\xa0to\\xa0promoting\\xa0cyber\\xa0health\\xa0among\\xa0communities,\\xa0such\\xa0a\\xa0\\ncapability\\xa0could\\xa0provide\\xa0vendors\\xa0and\\xa0system\\xa0owners\\xa0with\\xa0the\\xa0information\\xa0and\\xa0insight\\xa0needed\\xa0\\nto\\xa0diagnose\\xa0problems\\xa0and\\xa0evaluate\\xa0options\\xa0for\\xa0new\\xa0or\\xa0improved\\xa0capabilities.\\xa0\\xa0One\\xa0way\\xa0to\\xa0get\\xa0\\nstarted\\xa0is\\xa0through\\xa0increased\\xa0sharing\\xa0of\\xa0anonymized\\xa0cyber\\xa0incident\\xa0and\\xa0mitigation\\xa0data.\\xa0\\xa0\\nAggregation\\xa0and\\xa0analysis\\xa0of\\xa0such\\xa0data\\xa0might\\xa0lead\\xa0to\\xa0an\\xa0improved\\xa0ability\\xa0to\\xa0show\\xa0how\\xa0\\ninvestments\\xa0in\\xa0cyber\\xa0health\\xa0can\\xa0reduce\\xa0operating\\xa0costs,\\xa0improve\\xa0business\\xa0agility,\\xa0or\\xa0avoid\\xa0\\nextensive\\xa0mitigation\\xa0costs\\xa0(e.g.,\\xa0the\\xa0cost\\xa0of\\xa0data\\xa0leakage\\xa0protection\\xa0software\\xa0compared\\xa0with\\xa0\\nthe\\xa0cost\\xa0of\\xa0mitigating\\xa0large‐scale\\xa0identity\\xa0information\\xa0disclosure).\\xa0\\xa0Such\\xa0insights\\xa0would\\xa0likely\\xa0\\nstrengthen\\xa0consumer\\xa0demand\\xa0for\\xa0healthy\\xa0products\\xa0and\\xa0services\\xa0and\\xa0reduce\\xa0risks\\xa0to\\xa0\\nparticipants.\\xa0\\n\\nMarch\\xa023,\\xa02011\\xa0\\n\\n\\xa026\\xa0\\n\\n\\x0cWay\\xa0Ahead\\xa0\\n\\nWhile\\xa0this\\xa0paper\\xa0has\\xa0presented\\xa0a\\xa0comprehensive\\xa0view\\xa0of\\xa0a\\xa0healthy\\xa0cyber\\xa0ecosystem,\\xa0there\\xa0are\\xa0\\nmany\\xa0open\\xa0questions.\\xa0On\\xa0the\\xa0more\\xa0technical\\xa0side,\\xa0they\\xa0include:\\xa0\\xa0Can\\xa0the\\xa0ongoing\\xa0work\\xa0on\\xa0\\nsecurity\\xa0content\\xa0automation\\xa0be\\xa0repurposed\\xa0for\\xa0self\\xa0defense?\\xa0\\xa0Will\\xa0commercial\\xa0products\\xa0\\nconform\\xa0to\\xa0open\\xa0standards?\\xa0To\\xa0what\\xa0extent\\xa0can\\xa0focus,\\xa0convergence,\\xa0and\\xa0agility\\xa0be\\xa0\\ndecentralized\\xa0to\\xa0cyber\\xa0systems\\xa0in\\xa0an\\xa0autonomic\\xa0(i.e.,\\xa0self‐managing)\\xa0fashion?\\xa0\\xa0Can\\xa0autonomic\\xa0\\ndefenses\\xa0scale\\xa0to\\xa0encompass\\xa0large‐scale,\\xa0distributed\\xa0and\\xa0multi‐domain\\xa0environments\\xa0(e.g.,\\xa0\\nmobile\\xa0telephony,\\xa0IP‐based\\xa0networks,\\xa0and\\xa0computing\\xa0platforms),\\xa0and\\xa0if\\xa0so,\\xa0what\\xa0elements\\xa0of\\xa0\\ntrust\\xa0would\\xa0be\\xa0required?\\xa0\\n\\nMoreover,\\xa0the\\xa0path\\xa0to\\xa0successful\\xa0realization\\xa0is\\xa0unclear.\\xa0What\\xa0are\\xa0the\\xa0business\\xa0drivers\\xa0that\\xa0will\\xa0\\nincent\\xa0the\\xa0necessary\\xa0investments?\\xa0What\\xa0are\\xa0the\\xa0appropriate\\xa0roles\\xa0and\\xa0responsibilities\\xa0of\\xa0the\\xa0\\npublic\\xa0and\\xa0private\\xa0sector\\xa0in\\xa0delivering\\xa0the\\xa0healthy\\xa0ecosystem?\\xa0Which\\xa0elements\\xa0should\\xa0be\\xa0\\nprioritized\\xa0for\\xa0early\\xa0realization?\\xa0\\n\\nAs\\xa0a\\xa0healthy\\xa0cyber\\xa0ecosystem\\xa0emerges,\\xa0governance\\xa0questions\\xa0become\\xa0salient.\\xa0Will\\xa0system\\xa0\\nowners\\xa0cede\\xa0decision\\xa0making\\xa0to\\xa0the\\xa0community?\\xa0\\xa0Who\\xa0sets\\xa0policy\\xa0for\\xa0inter‐enterprise\\xa0\\ninformation\\xa0exchange\\xa0and\\xa0deployment\\xa0of\\xa0countermeasures?\\xa0\\xa0What\\xa0liability\\xa0regimes\\xa0apply\\xa0for\\xa0\\ncollateral\\xa0consequences\\xa0of\\xa0countermeasure\\xa0deployment\\xa0(or\\xa0the\\xa0failure\\xa0to\\xa0deploy\\xa0known\\xa0\\ncountermeasures)?\\xa0\\xa0What\\xa0legal\\xa0authorities\\xa0should\\xa0local\\xa0and\\xa0national\\xa0governments,\\xa0as\\xa0well\\xa0as\\xa0\\ninternational\\xa0entities,\\xa0have\\xa0to\\xa0compel\\xa0action\\xa0by\\xa0devices\\xa0owned\\xa0by\\xa0or\\xa0serving\\xa0private\\xa0parties\\xa0in\\xa0\\norder\\xa0to\\xa0secure\\xa0the\\xa0larger\\xa0cyber\\xa0commons?\\xa0\\n\\nClearly\\xa0the\\xa0field\\xa0is\\xa0ripe\\xa0for\\xa0planning\\xa0and\\xa0action.\\xa0The\\xa0authors\\xa0welcome\\xa0feedback\\xa0on\\xa0this\\xa0paper,\\xa0\\nand\\xa0comment\\xa0on\\xa0all\\xa0aspects\\xa0of\\xa0the\\xa0problem.\\xa0\\xa0We\\xa0are\\xa0continuing\\xa0our\\xa0own\\xa0analysis,\\xa0and\\xa0we\\xa0plan\\xa0\\nto\\xa0publish\\xa0our\\xa0findings,\\xa0together\\xa0with\\xa0your\\xa0feedback\\xa0(to\\xa0cyberfeedback@dhs.gov),\\xa0in\\xa0a\\xa0sequel\\xa0\\npaper\\xa0and\\xa0a\\xa0proposed\\xa0action\\xa0plan\\xa0that,\\xa0at\\xa0a\\xa0minimum,\\xa0identifies\\xa0key\\xa0game‐changing\\xa0initiatives\\xa0\\nfor\\xa0each\\xa0of\\xa0the\\xa0three\\xa0building\\xa0blocks.\\xa0\\xa0Potential\\xa0game‐changing\\xa0initiatives\\xa0might\\xa0include:\\xa0\\n\\n\\uf0b7  Piloting,\\xa0demonstration,\\xa0and\\xa0rapid\\xa0promulgation\\xa0of\\xa0community\\xa0and\\xa0inter‐community\\xa0\\n\\nACOAs\\xa0for\\xa0collective\\xa0defense\\xa0\\xa0\\n\\n\\uf0b7  Piloting,\\xa0demonstration,\\xa0and\\xa0rapid\\xa0promulgation\\xa0of\\xa0security\\xa0content\\xa0automation\\xa0\\nstandards\\xa0for\\xa0functions\\xa0described\\xa0in\\xa0the\\xa0second\\xa0and\\xa0third\\xa0waves\\xa0of\\xa0Figure\\xa05\\xa0\\n\\n\\uf0b7  Building\\xa0upon\\xa0the\\xa0draft\\xa0NSTIC\\xa0to\\xa0achieve\\xa0standards‐based\\xa0device\\xa0authentication,\\xa0\\nincluding\\xa0small\\xa0and\\xa0often\\xa0wireless\\xa0devices\\xa0composing\\xa0massively\\xa0scalable\\xa0grids.\\n\\nMarch\\xa023,\\xa02011\\xa0\\n\\n\\xa027\\xa0\\n\\n\\x0cGlossary\\xa0\\n\\nGeneral\\xa0Terms\\xa0\\n\\n\\uf0b7  Cyber\\xa0devices\\xa0is\\xa0a\\xa0general\\xa0term\\xa0used\\xa0to\\xa0refer\\xa0to\\xa0computers;\\xa0software\\xa0systems,\\xa0applications\\xa0\\n\\nor\\xa0services;\\xa0electronic\\xa0communications\\xa0systems,\\xa0networks,\\xa0or\\xa0services;\\xa0and\\xa0the\\xa0\\ninformation\\xa0contained\\xa0therein.\\xa0\\n\\n\\uf0b7  Cyber\\xa0participants\\xa0refers\\xa0to\\xa0people,\\xa0processes,\\xa0and\\xa0devices.\\xa0\\n\\n\\uf0b7 \\n\\nInformation\\xa0structuring\\xa0refers\\xa0to\\xa0methods\\xa0and\\xa0standards\\xa0that\\xa0organize\\xa0data\\xa0into\\xa0\\ncomponents\\xa0and\\xa0relationships.\\xa0\\xa0A\\xa0general\\xa0example\\xa0of\\xa0structured\\xa0information\\xa0is\\xa0a\\xa0United\\xa0\\nStates\\xa0address.\\xa0\\xa0Its\\xa0components\\xa0are\\xa0street\\xa0number,\\xa0street\\xa0name,\\xa0city,\\xa0state,\\xa0and\\xa0zip\\xa0code.\\xa0\\xa0\\nStates\\xa0have\\xa0fixed\\xa0two‐digit\\xa0code\\xa0names\\xa0and\\xa0zip\\xa0codes\\xa0have\\xa0a\\xa0specified\\xa0five‐\\xa0or\\xa0nine‐digit\\xa0\\nformat.\\xa0\\xa0An\\xa0example\\xa0of\\xa0structured\\xa0cyber\\xa0security\\xa0information\\xa0is\\xa0Common\\xa0Platform\\xa0\\nEnumeration\\xa0(CPE),\\xa0a\\xa0naming\\xa0scheme\\xa0for\\xa0some\\xa0elements\\xa0of\\xa0cyber\\xa0systems.\\xa0\\xa0The\\xa0top‐level\\xa0\\ncomponents\\xa0of\\xa0a\\xa0CPE\\xa0are\\xa0platform\\xa0name,\\xa0hardware\\xa0parts,\\xa0operating\\xa0system\\xa0parts,\\xa0and\\xa0\\napplication\\xa0parts.\\xa0\\xa0Structured\\xa0cyber\\xa0security\\xa0information\\xa0is\\xa0necessary\\xa0to\\xa0automate\\xa0\\nactivities\\xa0that\\xa0identify\\xa0and\\xa0manage\\xa0cyber\\xa0devices\\xa0and\\xa0their\\xa0components,\\xa0describe\\xa0and\\xa0\\nmanage\\xa0security\\xa0configurations\\xa0and\\xa0vulnerabilities,\\xa0identify\\xa0and\\xa0track\\xa0attackers\\xa0and\\xa0attack\\xa0\\ntools\\xa0(e.g.,\\xa0malicious\\xa0code\\xa0or\\xa0botnets),\\xa0detect\\xa0and\\xa0describe\\xa0events\\xa0and\\xa0attacks,\\xa0express\\xa0\\nand\\xa0execute\\xa0cyber\\xa0security\\xa0policies\\xa0or\\xa0courses\\xa0of\\xa0action,\\xa0describe\\xa0and\\xa0provide\\xa0notice\\xa0of\\xa0\\ncyber\\xa0posture,\\xa0and\\xa0so\\xa0on.\\xa0\\xa0\\n\\n\\uf0b7  Cyber\\xa0information\\xa0exchange\\xa0refers\\xa0to\\xa0sharing\\xa0relationships\\xa0and\\xa0protocols\\xa0that\\xa0allow\\xa0cyber\\xa0\\nparticipants\\xa0to\\xa0publish\\xa0and\\xa0subscribe,\\xa0signal,\\xa0or\\xa0request\\xa0and\\xa0respond\\xa0with\\xa0cyber\\xa0security\\xa0\\ninformation\\xa0using\\xa0consistent\\xa0semantics.\\xa0\\n\\nStandards\\xa0Acronyms\\xa0\\n\\nARF\\xa0\\nCAIF\\xa0\\nCAPEC\\xa0\\nCCE\\xa0\\nCEE\\xa0\\nCPE\\xa0\\nCVE\\xa0\\nCVSS\\xa0\\nCWE\\xa0\\nIDMEF\\xa0\\nIODEF\\xa0\\nMAEC\\xa0\\nNIEM\\xa0\\nOVAL\\xa0\\nSecDEF\\xa0\\nXCCDF\\xa0\\n\\nAssessment\\xa0Results\\xa0Format\\xa0\\nCommon\\xa0Announcement\\xa0Interchange\\xa0Format\\xa0\\nCommon\\xa0Attack\\xa0Pattern\\xa0Enumeration\\xa0and\\xa0Classification\\xa0\\nCommon\\xa0Configuration\\xa0Enumeration\\xa0\\nCommon\\xa0Event\\xa0Expression\\xa0\\nCommon\\xa0Platform\\xa0Enumeration\\xa0\\nCommon\\xa0Vulnerabilities\\xa0and\\xa0Exposures\\xa0\\nCommon\\xa0Vulnerability\\xa0Scoring\\xa0System\\xa0\\nCommon\\xa0Weakness\\xa0Enumeration\\xa0\\nIntrusion\\xa0Detection\\xa0Message\\xa0Exchange\\xa0Format\\xa0\\xa0\\xa0\\nIncident\\xa0Object\\xa0Description\\xa0and\\xa0Exchange\\xa0Format\\xa0\\nMalware\\xa0Attribute\\xa0Enumeration\\xa0and\\xa0Characterization\\xa0\\nNational\\xa0Information\\xa0Exchange\\xa0Model\\xa0\\nOpen\\xa0Vulnerability\\xa0and\\xa0Assessment\\xa0Language\\xa0\\nSecurity\\xa0Description\\xa0and\\xa0Exchange\\xa0Format\\xa0\\xa0\\nExtensible\\xa0Configuration\\xa0Checklist\\xa0Description\\xa0Format\\xa0\\n\\nMarch\\xa023,\\xa02011\\xa0\\n\\n\\xa028\\xa0\\n\\n\\xa0\\n\\x0cMarch\\xa023,\\xa02011\\xa0\\n\\n\\xa029\\xa0\\n\\n\\xa0\\n\\x0c', '2nd URSI AT-RASC, Gran Canaria, 28 May – 1 June 2018 \\n\\nSusceptibility testing of COTS Sensors to RF Pulses with focus on widespread \\nelectronics for Information Security risks management and mitigation \\n\\nE. Al Shahhi(1), M. Bluhm(1), A. Garipov(1) and C. Kasmi(1) \\n(1) TV Labs, Xen1thLabs, DARK MATTER LLC, Abu Dhabi, United Arab Emirates \\nchaouki.kasmi@darkmatter.ae \\n\\nDuring the last decades, high interest has been shown to the analysis of the susceptibility of electronic devices to \\nintentional  electromagnetic  interference.  One  of  the  recent  main  contributions  is  the  link  between  the \\nElectromagnetic Compatibility (EMC) and Interference (EMI) testing and the Information Security needs [1-2]. \\nUsing  appropriate  health  monitoring  agents,  it  has  been  demonstrated  that  a  fine-grained  analysis  of  effects \\ninduced by parasitic fields can be obtained. Having at hand a precise list of effects for a given excitation defined \\nby a set of characteristics (e.g., type of source, PHY layer parameters), risks management can be enhanced by \\ntaking  into  account  threats  of  electromagnetic  attacks  for  improving  the  resilience  and  the  integrity  of  an \\ninfrastructure and the provided services. \\n\\nWhile many challenges remain for non-experts in electronics to completely design embedded systems, low cost \\nboards and sensors have been made available. Users have the possibility to implement software applications to \\ncombine  and  control  electronic  actuators  and  sensors with  development  platform  like  the  Arduino [3]. \\nConsidering the popularity of these  easily accessible tools for building embedded solutions in  the Internet-Of-\\nThings  (IoT),  the  Electromagnetic  Compatibility  of  such  solutions  becomes  questionable  as  their  implications \\nmay  affect  our  daily  lives  due  to  low  immunity  (e.g.  devices  may  experience  malfunctions  due  to  parasitic \\nexposures) or a high emissivity (e.g. devices may emit higher level of noise than the defined levels by standards). \\nIn [4], the Arduino motherboard has been tested and EMC issues have been raised. Nevertheless, as far as we \\nknow, the shields composed of sensors connected to the Arduino board have not been tested. \\n\\nFigure 1. Experimental test set-up for the susceptibility testing of COTS sensors  \\n\\nWhile many sensors may have been tested with regards to EMC standards, it is very common to buy counterfeits \\nof electronic devices in online markets. The likeliness of the EMC testing of these counterfeits is known to be \\nvery  low.  As  a  result,  when  inserted  in  custom  applications,  these  counterfeits  introduce  a  risk  to  the  EMC \\ncompliance of the built system. In this presentation, we propose  to analyze the susceptibility of low-cost sensors \\nto RF pulses with a dedicated test set-up as depicted in Figure 1, which only exposes the set of sensors. From the \\ninduced malfunctions and measurement errors, it  will be shown that unexpected behaviors can be encountered \\nputting an embedded system at risk. As an additional outcome, it will demonstrated that part of failures induced \\nby measurement errors and malfunctions can be mitigated by following some basic programming rules. \\n\\n\\nAuthorized licensed use limited to: Ryerson University Library. Downloaded on May 02,2022 at 02:09:10 UTC from IEEE Xplore.  Restrictions apply. \\n\\n \\n \\n \\n \\n \\n \\n \\n \\n\\x0c', '2021 13th International Conference on Cyber Conflict \\nGoing Viral\\n\\nT. Jančárková, L. Lindström, G. Visky, P. Zotz (Eds.)\\n\\n2021 © NATO CCDCOE Publications, Tallinn\\n\\nPermission  to  make  digital  or  hard  copies  of  this  publication  for  internal \\nuse within NATO and for personal or educational use when for non-profit or \\nnon-commercial purposes is granted providing that copies bear this notice \\nand a full citation on the first page. Any other reproduction or transmission \\nrequires prior written permission by NATO CCDCOE.\\n\\nThe Vulnerability of the Financial \\nSystem to a Systemic Cyberattack\\n\\nBobby Vedral\\nManaging Partner\\nMacroEagle Capital\\nPhD candidate, Modern War Studies Department\\nBuckingham University, United Kingdom\\nbobby.vedral@macroeagle.com\\n\\nAbstract: The financial industry is a prime target of cybercriminal activity, mainly \\ndue to the nature of its underlying business (‘that’s where the money is’1), the sector’s \\nglobal interconnectedness, and its high level of digitalization. In response, the private \\nsector  has  invested  vast  sums  into  cybersecurity,  and  regulators  have  started  to \\nworry about systemic risk. The latter comes in two forms. The first is the risk of a \\nsuccessful cyberattack against a specific financial institution ‘spilling over’ into the \\nbroader financial system, hence unintentionally becoming systemic. The second is the \\nnational security concern of a systemic cyberattack launched specifically to disrupt \\nthe  target’s  financial  ecosystem  and  therefore  the  real  economy.  In  both  cases,  the \\nhistoric evidence is clear: neither type of event has been recorded thus far. Those who \\nconsider warnings of systemic cyberattacks to be little more than threat inflation see \\nthat as vindication. This paper takes the opposite view and argues that the probability \\nof a systemic cyberattack is significant enough to warrant a higher degree of cross-\\ndisciplinary  research  and  preparedness.  To  support  its  main  argument,  this  paper \\nproposes a conceptual framework that focuses on answering two key questions. First, \\nare  there  sufficient  known  structural  vulnerabilities  in  the  financial  ecosystem  that \\ncould be exploited by a willing adversary? And second, are there plausible scenarios \\nthat could see an adversarial nation-state launch such an attack? The answer to both \\nis positive.\\n\\nGiven the lack of data, this analysis is largely qualitative, based on discussions with \\nregulators, chief risk officers, academic experts, and the author’s own multi-decade \\nexperience as an active participant in the financial market.\\n\\nKeywords: finance, resilience, systemic risk, vulnerabilities\\n\\n\\n \\n \\n \\n \\n\\x0c1. INTRODUCTION\\n\\nThe global financial system lies at the heart of Western liberal democratic market \\neconomies,  performing  many  key  intermediary  functions,  such  as  deposit-taking, \\nlending,  capital  markets,  investments,  and  payments.  As  it  is  at  the  forefront  of \\nglobalization, interconnectedness, and digitalization, its reliance on the confidentiality, \\nintegrity,  and  availability  of  data  and  systems  is  mission  critical.  It  is  therefore \\nno  surprise  that  national  security  experts  have  long  predicted  the  possibility  of  a \\ncyberattack  on  the  financial  system  with  systemic  consequences,  one  where  states \\nwould ‘suffer greatly from the instability which would befall world markets should \\nnumbers  be  shifted  in  bank  accounts  and  data  wiped  from  international  financial \\nservers’.2\\n\\n‘Systemic  cyber  risk’  therefore  means  a  risk  of  disruption  in  the  financial  system \\nwith the potential of serious negative consequences for the real economy. This paper \\ndifferentiates between two types of systemic cyber risks (see Figure 1). The first is \\none that starts as an idiosyncratic (company-specific) cyberattack, most probably with \\ncriminal intent but not intent to cause system-wide damage, but which inadvertently \\nspills over to the wider financial system. This tends to be the main concern of financial \\nregulators, given that empirical evidence points to cybercrime as the main risk. The \\nsecond is the ‘systemic attack’, defined as a nation-state or transnational group acting \\nwith the political intent to cause severe financial instability in the target’s financial \\nmarkets and thus harm the real economy as well. This tends to be the main concern \\nof the national security establishment and is the main focus of this essay. In addition, \\nthis  paper  defines  ‘cyberattack’  as  an  event-risk/shock  and  not  as  the  long-term \\nundermining of an industry through espionage (‘slow burn’ or ‘death by a thousand \\ncuts’).3\\n\\n\\n96\\n\\nAuthorized licensed use limited to: Ryerson University Library. Downloaded on May 02,2022 at 02:11:43 UTC from IEEE Xplore.  Restrictions apply. \\n\\n\\x0cFIGURE 1: SYSTEMIC CRISIS BY SPILLOVER VS BY INTENT\\n\\nThe quantitative evidence regarding systemic cyberattacks is clear: neither a ‘systemic \\nspillover’ nor a ‘systemic attack’ have occurred so far. But, as Figure 2 highlights, the \\nfinancial sector ranks first in most studies when it comes to the frequency of cyber \\nincidents, with most of them idiosyncratic (company specific) and criminal in nature. \\nAlso  noticeable  is  that,  probably  due  to  the  industry’s  high  level  of  investment  in \\ncybersecurity, the average cost per incident is low.4\\n\\nFIGURE 2: CROSS-SECTOR ANALYSIS OF CYBER INCIDENT FREQUENCY AND LOSSES5\\n\\nCategory\\n\\nFinance & \\ninsurance\\n\\nFrequency of \\nincidents \\n(% of total)\\n\\nTotal loss \\n(% of total)\\n\\nMean loss\\nin USD \\n(%ile)\\n\\nStandard \\ndeviation of loss \\nin USD (%ile)\\n\\n24%\\n\\n16%\\n\\nUSD 1.69 m\\n(10th %ile)\\n\\nUSD 15.45 m \\n(13th %ile)\\n\\nMost exposed \\nsector\\n\\nFinance\\n(24%)\\n\\nProfessional, \\nscientific, technical\\nUSD 8,778 m\\n(22%)\\n\\nTransportation \\nand storage\\nUSD 16.8 m \\n(100th %ile)\\n\\nWholesale trade\\nUSD 120.6 m \\n(100th %ile)\\n\\nThis lack of systemic attacks can be attributed to three factors. First, even criminal \\nnation-state actors, such as North Korea, need the capitalist financial system to work \\nin order to cash out. Second, even strategic rivals, like China, need Western capitalist \\nresources to fund their own growth; hence they have no interest in ‘biting the hand \\nthat  feeds  them’. And  third,  systemic  attacks  on  less  well  guarded  critical  national \\ninfrastructures (CNIs) may be easier to execute. \\n\\n\\nAuthorized licensed use limited to: Ryerson University Library. Downloaded on May 02,2022 at 02:11:43 UTC from IEEE Xplore.  Restrictions apply. \\n\\n97\\n\\n\\x0cWhy, then, worry about a systemic cyberattack on the financial system? To answer this \\nquestion, this paper suggests a conceptual framework which defines the probability \\nadjusted  economic  cost  (PAEC)  of  such  an  event  as  a  function  of  the  expected \\neconomic  cost  (EEC)  should  it  occur,  times  the  probability  of  such  a  systemic \\ncyberattack succeeding, i.e., the probability of a successful attack (PSA). The PSA in \\nturn is a function of: (1) the number of structural vulnerabilities in the financial system \\nthat could be exploited; (2) the probability that an adversary has the technical ability \\nto exploit them; (3) the probability that an adversary has the political intent to launch \\nsuch an attack. \\n\\n= \\n\\n x \\n\\n (vulnerabilities,ability,intent)\\n\\n𝑃𝐴𝐸𝐶 \\n\\n𝐸𝐸𝐶 \\n\\n𝑃𝑆𝐴\\n\\nBased  on  various  conversations  with  financial  regulators  and  practitioners,  many \\nagree that the key parameter in this model is ‘intent’. As Tim Maurer writes, ‘the main \\nvariable determining whether an actor can cause harm is not technical sophistication, \\nnot  knowledge  of  specific  vulnerabilities  or  development  of  sophisticated  codes, \\nbut  intent.  If  the  intent  is  there,  the  capability  will  follow’.6  Backed  by  the  above-\\nmentioned  absence  of  precedent  for  historic  systemic  attacks,  many  practitioners \\npoint to the lack of intent as the main reason. As a chief information security officer \\nat a major European bank wrote:\\n\\n[…]  the  Chinese  have  zero  interest  in  doing  anything  destructive  to  us \\nor  any  other  member  of  a  financial  system  that  makes  them  wealthy  and \\nallows  them  to  wield  political  and  economic  influence  abroad.  Even  Iran \\nwas circumspect in 2013 when they DDOSed US banks – the attack tech \\nwas pretty considerable, but the targets (retail banking websites) were fairly \\ntrivial. As long as GDP is a meaningful indicator to a nation-state, I don’t \\nbelieve that nation-state would perpetrate systemic attacks. That said, I’m \\nsure  they’re  curious  what  their  rich  citizens  are  up  to,  especially  if  that \\nwealth  could  be  used  to  aid  the  opposition,  so  it  wouldn’t  surprise  me  if \\nnation-states use espionage tactics against banks. But I can’t get my head \\naround  any  country  just  wanting  to  watch  the  system  burn  –  even  North \\nKorea,  now  that  they’ve  discovered  how  to  raise  hard  currency  through \\nhacking.7\\n\\nHence the focus of this paper is to make the case that the probability of a systemic \\nattack is neither ‘zero’ nor ‘very low’, as the historical precedent and consensus view, \\nrespectively, imply. The argument is developed in five parts. Section 2 reviews the \\nexisting literature on systemic risk in the financial system, which broadly agrees with \\nthe  assessment  that  the  impact  of  such  an  event  would  be  significant  and  that  the \\n\\n\\n98\\n\\nAuthorized licensed use limited to: Ryerson University Library. Downloaded on May 02,2022 at 02:11:43 UTC from IEEE Xplore.  Restrictions apply. \\n\\n\\x0cprobability is not zero. Section 3 makes the point that sufficient known vulnerabilities \\nin the current financial ecosystem exist that could be exploited if the will to do so \\nwere there. Section 4 addresses the key question about political intent from various \\nperspectives,  including  historical,  cultural,  and  doctrinal.  Section  5  concludes  with \\nsome basic recommendations and suggestions for further research.\\n\\n2. LITERATURE REVIEW ON ‘SYSTEMIC CYBER RISK’ \\nTO THE FINANCIAL SYSTEM\\n\\nInterest in ‘systemic risk’ took off after the Great Financial Crisis (GFC) of 2007–2008, \\nalthough the focus was always more on quantifiable financial aspects, such as market, \\ncredit,  and  liquidity  risk.  Cyber  risk,  a  sub-category  of  operational  risk,  received \\nrelatively little attention. With no commonly accepted definition of systemic risk, by \\n2009 the Financial Stability Board (FSB) outlined three criteria: size, substitutability, \\nand interconnectedness.8\\n\\nBy 2013, and following the Stuxnet disclosures, the White House issued Executive \\nOrder  13636,  instructing  the  Department  of  Homeland  Security  (DHS)  to  identify \\nthose financial institutions for which a ‘cyber incident would have far reaching impact \\non regional or national economic security’.9 This led three years later to the creation \\nof  the  Financial  Systemic Analysis  &  Resilience  Centre  (FSARC),  one  of  the  first \\ncollaborative efforts in the private sector.\\n\\nJudging  by  the  Bank  of  England’s  (BOE)  semi-annual  Systemic  Risk  Survey  (see \\nFigure 3), ‘cyberattacks’ started to become prominent among financial risk practitioners \\nin 2014, after the cyberattack on JP Morgan. This attack, widely attributed to Iran, \\naffected over 83 million customers.10\\n\\nAuthorized licensed use limited to: Ryerson University Library. Downloaded on May 02,2022 at 02:11:43 UTC from IEEE Xplore.  Restrictions apply. \\n\\n99\\n\\n\\x0cFIGURE 3: BOE SYSTEMIC RISK SURVEY – SOURCES OF RISK TO THE UK FINANCIAL SYSTEM11\\n\\nIn 2016, the year North Korea attempted to steal USD 951 million from Bangladesh’s \\ncentral  bank,12  the  members  of  the  G7  released  the  G7’s  Fundamental  Elements \\nof  Cybersecurity  for  the  Financial  Sector,  suggesting  eight  elements  to  follow  in \\ndesigning and implementing a cybersecurity program.13 Although few academics by \\nthat time challenged the view that cyberattacks posed a systemic risk, one important \\nexception was a 2016 Vox article by Danielsson et al. The article claimed that systemic \\ncyber  crises  were  extremely  unlikely,  as  most  cyberattacks  were  micro-prudential \\n(company-specific)  in  nature  and  required  extremely  fortunate  timing  to  become \\nsystemic.14\\n\\nIn  2017,  the  year  of  the  WannaCry  ransomware  attack  and  Equifax  hack,  the \\nInternational  Monetary  Fund  (IMF)  published  a  paper  describing  cyber  risk  as  a \\ntextbook example of systemic financial stability risk and identified the main sources \\nof vulnerabilities as access, concentration risk, correlation risk, and contagion risk.15 \\nFurthermore, the Institute of International Finance (IIF) published a paper that focused \\non the main types of scenarios that could have systemic repercussions, such as attacks \\n\\n\\nAuthorized licensed use limited to: Ryerson University Library. Downloaded on May 02,2022 at 02:11:43 UTC from IEEE Xplore.  Restrictions apply. \\n\\n\\x0con  FMI,  data  corruption,  failure  of  wider  infrastructure,  and  loss  of  confidence.16  \\nFinally, the US Office of Financial Research (OFR) identified the three key financial \\nstability risks posed by cyberattacks: lack of substitutability, loss of confidence, and \\nloss of data integrity.17\\n\\nBy  2018  the  BOE  published  two  important  papers.  One  warned  that  ‘just  because \\nthere  has  not  been  a  clear  example  of  a  systemic  impact  on  the  sector  yet,  it  does \\nnot mean it cannot or will not happen in the future’.18 The second indicated a new \\nand innovative regulatory approach in which the BOE considered the management \\nof  operational  resilience  to  be  most  effectively  addressed  by  focusing  on  business \\nservices  rather  than  on  systems  and  processes.  It  also  announced  a  new  regime  of \\ncloser cooperation with the security services, as the lack of data required it to rely \\nmore on expert judgements.19\\n\\nThe same year also saw the publication of a widely cited Brookings paper by Jason \\nHealey  et  al.  identifying  the  three  main  differences  between  cyber  and  financial \\nshocks (timing, complexity, and adversary intent) and flagging four major concerns: \\nattacker sophistication, single points of failure, international coordination, and new \\ntechnologies.20\\n\\nFinally, that year the FSB published a ‘cyber lexicon’ to establish a common language \\nand ensure consistent data collection and reliable measurement.21 This was followed \\nin  2019  by  the  International  Organization  of  Securities  Commissions  (IOSCO) \\npublishing  an  overview  of  existing  frameworks  for  cyber  regulation  to  serve  as \\nguidance for good practise.22\\n\\nIn  2020  the  European  Systemic  Risk  Board  (ESRB)  published  two  important  and \\nrelated  papers,  both  with  substantial  input  from  the  BOE.  The  first  paper  presents \\na  conceptual  model  that  analyses  a  cyber  incident  in  four  distinct  phases:  context, \\n\\nAuthorized licensed use limited to: Ryerson University Library. Downloaded on May 02,2022 at 02:11:43 UTC from IEEE Xplore.  Restrictions apply. \\n\\n101\\n\\n\\x0cshock, amplification, and systemic event. It then uses the model and discusses three \\nhypothetical  scenarios:  (1)  the  incapacitation  of  a  large  domestic  bank’s  payment \\nsystem;  (2)  the  malicious  destruction  of  account  balance  data;  (3)  the  scrambling \\nof  price  and  position  data.23  In  the  second  paper,  the  same  model  is  reviewed  and \\nan  extensive  number  of  systemic  mitigants  are  listed.24  In  December,  the  Carnegie \\nEndowment  published  a  report  on  systemic  cyber  risk,  identifying  and  providing \\ndetailed  recommendations  for  six  priority  areas:  cyber  resilience,  international \\nnorms,  collective  response,  workforce  challenges,  capacity-building,  and  digital \\ntransformation.25\\n\\nIn  summary,  the  existing  literature  shows  that  systemic  cyber  risk  is  a  concern  for \\nfinancial regulators, especially those in Britain and the US, where most of the relevant \\npublications originate from. It is also noticeable that the concern is fairly recent; most \\nof the more in-depth studies have been produced over the last one or two years. The \\ncurrent paper aims to build on the existing literature in that it focuses specifically on \\nthe likelihood of a systemic attack launched by an adversarial nation-state with the \\nintent to disrupt the target financial system. To address this question, this paper will \\nnow  turn  towards  highlighting  a  number  of  structural  vulnerabilities  in  the  global \\nfinancial system that could be exploited as either a target or an amplifier during such \\nan  attack. This  goes  back  to  this  paper’s  conceptual  model:  that  the  probability  of \\nsuccess is conditioned in part on the availability of vulnerabilities to exploit.\\n\\n3. STRUCTURAL VULNERABILITIES \\nIN THE FINANCIAL ECOSYSTEM\\n\\nThis  section  provides  an  overview  of  10  known  structural  vulnerabilities  of  the \\nfinancial ecosystem that highlight liberal democracies’ higher exposure to financial \\ninstability  due  to  differences  in  their  respective  political  economies  (openness, \\nvalues), structural concentration risks (currency, geography, counterparty, participants, \\nstrategy)  or  amplification  channels  (technology,  trust)  across  the  system.  The  list \\nis not meant to be exhaustive or an in-depth analysis of any one vulnerability. The \\nintention is to highlight the fact that there is no shortage of them and that the number \\nof possible vulnerabilities is, if anything, a parameter that increases the PSA factor in \\nthe conceptual model.\\n\\nAuthorized licensed use limited to: Ryerson University Library. Downloaded on May 02,2022 at 02:11:43 UTC from IEEE Xplore.  Restrictions apply. \\n\\n\\x0c1 – Degree of financial openness. Figure 4 compares four autocratic regimes with \\nthe main Western financial centres (US, UK) and ranks them based on military and \\nsocioeconomic criteria. Although autocratic states differ greatly in terms of economic \\nsize, they show a much tighter control over their media and financial systems, which \\nsuggests a greater degree of control in times of crisis. For example, although China \\nhas  the  four  largest  banks  by  assets  in  the  world,  their  international  expansion  is \\nminimal.26 This contrasts with their American and European peers, who have extensive \\ninternational  networks.  Or  take  North  Korea,  which  has  a  record  of  attempting  to \\nparalyse  financial  networks  in  South  Korea  through  cyberattacks,  but  whose  own \\nfinancial system is largely analogue and hence immune.27\\n\\nFIGURE 4: KNOW YOUR ADVERSARY (COUNTRY’S GLOBAL RANKING BY CATEGORY)\\n\\nCountry\\n\\nUS\\nUK\\n\\nChina\\nRussia\\nIran \\nNorth Korea\\n\\nCyber \\nPower28\\n(2020)\\n\\n1\\n3\\n\\n2\\n4\\n23\\n16\\n\\nGDP29\\n(2019)\\n\\n1\\n6\\n\\n2\\n11\\n29\\nno data\\n\\nMilitary \\nSpending \\n(2019)30\\n\\nPress \\nFreedom31\\n(2020)\\n\\nFinancial \\nOpenness32\\n(2018)\\n\\n1\\n8\\n\\n2\\n4\\n18\\nno data\\n\\n45\\n35\\n\\n177\\n149\\n173\\n180\\n\\n1\\n1\\n\\n105\\n85\\n165\\nno data\\n\\n2  –  Domestic  politics.  Given  the  international  exposure  of  Western  financial \\ninstitutions, it is likely that they are more vulnerable to political pressure generated by \\ndomestic conflicts, such as when consumer activism at home clashes with commercial \\ninterests overseas. For example, Beijing’s 2020 imposition of a new security law in \\nHong Kong saw the British government lead the international condemnation, while \\nHSBC  and  Standard  Chartered,  two  British  banks  with  significant  commercial \\n\\n\\nAuthorized licensed use limited to: Ryerson University Library. Downloaded on May 02,2022 at 02:11:43 UTC from IEEE Xplore.  Restrictions apply. \\n\\n\\x0cinterests in China, publicly endorsed the new law.33 The point here is not to judge if \\nWestern institutions should have these conflicts but to highlight that they exist and to \\nencourage further research into their implications.\\n\\n3 – Currency concentration. Figure 5 provides a snapshot of the currency market, \\nwhere USD 6.6 trillion is traded every day.34 The US dollar is strongly overrepresented \\n(when compared to US GDP), while the Chinese yuan is strongly underrepresented \\n(when compared to China’s GDP). While in the short term, this may seem to confer \\nan  advantage  on  the  US  –  for  instance,  to  be  able  to  apply  economic  sanctions  on \\ncountries  such  as  Russia  and  Iran  –  there  are  three  drawbacks.  First,  any  loss  of \\nconfidence in the US dollar would immediately have systemic repercussions. Second, \\nthe sanctions have driven Russia and China to develop their own parallel financial \\ninfrastructure,  which  will  increase  their  operational  independence  and  resilience  in \\nthe future.35 Third, a country falling under US dollar sanctions is so cut off from the \\nglobal financial system that it might consider there to be no downside in attacking the \\nsystem.\\n\\nFIGURE 5: US DOLLAR HEGEMONY IN THE FINANCIAL SYSTEM\\n\\n% GDP (2019)36\\n\\nDaily currency turnover, \\n% of total (2019)\\n\\nCurrency as % \\nof global reserves37\\n\\nUnited States (USD)\\n\\n24.4%\\n\\nChina38 (RMB)\\n\\n16.3%\\n\\nEuro Area (EUR)\\n\\n15.2%\\n\\nAll others\\n\\n54.9%\\n\\n44.1%\\n\\n2.1%\\n\\n16.1%\\n\\n37.7%\\n\\n60.4%\\n\\n2.1%\\n\\n20.5%\\n\\n17.0%\\n\\n4 – Geographic concentration. The global financial system is extremely concentrated \\nin two markets: the US (New York), mainly for capital raising, and the UK (London), \\nmainly for international banking, such as currency and derivative transactions. While \\nthis has clear advantages such as the clustering of expertise, it also has a major drawback \\n\\n\\nAuthorized licensed use limited to: Ryerson University Library. Downloaded on May 02,2022 at 02:11:43 UTC from IEEE Xplore.  Restrictions apply. \\n\\n\\x0cin that it offers obvious geographic targets. It is yet to be seen if the pandemic-induced \\ntrend toward remote working will endure and help reduce this vulnerability.\\n\\nFIGURE  6:  GEOGRAPHICAL  DISTRIBUTION  OF  TOP  FIVE  FOREIGN  EXCHANGE AND  INTEREST \\nRATE DERIVATIVES TURNOVER\\n\\nCountry\\n\\nUnited States\\n\\nJapan\\n\\nUnited Kingdom\\n\\nChina (incl. Hong Kong)\\n\\nFrance\\n\\nEquities39\\n\\nFX turnover40\\n\\nIR Derivatives41\\n\\n54.5%\\n\\n7.7%\\n\\n5.1%\\n\\n4.0%\\n\\n3.2%\\n\\n26.5%\\n\\n4.5%\\n\\n43.1%\\n\\n8.2%\\n\\n2.0%\\n\\n32.2%\\n\\n1.7%\\n\\n50.2%\\n\\n6.0%\\n\\n1.6%\\n\\n5 – Central counterparty concentration. One of the key objectives of the regulatory \\nreform efforts after the Great Financial Crisis (GFC) of 2007–2008 was to move from \\na trading ecosystem centred on banks and bespoke bilateral contracts to one where \\nexchanges,  central  counterparties  (CCPs),  and  standardized  contracts  take  centre \\nstage (see Figure 7). But while connecting firms through centralized networks makes \\nsense,  when  market  and  liquidity  risk  are  a  regulator’s  key  priority,  it  might  have \\ninadvertently created a single point of failure from an operational perspective. \\n\\nFIGURE  7:  SECURITIES  TRADING  ECOSYSTEM  BEFORE  AND  AFTER  THE  GREAT  FINANCIAL \\nCRISIS (GFC)\\n\\n\\nAuthorized licensed use limited to: Ryerson University Library. Downloaded on May 02,2022 at 02:11:43 UTC from IEEE Xplore.  Restrictions apply. \\n\\n\\x0c6  –  Market  participant  concentration.  The  financial  industry  is  no  exception  to \\nthe global trend of industry concentration, usually a regulatory concern for reasons \\nof competition and antitrust.42 Like geographic concentration, this has the advantage \\nof clustering expertise and ability to invest in cybersecurity. But it also means that \\nonce  broken,  the  risk  of  systemic  contagion  is  higher. Also  worth  considering  are \\nthe  network  externalities  of  smaller  financial  institutions,  which  are  probably  less \\nprotected  and  hence  more  exposed.  A  recent  Federal  Reserve  paper  showed  that \\nunder the right circumstances, a single coordinated attack on an average of 24 small \\ninstitutions could lead to at least one of the top five institutions’ reserves dropping \\nbelow its minimum liquidity.43\\n\\n7 – Investment strategy concentration. In the aftermath of the GFC, as banks and \\ninsurance companies de-risked, the asset management industry picked up much of the \\nslack. At the same time, with financial conditions extremely loose (low interest rates \\nand central bank balance sheet expansion), equity markets rose and investors shifted \\ntowards passively managed funds, increasing the amount of ‘herding’, as these funds \\nmerely track indices and benchmarks. A recent study by the US Federal Reserve Board \\nnoted that this active-to-passive shift meant an increased risk of amplifying market \\nvolatility  (due  to  herding)  and  led  to  increasing  industry  concentration  (economies \\nof  scale).44 A  cyberattack  on  the  integrity  of  critical  market  data  underlying  these \\nbenchmark  indices  and  strategies  would  likely  paralyse  much  of  the  investment \\nmarket.\\n\\n8 – FinTech and Digitalization. FinTech is a relatively new term that, loosely defined, \\nrefers to technological innovations that affect financial services. These include cloud \\ncomputing, robotics, artificial intelligence (AI) and machine learning (ML), mobile \\napplications, big data analytics, blockchain or distributed ledger technology (DLT), \\ncryptography,  and  quantum  computing.  While  FinTech  clearly  has  the  potential  to \\nenhance, transform, and disrupt financial services, it also poses significant new risks. \\nFirst is the risk that speed and innovation comes at the expense of safety. Second is \\nthe lack of visibility for regulators to assess technological commonalities.45 Third is \\n\\n\\n\\nAuthorized licensed use limited to: Ryerson University Library. Downloaded on May 02,2022 at 02:11:43 UTC from IEEE Xplore.  Restrictions apply. \\n\\n\\x0cthe risk that the rapid adoption of new technology makes existing regulatory models \\nobsolete and hence creates new risks to financial stability.46\\n\\n9  – Automation.  In  July  2015  the  New York  Stock  Exchange  (NYSE)  halted  the \\ntrading of USD 28 trillion worth of stocks because of a coding error at Knight Capital \\nGroup,  which  itself  declared  bankruptcy  a  few  days  later.  While  this  and  various \\nother  technical  flash  crashes  do  not  themselves  point  to  anything  bigger,  they  do \\nreveal the fragility of the underlying reliance on high-frequency data-driven systems, \\nquantitative algorithms, and ever-increasing trading speed, which taken together can \\nlead to errors spreading faster and further, outpacing a management’s ability to take \\ncorrective action. As Lucas Kello points out: ‘A major and international interruption \\nof stock-trading platforms could create psychological reverberations that undermine \\npublic confidence in the entire financial system.’47\\n\\n10 – Trust. The lifeblood of financial markets is news, data, and trust. Since cyber \\noperations allow attackers to target the integrity and/or availability of key financial \\ndata  (as  mentioned  above)  or  spread  misinformation,  a  cyberattack  becomes  the \\nweapon of choice, should finance be the target. An early example of the impact of \\nmisinformation was the Syrian Electronic Army’s takeover of the Associated Press’s \\nTwitter account in April 2013, sending the fake message of a bomb attack on President \\nObama, that caused the Dow to plunge 146 points in a few seconds, erasing USD 136 \\nbillion in market value.\\n\\nAs mentioned above, the point of illustrating these vulnerabilities is to flag that the \\nfinancial system has various vulnerabilities that can be exploited, if the will to do so \\nexists. In the next section, we turn to the crucial question of intent.\\n\\n4. ON POLITICAL INTENT\\n\\nAs mentioned in the introduction, one of the most consistent pushbacks on the PSA is \\nthat most practitioners consider such an act economically irrational and hence conclude \\nthat there is little or no chance of an adversary acting this way. Six arguments can be \\nmade to argue that the probability is high enough to make the PSA and therefore the \\nPAEC significant.\\n\\nFirst,  historical  precedent  shows  the  fallacy  of  the  economic  interdependence \\nargument.48 Henry Kissinger recently warned that the current Sino-American state of \\n\\n\\nAuthorized licensed use limited to: Ryerson University Library. Downloaded on May 02,2022 at 02:11:43 UTC from IEEE Xplore.  Restrictions apply. \\n\\n\\x0crelations bears similarities to the conditions that led to World War I.49 Back then, well-\\nregarded authors such as J.G. Bloch (Is War Now Impossible?) and Norman Angell \\n(The  Great  Illusion)  argued  that  economic  interdependence,  especially  the  cross-\\nborder flow of credit, technological innovation, and pure self-interest, would triumph \\nin the face of narrow concepts of national interest and hence make war impossible.50 \\nIt did not. \\n\\nSecond, nations with different histories, cultures, geographies, economies, and real or \\nperceived threat perceptions still struggle to correctly assess other nations’ strategic \\ninterests. Recent evidence of this includes the Iraqi invasion of Kuwait (1990), the \\n9/11 attacks (2001), the ISIS offensive (2014), the Russian invasion of Crimea (2014), \\nthe Chinese militarization of the South China Sea (2016), and the recent crackdown in \\nHong Kong (2020), most of which caught Western intelligence services by surprise. \\nThis  is  relevant,  as  some  Western  observers  believe  that  China  will  not  overreact \\nwhen it comes to Taiwan. But as Coker correctly points out: ‘The US palpably failed \\n[...] in its own overreaction to 9/11. There is no “reason” to suspect the Chinese of \\nbeing any more sophisticated in reasoning out what is in their best interests.’51\\n\\nThird, a common misconception is to see a systemic attack on the financial system as an \\nopening shot to war. However, it could just be an act of non-violent political coercion \\nintended to strategically undermine another nation’s will to fight by highlighting the \\neconomic cost of intervention. To return to the Taiwan example, if China wanted to \\nsend a strong message, a cyberattack would probably be preferable to a kinetic attack. \\nAs Adam Segal points out: ‘In the future the moral expectation may be that states use \\ncyber weapons before kinetic ones.’52\\n\\nFourth, military doctrine naturally evolves with technological capabilities. The 2010 \\nmilitary doctrine of the Russian Federation made clear that information warfare is an \\ninstrument ‘to achieve political objectives without the utilization of military force’.53 \\nIn a similar fashion, Chinese strategists speak of strategic cyber warfare being intended \\nto ‘paralyze state apparatus and [bring] about social unrest and the downfall of enemy \\ncountries’ governments’.54 According to Coker:\\n\\n\\nAuthorized licensed use limited to: Ryerson University Library. Downloaded on May 02,2022 at 02:11:43 UTC from IEEE Xplore.  Restrictions apply. \\n\\n\\x0cThe use of cyber-attacks is entirely consistent with Chinese strategic thinking. \\n‘Force’ (‘Li’) only appears nine times in Art of War’s 13 chapters. As far as \\nSun Tzi was concerned victory and defeat are essentially psychological. The \\nobject is to inflict pain psychologically rather than physically – to put the \\nenemy on the back foot and keep him there.55\\n\\nFifth, targeting the financial system allows attackers to disproportionally target the \\nelites.  For  example,  in  the  US,  the  top  10%  of  households  owned  88.1%  of  stock \\nwealth in the fourth quarter of 2019, the highest level since record-keeping began in \\n1989.56 The implication of this is twofold in the case of a coercive cyberattack: either \\nthe elites will put pressure on their national government to safeguard their financial \\ninterests, or the ‘bottom 90%’ will put pressure to stop the financial chaos before it \\nspreads into the real economy. \\n\\nSixth is a question of reciprocity. The US and UK are reported to have ‘war-gamed a \\nmassive cyber strike to black out Moscow if Vladimir Putin launches a military attack \\non the West’.57 One can only assume that, in the unlikely case they had not thought \\nabout it already, they have now taken notice and are planning their own measures.\\n\\n5. CONCLUSION\\n\\nThis paper has argued that the probability of a successful systemic cyberattack (PSA) \\nis  higher  than  the  one  implied  by  precedent  (zero)  or  the  very  low  estimate  given \\nby various financial practitioners. Given that the economic impact of such an attack \\n(EEC)  would  most  likely  be  significant,  any  non-zero  PSA  implies  a  high  enough \\nprobability  adjusted  economic  cost  (PAEC)  to  warrant  investment  into  further \\nresearch and preparedness planning. In fact, it is possible that the numerous observed \\ncyberattacks  on  the  financial  sector  are  serving  as  an  ongoing  laboratory  where \\nmalicious payloads and exploits are developed and refined in order to be used later for \\nsystemic cyberattack purposes.\\n\\nFuture  research  could  consider  a  number  of  other  questions.  For  instance,  it  could \\nattempt  to  quantify  the  parameters  identified  in  the  conceptual  model,  where,  for \\nexample,  the  EEC  should  vary  from  country  to  country  given  differences  in  the \\nunderlying  economic  size  and  structure.  Moreover,  an  in-depth  analysis  could  be \\nmade into any of the mentioned vulnerabilities, not only in terms of their stand-alone \\n\\n\\nAuthorized licensed use limited to: Ryerson University Library. Downloaded on May 02,2022 at 02:11:43 UTC from IEEE Xplore.  Restrictions apply. \\n\\n\\x0cimpact but also considering the potential multiplier effect if two or more were targeted \\nat the same time.\\n\\nAs  for  basic  policy  recommendations,  three  stand  out.  First,  from  the  publicly \\navailable literature review, it is clear that US and UK financial regulators are at the \\nforefront in terms of quantitative and qualitative analysis. That makes intuitive sense, \\nsince both host the world’s major financial centres but also benefit from world-leading \\ncybersecurity and intelligence services. NATO members’ financial regulators should \\nactively seek their advice and look for possibilities for cooperation. \\n\\nSecond, the ultimate backup plan against a systemic cyberattack is to switch off the \\ndigitalized part of the financial system while keeping the real economy running. One \\nEuropean financial regulator feared that the financial industry was too digitalized for \\nthis alternative to be an option.58 But on the other hand, as recently as February 2018, \\nSweden’s central bank governor called for public control over the country’s (largely \\nprivate) payment system, fearing that a fully digital system would be vulnerable to \\nattack. He said: ‘It should be obvious that Sweden’s preparedness would be weakened \\nif,  in  a  serious  crisis  or  war,  we  had  not  decided  in  advance  how  households  and \\ncompanies would pay for fuel, supplies and other necessities.’59 Regulators should \\ntherefore consider public backup institutions on zero-trust architecture that, in an act \\nof ultimate resilience, would allow for commercial banking to ‘go manual’. A possible \\nanalogy is the response of Norsk Hydro to a March 2019 cyberattack: the Norwegian \\nfirm averted a major operational disaster by switching its plants to manual.60 One idea \\nwould be to use the military’s logistical capabilities to support the financial regulators \\nand the private sector in providing an emergency backup banking system to the real \\neconomy during a state of emergency.\\n\\nThird,  cross-disciplinary  scenario  planning  and  war-gaming  involving  practitioners \\nfrom finance, intelligence services, technology providers, and the armed forces should \\nbe encouraged. A common language should be created, and industry-specific jargon \\nshould  be  avoided  so  as  not  to  create  distance  and  separation  in  cross-disciplinary \\ncommunication.  Critical  issues  are  too  often  misunderstood  and  hence  remain \\nundebated.  Worst-case-scenario  planning  between  finance,  financial  regulators, \\nand  national  security  needs  to  be  encouraged,  as  economic  interconnectedness  and \\nrational-choice theory are no protection against geopolitical conflict.\\n\\n\\nAuthorized licensed use limited to: Ryerson University Library. Downloaded on May 02,2022 at 02:11:43 UTC from IEEE Xplore.  Restrictions apply. \\n\\n\\x0c', 'The RUSI Journal\\n\\nISSN: 0307-1847 (Print) 1744-0378 (Online) Journal homepage: https://www.tandfonline.com/loi/rusi20\\n\\nAn Assessment of Supply-Chain Cyber Resilience\\nfor the International Space Station\\n\\nNoel Hannan\\n\\nTo cite this article: Noel Hannan (2018) An Assessment of Supply-Chain Cyber\\nResilience for the International Space Station, The RUSI Journal, 163:2, 28-32, DOI:\\n10.1080/03071847.2018.1469249\\n\\nTo link to this article:  https://doi.org/10.1080/03071847.2018.1469249\\n\\nPublished online: 31 May 2018.\\n\\nSubmit your article to this journal \\n\\nArticle views: 389\\n\\nView related articles \\n\\nView Crossmark data\\n\\nFull Terms & Conditions of access and use can be found at\\nhttps://www.tandfonline.com/action/journalInformation?journalCode=rusi20\\n\\n\\x0cAN ASSESSMENT OF SUPPLY-CHAIN \\nCYBER RESILIENCE FOR THE \\nINTERNATIONAL SPACE STATION\\n\\nNOEL HANNAN\\n\\nNoel Hannan addresses the subject of supply-chain cyber resilience for the International \\nSpace Station (ISS), examining and cross-referencing supply-chain security and the ISS, \\nboth relatively new focuses in the domain of cyber security. He concludes that there \\nwill be a significant threat from many attack vectors to the ISS in its remaining years of \\noperation.\\n\\nDuring  the  research  for  this \\n\\narticle  into  supply-chain  cyber \\nresilience  for  the  International \\nSpace Station (ISS), it became apparent \\nthat  cyber  and  space  as  conceptual \\ndomains  have  been  intertwined  since \\ndeveloping in parallel after the Second \\nWorld  War.  The  requirement  then \\nto  build  a  digital  computer  to  beat \\nan  analogue  one  (the  BOMBE  vs  the \\nEnigma)1  drove  the  birth  of  modern \\ncomputing  (and  perhaps,  the  opening \\nshots  of  what  we  may  now  call  the \\nCyber  War).  In  addition,  Wernher  von \\nBraun’s rocketry in support of the Nazi \\nwar  effort \\nin  the  1940s  eventually \\nplaced US astronauts on the Moon.2\\n\\nScience  fiction  has  added  to  this \\nlexicon  with  imaginative  leaps  in  the \\ndevelopment  of  artificial  intelligence, \\nsuch  as  the  character  HAL  in  Arthur  C \\nClarke’s  2001:  A  Space  Odyssey.3  The \\ndefinitions  were  perhaps  blurred  even \\nfurther  with  the  widespread  use  of \\nthe  term  ‘cyberspace’,  first  coined  (in  a \\nsomewhat  offhand  but  typical  way)  by \\nWilliam Gibson in his 1986 story, Burning \\nChrome, in which he wrote: \\n\\nIt was hot, the night we burned Chrome. \\nOut in the malls and plazas, moths were \\nbatting themselves to death against the \\nneon, but in Bobby’s loft the only light \\ncame  from  a  monitor  screen  and  the \\ngreen  and  red  LEDs  on  the  face  of  the \\nmatrix  simulator.  I  knew  every  chip  in \\nBobby’s  simulator  by  heart;  it  looked \\nlike  your  workaday  Ono-Sendai  VII, \\nthe  ‘Cyberspace  Seven’,  but  I’d  rebuilt \\nit so many times that you’d have had a \\nhard time finding a square millimetre of \\nfactory circuitry in all that silicon.4\\n\\nFor clarity in this article, the terms \\n‘cyber’ and ‘space’ will remain separate, \\nbut  it  is  interesting  to  note  during  the \\nassessment  of  cyber  resilience  for  a \\nspace-based  platform  how  dependent \\nare  all  modern \\nsystems,  whether \\ntechnological  (life  support,  transport, \\nlaunch,  communications,  medical)  or \\nhuman \\n(psychological,  physiological, \\nsociological,  political),  on  information \\ntechnologies. The intertwining of the two \\ndomains  is  an  interesting  combination \\nof \\ninterdependence, \\ndevelopment  over  broadly  parallel \\n\\ntechnological \\n\\ntimeframes, and  the  semantics  of  using \\nthe same term with two meanings (space \\nas a concept, space as an actuality). Cyber \\nresilience therefore touches every facet \\nof the ISS’s operations.\\n\\nSelecting  the  ISS  as  the  target  of \\nthe  research  was  always  going  to  be  a \\ndemanding  decision.  It  was  launched \\nin  1998  and  in  its  present  form  is  the \\ncombined effort of a core of four states \\n–  the  US,  Russia,  Canada  and  Japan  – \\nas  well  as  EU  member  states.  China, \\nan  early  potential  collaborator  with  an \\nextensive and relatively successful space \\nprogramme  of  its  own,  was  banned  in \\n2011  from  involvement  in  the  ISS  by \\nthe  US  Congress  due  to  allegations  of \\nindustrial  espionage,5  a  decision  that \\nhas  yet  to  be  rescinded  and  which  has \\nresulted in a threat vector that remains \\nto be explored in some detail.\\n\\nhistory \\n\\nChina  has  a \\n\\nof \\nto  accelerate \\n\\nlong  and  well-\\nindustrial \\ndocumented \\nespionage  used \\nthe \\nachievement  of  aggressive  economic \\ntargets.  This  article  does  not  suggest \\nthat the Chinese would necessarily wish \\nthe ISS or its occupants harm, but it does \\n\\n© RUSI JOURNAL APRIL/MAY 2018 VOL. 163 NO. 2 pp. 28–32\\n\\nDOI: 10.1080/03071847.2018.1469249\\n\\nTHE RUSI JOURNAL\\x0cNOEL HANNAN\\n\\nThe International Space Station viewed from STS-133. Courtesy of NASA Images/Dominic Lipinski\\n\\nposit that they would appreciate access \\nto  some  of  its  multi-use  technologies. \\nThis  article  also  does  not  extend  to  the \\nbroader  review  of  threat  actors  and \\ngroups or an analysis of those who might \\nwish catastrophe on the ISS, which would \\ninclude nihilistic stateless groups, such as \\nDaesh (also known as the Islamic State of \\nIraq and Syria, or ISIS). For organisations \\nwith destructive or anarchistic agendas, \\nbeing able to affect the operation of the \\nISS  in  even  a  small  manner,  let  alone  a \\nspectacular  event,  would  be  a  huge \\npublicity coup.\\n\\nincluding  the \\n\\nHowever,  perhaps \\n\\nthe  greatest \\nthreats to the ISS come from failures in \\nprocess  and  design,  which  have  been \\nthe  cause  of  all  major  historic  space \\ndisasters, \\nloss  of  the \\nshuttles  Challenger  on  28  January  1986 \\nand Columbia on 1 February 2003.6 There \\nis  also,  of  course,  the  possibility  of  ISS \\noperations  being  disrupted  by  a  cyber \\nevent,  whether  accidental  or  malicious \\n(the  ISS  has  had  instances  of  computer \\nviruses being introduced via laptops7), in \\nthe  same  way  that  the  constellation  of \\ncommunications,  GPS  and  other  critical \\nsatellites  are  being  assessed  for  cyber \\nvulnerabilities.8\\n\\nIn its almost 20 years of existence, the \\nISS has had a varied and interesting history. \\nIt is now the longest-surviving permanently \\nmanned space habitat. It has built on the \\nsolid foundations of its predecessors, the \\nSoviet Union’s Salyut programme, the US \\nSkylab,  and  most  notably  Russia’s  Mir, \\nwith  which  it  briefly  shared  space.  Since \\n1971,  there  have  been  222  astronauts, \\ncosmonauts and in some cases commercial \\nvisitors  living  onboard  for  time  periods \\nstretching from a week to almost a year.9\\n\\nThe ISS has seen its original resupply \\nvessel, the NASA Space Shuttle, consigned \\nto  history  and  a  place  in  aerospace \\nmuseums across the US, and now relies \\non the Russian-designed Soyuz series of \\nspacecraft,  in  service  in  various  forms \\nsince 1967 and currently the only assured \\nmethod of transporting humans into low \\nEarth  orbit  (LEO)  and  back  again.  For \\nlogistics  resupply,  there  is  the  Russian \\nProgress cargo spacecraft, the European \\nAutomated Transfer Vehicle, the Japanese \\nH-II  Transfer  Vehicle,  and  the  Dragon \\nand  Cygnus  vehicles,  which  are  flown \\ncommercially  by  Elon  Musk’s  SpaceX \\norganisation and Orbital ATK, respectively. \\nThe  intent  is  for  the  Dragon  vehicles  to \\none day transport personnel in addition \\n\\nis  currently  finding \\n\\nto  cargo,  but  commercial  manned \\nspaceflight \\nitself \\ninhibited by US safety legislation and test-\\nflight requirements that would have left \\nthe Apollo and Space Shuttle programmes \\non  the  ground.10  It  seems  that  this  is  a \\nparticularly  twenty-first-century  hurdle \\nwhich  will  need  to  be  overcome  before \\nhumanity is once again heading per ardua \\nad astra (‘through adversity to the stars’).\\nThe  ISS  stands  as  an  incredible \\nsymbol of human endeavour and appears \\n(at  least  through  the  lens  of  popular \\nmedia) to navigate the morass of political, \\nsocial and economic issues with an ease \\nwhich would strangle at birth many lesser \\nprojects. As this article will demonstrate, \\nthe reality is not that simple, but it remains \\ntrue  that  Russian  and  NATO  military \\nofficers have sat together looking through \\nthe ISS observation windows while their \\nrespective  armies  have  rattled  sabres \\nat each other back on Earth, in Kosovo, \\nGeorgia,  Ukraine  and  Syria.  Although \\nthere is recorded criticism of the ‘military \\ndominance of space “thinking”’,11 the ISS \\nis one of the few truly demilitarised zones \\nof international cooperation. There are no \\nweapons on the ISS. It is also a frequent \\ncomment from returning astronauts that \\n\\n29\\n\\n\\x0cAN ASSESSMENT OF SUPPLY-CHAIN CYBER RESILIENCE FOR THE INTERNATIONAL SPACE STATION\\n\\ntheir time on the ultimate physical ‘high \\nground’ gives them a new perspective on \\nthe problems faced below, and that the \\nuniquely human concept of borders is not \\ngenerally visible from space.\\n\\nIt \\n\\nThere  may  be  no  weapons  on  the \\nISS,  but  there  are  some  very  definite \\nthreats  to  its  resilience  and  that  of  its \\nsupply chain. The ISS is one of the most \\ncomplex single entities ever constructed, \\nas an engineering and scientific feat it is \\neasily  comparable  to  a  modern  nuclear \\naircraft  carrier,  nuclear  submarines \\nor  the  space  shuttles  themselves,  as \\nevidenced  by  a  discussion  between \\nNASA  and  British  engineers  working \\non  the  Astute  submarine  programme \\nduring  the  2000s.12 \\nis  essentially \\ninterconnected  and \\na  platform  of \\ninterdependent \\ncontrol \\nindustrial \\nsystems and supervisory, control and data \\nacquisition systems (SCADA), in addition \\nto  an  extensive  communications  suite, \\norbital  engineering  and  repair,  medical \\nfacilities,  life  support,  and  of  course \\nseveral large and continually functioning \\nlaboratories researching space medicine, \\nlife  and  physical  sciences,  astronomy \\nand  meteorology.  Scientific  research  is \\nits primary purpose.13 The specification, \\ndeployment,  management \\ndesign, \\nand  recovery  of  these  components, \\nincluding  orbital  experiments,  is  largely \\nthe  responsibility  of  a  vast  and  diverse \\ninternational  supply  chain.  Within  this \\nsupply chain there can be vulnerabilities \\nto  the  station’s  cyber  resilience:  that  is, \\nits  ability  to  receive,  communicate  and \\nprocess  critical  information  in  a  timely \\nand  accurate  manner  to  ensure  the \\nintegrity of ISS operations and, primarily, \\nthe safety of its crew.\\n\\nIt is also worth noting the changes to \\nthe  political  and  economic  environment \\nduring  the  34  years  since  the  grand \\ninauguration of the project by US President \\nRonald  Reagan  in  1984,  mimicking  and \\nechoing  President  John  F  Kennedy’s \\ncommitment in 1962 to place men on the \\nMoon before the end of that decade,14\\n\\nOur progress in space, taking giant steps \\nfor all mankind, is a tribute to American \\nteamwork  and  excellence.  Our  finest \\nminds \\nindustry  and \\nacademia have all pulled together. And \\nwe  can  be  proud  to  say:  We  are  first; \\n\\nin  government, \\n\\nwe are the best; and we are so because \\nwe’re free.\\n\\nAmerica has always been greatest when \\nwe  dared  to  be  great.  We  can  reach \\nfor  greatness  again.  We  can  follow \\nour  dreams  to  distant  stars,  living  and \\nworking in space for peaceful, economic, \\nand scientific gain. Tonight, I am directing \\nNASA to develop a permanently manned \\nspace  station  and  to  do  it  within  a \\ndecade.\\n\\nin  our  research \\n\\nA  space  station  will  permit  quantum \\nleaps \\nin  science, \\ncommunications,  and  in  metals  and \\nlifesaving  medicines  which  could  be \\nmanufactured  only  in  space.  We  want \\nour  friends  to  help  us  meet  these \\nchallenges  and  share  in  their  benefits. \\nNASA  will  invite  other  countries  to \\nparticipate so we can strengthen peace, \\nbuild prosperity, and expand freedom for \\nall who share our goals.\\n\\nIn 1984, the US and the ailing USSR \\nwere still locked into the Cold War, with \\nthe thaw of glasnost, perestroika and the \\nfall  of  the  Iron  Curtain  still  years  away. \\nReagan’s  enthusiastic  commitment  to \\nbuilding the ISS may not have envisaged \\nthat  it  would  be  near  to  impossible \\nwithout  deep  Russian \\ninvolvement, \\nparticularly since the ISS would come to \\nrely on the Russians’ experience (mainly \\nvia  Mir)  of  long-term  human  habitation \\nin orbit and zero gravity, and the robust \\nand no-nonsense technology such as the \\nSoyuz, after the retirement of the Space \\nShuttle fleet.\\n\\nIt  would  be  a  little  longer  than  a \\ndecade  before  Reagan’s  promise  was \\nrealised. The first module of the ISS, Zarya, \\nwas  launched  on  a  Russian  rocket  on  \\n20 November 1998, nine years after the \\nfall of the Berlin Wall and during a period \\nof unparalleled cooperation between the \\nUS and Russia (specifically NASA and its \\nRussian  equivalent  Roscosmos),  which \\nwould result in the early modules of the \\nISS and the retiring Mir sharing LEO from \\n1998 to 2001.\\n\\nThe  ISS  was  set  in  motion  during  a \\ntime when NASA was still computing largely \\non the machines of the Apollo era, and the \\nfocus of the US space effort was the recently \\nlaunched  Space  Shuttle  programme.  Fast \\n\\nforward to 1998, where desktop computing \\nand mobile telephony had started to reach \\ntipping point, and it is evident that the overall \\nthreat  environment  had  already  changed \\nradically.  Then  compare  1998  with  2016, \\nand look at the range of communications \\nand  media  channels  available  to  British \\nastronaut  Major  Tim  Peake  during  his \\nwork  on  the  ISS  from  December  2015  to \\nJune 2016, as exemplified by the icons at \\nthe bottom of his European Space Agency \\n(ESA) webpage.15 (He also used Skype, but \\nas a potential direct channel rather than a \\nbroadcast  media,  the  ESA  have  naturally \\nnot  provided  an  icon  or  direct  link  to  his \\naccount.)\\n\\nPeake used these outlets extensively \\nduring his time on the ISS, posting stunning \\nphotography  of  the  Earth  from  space \\nin  the  manner  of  one  of  his  charismatic \\npredecessors, the Canadian Colonel Chris \\nHadfield, and publishing the collection in \\nhis  book.16  These  are  hugely  important \\nfunctions  for  ISS  astronauts,  as  they \\nconnect space science to the public and \\nassist  in  the  long  process  of  persuading \\nfinancial  authorities  to  continue  to \\nsupport  space  exploration,  when  there \\nmay be larger, more immediate and more \\npressing  needs  Earthbound.  However, \\nthey  are  part  of  a  broader  reliance  on \\ninformation \\ntechnologies,  many  of \\nthem  either  commercial,  open  source \\nor  without  a  functioning  service  level \\nagreement (in that they are effectively free \\nfor private use). This is important from a \\nthreat assessment point of view, as they \\npotentially create new ways to attack and \\na broader attack surface. As an example \\nof  a  low-level  threat  vector  exposed  by \\nthis,  during  his  time  on  the  ISS,  Peake \\nused Skype to initiate a call to an incorrect \\nnumber on Earth, and for a brief period a \\ndata connection was initiated between the \\nISS and an unknown location and person \\n(admittedly,  via  several  proxies,  but  the \\nprinciple of risk via an unwanted external \\nconnection is still valid).17\\n\\nThe  overall  geopolitical  and  socio-\\npolitical  environment  in  which  the  ISS \\noperates has also shifted significantly in \\nthe 20 years of its operation. Information \\nand communications technologies aside, \\nthe  ISS  now  relies  heavily  on  broad \\ncommercial  operations  to  function,  in \\nparticular SpaceX, whose Falcon rockets \\nand  Dragon  capsules  are  now  critical  to \\n\\n© RUSI JOURNAL APRIL/MAY 2018\\x0cISS  resupply  operations,  and  provide  a \\nbaseline  for  the  development  of  joint \\nMars missions by SpaceX and NASA of a \\nmagnitude of ambition far in excess of any \\nprevious efforts.18 The ISS’s importance as \\na staging platform for the Moon, Mars and \\nbeyond, both in a supporting sense (testing \\nof  technologies  and  human  biology  and \\nendurance)  and  a  staging  sense  (an \\norbital  safe  haven,  or  base  platform  for \\nthe  construction  of  interplanetary  craft \\nin orbit) cannot be overstated. With the \\nretirement of the shuttles, human space \\nflight is for now confined to the ISS and \\nthe Soyuz. Its importance, therefore, and \\nefforts  to  ensure  its  safe  and  continued \\noperation, are paramount.\\n\\nThe US concept of Cyber as the fifth \\nwarfighting  domain  (along  with  Land, \\nSea, Air and Space) has taken a firm hold \\nin the military arena. US Cyber Command \\nemploys  more  than  700  military  and \\ncivilian  personnel  and  its  commander \\ncurrently  double-hats  as  the  Director  of \\nthe  National  Security  Agency  (although \\nthis close arrangement may be changing \\nin  the  near  future).19  It  is  referred  to \\nin  different  terms  (such  as  the  ‘global \\ncommons’);  in  the  commercial  sector  it \\nis  considered  a  domain  of  commerce  as \\nopposed to a domain of conflict.20 While \\nit  is  generally  accepted  that  large-scale \\nconflict or commerce in any of the three \\noriginal  domains  (Land,  Sea  and  Air)  is \\nunfeasible  in  the  twenty-first  century \\nwithout  a  supporting  cyber  model,  it \\nis  reasonable  to  state  that  humanity \\nmanaged  to  develop  in  all  areas  up  to \\nand  including  the  militarisation  of  flight \\nin the First World War without the aid of \\ndigital  processing  or  global  information \\nnetworks.  The  exploration  of  space, \\nhowever, as primitive as those information \\ntechnologies  may  have  been  during  the \\nage  of  Sputnik,  Gagarin  and  Armstrong, \\nhas  developed  in  something  akin  to  a \\nsymbiotic parallel with cyber technologies.\\nAs evidence of this, the UK Ministry \\nof  Defence  created  a  Cyber  and  Space \\nPolicy Department with a 1* (a Brigadier \\nor  civil  service  equivalent)  head,21  in \\nrecognition  of  the  interlinking,  mutual \\ndependency  and  commonality  between \\nthese newest domains. Specifically, they \\ndiffer  from  the  ‘old’  domains  in  that \\nfreedom  of  movement  (or  ‘manoeuvre’ \\nin  military  terms)  is  both  technically \\n\\nunrestricted  yet  ethically  bound  (the \\ndemilitarisation or deregulation of space \\nand cyberspace) and the use of weapons \\nin  both  domains  has \\nfar-reaching \\ninternational  ramifications.  The  first \\nindicators of the success of the Stuxnet \\nSCADA  malware  were  via  accidental \\ninfections  in  other  countries  where  the \\nmalware had been inadvertently leaked \\non the internet;22 Russia and China have \\ntested  anti-satellite  technology  in  orbit \\nand  destroyed  defunct  satellites,  most \\nfamously  used  as  the  triggering  plot \\ndevice in the 2013 movie Gravity.23\\n\\nreview, \\n\\nliterature \\n\\nTaking  all  this  into  account,  the \\nkey  research  question  for  this  article, \\ntherefore,  is  how  resilient  is  the  critical \\nsupply  chain  servicing  the  ISS,  and  the \\nstation itself, to attack by cyber means? \\nThrough \\nresearch \\nefforts and an assessment of the global \\nthreat environment in which it operates, a \\npicture builds of the interdependencies of \\nthe cyber and space domains, the mutual \\ndevelopment  routes  and  catalysts  and \\ndrivers  for  technological  advance  since \\nthe  end  of  the  Second  World  War.  The \\nconcept  of  cyber  resilience  touches  all \\naspects  of  ISS  operations,  affecting  a \\ncomplex supply chain, and how the space \\nstation operates in an environment where \\nmilitary  thinking  is  dominant,  and  the \\nsharing of information challenged by legal \\nand social conventions.\\n\\nThe  ISS  is  due  to  retire  in  2024, \\nwith  a  potential  stay  of  execution  until \\n2028.24 Despite its unrivalled success as \\nhumanity’s longest continually inhabited \\nspace  station  (it  may  reach  its  30th \\nbirthday before retirement), and the fact \\nthat  it  has  continued  to  operate  under \\nhugely  demanding  conditions  in  terms \\nof its design, deployment, construction, \\nmanagement and resupply, its existence \\nnow  appears  to  be  something  of  an \\noddity.  If  an  alien  visitor  were  to  be \\nushered  aboard  as  their  first  contact \\nwith  humans  (given  its  location,  not  a \\ncompletely  outlandish  scenario),  they \\nwould  be  forgiven  for  thinking  (from \\nthe  author’s  humble  perspective)  that \\nthey had stumbled across a multicultural \\nutopia. The truth on the ground, however, \\nis very different. While the world in which \\nthe ISS was conceived and launched was \\nhardly peaceful, it is difficult to imagine \\nthat  a  multinational  project  of  this \\n\\nNOEL HANNAN\\n\\ntype,  particularly  one  which  relies  so \\nmuch on US, Russian and pan-European \\ncooperation, would even be considered in \\nthe present climate. At the time of writing \\n(April 2018), the West and Russia are in \\nthe most volatile period since the height \\nof the Cold War. Under these depressing \\ncircumstances,  it  is  hard  not  to  see  the \\nISS  facing  the  same  fate  as  the  Space \\nShuttle, Concorde and the Vulcan bomber \\n–  ahead  of  its  time,  and  a  snapshot  of \\nhistory  where  humanity  took  a  mighty \\nleap  forward,  then  sadly  chose  to  stop, \\nand take a step back.\\n\\nAlthough  activity  in  all  the  space \\nagencies  is  healthy  and  active,  with \\nthe  Moon  and  Mars  the  focus  areas, \\nit  is  with  the  commercial  world  that \\nperhaps the future wellbeing of the ISS \\nand  its  successors  lie,  specifically  with \\nthe SpaceX programme. SpaceX founder \\nand CEO Elon Musk has famously stated \\nthat he intends to die on Mars, ‘just not \\non impact!’,25 and only time will tell if he \\nfulfils that ambition. As a stepping-stone \\nto the Moon and Mars, and potentially \\nas  a  significant  PR  exercise,  it  would \\nnot  be  unreasonable  to  propose  that \\nMusk assumes control of the ISS when \\nthe space agencies decide to retire it, if \\nthis was technically (and safely) feasible. \\nHowever, a watching brief should be kept \\non the fact that the world is handing yet \\nanother  facet  of  human  endeavour  to \\na  private  corporation,  and  that  all  the \\n(Google/LunarX,26 \\ntechnology  giants \\nAmazon/Blue  Origin,27  and  Facebook/\\nStarshot28) are in the process of funding \\nspace development. Lieutenant Colonel \\nB C Cornell of the Canadian armed forces \\nrefers  to  this  as  the  ‘democratization \\nof  space’ \\nin  his  2016  paper,  ‘The \\nFinal  Frontier:  The  Emergence  of  the \\nCommercial  Space  Industry  and  the \\nLoss of Space Hegemony’. He suggests \\nthat increased access to space resources \\noutside  state  control,  and  potentially \\nlower  launch  and  transit  costs,  could \\nthreaten what he terms as the ‘Western \\nhegemony’ in space.29\\n\\nIt is fair to say that this article poses \\nmore questions than it answers. Access \\nto personnel in the space agencies and \\nthe main commercial entities proved to \\nbe almost impossible to obtain, through \\na combination of tactical silence, rebuff, \\nor redirection to PR departments which \\n\\n31\\n\\n\\x0cAN ASSESSMENT OF SUPPLY-CHAIN CYBER RESILIENCE FOR THE INTERNATIONAL SPACE STATION\\n\\nproved  fruitless.  The  author,  by  way \\nof  a  military  connection,  managed  to \\nspend 120 seconds in a lift with Peake \\nearlier  this  year.  The  brief  but  fruitful \\nconversation  reinforced  the  thinking \\nthat even if the space agencies were not \\ninterested  in  talking  about  the  cyber \\nresilience  of  the  ISS,  it  was  definitely \\non  the  minds  of  the  astronauts  who \\nrely on it for their safety and security. \\n\\nLike  many  pilots  who  have  a  deep \\nand  vested  interest  in  understanding \\ntheir  technical  platform,  Peake  was \\ndemonstrably fascinated by the subject \\nat hand.\\n\\nPerhaps a longer period spent with \\nPeake, or one of his astronaut colleagues, \\ndiscussing  the  space  approach  to  cyber \\nsecurity,  if  feasible,  would  be  a  good \\ncandidate for a future article. \\uf06e\\n\\nNoel Hannan is the Cyber and Digital \\nInnovation Lead for GoSecure. He is \\nalso an Army Reserve Major with the \\nLand Information Assurance Group, \\nwith more than 30 years’ service and \\noperational experience. He writes \\nand talks on cyber security, with an \\ninterest in advanced threat detection, \\nnational resilience and social \\nengineering.\\n', 'The 2013 Cybersecurity Executive Order: \\nOverview and Considerations for Congress \\n\\nEric A. Fischer \\nSenior Specialist in Science and Technology  \\n\\nEdward C. Liu \\nLegislative Attorney \\n\\nJohn W. Rollins \\nSpecialist in Terrorism and National Security \\n\\nCatherine A. Theohary \\nSpecialist in National Security Policy and Information Operations \\n\\nDecember 15, 2014 \\n\\nCongressional Research Service \\n\\n7-5700 \\nwww.crs.gov \\n\\nR42984 \\n\\n \\n \\n\\x0cThe 2013 Cybersecurity Executive Order: Overview and Considerations for Congress \\n\\nSummary \\n\\nThe federal role in cybersecurity has been a topic of discussion and debate for over a decade. \\nDespite significant legislative efforts in the 112th Congress on bills designed to improve the \\ncybersecurity of U.S. critical infrastructure (CI), no legislation on that issue was enacted in that \\nCongress. In an effort to address the issue in the absence of enacted legislation, the White House \\nissued an executive order in February 2013. Citing repeated cyber-intrusions into critical \\ninfrastructure and growing cyberthreats, Executive Order 13636, Improving Critical \\nInfrastructure Cybersecurity, was an attempt to enhance security and resiliency of CI through \\nvoluntary, collaborative efforts involving federal agencies and owners and operators of privately \\nowned CI, as well as use of existing federal regulatory authorities. \\n\\nEntities posing a significant threat to the cybersecurity of CI assets include cyberterrorists, \\ncyberspies, cyberthieves, cyberwarriors, and cyberhacktivists. E.O. 13636 has attempted to \\naddress such threats by, among other things, \\n\\n• \\n\\n• \\n\\n• \\n\\nexpanding to other CI sectors an existing Department of Homeland Security \\n(DHS) program for information sharing and collaboration between the \\ngovernment and the private sector; \\n\\nestablishing a broadly consultative process for identifying CI with especially high \\npriority for protection; \\n\\nrequiring the National Institute of Standards and Technology (NIST) to lead in \\ndeveloping a cybersecurity framework of standards and best practices for \\nprotecting CI; and \\n\\n•  directing regulatory agencies to determine the adequacy of existing requirements \\n\\nand their authority to establish additional ones to address the risks. \\n\\nAmong the major issues covered by the unenacted legislative proposals in the 112th Congress, \\nE.O. 13636 mainly addresses two: information sharing and protection of privately held critical \\ninfrastructure. It does not provide exemptions from liability stemming from information sharing, \\nwhich would require changes to current law. Several of the legislative proposals included such \\nchanges. With respect to protection of critical infrastructure, the provisions on designation of CI \\nand identification of relevant regulations are related to those in some legislative proposals.  \\n\\nIn the 113th Congress, some bills would provide explicit statutory authority for information-\\nsharing along the lines of some bills in the 112th Congress. Others would authorize activities on \\ndeveloping a cybersecurity framework similar to those in the executive order. \\n\\nThe issuance of E.O. 13636, as with many other executive orders, raises questions about whether \\nthe order exceeds the scope of the President’s authority, in relation to the constitutional separation \\nof powers and validly enacted legislation. While answers to those questions are complex, the \\nexecutive order specifies that implementation will be consistent with applicable law and that \\nnothing in the order provides regulatory authority to an agency beyond that under existing law. \\n\\nOverall, response to the executive order has been optimistic. Given the absence of comprehensive \\ncybersecurity legislation, some security observers contend that the order is a necessary step in \\nsecuring vital assets against cyberthreats. Others have argued, in contrast, that it offers little more \\nthan do existing processes, that it could make enactment of a bill less likely, or that it could lead \\n\\nCongressional Research Service \\n\\n \\n\\x0cThe 2013 Cybersecurity Executive Order: Overview and Considerations for Congress \\n\\nto government intrusiveness into private-sector activities, for example through increased \\nregulation under existing statutory authority. Despite considerable progress in meeting the \\nspecific objectives in the executive order, especially the NIST Framework, it still appears to be \\ntoo early in the implementation of the order to determine whether such concerns will be \\naddressed to the satisfaction of critics and skeptics. \\n\\nCongressional Research Service \\n\\n \\n \\n\\x0cThe 2013 Cybersecurity Executive Order: Overview and Considerations for Congress \\n\\nContents \\n\\nBackground: Threats and Consequences ......................................................................................... 2 \\nCyberthreats ............................................................................................................................... 2 \\nCyberterrorists ........................................................................................................................... 3 \\nCyberspies ................................................................................................................................. 3 \\nCyberthieves .............................................................................................................................. 4 \\nCyberwarriors ............................................................................................................................ 4 \\nCyberhacktivists ........................................................................................................................ 4 \\nCyberthreats and Implications for U.S. Policy .......................................................................... 5 \\nOverview of the Executive Order .................................................................................................... 5 \\nInformation Sharing ................................................................................................................... 6 \\nVoluntary Cybersecurity Framework ......................................................................................... 8 \\nOther Provisions ...................................................................................................................... 10 \\nE.O. 13636 Implementation Deliverables and Deadlines ........................................................ 11 \\nJune 12, 2013 .................................................................................................................... 11 \\nJuly 12, 2013 ..................................................................................................................... 11 \\nOctober 10, 2013 ............................................................................................................... 11 \\nFebruary 12, 2014 ............................................................................................................. 12 \\nMay 13, 2014 .................................................................................................................... 12 \\nFebruary 12, 2016 ............................................................................................................. 12 \\nRelationship of the Executive Order to Presidential Policy Directive 21................................ 13 \\nPPD 21 Implementation Deliverables and Deadlines ....................................................... 13 \\nScope of Presidential Authority ..................................................................................................... 14 \\n\\nRelationship to Legislative Proposals ............................................................................................ 16 \\n\\nReactions to the Executive Order .................................................................................................. 17 \\n\\nFigures \\n\\nFigure 1. Schematic Description of ECS Information-Sharing Process .......................................... 8 \\n\\nContacts \\n\\nAuthor Contact Information........................................................................................................... 20 \\n\\nCongressional Research Service \\n\\n \\n \\n \\n \\n\\x0cThe 2013 Cybersecurity Executive Order: Overview and Considerations for Congress \\n\\nT\\n\\nhe federal legislative framework for cybersecurity is complex, with more than 50 statutes \\naddressing various aspects of it either directly or indirectly. Many observers have \\nexpressed doubt that the current statutory framework is sufficient to address the growing \\nconcerns about the security of cyberspace in the United States, especially with respect to critical \\ninfrastructure (CI).1 Several legislative proposals were made in recent Congresses to address \\nthose concerns. While a few cybersecurity bills were enacted in the 113th Congress, they \\naddressed only the security of federal information systems (S. 2521) and workforce issues (H.R. \\n2952 and S. 1691) and information-sharing activities (S. 2519) at the Department of Homeland \\nSecurity (DHS).  \\n\\nWithin the executive branch, both the George W. Bush and Obama Administrations have focused \\non improving the cybersecurity of critical infrastructure. The Bush Administration created the \\nclassified Comprehensive National Cybersecurity Initiative (the CNCI) in 2008.2 The Obama \\nAdministration performed an interagency review of federal cybersecurity initiatives in 2009, \\nculminating in the release of its Cyberspace Policy Review3 and the creation of the White House \\nposition of Cybersecurity Coordinator. In the absence of enacted legislation, the Obama \\nAdministration began drafting a cybersecurity executive order in 2012. The development \\ninvolved input from both federal agencies and stakeholders in the private sector.4 \\n\\nOn February 12, 2013, President Obama issued Executive Order 13636, Improving Critical \\nInfrastructure Cybersecurity,5 along with Presidential Policy Directive 21 (PPD 21),6 Critical \\nInfrastructure Security and Resilience. The issuance of the executive order in the absence of \\ncongressional action raises several questions that are addressed in this report: \\n\\n•  What are the kinds of threats to the national security and economic interests of \\n\\nthe United States that the executive order is intended to address? \\n\\n•  What steps does it take to address those threats, what is the status of their \\n\\nimplementation, and what issues do they raise? \\n\\n•  What is the legislative and constitutional authority for the executive order? \\n\\n1 \\n\\n \\n                                                 \\n\\x0cThe 2013 Cybersecurity Executive Order: Overview and Considerations for Congress \\n\\n•  How do its provisions relate to those in legislative proposals in the 112th and \\n\\n113th Congresses? \\n\\n•  What has been the reaction of stakeholders to the order and what issues does it \\n\\nraise? \\n\\nBackground: Threats and Consequences \\n\\nRepeated cyber intrusions into critical infrastructure demonstrate the need for improved \\ncybersecurity. The cyber threat to critical infrastructure continues to grow and represents one \\nof  the  most  serious  national  security  challenges  we  must  confront.  The  national  and \\neconomic security of the United States depends on the reliable functioning of the Nation’s \\ncritical infrastructure in the face of such threats.7 \\n\\nCyberthreats to U.S. infrastructure and other assets are a growing concern to policy makers. \\nInformation and communications technology (ICT)8 is ubiquitous and relied upon for government \\nservices, corporate business processes, and individual professional and personal pursuits—almost \\nevery facet of modern life. Many ICT devices and other components are interdependent, and \\ndisruption of one component may have a negative, cascading effect on others. A denial of service, \\ntheft or manipulation of data, or damage to critical infrastructure through a cyber-based attack \\ncould have significant impacts on national security, the economy, and the livelihood and safety of \\nindividual citizens. \\n\\nCyberthreats \\n\\nCyber-based technologies9 are now ubiquitous around the globe. The vast majority of users \\npursue lawful professional and personal objectives. However, criminals, terrorists, and spies also \\nrely heavily on cyber-based technologies to support their objectives. These malefactors may \\naccess cyber-based technologies in order to deny service, steal or manipulate data, or use a device \\nto launch an attack against itself or another piece of equipment. Entities using cyber-based \\ntechnologies for illegal purposes take many forms and pursue a variety of actions counter to U.S. \\nglobal security and economic interests. While E.O. 13636 discusses in general terms cyber-based \\nthreats directed at the nation’s critical infrastructure, it does not identify the types of cyber-actors \\nand possible consequences of a successful attack. Commonly recognized cyber-aggressors \\ndiscussed below, along with representative examples of the harm they can inflict, include \\ncyberterrorists, cyberspies, cyberthieves, cyberwarriors, and cyberhacktivists. \\n\\n\\n \\n                                                 \\n\\x0cThe 2013 Cybersecurity Executive Order: Overview and Considerations for Congress \\n\\nCyberterrorists \\n\\nCyberterrorists are state-sponsored and non-state actors who engage in cyberattacks as a form of \\nwarfare. Transnational terrorist organizations, insurgents, and jihadists have used the Internet as a \\ntool for planning attacks, radicalization and recruitment, a method of propaganda distribution, and \\na means of communication.10 While no unclassified reports have been published regarding a \\nterrorist-initiated cyberattack on U.S. critical infrastructure (CI),11 the vulnerability of essential \\ncomponents of that infrastructure to access and even destruction via the Internet has been \\ndemonstrated. In 2009, the Department of Homeland Security (DHS) conducted an experiment \\nthat revealed some of the vulnerabilities to the nation’s control systems that manage power \\ngenerators and grids. The experiment, known as the Aurora Project, entailed a computer-based \\nattack on a power generator’s control system that caused operations to cease and the equipment to \\nbe destroyed.12 \\n\\nCyberspies \\n\\nCyberspies are individuals who steal classified or proprietary information used by governments or \\nprivate corporations to gain a competitive strategic, security, financial, or political advantage. \\nThese individuals often work at the behest of, and take direction from, foreign government \\nentities. For example, a 2011 FBI report noted, “a company was the victim of an intrusion and \\nhad lost 10 years’ worth of research and development data—valued at $1 billion—virtually \\novernight.”13 Likewise, in 2008 the Department of Defense’s (DOD’s) classified computer \\nnetwork system was unlawfully accessed and “the computer code, placed there by a foreign \\nintelligence agency, uploaded itself undetected onto both classified and unclassified systems from \\nwhich data could be transferred to servers under foreign control.”14 The U.S. intelligence \\ncommunity recently completed a classified National Intelligence Estimate (NIE) focused on \\ncyberspying against U.S. targets. Reportedly, the NIE “concluded that the United States is the \\ntarget of a massive, sustained cyber-espionage campaign that is threatening the country’s \\neconomic competitiveness.”15 Media reports suggest that the NIE also assessed that Russia, Israel, \\nand France also engage in illegal accessing of United States entities for economic intelligence \\npurposes but notes that “cyber-espionage by those countries pales in comparison with China’s \\neffort.”16 A February 2013 report of an investigation by a private-sector security firm of intrusions \\n\\n\\n \\n                                                 \\n\\x0cThe 2013 Cybersecurity Executive Order: Overview and Considerations for Congress \\n\\nagainst more than 100 targets over the past seven years states that the attacks were performed by \\na single Chinese group that appears to be linked to the People’s Liberation Army.17 \\n\\nCyberthieves \\n\\nCyberthieves are individuals who engage in illegal cyberattacks for monetary gain. Examples \\ninclude an organization or individual who illegally accesses a technology system to steal and use \\nor sell credit card numbers and someone who deceives a victim into providing access to a \\nfinancial account. Cybercrime is widely regarded as lucrative and relatively low-risk for criminals \\nand costly for victims, with some estimates placing the annual global cost to individuals as high \\nas hundreds of billions of dollars.18 However, making accurate estimates of such aggregate costs \\nis problematic, and there does not appear to be any publicly available, comprehensive, reliable \\nassessment of the overall costs of cyberattacks. \\n\\nCyberwarriors \\n\\nCyberwarriors are agents or quasi-agents of nation-states who develop capabilities and undertake \\ncyberattacks in support of a country’s strategic objectives.19 These entities may or may not be \\nacting on behalf of the government with respect to target selection, timing of the attack, and \\ntype(s) of cyberattack and are often blamed by the host country when accusations are levied by \\nthe nation that has been attacked. Often, when a foreign government is provided evidence that a \\ncyberattack is emanating from its country, the nation that has been attacked is informed that the \\nperpetrators acted of their own volition and not at the behest of the government. In August 2012 a \\nseries of cyberattacks were directed against Saudi Aramco, the world’s largest oil and gas \\nproducer and most valuable company. The attacks compromised 30,000 of the company’s \\ncomputers and the code was apparently designed to disrupt or halt the production oil. Some \\nsecurity officials have suggested that Iran may have supported this attack.20 However, other \\nobservers suggest that the perpetrator of the attack was an employee of Saudi Aramco.21 \\n\\nCyberhacktivists \\n\\nCyberhacktivists are individuals who perform cyberattacks for pleasure, or for philosophical or \\nother nonmonetary reasons. Examples include someone who attacks a technology system as a \\npersonal challenge (who might be termed a “classic” hacker), and a “hacktivist” such as a \\n\\n \\n                                                 \\n\\x0cThe 2013 Cybersecurity Executive Order: Overview and Considerations for Congress \\n\\nmember of the cyber-group Anonymous who undertakes an attack for political reasons. The \\nactivities of these groups can range from simple nuisance-related denial of service attacks to \\ndisrupting government and private corporation business processes. \\n\\nCyberthreats and Implications for U.S. Policy \\n\\nThese different kinds of cyber-aggressors and the types of attacks they can pursue are not \\nmutually exclusive. For example, a hacker targeting the intellectual property of a corporation may \\nbe categorized as both a cyberthief and a cyberspy, and possibly a cyberwarrior if the activity is \\nconducted by a military enterprise, as has been claimed for some such attacks.22 A cyberterrorist \\nand cyberwarrior may be employing different technological capabilities in support of a nation’s \\nsecurity and political objectives. Ascertaining information about the aggressor and its capabilities \\nand intentions is very difficult.23 The threats posed by these aggressors, coupled with the United \\nStates’ proclivity to be an early adopter of emerging technologies,24 which often contain \\nunrecognized vulnerabilities and are introduced into existing computer networks, make for a \\ncomplex environment when considering operational responses, policies, and legislation designed \\nto safeguard the nation’s strategic economic and security interests. E.O. 13636 discusses the \\nnation’s reliance on cyber-based technologies and identifies activities and reporting requirements \\nto be addressed by numerous federal government departments and agencies. \\n\\nOverview of the Executive Order \\n\\nThe federal role in what is now called cybersecurity25 has been debated for more than a decade. \\nMuch of the recent debate has focused on two issues: sharing of cybersecurity-related information \\nwithin and across sectors, and the cybersecurity of CI sectors, including federal systems. E.O. \\n13636 attempts to address both of those issues, as well as others.  \\n\\nIt uses existing statutory and constitutional authority to  \\n\\n\\n \\n                                                 \\n\\x0cThe 2013 Cybersecurity Executive Order: Overview and Considerations for Congress \\n\\n• \\n\\nexpand information sharing and collaboration between the government and the \\nprivate sector, including sharing classified information by broadening a program \\ndeveloped for the defense industrial base to other CI sectors; \\n\\n•  develop a voluntary framework of cybersecurity standards and best practices for \\n\\nprotecting CI, through a public/private effort; \\n\\n• \\n\\n• \\n\\n• \\n\\n• \\n\\nestablish a consultative process for improving CI cybersecurity; \\n\\nidentify CI with especially high priority for protection, using the consultative \\nprocess; \\n\\nestablish a program with incentives for voluntary adoption of the framework by \\nCI owners and operators; \\n\\nreview cybersecurity regulatory requirements to determine if they are sufficient \\nand appropriate; and \\n\\n• \\n\\nincorporate privacy and civil liberties protections in activities under the order. \\n\\nThe information-sharing and framework provisions in particular have received significant public \\nattention. \\n\\nInformation Sharing \\n\\nImproved sharing of information on cybersecurity threats, vulnerabilities, attacks, prevention, and \\nresponse both within and across sectors, including government, is thought by most experts to be \\ncritical to improving cybersecurity but fraught with barriers and uncertainties, relating especially \\nto privacy, liability, reputation costs,26 protection of proprietary information, antitrust law, and \\nmisuse of shared information. A few sectors are subject to federal notification requirements,27 but \\nmost such information sharing is voluntary, often through sector-specific Information Sharing and \\nAnalysis Centers (ISACs)28 or programs under the auspices of the Department of Homeland \\nSecurity (DHS) or sector-specific agencies.29 A key question is how to balance the need for better, \\nmore timely cybersecurity information with other needs such as protection of privacy and civil \\nrights as well as legitimate business and economic interests. \\n\\nTo improve information sharing, the order builds on a voluntary effort established in May 2011. \\nThat program, known as the DIB30 Cyber Pilot, involved several defense industry partners, the \\nNational Security Agency (NSA), and DOD31 in sharing classified threat-vector information \\n\\n\\n \\n                                                 \\n\\x0cThe 2013 Cybersecurity Executive Order: Overview and Considerations for Congress \\n\\namong stakeholders. One aspect was sharing by the NSA of threat signatures obtained through its \\ncomputer monitoring activities.32 \\n\\nIn May 2012, DOD established the DIB Cybersecurity/Information Assurance (CS/IA) \\nProgram,33 making it broadly available to all eligible DIB partners. Under the program, DOD \\nprovides defense contractors with classified and unclassified cyberthreat information and \\ncybersecurity best practices, while DIB participants report cyber-incidents, coordinate on \\nmitigation strategies, and participate in cyber intrusion damage assessments if DOD information \\nis compromised. Participating companies may also join an optional classified-information sharing \\nsubprogram, known as the DIB Cybersecurity Enhancement Program (DECS)—the former DIB \\nCyber Pilot34—by meeting specified security requirements. \\n\\nTo expand the program beyond the DIB sector, DHS established the Joint Cybersecurity Services \\nPilot (JCSP) in January 2012, the first phase of which focused on the DECS program and shifted \\noperational relationships with participating commercial service providers (CSPs) to DHS. DHS \\nmade the program permanent in July 2012. In January 2013, the department named the program \\nEnhanced Cybersecurity Services (ECS) and expanded it to all CI sectors, including the federal \\nsector,35 as well as nonfederal government entities.36 In this program, DHS does not share threat \\nindicators with CI entities directly but rather with participating CSPs (see Figure 1). DOD still \\nserves as the point of contact for participating DIB contractors.37 \\n\\nThe executive order builds on such established programs by requiring the Secretary of Homeland \\nSecurity to \\n\\n• \\n\\n• \\n\\n• \\n\\nexpand ECS to all CI sectors; \\n\\nexpedite processing of security clearances to appropriate CI personnel; and \\n\\nexpand programs to place relevant private-sector experts in federal agencies on a \\ntemporary basis.  \\n\\nIt also requires the Secretary of Homeland Security and the Attorney General to expedite \\ncollection of threat indicators and dissemination of them to targeted entities. \\n\\n \\n                                                 \\n\\x0cThe 2013 Cybersecurity Executive Order: Overview and Considerations for Congress \\n\\nFigure 1. Schematic Description of ECS Information-Sharing Process \\n\\nSource: Department of Homeland Security, “Enhanced Cybersecurity Services,” November 14, 2014, \\nhttp://www.dhs.gov/sites/default/files/publications/ECS-Fact-Sheet.pdf. \\n\\nVoluntary Cybersecurity Framework \\n\\nThe increasing potential for attacks that might cripple components of CI or otherwise damage the \\nnational economy, as discussed above, has led to debate about the best ways to protect those \\nsectors beyond improvements in information sharing. Some CI sectors are subject to federal \\nregulation with respect to cybersecurity,38 while the protection of others relies largely on \\nvoluntary efforts. The efficacy of that mix of voluntary and regulatory efforts has been a \\nprominent issue in the ongoing debate about federal cybersecurity legislation. Proponents of \\nadditional regulation argue that the voluntary approach has not provided sufficient protection and \\nthat regulation has been effective in sectors such as electricity and financial services. Opponents \\nargue that expanding federal requirements would be costly and ineffective and may impede \\ninnovation. Also, there has appeared to be some uncertainty about the extent to which existing \\nstatutory authority would permit new cybersecurity requirements in some sectors.  \\n\\nE.O. 13636 builds on the involvement of the National Institute of Standards and Technology \\n(NIST) in the development of cybersecurity technical standards39 and its statutory responsibilities \\nto work with both government and private entities on various aspects of standards and \\ntechnology.40 The order requires the following: \\n\\n•  NIST—lead the development of the Cybersecurity Framework, an effort that uses \\nan open, consultative process to reduce cybersecurity risks to CI; focuses on \\ncross-sector, voluntary consensus standards and business best practices; is \\ntechnology-neutral; identifies areas for improvement; and is reviewed and \\nupdated as necessary. \\n\\n \\n                                                 \\n\\x0cThe 2013 Cybersecurity Executive Order: Overview and Considerations for Congress \\n\\n•  Secretary of Homeland Security—set performance goals for the framework, \\n\\nestablish a voluntary program to support its adoption, and coordinate \\nestablishment of incentives for adoption. \\n\\n•  Sector-specific agencies—coordinate review of the framework and development \\nof sector-specific guidance, and report annually to the President on participation \\nby CI sectors. \\n\\n•  CI regulatory agencies—engage in consultative review of the framework, \\n\\ndetermine whether existing cybersecurity requirements are adequate, and report \\nto the President whether the agencies have authority to establish requirements \\nthat sufficiently address the risks (it does not state that the agencies must \\nestablish such requirements, however), propose additional authority where \\nrequired, and identify and recommend remedies for ineffective, conflicting, or \\nexcessively burdensome cybersecurity requirements. \\n\\nThe executive order stipulates that it provides no authority for regulating critical infrastructure in \\naddition to that under existing law, and it does not alter existing authority. \\n\\nThe development of the framework is arguably the most innovative and labor-intensive \\nrequirement in the executive order. None of the major legislative proposals in the 111th and 112th \\nCongresses had proposed using NIST to coordinate an effort led by the private sector to develop a \\nframework for cybersecurity, such as was envisioned by the executive order. Hundreds of entities \\nhave been involved in NIST’s efforts, which led to release of the first version of the framework in \\nFebruary 2014.41 \\n\\nThe framework is intended to provide broad guidance on cybersecurity using a risk-based \\napproach that can be adapted to the needs of different CI sectors. It consists of three parts: \\n\\n•  The core is a common set of activities and outcomes applicable to all CI sectors \\n\\nIt is organized into five functions—identify, protect, detect, respond, and \\nrecover—that are widely recognized components of any cybersecurity \\nmanagement lifecycle, along with associated programmatic and technical \\noutcomes, for example, “access control” and “data-at-rest is protected.”42 \\n\\n•  The profile describes an entity’s current and target cybersecurity postures, based \\non business needs identified by considering the relevant core components. It can \\nbe used to support prioritization of action and measurement of progress. The \\ncurrent profile lists outcomes that are being achieved, while the target profile lists \\nthe outcomes needed to achieve desired cybersecurity goals. \\n\\n•  The implementation tiers characterize an entity’s current and intended practices, \\nwhich can range from “informal, reactive responses” (Tier 1) to “agile and risk-\\ninformed” approaches (Tier 4).43  \\n\\n\\n \\n                                                 \\n\\x0cThe 2013 Cybersecurity Executive Order: Overview and Considerations for Congress \\n\\nThe framework is not intended to be static but will be updated as required. Areas that NIST has \\nalready identified for improvement include authentication, automated sharing of indicators, \\nassessment of the degree of conformity to risk-management requirements, cybersecurity \\nworkforce needs, data analytics, supply-chain risk management, technical standards relating to \\nprivacy, alignment of the framework with federal agency cybersecurity requirements, and \\ninternational aspects and implications.44 Several of those are broadly recognized as key issues in \\ncybersecurity.  \\n\\nTo assist in adoption and implementation of the framework by CI entities, DHS has developed the \\nCritical Infrastructure Cyber Community C³ Voluntary Program. Its goals are to help CI entities \\nunderstand and use the framework and obtain feedback from them on improvements.45  \\n\\nOther Provisions \\n\\nThe executive order contains several additional provisions on CI cybersecurity: \\n\\nAcquisition and Contracting. The Secretary of Defense and the Administrator of General Services \\nmust make recommendations to the President on incorporating security standards in acquisition \\nand contracting processes, including harmonization of cybersecurity requirements. \\n\\nConsultative Process. The Secretary of Homeland Security is required to establish a broad \\nconsultative process to coordinate improvements in the cybersecurity of critical infrastructure. \\n\\nCybersecurity Workforce. The Secretary of Homeland Security is required to coordinate technical \\nassistance to critical-infrastructure regulatory agencies on development of their cybersecurity \\nworkforce and programs. \\n\\nHigh-Risk Critical Infrastructure. The order requires the Secretary of Homeland Security to use \\nconsistent and objective criteria, the consultative process established under the order, and \\ninformation from relevant stakeholders to identify and update annually a list of critical \\ninfrastructure for which a cyberattack could have catastrophic regional or national impact, but not \\nincluding commercial information technology products or consumer information technology \\nservices. The Secretary must confidentially notify owners and operators of critical infrastructure \\nthat is so identified of its designation and provide a process to request reconsideration.  \\n\\nPrivacy and Civil Liberties. The order requires agencies to ensure incorporation of privacy and \\ncivil liberties protections in agency activities under the order, including protection from \\ndisclosure of information submitted by private entities, as permitted by law. The DHS Chief \\nPrivacy Officer and Officer for Civil Rights and Civil Liberties must assess risks to privacy \\nand civil liberties of DHS activities under the order and recommend methods of mitigation to \\nthe Secretary in a public report. Agency privacy and civil liberties officials must provide \\nassessments of agency activities to DHS. \\n\\n\\n \\n                                                 \\n\\x0cThe 2013 Cybersecurity Executive Order: Overview and Considerations for Congress \\n\\nE.O. 13636 Implementation Deliverables and Deadlines \\n\\nThe order contains several requirements with deadlines, and other requirements with no \\nassociated dates. In March 2013, DHS announced that it had formed a task force with eight \\nworking groups focused on the various deliverables for which it is responsible.46 Several \\ndeliverables have specific associated dates: \\n\\nJune 12, 2013 \\n\\n• \\n\\nInstructions for producing unclassified threat reports (Secretary of Homeland \\nSecurity, Attorney General, Director of National Intelligence) (Sec. 4(a)). \\n\\n•  Procedures for expansion of the Enhanced Cybersecurity Services Program \\n\\n(Secretary of Homeland Security) (Sec. 4(c)).47 \\n\\n•  Recommendations to the President on incentives to participate in the framework \\n(Secretaries of Homeland Security, Commerce, and the Treasury) (Sec. 8(d)).48 \\n\\n•  Recommendations to the President on acquisitions and contracts (Secretary of \\n\\nDefense, Administrator of General Services) (Sec. 8(e)).49 \\n\\nJuly 12, 2013 \\n\\n•  Designation of critical infrastructure at greatest risk (Secretary of Homeland \\n\\nSecurity) (Sec. 9(a)).50 \\n\\nOctober 10, 2013 \\n\\n•  Publication of preliminary Cybersecurity Framework (Director of the National \\n\\nInstitute of Standards and Technology) (Sec. 7(e)).51 \\n\\n \\n                                                 \\n\\x0cThe 2013 Cybersecurity Executive Order: Overview and Considerations for Congress \\n\\nFebruary 12, 2014 \\n\\n•  Report on privacy and civil liberties, preceded by consultations (Chief Privacy \\nOfficer and Officer for Civil Rights and Civil Liberties of DHS) (Sec. 5(b)).52 \\n\\n•  Publication of final Cybersecurity Framework (Director of the National Institute \\n\\nof Standards and Technology) (Sec. 7(e)).53 \\n\\nMay 13, 2014 \\n\\n•  Reports to the President on review of regulatory requirements (agencies with \\n\\nregulatory responsibilities for critical infrastructure) (Sec. 10(a)).54 \\n\\n•  Proposed additional risk mitigation actions (agencies with regulatory \\n\\nresponsibilities for critical infrastructure) (Sec. 10(b)).55 \\n\\nFebruary 12, 2016 \\n\\n•  Reports to the Office of Management and Budget on ineffective, conflicting, \\nor burdensome requirements (agencies with regulatory responsibilities for \\ncritical infrastructure) (Sec. 10(c)). \\n\\nThe order also includes more than 20 actions for which no specific date is provided. Some of the \\ndeliverables have been made publicly available, largely in accordance with the deadlines in the \\norder, as noted above in the footnotes. Some provisions appeared to have had some effect soon \\nafter the order was issued. For example, the provision on expedited security clearances was \\napparently used to facilitate communication by the FBI with banks in response to a cyberattack in \\nthe spring of 2013 on several banks.56  \\n\\nThe assessments of regulatory requirements and proposed actions focused on three agencies: \\nDHS, the Environmental Protection Agency (EPA), and the Department of Health and Human \\nServices (HHS). The Administration concluded that “existing regulatory requirements, when \\ncomplemented with strong voluntary partnerships, are capable of mitigating cyber risks to our \\ncritical systems and information.”57 \\n\\n\\n \\n                                                 \\n\\x0cThe 2013 Cybersecurity Executive Order: Overview and Considerations for Congress \\n\\nRelationship of the Executive Order to Presidential Policy \\nDirective 21 \\n\\nPresidential Policy Directive 21 (PPD 21),58 Critical Infrastructure Security and Resilience, on \\nprotection of critical infrastructure, was released in tandem with Executive Order 13636. PPD 21 \\nsupersedes Homeland Security Presidential Directive 7 (HSPD 7), Critical Infrastructure \\nIdentification, Prioritization, and Protection, released December 17, 2003. The PPD seeks to \\nstrengthen both the cyber- and physical security and resilience of critical infrastructure by  \\n\\n• \\n\\n• \\n\\n• \\n\\nclarifying functional relationships among federal agencies, including the \\nestablishment of separate DHS operational centers for physical and cyber-\\ninfrastructure; \\n\\nidentifying baseline requirements for information sharing, to facilitate timely and \\nefficient information exchange between government and critical-infrastructure \\nentities while respecting privacy and civil liberties;  \\n\\napplying integration and analysis capabilities in DHS to prioritize and manage \\nrisks and impacts, recommend preventive and responsive actions, and support \\nincident management and restoration efforts for critical infrastructure; and \\n\\n•  organizing research and development (R&D) to enable secure and resilient \\n\\ncritical infrastructure, enhance impact-modeling capabilities, and support \\nstrategic DHS guidance.  \\n\\nPPD 21 Implementation Deliverables and Deadlines \\n\\nJune 12, 2013 \\n\\n•  Description of functional relationships within DHS and across other federal \\n\\nagencies relating to critical infrastructure security and resilience (Secretary of \\nHomeland Security).59 \\n\\nJuly 12, 2013 \\n\\n•  Analysis of public-private partnership models with recommended improvements \\n\\n(Secretary of Homeland Security).60 \\n\\nAugust 11, 2013 \\n\\n•  Convening of experts to identify baseline information and intelligence exchange \\n\\nrequirements (Secretary of Homeland Security). \\n\\n \\n                                                 \\n\\x0cThe 2013 Cybersecurity Executive Order: Overview and Considerations for Congress \\n\\nOctober 10, 2013 \\n\\n•  Demonstration of “near real-time” situational-awareness capability for critical \\n\\ninfrastructure (Secretary of Homeland Security). \\n\\n•  Updated National Infrastructure Protection Plan that addresses implementation of \\n\\nthe directive (Secretary of Homeland Security).61 \\n\\nFebruary 12, 2015 \\n\\n•  First quadrennial National Critical Infrastructure Security and Resilience R&D \\n\\nPlan (Secretary of Homeland Security).62 \\n\\nIn addition to DHS, the directive describes specific responsibilities for the Departments of \\nCommerce, Interior, Justice, and State, the Intelligence Community, the General Services \\nAdministration, the Federal Communications Commission, the sector-specific agencies, and all \\nfederal departments and agencies.63  \\n\\nScope of Presidential Authority \\n\\nE.O. 13636 was issued in the wake of the lack of enactment of cybersecurity legislation in the \\n112th Congress, apparently at least in part as a response to that.64 That raises questions about what \\nauthority the President has to act on this matter through an executive order. That issue is \\ndiscussed below. \\n\\nThe issuance of an executive order frequently raises questions about whether the order exceeds \\nthe scope of the President’s authority, in relation to the constitutional separation of powers and \\nvalidly enacted legislation. Since the latter half of the 20th century, these questions have typically \\nbeen evaluated using the tripartite framework set forth by U.S. Supreme Court Justice Jackson in \\nhis concurring opinion in the case of Youngstown Sheet & Tube Company v. Sawyer.65 First, if the \\nPresident has acted according to an express or implied grant of congressional authority, \\npresidential “authority is at its maximum.” Second, in situations where Congress has neither \\ngranted nor denied authority to the President, the President acts in reliance only “upon his own \\nindependent powers, but there is a zone of twilight in which he and Congress may have \\nconcurrent authority, or in which its distribution is uncertain.” Third, in instances where \\npresidential action is “incompatible with the express or implied will of Congress,” the power of \\n\\n \\n                                                 \\n\\x0cThe 2013 Cybersecurity Executive Order: Overview and Considerations for Congress \\n\\nthe President is at its minimum. In such a circumstance, presidential action must rest upon an \\nexclusive Article II power. \\n\\nAs an example of the first category, Congress has previously provided explicit statutory authority \\nfor the executive to regulate the security of private entities.66 For example,67 chemical facilities \\nare subject to chemical facility anti-terrorism standards (CFATS) promulgated by the Department \\nof Homeland Security (DHS), which include provisions requiring chemical facilities to take \\nmeasures to protect against cyberthreats.68 Similarly, the Maritime Transportation Security Act \\n(MTSA) gives the Coast Guard the authority to regulate the security of maritime facilities and \\nvessels, including requiring security plans that contain provisions for the security of \\ncommunications systems used in those facilities.69 In these and other situations where Congress \\nhas provided explicit regulatory authority to the executive branch related to cybersecurity, the \\nPresident’s authority to direct sector-specific agencies to coordinate, evaluate, develop, or \\nimplement appropriate cybersecurity standards pursuant to the executive order70 would appear to \\nbe at its maximum. \\n\\nIn other cases, where there may only be congressional silence regarding the President’s authority \\nto direct action on cybersecurity issues, an argument could be made that the issuance of such an \\nexecutive order falls within the “zone of twilight,” assuming that the action could be concurrently \\njustified under some explicit or implied power granted to the President by the Constitution. For \\nexample, Section 9 of E.O. 13636 directs the Secretary of Homeland Security to use a risk-based \\napproach to identify critical infrastructure where a cybersecurity incident could result in \\ncatastrophic effects.71 While such identification is arguably authorized under the Homeland \\nSecurity Act of 2002,72 it might alternatively be justified under the President’s constitutional \\nauthority to request written opinions from the heads of executive departments.73 \\n\\nHowever, some past legislative proposals may be beyond the reach of unilateral executive action. \\nFor example, prior proposals to regulate the cybersecurity of critical infrastructure have also \\nproposed limits on liability or safe harbors for regulated entities that comply with the regulatory \\nschemes,74 because the creation of a regulatory scheme can have an adverse effect on the \\n\\n \\n                                                 \\n\\x0cThe 2013 Cybersecurity Executive Order: Overview and Considerations for Congress \\n\\nexposure of regulated entities to civil liability.75 The scope of such proposed limits has ranged \\nfrom complete immunity, to lesser restrictions such as prohibitions against the awarding of \\npunitive damages. Such limits on liability may also be made dependent upon an entity’s \\nsatisfaction of its regulatory obligations, in order to create a further incentive for compliance. \\n\\nThe abrogation of civil claims under common law or contract law without explicit congressional \\nauthorization may be difficult to justify on the executive’s constitutional powers alone. Notably, \\nthe executive order does not purport to provide any similar liability safe harbors for private \\nentities that comply with cybersecurity standards developed pursuant to the executive order. \\nWhile it does direct the Secretary of Homeland Security to coordinate the establishment of a set \\nof incentives to promote voluntary participation in the critical infrastructure program, it also \\nacknowledges that some incentives may require legislation affirmatively authorizing such \\nlimitations.76 This is not to say that the executive order will have no impact on liability. The \\npublication of recommendations or risk assessments, as provided under the executive order, may \\nbe used by litigants as evidence of the appropriate standard of care to apply in tort litigation \\nresulting from a cybersecurity incident, even if such standards are not controlling.77 \\n\\nSimilarly, it may not be possible for an executive order to authorize telecommunications \\nproviders to engage in more aggressive monitoring of communications networks to help identify \\ncyber threats or attacks in real-time. Such an executive action would contravene current federal \\nlaws protecting electronic communications, and would be evaluated in the third category of \\nJustice Jackson’s Youngstown framework, where the President’s power is at its minimum. Such an \\nexecutive order would not be effective, unless such action fell within a power exclusively granted \\nto the executive by the Constitution. Consistent with this analysis, E.O. 13636 does not purport to \\nprovide any authority for private telecommunications providers to engage in monitoring of their \\nnetworks. \\n\\nRelationship to Legislative Proposals \\n\\nWhile E.O. 13636 does not purport to create new authorities, there are commonalities between \\nsome of its provisions and some of the cybersecurity proposals from the 112th and 113th \\nCongresses. A comparison of a selection of the issues covered by those proposals and the \\nexecutive order is below.78 \\n\\nSeveral comprehensive legislative proposals on cybersecurity in the 112th Congress received \\nconsiderable attention, including a Senate bill, a set of bill proposals by the Obama \\n\\n                                                 \\n\\x0cThe 2013 Cybersecurity Executive Order: Overview and Considerations for Congress \\n\\nAdministration, and a report with recommendations from a House Republican task force,79 which \\ninformed several House bills. The various proposals differed both in some of the issues they \\naddressed and in how they approached them. Among the issues addressed were the following: \\n\\n•  Cybersecurity workforce authorities and programs, \\n\\n•  Cybersecurity R&D, \\n\\n•  Data-breach notification, \\n\\n•  DHS authorities for protection of federal systems, \\n\\n•  FISMA reform, \\n\\n• \\n\\nInformation sharing, \\n\\n•  Penalties for cybercrime, \\n\\n•  Protection of privately held CI, including public/private sector collaboration and \\n\\nregulation of privately held CI, \\n\\n•  Public awareness about cybersecurity, and \\n\\n•  Supply-chain vulnerabilities. \\n\\nE.O. 13636 mainly addresses two of those topics: information sharing and protection of privately \\nheld CI. With respect to information sharing, the executive order does not provide exemptions \\nfrom liability stemming from information sharing, which would require changes to current law. \\nSeveral of the legislative proposals included such changes. Also, some proposals included the \\ncreation of new entities for information sharing, whereas the executive order uses existing \\nmechanisms. \\n\\nWith respect to protection of critical infrastructure, the provisions on designation of CI and \\nidentification of relevant regulations are related to those in some legislative proposals in the 112th \\nCongress. The role of NIST in developing the Cybersecurity Framework was not in the legislative \\nproposals from that Congress, although several would have expanded the agency’s role in \\ncybersecurity.  \\n\\nIn the 113th Congress, H.R. 624 and S. 2588 would address information sharing, and H.R. 3696 \\nand S. 1353 would require NIST to lead a public/private effort similar to the process by which the \\nCybersecurity Framework is being developed. Both House bills passed in the House, H.R. 694 in \\nApril 2013 and H.R. 3696 in July 2014, but some provisions in each were controversial.80 \\n\\nReactions to the Executive Order \\n\\nGiven the absence of enacted comprehensive cybersecurity legislation, some security observers \\nhave contended that the executive order is a necessary step in securing vital assets against \\n\\n\\n                                                 \\n\\x0cThe 2013 Cybersecurity Executive Order: Overview and Considerations for Congress \\n\\ncyberthreats. Proponents of the framework point to its ability to alleviate the problems created by \\na lack of understanding about cybersecurity issues and practices among different classes of \\nstakeholders. They claim that the framework provides a common, nontechnical basis for \\ndeveloping consensus on how best to approach cybersecurity needs.81 \\n\\nOther observers, however, have raised concerns.82 Common themes by such critics have included \\nthe following claims: \\n\\n•  The order offers little more than do existing processes. Such critics point out that, \\nfor example, the Enhanced Cybersecurity Services program was in place before \\nthe release of the order, and that a variety of efforts have been underway to \\ndevelop and adopt voluntary standards and best practices in cybersecurity for \\nmany years. Proponents of the order argue that it lays out and clarifies Obama \\nAdministration goals, requires specific deliverables and timelines, and that the \\nframework and other provisions are in fact new with the executive order. \\n\\n•  The order could make enactment of legislation less likely. These critics express \\nconcern that Congress might decide to wait until the major provisions of the \\norder have been fully implemented before considering legislation. Proponents \\nstate that immediate action was necessary in the absence of legislation, and that \\nchanges in current law are necessary no matter how successful the executive \\norder might be, to provide liability protections for information sharing and to \\nmeet other needs. \\n\\n•  The process for developing the framework is either too slow or too rushed. Some \\nobservers believe that some actions to protect critical infrastructure are well-\\nestablished and should be taken immediately, given the nature and extent of the \\ncurrent threat. They state that the year-long process to develop the framework \\nmay have delayed implementation of needed security measures,83 creating \\nunnecessary and unacceptable risks. Others counter that widespread adoption of \\nthe framework requires consensus, which takes time to achieve, and that the one-\\nyear timeframe may be insufficient, given that the process for developing and \\nupdating consensus standards often takes several years. In fact, some CI entities \\nhave reportedly delayed implementation while waiting for additional federal \\nguidance.84 Some also state that the framework process does not preclude entities \\nfrom adopting established security measures immediately. \\n\\n                                                 \\n\\x0cThe 2013 Cybersecurity Executive Order: Overview and Considerations for Congress \\n\\n•  The framework risks becoming a form of de facto regulation, or alternatively, its \\nvoluntary nature makes it insufficiently enforceable. Another concern of some is \\nthat the executive order could lead to government intrusiveness into private-\\nsector activities, for example through increased regulation under existing \\nstatutory authority,85 while others contend that voluntary measures have a poor \\nhistory of success. Some others, however, have argued that changes in the \\nbusiness environment—such as the advent of continuous monitoring, more \\npowerful analytical tools, and a better prepared workforce—improve the \\nlikelihood that a voluntary approach can be successful.86 \\n\\n•  The order could lead to overclassification or underclassification of high-risk \\n\\ncritical infrastructure by DHS. Some observers have expressed concern that the \\nrequirement in the order for DHS to designate high-risk critical infrastructure \\nmay be insufficiently clear and could lead to either harmfully expansive \\ndesignations or inappropriate exclusions of entities.87 This might be particularly a \\nproblem if the criteria are not sufficiently validated.88  \\n\\nIt appears to be too early in the implementation of the executive order to determine how \\neffectively the concerns described above will be addressed and whether the responses will satisfy \\ncritics and skeptics. Overall, however, response to the order from the private sector—including \\ncritical-infrastructure entities, trade associations, and cybersecurity practitioners—appears to be \\nlargely positive. Some organizations and experts have urged adoption of the framework by CI \\nentities.89  \\n\\n \\n                                                 \\n\\x0cThe 2013 Cybersecurity Executive Order: Overview and Considerations for Congress \\n\\nIn August 2014, NIST requested public comments on implementation of the framework and \\nposted more than 60 it received from various companies, trade associations, and other \\norganizations.90 The responses demonstrate a range of understanding and implementation both \\nacross and within sectors and generally support the contention that additional experience will be \\nnecessary before the success of the framework at improving CI cybersecurity can be adequately \\nassessed.  \\n\\nAuthor Contact Information \\n\\nEric A. Fischer \\nSenior Specialist in Science and Technology  \\nefischer@crs.loc.gov, 7-7071 \\n\\n  John W. Rollins \\n\\nSpecialist in Terrorism and National Security \\njrollins@crs.loc.gov, 7-5529 \\n\\nEdward C. Liu \\nLegislative Attorney \\neliu@crs.loc.gov, 7-9166 \\n\\n  Catherine A. Theohary \\n\\nSpecialist in National Security Policy and \\nInformation Operations \\nctheohary@crs.loc.gov, 7-0844 \\n\\n\\n \\n \\n \\n                                                                  \\n\\x0c', 'Chapter 8\\nA Two-Tier Control Architecture\\nFor Cybersecurity and Operational\\nSafety\\n\\n8.1 Introduction\\n\\nWhile the resilient control systems in Chap. 7 were shown to successfully mitigate\\nthe impact of cyber-attacks and re-stabilize the system upon detection, the control\\nsystems themselves are not inherently cyber-secure, which means they have to rely\\non redundant sensors or accurate state estimation in the presence of cyber-attacks.\\nAlthough many advances have been made in improving efﬁciency of data-based\\ndetectors and in the development of resilient control schemes in response to cyber-\\nattacks, it is possible that the control system has to be shut down due to unavailability\\nof state measurements from redundant sensors or of reliable state estimation.\\n\\nThis chapter presents a detector-integrated control system with a two-tier control\\narchitecture that can ensure closed-loop stability of nonlinear processes upon detec-\\ntion of cyber-attacks without having to switch to secure redundant sensors or state\\nestimation. Traditionally, control systems are developed based on a small number of\\nactuators and sensors with point-to-point wired communication. Hybrid communi-\\ncation networks that incorporate additional (wired or wireless) networked sensor and\\nactuator devices into the existing point-to-point communication networks may beneﬁt\\nthe operation of chemical processes. In the study of hybrid communication networks\\nthat use both point-to-point and networked sensors, cybersecurity is a key issue for\\nsecure and stable operation of chemical processes. Working with a general class of\\nnonlinear systems, cyber-secure lower-tier controllers that stabilize a multivariable\\nnonlinear process at the steady-state based on point-to-point dedicated sensor mea-\\nsurements are coupled with an upper-tier model predictive controller (MPC) that uses\\nnetworked sensor measurements to improve closed-loop performance. The two-tier\\ncontrol system guarantees that the process stays immune to malicious cyber-attacks\\nthat target the networked sensor measurements to destabilize the system. Addition-\\nally, the safety systems discussed in the previous chapters are also integrated with\\ncyber-secure control systems to ensure safe operation upon successful detection of\\n\\n© The Author(s), under exclusive license to Springer Nature Switzerland AG 2021\\nZ. Wu and P. D. Christoﬁdes, Process Operational Safety and Cybersecurity,\\nAdvances in Industrial Control, https://doi.org/10.1007/978-3-030-71183-2_8\\n\\n241\\n\\n\\x0c242\\n\\n8 A Two-Tier Control Architecture For Cybersecurity and Operational Safety\\n\\ncyber-attacks. In this chapter, we ﬁrst develop machine-learning-based attack detec-\\ntors that identify the occurrence of cyber-attacks based on real-time sensor mea-\\nsurements. Simulation results of the application to a multivariable nonlinear process\\nexample, e.g., [156, 185, 232], demonstrate that the detection algorithms can efﬁ-\\nciently detect and distinguish between multiple types of intelligent cyber-attacks.\\nA reactor-reactor-separator process will be used to illustrate the application of the\\nmachine-learning-based attack detectors and of the two-tier control architecture. It\\nwill be demonstrated in the simulation studies that the cyber-secure control archi-\\ntecture ensures closed-loop stability through reconﬁguration of the control system\\nonce the cyber-attacks are successfully detected.\\n\\n8.1.1 Class of Nonlinear Systems\\n\\nThe class of continuous-time nonlinear systems considered is described by the fol-\\nlowing state-space form:\\n\\n˙x(t) = f (x(t), uc(t), ua(t), us(t))\\nyc(t) = hc(x(t)), ya(t) = ha(x(t))\\n\\n(8.1a)\\n(8.1b)\\n\\ni\\n\\ni\\n\\n+ mua\\n\\n≤ ui ≤ umax\\n\\n, i = 1, . . . , muc\\n\\nwhere x ∈ D ⊂ Rnx is the state vector, yc(t) ∈ Rn yc represents the vector of measured\\nstates that are continuously sampled (e.g., yc(t) is the reactor temperature in the\\nbenchmark chemical process example in this chapter), and ya(t) ∈ Rn ya represents\\nthe vector of networked state measurements that are asynchronously sampled at\\nt = tk (e.g., ya(t) is product concentration in the reactor example); uc and ua are\\nthe manipulated input vectors, which are constrained by [uc ∈ Rmuc , ua ∈ Rmua ] ∈\\n}. us ∈ Rmus represents the vector of\\nU := {umin\\ninputs to the process controlled by the safety system, with each component us,i , i =\\n1, . . . , mus , restricted to a set of discrete (on-off) values. For simplicity, we use\\nus,i = 0 and us,i = 1 to represent deactivation and activation of the safety system,\\nrespectively, throughout this chapter. The safety system is then incorporated within\\nthe two-tier control system under many different operating conditions to allow the\\nimpacts of various safety system actions based on different states and threshold\\ncrossings to be evaluated so that: (1) Appropriate recommended procedures can be\\ndeveloped for operators given the alarms, (2) Appropriate automatic actions can be\\ntaken by the emergency shutdown system (ESS), and (3) Appropriate equipment\\nchoices can be made for the relief system (e.g., the safety relief valves that are\\ndesigned to open/close to maintain chemical plant pressure within a desired range;\\nsee, also, Chap. 5 for the integration of safety systems with control systems).\\n\\nThrough yc and ya, we assume that the full-state measurements are available at\\ntk. Without loss of generality, the vector function f (·, ·, ·, 0), hc(·) and ha(·) are\\nassumed to be sufﬁciently small with ha(0) = 0, hc(0) = 0, and f (0, 0, 0, 0) = 0\\n\\n\\x0c8.1 Introduction\\n\\n243\\n\\nsuch that the origin is an equilibrium point of the system of Eq. 8.1 under uc(t) = 0,\\nua(t) = 0 and us(t) = 0. Additionally, the initial time t0 is taken to be zero (t0 = 0).\\n\\nRemark 8.1 To simplify the notation, we assume that (asynchronous) full-state\\nmeasurements are available for the controller ua(t). The results can be extended to\\nthe case where only partial state information is available.\\n\\n8.2 Cyber-Secure Two-Tier Control Architecture\\n\\nThis section presents a cyber-secure control architecture that integrates a lower-tier\\ncontroller that stabilizes the nonlinear system at the steady-state based on the dedi-\\ncated sensor measurements, yc(t), with an upper-tier, advanced control system (e.g.,\\nmodel predictive control) that improves closed-loop performance signiﬁcantly above\\nwhat could be achieved with the lower-tier control system using both networked\\n(ya(t)) and dedicated (yc(t)) sensor measurements. Due to the asynchronous nature\\nof networked sensor measurements ya(t), the unknown time interval between two\\nasynchronous measurements should be taken into account in the design of upper-tier\\ncontroller. The main objective of two-tier control architecture is to enhance closed-\\nloop performance with the additional state information from networked sensors while\\nmaintaining closed-loop stability properties achieved by lower-tier controller. The\\nformulations of upper-tier and lower-tier control systems are presented in detail\\nbelow.\\n\\n8.2.1 Lower-Tier Control System\\n\\nThroughout this chapter, it is assumed that an explicit feedback controller uc(t) =\\nΦc(yc) ∈ U exists to stabilize the nominal system of Eq. 8.1 (i.e., in the absence\\nof cyber-attacks) at the steady-state. This stabilizing controller will be used as in\\nthe lower-tier control system as it only uses the continuous measurements yc(t) to\\ncompute control actions. Additionally, we assume that the origin of the nominal\\nsystem of Eq. 8.1 can be rendered asymptotically stable under uc(t) = Φc(yc) ∈ U\\nand ua(t) = 0 (i.e., ua is set to its steady-state value at all times). This stabilizability\\nassumption implies that there exist a C 1 control Lyapunov function V (x) : D → R+\\nand class K functions αi (·), i = 1, 2, 3, 4, that satisfy the following conditions:\\n\\nα1(|x|) ≤ V (x) ≤ α2(|x|),\\n\\n∂ V (x)\\n∂ x\\n\\nf (x, Φc(yc), 0, 0) ≤ −α3(|x|),\\n\\n(cid:2)\\n(cid:2)\\n(cid:2)\\n(cid:2)\\n\\n∂ V (x)\\n∂ x\\n\\n(cid:2)\\n(cid:2)\\n(cid:2)\\n(cid:2) ≤ α4(|x|)\\n\\n(8.2a)\\n\\n(8.2b)\\n\\n(8.2c)\\n\\n\\x0c244\\n\\n8 A Two-Tier Control Architecture For Cybersecurity and Operational Safety\\n\\nfor all x ∈ D ⊂ Rnx , where D is an open neighborhood around the origin. Then, using\\nthe stabilizing controller uc = Φc(yc) ∈ U , we characterize the closed-loop stability\\nregion Ωρ as a level set of V (x) within the set D, i.e., Ωρ := {x ∈ D | V (x) ≤\\nρ, ρ > 0}, from which the state trajectory of the closed-loop system remains within\\nΩρ and asymptotically converges to the origin under u = Φc(yc) ∈ U for any initial\\ncondition in Ωρ. Therefore, for any initial condition inside Ωρ, closed-loop stability\\nis guaranteed for the process using the lower-tier controller only, provided that secure\\nand reliable sensor measurements are available to the lower-tier controller.\\n\\nRemark 8.2 Static lower-tier controllers are considered in this section to simplify\\nthe discussion of stabilization of the nonlinear system of Eq. 8.1 at the steady-state.\\nHowever, the formulation of lower-tier controllers can be extended to dynamic control\\nschemes. For example, in Sect. 8.4, we use proportional–integral (PI) controllers as\\nthe lower-tier controllers to stabilize a nonlinear chemical process at the operating\\nsteady-state.\\n\\n8.2.2 Upper-Tier Model Predictive Control System\\n\\nWhile the continuous dedicated sensor measurements yc(t) are used to ensure closed-\\nloop stability, the (potentially asynchronous) networked state measurements ya(t)\\ncan be used in the optimization of the control actions ua(t) in the upper-tier controller\\nto improve the closed-loop performance than using the lower-tier controller only. In\\nthis study, to take advantage of the process model in optimizing process performance,\\nand to control the process when the feedback is unavailable between two consecutive\\n(asynchronous) measurements, we use model predictive control scheme in upper-tier\\ncontrol system. Speciﬁcally, the Lyapunov-based MPC (LMPC) with the contractive\\nconstraint designed based on the stability region characterized by the lower-tier\\ncontroller is used as the upper-tier controller, such that the calculation of ua(t) will not\\naffect the asymptotic stability of the closed-loop system. The LMPC is represented\\nas the following optimization problem:\\n\\nmin\\nua ∈S(Δ)\\n\\ns.t.\\n\\ntk+N(cid:3)\\n\\ntk\\n\\nlt ( ˜x(t), ˜uc(t), ua(t))dt\\n\\n˙˜x(t) = f ( ˜x(t), Φc(hc( ˜x(t)), ua(t), 0)\\n˙ˆx(t) = f ( ˆx(t), Φc(hc( ˆx(t)), 0, 0)\\n˜x(tk) = ˆx(tk) = x(tk)\\n[uc(t), ua(t)] ∈ U, ∀ t ∈ [tk, tk+N )\\nV ( ˜x(tk)) ≤ V ( ˆx(tk)),\\nV ( ˜x(t)) ≤ ρmin, ∀ t ∈ [tk, tk+N ),\\n\\nif V ( ˜x(tk)) > ρmin\\n\\nif V ( ˜x(tk)) ≤ ρmin\\n\\n(8.3a)\\n\\n(8.3b)\\n\\n(8.3c)\\n(8.3d)\\n\\n(8.3e)\\n(8.3f)\\n\\n(8.3g)\\n\\n\\x0c8.2 Cyber-Secure Two-Tier Control Architecture\\n\\n245\\n\\nwhere Δ, N , and S(Δ) are the sampling period, the number of sampling periods in\\nthe prediction horizon, and a family of piecewise constant functions with the time\\ninterval of Δ, respectively. The optimal control actions u∗\\n(t) over the prediction\\na\\nhorizon t ∈ [tk, tk+N ) are calculated at time tk by the LMPC optimization problem\\nof Eq. 8.3 based on a full-state measurement, from which the ﬁrst control action, i.e.,\\nua(t) = u∗\\n(tk|tk), is applied in open loop to the nonlinear system until the next full-\\na\\nstate measurement x of yc and ya in Eq. 8.1b is available to the optimization problem\\nof LMPC. Then, the LMPC optimization problem will be solved with the new state\\nmeasurements, and the above process is repeated until the end of the operating\\nperiod. Note that if the time between two consecutive asynchronous measurements\\nis longer than the prediction horizon N · Δ, then we set ua to its steady-state value\\n(i.e., ua = 0) for the remaining time in the asynchronous sampling interval past the\\nprediction horizon, such that it will not affect the closed-loop stability achieved by\\nthe lower-tier controller. Meanwhile, the lower-tier control actions uc = Φc(yc) are\\nstill continuously calculated based on continuous measurement feedback yc to drive\\nthe process state towards the steady-state. ˜x(t) and ˆx(t) in Eqs. 8.3b and 8.3c are\\nthe predicted states of the nominal system under the two-tier control system (i.e.,\\nuc = Φc(yc) where yc = hc( ˜x) and ua is optimized by LMPC), and under the lower-\\ntier controller only (i.e., uc = Φc(yc), and ua is set to 0), respectively. Equation 8.3d\\ndeﬁnes the initial condition for the optimization problem of LMPC, which is the\\nfull-state measurement received at the time tk. Equation 8.3e deﬁnes the constraints\\non control actions for both lower-tier and upper-tier controllers.\\n\\nSince the origin of the nonlinear system of Eq. 8.1 is rendered asymptotically\\nstable under the lower-tier controller that satisﬁes the conditions in Eq. 8.2, the con-\\nstraint of Eq. 8.3f ensures that the Lyapunov function value of the closed-loop system\\nunder two-tier control, V ( ˜x(tk)), is not greater than that under lower-tier control alone\\nV ( ˆx(tk)). Hence, the controller forces the closed-loop state to move towards the ori-\\ngin under the contractive constraint of Eq. 8.3f, and thus, is also bounded in the\\nstability region Ωρ for all times under two-tier control. When the state approaches\\nthe steady-state and enters a small region around the steady-state, i.e., x(tk) ∈ Ωρmin ,\\nwhere Ωρmin , 0 < ρmin < ρ is a level set of Lyapunov function, the constraint of\\nEq. 8.3g requires that the future states remain inside Ωρmin for the entire prediction\\nhorizon. Since the closed-loop state is ultimately bounded in Ωρmin that is very close\\nto the origin under the LMPC of Eq. 8.3, the system is considered practically stable.\\nAdditionally, the two-tier control system improves the overall closed-loop perfor-\\nmance through the optimization problem of LMPC, while maintaining the system\\nstability by using the stabilizing constraint based on lower-tier control actions. It\\nshould be pointed out that the upper-tier MPC is executed only when a full-state\\nmeasurement is available from both the asynchronous and continuous sensor mea-\\nsurements. Speciﬁcally, the continuous measurements are readily used by LMPC as\\nthey are continuously measured in a point-to-point sensor network and sent to the\\nlower-tier controller to compute the control actions uc (i.e., the stabilizing controller).\\nTherefore, the execution of the LMPC optimization problem basically depends on\\nthe availability of (asynchronous) networked sensor measurements. Figure 8.1 shows\\n\\n\\x0c246\\n\\n8 A Two-Tier Control Architecture For Cybersecurity and Operational Safety\\n\\nFig. 8.1 Two-tier control-detector architecture with the upper-tier controller (i.e., MPC) using both\\nnetworked and continuous (secure) sensor measurements, and the lower-tier controllers using only\\ncontinuous (secure) sensor measurements, where the networked sensors are vulnerable to cyber-\\nattacks\\n\\na structure of the two-tier control system, in which the networked sensors, ya(t) that\\nwill be used in LMPC are vulnerable to cyber-attack.\\n\\nRemark 8.3 The lower-tier controller views the input ua(t) as a disturbance to the\\nprocess if the upper-tier controller that manipulates ua(t) is designed improperly.\\nTherefore, to improve closed-loop performance while maintaining system stability,\\nthe upper-tier controller should be designed accounting for the decisions that are\\nmade by the lower-tier controller. Speciﬁcally, in the formulation of upper-tier MPC\\nsystem, the upper-tier controller is switched off when the system starts operating in\\nopen loop (i.e., all the control actions optimized over the prediction horizon have\\nbeen implemented before the next asynchronous measurements are available). In\\nthis case, the last received optimal control actions from upper-tier controllers are no\\nlonger useful for the lower-tier controller to improve the closed-loop performance,\\nand may even act as a disturbance to the process. As the two-tier control architecture\\nis inherently stable (due to the stability properties of lower-tier controllers), the\\nmain challenge for the upper-tier controller is to improve closed-loop performance\\nusing non-reliable communications in a way such that closed-loop stability is not\\ncompromised. Therefore, when implementing upper-tier MPC, we will set the control\\naction of the upper-tier controller to zero after a certain time to maintain the stability\\nproperties.\\n\\nRemark 8.4 Note that the control systems using dedicated, local control networks\\nhave already been implemented in many chemical plants for years, and these con-\\ntrollers will not be replaced by networked control systems. Instead, to improve closed-\\n\\n\\x0c8.2 Cyber-Secure Two-Tier Control Architecture\\n\\n247\\n\\nloop performance and maintain system stability, we develop the networked control\\nsystems by augmenting the pre-existing control systems with networked sensor mea-\\nsurements. This supports the assumption we made at the beginning of this chapter\\nthat a stabilizing lower-tier controller exists for the nonlinear system based on the\\ncontinuous sensor measurements.\\n\\nRemark 8.5 The two-tier control system with stabilizing lower-tier controllers and\\nupper-tier model predictive controllers can guarantee closed-loop stability in the\\nsense that the closed-loop state remains within the stability region for all times, and is\\nultimately bounded in a small neighborhood around the origin for any initial condition\\nin the stability region under nominal operating conditions (i.e., in the absence of\\nprocess disturbances and cyber-attacks). The interested readers may refer to [111]\\nfor the stability analysis of the two-tier control architecture. Additionally, it should\\nbe noted that although the closed-loop performance is improved in general using\\ntwo-tier control architecture as the cost function accounts for process performance\\nindex, we may not be able to derive quantitative results for guaranteed improvement\\nof closed-loop performance using two-tier control architecture over other controllers,\\nunless an inﬁnite horizon is utilized.\\n\\n8.3 Cyber-Attack Design and Detection\\n\\nIn this section, we consider intelligent cyber-attacks that are adaptive to the pro-\\ncess and control system behavior. The intelligent cyber-attacks are assumed to be\\nprocess-aware in the sense that they have access to process information such as the\\ncontrol command signals (actuator attack), and the measurement feedback signals\\n(sensor attack), or auxiliary information such as the bias and threshold parameters\\nin conventional detection methods, e.g., cumulative sum (CUSUM) [43, 132] (see,\\nalso, Eq. 7.10 for the formulation of CUSUM). Particularly, in this study, the attacks\\nare designed with the information on the existing alarms that indicate normal oper-\\nating conditions for the output and input variables, as well as the stability region\\ncharacterized for the closed-loop system under two-tier control. Additionally, in this\\nstudy, we only consider attacks on sensor measurements. Under nominal operation\\n(i.e., under no attack), the closed-loop system is operated normally under the two-tier\\ncontrol system as the sensor feedback measurements remain secure and reﬂect the\\ntrue process state accurately. However, in the presence of cyber-attacks on sensor\\nmeasurements, closed-loop stability is no longer guaranteed as the process state may\\nbe driven away from the equilibrium point and eventually outside of the stability\\nregion Ωρ under falsiﬁed states measurements. Additionally, the falsiﬁed state mea-\\nsurement under intelligent cyber-attacks will be set to a value inside the closed-loop\\nstability region Ωρ such that feasible control actions still exist, but will have large\\nenough magnitude of variations to disrupt the control objective. Speciﬁcally, the four\\nmost important types of cyber-attacks, i.e., min-max, geometric, replay, and surge\\nattacks that have been discussed in Sect. 7.2.1 are considered in this chapter.\\n\\n\\x0c248\\n\\n8 A Two-Tier Control Architecture For Cybersecurity and Operational Safety\\n\\n8.3.1 Attack Scenarios\\n\\nSince part of the measurement feedback (i.e., networked sensor information) is asyn-\\nchronous in the upper-tier control system, the networked sensor measurements are\\nvulnerable to cyber-attacks. Due to the sparse and irregular measurements as well as\\nthe possibility that multiple states are attacked by intelligent cyber-attacks, the result-\\ning deviations on the process may be undetectable by conventional fault-detection\\nschemes or by control engineers. While the asynchronous networked measurements\\nare vulnerable to cyber-attacks, we assume that the dedicated sensor measurements\\nreceived by both lower-tier and upper-tier controllers remain secure based on the\\nfollowing reasons. Firstly, the two-tier control system is developed based on the\\nassumption that the system is stabilizable under lower-tier controllers. In fact, the\\nclosed-loop stability is guaranteed under two-tier control using the constraints based\\non lower-tier control actions, for which, secure and reliable continuous measurements\\nare required. Secondly, when a cyber-attack targeting networked measurements is\\nsuccessfully identiﬁed by detector, the control structure will be reconﬁgured and\\nthe lower-tier controller (i.e., secure stabilizing controller) can quickly mitigate the\\nimpact of cyber-attacks. Since the closed-loop system can be stabilized at the oper-\\nating steady-state using the lower-tier controller only, we will shut off the upper-tier\\ncontroller and stop using the corrupted networked measurements after the detection\\nof cyber-attack is conﬁrmed. However, in the worst-case scenario that the continuous\\nmeasurements are also attacked, cybersecurity is no longer guaranteed for the two-\\ntier control system because the lower-tier controllers are also unable to stabilize the\\nsystem at the steady-state. Due to the above considerations, it is instrumental to have\\nsecure continuous sensor measurements to ensure cybersecurity for the nonlinear\\nsystem under a two-tier control system.\\n\\nTo distinguish between normal device ﬂuctuations and cyber-attacks, and to cap-\\nture realistic sensor variance, we also consider bounded sensor noise in this study.\\nTherefore, we consider the following two scenarios in this study:\\n\\n1. Nominal model refers to the nonlinear system of Eq. 8.1 where no sensor noise\\n\\nis added on sensor measurements.\\n\\n2. Noise model adopts the same nonlinear model of Eq. 8.1a, where sensor mea-\\nsurements are corrupted by Gaussian noise w(t) ∈ W that is bounded by the set\\n+n ya | |w| ≤ wmax}. We adjust the noise distribution (i.e., stan-\\nW = {w ∈ Rn yc\\ndard deviation) for different sensors based on the range of the measured process\\nvariables. Therefore, we modify Eq. 8.1b to the following form to account for\\nthe sensor noise :\\n\\nyc(t) = hc(x(t)) + w(t), ya(t) = ha(x(t)) + w(t), w(t) ∈ W.\\n\\n(8.4)\\n\\nThe training dataset is generated from extensive closed-loop simulations with attacks\\nbeing introduced at random times i0 with varying durations L a during the simulation\\nperiod. The reader is referred to Sect. 7.2.1.5 for a detailed simulation design guide.\\nIn both the cases of the nominal model and of the noise model, we classify the\\n\\n\\x0c8.3 Cyber-Attack Design and Detection\\n\\n249\\n\\nsignals without attack as “no attack”. Additionally, we consider both the attacks that\\ntarget single and multiple sensors, where the training process will utilize the data\\nfrom single-sensor attack, and the multiple-sensor attacks are used for online testing\\nto demonstrate the effectiveness of detection methods. Additionally, the machine-\\nlearning-based detector trained for a single-sensor attack can also be used for sensor\\nisolation once the cyber-attack is detected. For clarity, in this study, we only consider\\nthe scenario that one type of cyber-attack occurs at a time, i.e., during each attack\\nduration, the system is not attacked by a hybrid of multiple types of cyber-attacks.\\n\\nRemark 8.6 Note that upper-tier controller and lower-tier controllers share the same\\ncontinuous state measurements despite the asynchronous execution frequency of the\\nupper-tier controller. This implies that the continuous state measurements sent to\\nthe upper-tier control system remain intact during the entire operating period. It also\\nimplies that even when a multiple-sensor attack occurs, it will only target the sensors\\nthat send sampled asynchronous state measurements to upper-tier controller, and not\\nattack the continuous sensor measurements. Additionally, it is not meaningful for the\\nintelligent cyber-attack to attack the two separate communication channels in the two\\ntiers of controllers, under which the continuous measurements for the upper-tier con-\\ntroller are compromised while those sent to lower-tier controllers remain unchanged.\\nThe reason is that we can always develop a simple tracker that identiﬁes the presence\\nof this abnormality by examining the error between the same measurements sent to\\nthe lower and upper-tier controllers. Therefore, the assumption that both controllers\\nreceive secure continuous state measurements is valid in the two-tier control system.\\n\\n8.3.2 Mitigation Measures via Reconﬁguration of Control\\n\\nSystem\\n\\nA feedforward artiﬁcial neural network is developed following the construction\\nmethod in Sect. 7.3 to detect cyber-attacks by solving supervised classiﬁcation prob-\\nlems. Compared to conventional detection schemes, data-based approaches have\\nmany advantages in the develop to development of the cyber-attack detector [1, 81,\\n145]. Firstly, physical-model-based detection methods that identify cyber-attacks\\nbased on false alarm thresholds may become ineffective for the intelligent cyber-\\nattacks that have access to process information (e.g., variable operating window and\\nstability region) [43]. Secondly, in a chemical plant, plant model parameters and\\nstructure may be modiﬁed sometimes to adapt to the variation of operating environ-\\nment. In this case, the data-based detection method that does not depend on physical\\nmodels is resilient to intelligently designed attacks and process changes. In this study,\\nneural networks are developed to distinguish between two classes, i.e., “no attack”\\nand “attack”, or to distinguish between multiple classes, i.e., types of attacks and “no\\nattack”, depending on the training data collected from simulations. Additionally, a\\nneural-network-based isolator can also be developed using the data collected from\\nindividual sensors to locate the corrupted sensor upon the detection of cyber-attacks.\\n\\n\\x0c250\\n\\n8 A Two-Tier Control Architecture For Cybersecurity and Operational Safety\\n\\nIn this case, this neural network model is developed with multiple labeled classes,\\nwhere every class represents one problematic sensor.\\n\\nOnce an attack on the sensors is detected based on the (asynchronous) networked\\nstate measurements provided to two-tier control system, control system reconﬁgu-\\nration is executed using the following steps. First, the upper-tier controller should\\nbe deactivated completely, and the stabilizing controller (i.e., lower-tier controller)\\nwith secure, dedicated sensor measurements will be used to operate the system.\\nSince the continuous measurements remain secure all the time, and system stability\\nis ensured using the lower-tier controllers, the impact of the cyber-attacks can be\\nfully eliminated after the reconﬁguring the control system. Second, once we con-\\nﬁrm sensor attack in the system and use sensor isolation detector (if there is any)\\nto locate the compromised sensor(s), the upper-tier controller needs to abandon the\\ncorrupted sensors and use the secure, redundant back-up sensors. In this case, the\\nupper-tier controller remains functional and an improved closed-loop performance\\ncan be achieved under the two-tier controller.\\n\\nIn the worst-case scenario that both asynchronous and continuous sensor mea-\\nsurements are attacked, we will shut off the upper-tier controller and continue to use\\nthe lower-tier controllers with secure back-up sensor measurements replacing the\\ncompromised continuous measurements. A reactor-reactor-separator process will be\\nutilized in Sect. 8.4 to demonstrate the robustness of the two-tier control architecture\\nagainst different types of attacks.\\n\\nRemark 8.7 By reconﬁguring the control system, we have shown that closed-loop\\nstability is maintained for the system subject to cyber-attacks. This implies that the\\ntwo-tier control architecture is inherently cyber-secure due to stabilizing lower-tier\\ncontroller, and does not rely on redundant senors or accurate state estimation to re-\\nstabilize the system at the steady-state. However, as upper-tier controller (i.e., model\\npredictive controller) is deactivated after detection of cyber-attacks, closed-loop per-\\nformance degradation may be observed afterwards by using lower-tier controller only.\\nTherefore, to improve closed-loop performance by continuing using the upper-tier\\ncontroller, the redundant back-up sensors and state reconstruction methods that have\\nbeen discussed in Chap. 7 can be utilized within upper-tier controller. Speciﬁcally,\\nif redundant back-up sensors are available, a straightforward approach to continuing\\nclosed-loop control is to replace the problematic sensors with the redundant sensors.\\nHowever, as redundant sensors may not be immediately deployed upon detection of\\ncyber-attacks, sensor device replacement is not an effective measure for all circum-\\nstances. Therefore, instead of using falsiﬁed state measurements, state reconstruction\\nmethod provides an alternative way to optimize closed-loop performance via MPC\\nwith reconstructed process states (i.e., estimated true state values).\\n\\n\\x0c8.3 Cyber-Attack Design and Detection\\n\\n251\\n\\n8.3.3 Integration of Safety Systems with Two-Tier Control\\n\\nSystems\\n\\nAs cyber-attacks on safety-critical systems have the potential to cause real harm\\nin the physical world, the scope of cybersecurity goes beyond the use of cyberse-\\ncurity software. In addition to the cyber-secure control systems introduced in the\\nprevious chapter and this chapter, process safety systems such as alarms systems,\\nemergency shutdown systems and safety relief devices that have been discussed\\nin the ﬁrst half of the book can provide the last line of defense in the event of\\nan abnormal situation due to cyber-attacks. It is noted that although the two-tier\\ncontrol system is able to maintain stable and safe operation using the lower-tier\\ncontroller only with dedicated, secure sensor measurements yc, the remaining pro-\\ncess states (i.e., measured by networked sensors ya) may leave their safety limits\\nprior to the successful detection of cyber-attacks. To reduce physical risks of cyber-\\nattacks ranging from simple unplanned downtime in operations to a plant explosion\\nor release of hazardous materials, we integrate safety system with two-tier control\\nsystem to maintain all process states within their safety operating limits once the\\ncyber-attack is detected by the neural-network-based detector. Speciﬁcally, Safeness\\nIndex functions S(x), a function of the (closed loop) process states that character-\\nizes the “safeness” of a process operation, is initially adopted as a safety metric for\\nactivation/deactivation of safety systems (see Chap. 3 for the deﬁnition and appli-\\ncation of Safeness Index in chemical process control problems). Safe and unsafe\\noperations can then be evaluated by comparing the value of S(x) with the threshold\\nvalue ST H that is pre-determined using process ﬁrst-principles knowledge or past\\nplant data (i.e., S(x) < ST H and S(x) > ST H represent safe and unsafe operations,\\nrespectively). Additionally, because S(x) can provide information on both measured\\nand estimated states, its use in the alarm system can help manage the trade-off\\nbetween measuring fewer states (which may lead to missed alarms) and more states\\n(which leads to instrumentation expenses and possibly more occurrences of alarm\\noverloading).\\n\\nIn the traditional process safety paradigm, process variables are stabilized at their\\nset-points by basic process control systems (BPCS) under normal operation; when\\nthe control system (BPCS) fails to operate the process in a safe operating region in\\nthe presence of disturbances or cyber-attacks, the safety systems (e.g., alarm systems,\\nemergency shutdown systems (ESS), and safety relief devices) are activated to pre-\\nvent further unsafe operation. However, since the process dynamics is changed after\\nthe activation of safety systems (e.g., opening of a pressure relief valve to prevent\\nhigh pressure in a chemical reactor), the actions taken by the safety systems should\\nbe taken into account in the reconﬁguration of control systems. In this section, we\\ndevelop an integrated safety and cyber-secure control system that takes appropriate\\nactions based on measured variables and S(x) thresholds being crossed is developed\\nbased on the following requirements: (1) Secure, redundant sensors or reliable state\\nestimation are available to the control, alarm, emergency shutdown, and relief sys-\\ntems with standard industrial practice; (2) To simplify the discussion, the actions\\n\\n\\x0c252\\n\\n8 A Two-Tier Control Architecture For Cybersecurity and Operational Safety\\n\\ninitiated as a result of the alarm, ESS, and relief systems are on-off type actions (i.e.,\\nan operator or the relief system can fully open or fully close a valve; the ESS can\\nturn a pump on or off); (3) The safety-based (lower-tier) control system continues\\nto regulate the process state even when the safety system is triggered. Speciﬁcally,\\nsince networked sensor measurements ya are untrustworthy under cyber-attacks, we\\nmeasure/estimate the true state x value through redundant, secure sensors or state\\nestimator based on secure and dedicated sensor measurements (see, also, Sect. 7.4\\nfor a detailed description of the two methods). Additionally, it should be noted that\\nthe system dynamics is changed after the activation of the safety system, i.e., us = 1\\nin Eq. 8.1. Therefore, the two-tier control system needs to account for the change in\\nsystem dynamics by updating the prediction model of Eqs. 8.3b–8.3c in the upper-\\ntier MPC. After process states move into the safe operating region, the safety system\\nis taken off-line and the two-tier control system switches to the initial process model\\nwhere us = 0.\\n\\n8.4 Application to a Chemical Process Example\\n\\nWe consider a chemical process network consisting of two CSTRs followed by a\\nﬂash tank separator, in which the species concentration and the temperature in the\\nthree vessels are regulated by manipulating multiple inputs in both the lower-tier and\\nupper-tier controllers [235]. A schematic diagram of the reactor-reactor-separator\\nprocess is given in Fig. 8.2. Two reactions (A → B → C) take place in series in both\\nreactors, and the overhead vapor from the ﬂash tank is recycled to the ﬁrst CSTR.\\n\\nFig. 8.2 Schematic of the reactor-reactor-separator process with two CSTRs and a ﬂash drum\\nseparator\\n\\n\\x0c8.4 Application to a Chemical Process Example\\n\\n253\\n\\nIt is assumed that all three vessels have constant holdup. Based on mass and energy\\nbalances, the following nine nonlinear ordinary differential equations are developed\\nto describe the process dynamics:\\n\\ndx A1\\ndt\\ndx B1\\ndt\\ndT1\\ndt\\n\\ndx A2\\ndt\\ndx B2\\ndt\\ndT2\\ndt\\n\\ndx A3\\ndt\\ndx B3\\ndt\\ndT3\\ndt\\n\\n+ Fr\\nV1\\n\\n(x A10 − x A1) + Fr\\nV1\\n(x B10 − x B1) + Fr\\nV1\\n(−ΔH1)\\nρC p\\n\\n(T10 − T1) +\\n\\n= F10\\nV1\\n= F10\\nV1\\n= F10\\nV1\\n+ Q1\\n\\n(T3 − T1)\\n\\nρC p V1\\n(x A1 − x A2) + F20\\nV2\\n(x B1 − x B2) + F20\\nV2\\n(−ΔH1)\\nρC p\\n\\n(T20 − T2) +\\n\\n= F1\\nV2\\n= F1\\nV2\\n= F20\\nV2\\n+ Q2\\n\\n+ F1\\n(T1 − T2)\\nρC p V2\\nV2\\n(x A2 − x A3) − Fr + Fp\\n(x B2 − x B3) − Fr + Fp\\n\\nV3\\n\\n= F2\\nV3\\n= F2\\nV3\\n= F2\\nV3\\n+ Q3\\n\\nρC p V3\\n\\n(T2 − T3) +\\n\\nV3\\n(Fr + Fp)C M\\nρC pV3\\n\\n(x Ar − x A1) − k1e\\n\\n−E1\\nRT1 x A1\\n\\n(x Br − x B1) + k1e\\n\\nC M k1e\\n\\n−E1\\nRT1 x A1 +\\n\\nC M k2e\\n\\n−E2\\nRT1 x B1\\n\\n−E2\\nRT1 x B1\\n\\n−E1\\nRT1 x A1 − k2e\\n(−ΔH2)\\nρC p\\n\\n(x A20 − x A2) − k1e\\n\\n−E1\\nRT2 x A2\\n\\n(x B20 − x B2) + k1e\\n\\nC M k1e\\n\\n−E1\\nRT2 x A2 +\\n\\nC M k2e\\n\\n−E2\\nRT2 x B2\\n\\n−E2\\nRT2 x B2\\n\\n−E1\\nRT2 x A2 − k2e\\n(−ΔH2)\\nρC p\\n\\n(8.5a)\\n\\n(8.5b)\\n\\n(8.5c)\\n\\n(8.5d)\\n\\n(8.5e)\\n\\n(8.5f)\\n\\n(8.5g)\\n\\n(8.5h)\\n\\n(x Ar − x A3)\\n\\n(x Br − x B3)\\n\\n(x Ar ΔHvap A + x Br ΔHvap B + xCr ΔHvapC )\\n\\n(8.5i)\\n\\nwhere the state variables include the mass fractions of species A and B, i.e., x A1, x A2,\\nx A3 and x B1, x B2, x B3, as well as the temperatures of the three vessels, i.e., T1, T2,\\nT3. Speciﬁcally, the temperatures are measured continuously and securely, while the\\nspecies mass fractions are measured asynchronously. The upper-tier control system\\nreceives the asynchronous networked measurements through a digital network that\\nis vulnerable to cyber-attacks. The LMPC scheme is used as the upper-tier controller\\nto optimize closed-loop performance based on both continuous and asynchronous\\nstate measurements. It needs to be mentioned that the LMPC optimization problem\\nis executed only when the upper-tier controller receives a full-state measurement.\\nIn this example, each of the three vessels has an external heat input. To control the\\ntemperatures (in three vessels) at their desired set-points, we use three PI controllers\\nto manipulate the heat inputs (i.e., Q1, Q2, and Q3) to the three vessels. To speed up\\nthe closed-loop response, the manipulated input in LMPC is chosen to be the ﬂow\\n\\n\\x0c254\\n\\n8 A Two-Tier Control Architecture For Cybersecurity and Operational Safety\\n\\nrate of the feed stream to second CSTR, F20. Assuming that the relative volatility\\nof each species remains constant within the operating temperature range and the\\nreaction in the separator tank is negligible, the composition of the recycle stream is\\nas follows:\\n\\nx Ar =\\n\\nx Br =\\n\\nx Ar =\\n\\nαAx A3\\nαAx A3 + αB x B3 + αC xC3\\nαB x B3\\nαAx A3 + αB x B3 + αC xC3\\nαC xC3\\nαAx A3 + αB x B3 + αC xC3\\n\\n(8.6a)\\n\\n(8.6b)\\n\\n(8.6c)\\n\\nwhere the relative volatility of species i is represented by αi , i = A, B, C. As dis-\\ncussed in Sect. 8.3, the sensor measurements of six mass fraction (i.e., networked\\nmeasurements) are vulnerable to the cyber-attacks that can tamper the sensor read-\\nings based on the current true states values. The control objective of the two-tier\\ncyber-secure control system is to stabilize all 9 states at an unstable steady-state\\nwhile staying immune to potential cyber-attacks. Table 8.1 lists the values of process\\nparameter and of the steady-state used in this example.\\n\\nWe use deviation variables to present the input vector and the state vector as\\nthe deviation from their steady-state values, such that the origin of state-space\\nis the equilibrium point of the process. The following operating constraints are\\nimposed on the manipulated inputs (in deviation variable form): −4.04 m3/h ≤\\nΔF20 ≤ 3.96 m3/h, |ΔQ1| ≤ 5 × 107 kJ/h, |ΔQ2| ≤ 5 × 107 kJ/h, |ΔQ3| ≤\\n5 × 107 kJ/h.\\n\\nAs proportional–integral (PI) controllers are easy to implement and can be solved\\ninstantaneously, they are used to regulate the vessel temperatures in lower-tier con-\\ntroller. The formulation of PI controller is given below\\n\\nuci\\n\\n(t) = Kci\\n\\n(eci\\n\\n(t) + 1\\nτi\\n\\nt(cid:3)\\n\\n0\\n\\neci\\n\\n(τ )dτ ), eci\\n\\n(t) = y R E F\\n\\nci\\n\\n(t) − yci\\n\\n(t)\\n\\n(8.7a)\\n\\n(t) is the error between the set-points y R E F\\n\\nwhere τi and Kci , i = 1, 2, 3, are the integral time constant and proportional gain of\\neach PI controller, respectively. eci\\n(i.e.,\\nthe operating steady-state in this example), and the measured output values yci . In\\norder to guarantee stability for the closed-loop system under PI control, we linearize\\nthe nonlinear model of Eq. 8.1 around the operating steady-state we considered, and\\nevaluate the eigenvalues of this linearized model ˙x = Ax + Buc to determine the\\nvalue of Kci and τi . The values of Kci and τi used in this example are reported below\\n\\nci\\n\\n[Kc1 Kc2 Kc3\\n\\n]T = [−8 × 105, − 8 × 105, − 8 × 105]T\\n\\n[τ1 τ2 τ3]T = [5000, 5000, 5000]T .\\n\\n(8.8a)\\n\\n(8.8b)\\n\\n\\x0c8.4 Application to a Chemical Process Example\\n\\n255\\n\\nHeat of reaction for reactions 1 & 2\\n\\nDescription\\n\\nFeed ﬂow rate of CSTR 1\\nFlow rate of recycle stream\\nFlow rate of purge stream\\nFeed temperatures of CSTR 1 & 2\\nVolume of 3 vessels\\nHeat of vaporization for A, B, C\\n\\nTable 8.1 Descriptions and values of process parameters.\\nParameter/Value\\nF10 = 5.04 m3/h\\nFr = 50.4 m3/h\\nFp = 5.04 m3/h\\nT10 = 300 K, T20 = 300 K\\nV1 = 1.0 m3, V2 = 0.5 m3, V3 = 1.0 m3\\nΔHvap A = −3.53 × 104 kJ/kmol,\\nΔHvap B = −1.57 × 104 kJ/kmol,\\nΔHvapC = −4.068 × 104 kJ/kmol\\nΔH1 = −1.2 × 105 kJ/kmol,\\nΔH2 = −1.4 × 105 kJ/kmol\\nE1 = 5.0 × 104 kJ/kmol,\\nE2 = 6.0 × 104 kJ/kmol\\nk1 = 9.972 × 106 h−1,\\nk2 = 9.36 × 106 h−1\\nQ1s = 2.9 × 109 kJ/h,\\nQ2s = 1.9 × 109 kJ/h,\\nQ3s = 2.9 × 109 kJ/h, F20s = 5.04 m3/h\\nx A1s = 0.1762, x A2s = 0.1965, x A3s = 0.0651, Process state steady-state values\\nx B1s = 0.6731, x B2s = 0.6536, x B3s =\\n0.6703,\\nT1s = 480.32 K, T2s = 472.79 K, T3s =\\n474.89 K\\nC M = 2 kmol/m3\\nαA = 3.5, αB = 1.0, αC = 0.5\\nρ = 1000 kg/m3\\nR = 8.314 kJ/(kmol K)\\nC p = 4.2 kJ/(kg K)\\n\\nTotal molar concentration\\nRelative volatility of A, B, C\\nLiquid solution density\\nGas constant\\nHeat capacity\\n\\nInput steady-state values\\n\\nActivation energy of reactions 1 & 2\\n\\nPre-exponential constants of reactions 1 & 2\\n\\nThe Cohen-Coon tuning method is initially utilized to choose the PI controller param-\\neters. Then, the optimal PI parameters that lead to smooth and reasonable control\\nactions are determined via closed-loop simulations. It is shown that P-only control\\nguarantees closed-loop stability using the above parameters since the eigenvalues of\\nmodel ˙x = Ax + Buc all have negative real parts, which is shown below\\n\\nΛ = [ − 2.599, − 56.97, − 758.8, − 257.8 − 26.93i, − 257.8 + 26.93i,\\n\\n− 27.93 + 149.2i, − 27.93 − 149.2i, − 99.98 + 26.28i, − 99.98 − 26.28i].\\n\\n(8.9)\\nAdditionally, an integral term is added to eliminate the offset. To prevent integral\\nwindup, we implement an anti-windup strategy within PI controllers to temporarily\\neliminate the integral term after the system input hits the lower/upper bound. In\\n\\n\\x0c256\\n\\n8 A Two-Tier Control Architecture For Cybersecurity and Operational Safety\\n\\nthis simulation, the LMPC of Eq. 8.3 is used for the upper-tier control system with\\nthe objective function in the form of lt (x, ua) = x T Qcx + uT\\na Rcua, where Qc =\\ndiag([5000, 10, 0.001, 5000, 10, 0.001, 5000, 10, 0.001]) and Rc = 1.0 are\\nweighting matrices to penalize x and ua, respectively. The control Lyapunov function\\nis developed in a quadratic form, i.e., V (x) = x T P x, where P is a positive deﬁnite\\nmatrix:\\n\\nP = diag([3228.31, 220.79, 4.334 × 10−4, 2576.72, 233.80, 4.474 × 10−4,\\n\\n23675.92, 222.77, 4.434 × 10−4]).\\n\\n(8.10)\\nThe LMPC is simulated with the following settings: the prediction horizon is N = 10\\nand the sampling period is Δ = 0.02 hr . The OPTI-Toolbox in MATLAB is used\\nto solve the optimization problem of LMPC. The explicit Euler method is used to\\nnumerically simulate the system of Eq. 8.5 with a sufﬁciently small integration step\\nof hc = 10−4 h. A lower-bounded random Poisson process is used to choose the time\\nsequence at which the upper-tier controller receives the asynchronous measurements.\\nThe following sequence of asynchronous intervals is used for the execution of the\\nLMPC calculations in the simulation for every 1.5 h:\\n\\nΔa = [0.04, 0.08, 0.1, 0.06, 0.12, 0.08, 0.02].\\n\\nNote that the unequal interval between two consecutive asynchronous measurements\\n≥ Δ for all k ∈ [1, NT ]. After we design the Lyapunov function to\\nshould satisfy Δak\\nbe in the form of V (x) = x T P x, the stability region Ωρ, and the small neighborhood\\nΩρmin that the state will be ultimately bounded in are characterized as the level sets\\nof V with ρ = 120 and ρmin = 0.1, respectively. The safe operating region for all\\nthe states in this example is designed as follows:\\n\\nxu = [0.7237, 0.2269, 50, 0.7035, 0.2464, 50, 0.8349, 0.2297, 50]T\\nxl = [ − 0.1763, − 0.6731, − 50, − 0.1965,\\n\\n(8.11)\\n\\n− 0.6536, − 50, − 0.0651, − 0.6703, − 50]T\\n\\nwhere xu and xl denote the upper and lower bounds for the process states in deviation\\nvariable form, respectively. The operating envelope and the stability region are the\\ntwo key parameters in designing intelligent cyber-attacks.\\n\\nTo generate the training dataset, we run extensive closed-loop simulations for 3 h,\\nwithin which LMPC is executed 42 times and PI controllers are executed 150 times.\\nAs a result, each state trajectory contains NT = 43 state measurements, accounting\\nfor the initial condition and the state measurements received by LMPC that was\\nexecuted 42 times. The following initial condition is used in the closed-loop simu-\\nlations under PI-only and under two-tier control for comparison of the closed-loop\\nperformances:\\n\\nx0 = [0.0176, 0.067299, 48.032, 0.0197, 0.0654, 47.279, 0.006499, 0.067, 47.489]T .\\n\\n(8.12)\\n\\n\\x0c8.4 Application to a Chemical Process Example\\n\\n257\\n\\nWe compare the closed-loop performances under the two-tier PI/LMPC control\\nscheme and under the lower-tier PI controllers only by evaluating their normalized\\ncumulative mean squared errors (MSEs) along the state trajectories and settling times.\\nThe simulation results show that it takes 0.6 h for two-tier PI/LMPC, and 2.46 h\\nfor lower-tier PI controllers, to settle to the set-point. The normalized cumulative\\nMSEs are calculated to be 0.8014 and 4.1203 for two-tier PI/LMPC and lower-\\ntier PI, respectively. Therefore, it is demonstrated that the two-tier control system\\noutperforms the lower-tier PI control system as it eliminates process overshoots and\\noffset more effectively, and stabilizes the system within shorter time.\\n\\n8.4.1 Cyber-Attacks and Detector Training\\n\\nWe train the neural-network-based detector for detecting min-max cyber-attack with\\nand without sensor noise. When only one type of attack is considered, the neural\\nnetwork (NN) detector is developed to solve a binary classiﬁcation problem, where\\nthe resulting output has 2 classes—no attack and under attack. Additionally, as replay\\nattacks are challenging to detect (see discussion in Remark 7.9), we also incorporate\\nreplay attack in the neural network detector such that it is capable of identifying dif-\\nferent types of attack (i.e., the neural network output consists of three labeled classes:\\nattacked by replay attacks, by min-max attacks, and not attacked). Speciﬁcally, state\\nfeedback shows extreme oscillations with larger magnitudes in the ﬁrst ﬁve sampling\\nsteps. Therefore, we design replay attacks by collecting the aggressively oscilla-\\ntory measurements with attack duration L a = 5. Considering that cyber-attacks can\\noccurr at various times and with various durations during operation, other attacks\\ncan be randomly introduced at the sampling time between i0 ∈ [6, 42] with varying\\nattacking lengths. We collect equal number of samples for each output class from\\nextensive closed-loop simulations. In the case of attack identiﬁcation, each sample\\nconsists of a 1 × 43 array of V (x) values, while in the case of sensor isolation, each\\nsample will consist of x values with the dimension of 9 × 43 along the dynamic tra-\\njectory. To generate the input to the NN-based detector, we then collapse the 9 × 43\\nmatrix into a 1 × 387 array for each data sample. We develop the following NN-based\\ndetectors to detect cyber-attacks: (1) to detect a min-max cyber-attack in a nominal\\nsystem, a 2-class NN model is developed with nominal operation, where 12000 sam-\\nples are collected for each class label, and the training time is 24.05 seconds, (2) to\\ndetect a min-max cyber-attack in the presence of sensor noise, a 2-class NN model\\nis developed with noisy sensor measurements, where 1044 samples are collected for\\neach class label. The training time is 4.332 seconds, (3) to detect min-max and replay\\nattacks with noisy sensors, a 3-class NN model is developed, where 1044 samples are\\ncollected for each class label, and the training time is 5.265, and (4) To train the com-\\npromised sensor isolation detector, a 6-class NN model is developed under min-max\\nattack with noisy sensors, where 2800 samples are collected for each class label.\\nThe training time is 6211.52 seconds. To develop the NN-based detector that can\\ndistinguish between sensor noise and cyber-attacks, we add bounded white noise of\\n\\n\\x0c258\\n\\n8 A Two-Tier Control Architecture For Cybersecurity and Operational Safety\\n\\nGaussian distribution on sensors to simulate the sensor noise. Additionally, the sen-\\nsor noises are bounded as follows: |w1| ≤ 7.5 × 10−5, |w2| ≤ 5.5 × 10−5, |w3| ≤\\n0.032 K, |w4| ≤ 7.5 × 10−5, |w5| ≤ 5.5 × 10−5, |w6| ≤ 0.032 K, |w7| ≤ 3.5 ×\\n10−5, |w8| ≤ 5.5 × 10−5, |w9| ≤ 0.032 K. These white Gaussian noises have stan-\\ndard deviations σ1 = σ4 = 0.0002, σ2 = σ5 = σ8 = 0.001, σ3 = σ6 = σ9 = 0.1 K ,\\nand σ7 = 0.0001, and a mean of μ = 0. The MATLAB Machine Learning and Deep\\nLearning Toolboxes are used to develop the two-layer feedforward neural networks\\n(FNNs) with 12 and 10 neurons, respectively, in each hidden layer. The activation\\n− 1 is used in both hidden layers. The acti-\\nfunction tansig, i.e., g1,2(z) = 2\\nvation function so f tmax, i.e., g3(z j ) = ez j(cid:4)\\n, where H represents the number of\\nclass labels, is used in the output layer to provide a predicted probability of the class\\nlabels.\\n\\n1+e−2z\\n\\nH\\ni=1 ezi\\n\\nThe training and testing accuracy are 99.6% and 92.2%, respectively, for the NN\\ndetector trained with nominal conditions, and those of the NN detector trained with\\nsensor noise are 99.9% and 100%, respectively. The reason for the NN algorithm\\ntrained with noisy sensors achieving a higher accuracy than the NN model trained\\nusing the nominal model is that the NN detector is rendered more robust by introduc-\\ning more variance (i.e., the contributions of sensor noise) into the training dataset.\\nMoreover, the NN detector trained with two different types of cyber-attacks and\\naccounting for sensor noise has accuracy of 98.2% and 91.4% for training and test-\\ning datasets, respectively, and the NN-based sensor isolation detector has an accuracy\\nof 99.6% and 99.0% on training and testing datasets, respectively.\\n\\n8.4.2 Cyber-Attack Detection Results\\n\\nWe carry out the closed-loop simulation for the system under an detector-integrated\\ntwo-tier control system with initial conditions x0 = [0, 0, 0, 0, 0, 0, 0, 0, 0]T .\\nWe introduce the cyber-attacks after the control system stabilizes the process at the\\nsteady-state. Since the NN detectors in this simulation example are developed with\\na ﬁxed input dimension of 43 (i.e., 42 sampling steps), we activate the detector at\\nthe k = 42th sampling time in the asynchronous time sequence to ensure that there\\nis sufﬁcient input data for executing the NN prediction. The NN-based detector\\ncomputes an output showing the status of system cybersecurity (i.e., attacked or\\nnot attacked) based on the previous 42 state measurements. As the attack detector\\nand the upper-tier LMPC are executed in real time, this ﬁxed-length window of\\ntime-series data also rolls forward in time. In this example, we designed a three-\\nsampling-period alarm veriﬁcation window for the upper-tier LMPC. The presence\\nof a cyber-attack is conﬁrmed if two positive detections are observed within the\\nalarm veriﬁcation window (i.e., within three consecutive sampling periods). Once an\\nattack is conﬁrmed, it triggers the detection alarm and at the same time, deactivates the\\nLMPC. Furthermore, to examine whether not-attacked signals will be misclassiﬁed\\nas attack by detector, we introduce attacks a few sampling periods after the activation\\n\\n\\x0c8.4 Application to a Chemical Process Example\\n\\n259\\n\\nof detector at t = 3.0 h. In this way, the ﬁrst few outputs are from nominal process for\\nthe detector. Speciﬁcally, in this example, we introduce cyber-attacks at time instant\\ni0 = 45 corresponding to the simulation time t = 3.22 h. The attack will last for\\nL a = 40 sampling periods. The sensor is under attack till the end of the simulation\\nperiod (i.e., t = 6 h). The sensor measurements and the true state values of state 1 for\\nthe closed-loop system of Eq. 8.5 under surge, geometric, replay, and min-max cyber-\\nattacks on sensor measurements of mass fraction x A1 with sensor noise are shown\\nin Fig. 8.3, from which the pattern and impact of different types of cyber-attacks\\nare illustrated. Speciﬁcally, it is shown that the true state settles at an offset under\\nmin-max attack; the true state shows aggressive oscillations under replay attack; the\\nprocess state is driven away from the steady-state and settles at an offset when the\\ngeometric attack hits the boundary of Ωρ; the true state shows an initial jump similar\\nto that under min-max attack, and is ultimately driven closer to the set-point with\\na smaller offset than min-max attack because the surge cyber-attack reduce attack\\nseverity to avoid being detected by conventional detection methods. Although we\\nonly show one of the states in Fig. 8.3, we observe that the deviating patterns of\\nall 9 states are similar under the cyber-attacks. The simulation results of all 9 states\\nare not shown here due to the space limitation. After the sensor measurements are\\ntampered by cyber-attacks and received by the upper-tier controller, the LMPC is\\nunable to compute correct control actions that drive the true state back to the steady-\\nstate. However, since three PI controllers (in lower-tier control system) that utilize\\nsecure sensor measurements play a dominant role in the stabilization of the system,\\nit is shown in Fig. 8.3 that the true states do not diverge and can be bounded in Ωρ.\\nRegardless, when no data-based detectors are utilized, the attack successfully disrupt\\nthe closed-loop performance by driving the state away from its steady-state.\\n\\nSince we use an alarm veriﬁcation window to reduce false alarm rates by requiring\\ntwo or three positive detections in three detection instances, time delays are observed\\nwhen we implement NN detectors online. The time delay in this simulation study\\nis deﬁned as the number of sampling periods between the time of the attack being\\nadded, and the time of the attack being conﬁrmed. Although the ﬁrst two detectors\\nare trained for the system under min-max attack only with noise and with nomi-\\nnal operations, respectively, all four types of cyber-attacks (i.e., min-max, replay,\\ngeometric, and surge attacks) are identiﬁed by the neural-network-based detector\\ntrained with nominal model. Speciﬁcally, the min-max, surge, and replay attacks are\\ndetected by the NN detector with a time delay of 1 sampling period, at which time\\nthe control system receives the second consecutive positive detection to conﬁrm the\\noccurrence of cyber-attaks in the alarm veriﬁcation window. The geometric attack is\\ndetected with a time delay of 2 sampling periods due to the small bias implemented\\nat the early stage, which is challenging for the NN detector to classify it as an attack.\\nAs time progresses, the geometric cyber-attack exponentially increases towards an\\nattacking value, at which the detector recognizes this abnormal behavior that is on\\npar with the other three attacks. The potential time delay for the case of geometric\\nattacks will vary according to different geometric parameters, i.e., α and β in Eq. 7.8,\\nused by attackers. Then, we test the NN detector whose training process accounts\\nfor sensor noise. It is demonstrated that this NN detector can successfully detect\\n\\n\\x0c260\\n\\n8 A Two-Tier Control Architecture For Cybersecurity and Operational Safety\\n\\nFig. 8.3 Measured and true state values (in deviation variable form) of x A1 when a min-max, b\\nreplay, c geometric, and d surge cyber-attacks are added on the sensor measurement of concentration\\nx A1 at 3.22 h, and no detection or mitigation mechanisms are used\\n\\nsurge, min-max, and geometric attacks, with a longer time delay for detecting the\\ngeometric attack (i.e., it takes 7 sampling periods). However, replay attacks cannot\\nbe detected by this NN detector because of the oscillatory pattern of replay signals.\\nIt is observed that replay attacks are oscillating over time, which is signiﬁcantly dif-\\nferent from the other 3 attacks that share similar attacking pattern (i.e., the attacked\\nmeasurement remains at the attack target for at least 2 sampling periods). As replay\\nattacks show oscillatory behavior that is similar to the system with sensor noise,\\nthe NN detector trained with sensor noise is unable to distinguish between sensor\\nnoise and replay attacks. Therefore, we train a third NN detector to account for both\\nmin-max and replay cyber-attacks. In this case, the min-max and replay attacks are\\ncorrectly classiﬁed, and the detection is conﬁrmed with a 1-sampling-period time\\ndelay.\\n\\nSubsequently, we test the detection algorithms on cyber-attacks targeting multi-\\nple sensors at once. An extreme case where all 9 sensors are attacked by min-max\\ncyber-attack and no online detectors are implemented is ﬁrst simulated to demon-\\n\\n\\x0c8.4 Application to a Chemical Process Example\\n\\n261\\n\\nFig. 8.4 Proﬁles of true process states when all 9 state measurement sensors are attacked at 3.22 h\\nby min-max cyber-attacks, and no detection or reconﬁguration of the two-tier control architecture\\nare implemented\\n\\nstrate the effect of cyber-attacks that target all sensor measurements; this scenario\\nhelps demonstrate the motivation for the two-tier control architecture. Fig. 8.4 shows\\nthe true state trajectories, where a min-max attack is added at 3.22 h and lasts until\\nthe end of simulation. As the continuous measurements of temperature are attacked,\\nsystem stability properties are no longer achieved by the lower-tier controllers. As a\\nresult, the true state trajectory leaves the stability region without the implementation\\nof cyber-attack detectors. Additionally, the temperatures and the mass fractions of\\nspecies A in CSTRs and separator violate the safety limits (in deviation variable\\nform), and exceed their operating boundaries as well. Under this worst-case scenario\\nthat the attack also jeopardizes continuous temperature measurements, the only way\\nto ensure cybersecurity is to abandon the corrupted sensors, and use measured tem-\\nperature signals from a set of redundant sensors with secure readings (if there are\\nany) in the lower-tier controllers. Moreover, safety systems such as safety relief valve\\n\\n\\x0c262\\n\\n8 A Two-Tier Control Architecture For Cybersecurity and Operational Safety\\n\\nFig. 8.5 Proﬁles of true process states when the six sensors of mass fraction are attacked at 3.22 h\\nby min-max cyber-attacks; the attacks are detected at 3.28 h, and the process is re-stabilized at the\\nsteady-state by turning off upper-tier LMPC and using lower-tier PIs\\n\\nand cold water injection can be adopted to discharge material from the reactor and\\ncool down reaction mixture’s temperature when the reactor temperature exceeds its\\nsafety limit (see, also, the case study of MIC reaction in a CSTR in Sect. 5.2.1.1\\nfor the implementation of the aforementioned safety systems). Through this extreme\\nscenario, we demonstrate the destabilizing impacts of cyber-attacks that target nine\\nsensor measurements. It also implies that to maintain cybersecurity of the two-tier\\ncontrol system, reliable and secure feedback measurements should be available for\\nlower-tier control system all the time.\\n\\nTo efﬁciently detect the above cyber-attack that targets all sensor measurements,\\nwe implement the NN detector trained with two cyber-attack types and noisy mea-\\nsurements. It is shown that the min-max attack added at 3.22 h can be detected within\\n0.06 h (i.e., at t = 3.28 h) with the use of an alarm veriﬁcation window. After that,\\nwe turn off the upper-tier LMPC, replace the corrupted sensors with secure back-up\\nsensors, and then control the system using the lower-tier PI controllers. In this way,\\nstability properties hold for the closed-loop system under lower-tier control in the\\nsense that the system is re-stabilized at the steady-state.\\n\\n\\x0c8.4 Application to a Chemical Process Example\\n\\n263\\n\\nFig. 8.6 Proﬁles of true process states when the six sensors of mass fraction are attacked at 3.22 h\\nby replay cyber-attacks; the attacks are detected at 3.28 h, and the process is re-stabilized at the\\nsteady-state by turning off upper-tier LMPC and using lower-tier PIs\\n\\nThen, we consider a more practical case where the measurements of temperature\\nreceived by lower-tier PIs and upper-tier LMPC remain secure, and the cyber-attacks\\nonly target the networked mass fraction measurements received by the upper-tier\\nLMPC. Therefore, once the detection of an attack is conﬁrmed, to prevent the erro-\\nneous control actions by LMPC from acting as a unnecessary disturbance to the\\noverall system, we will turn off the upper-tier LMPC (i.e., ua = 0) for the remaining\\ntime of simulation. Similarly, we use the lower-tier PI controllers only with secure\\ncontinuous temperature measurements to stabilize the system at the steady-state.\\nThe simulation results illustrate the effectiveness of the mitigation method, from\\nwhich it is seen that the true process states ultimately converge to the steady-states\\nunder lower-tier PIs despite the gradual deviations or the sudden jumps as a result of\\ncyber-attacks. Figures 8.5, 8.6, 8.7, and 8.8 show the closed-loop state trajectories\\n\\n\\x0c264\\n\\n8 A Two-Tier Control Architecture For Cybersecurity and Operational Safety\\n\\nFig. 8.7 Proﬁles of true process states when the six sensors of mass fraction are attacked at 3.22 h\\nby geometric cyber-attacks; the attacks are detected at 3.28 h, and the process is re-stabilized at the\\nsteady-state by turning off upper-tier LMPC and using lower-tier PIs\\n\\nunder min-max, replay, geometric, and surge attacks, respectively. Speciﬁcally, for\\nthe attacks that occur at t = 3.22 h, the detector successfully identiﬁes the occur-\\nrence of cyber-attacks at 3.28 h. Then, we turn off the LMPC and use the lower-tier\\nPI controllers to re-stabilize the process state at the steady-state. Despite the minor\\ndegradation in closed-loop performance due to the use of lower-tier controllers only,\\nclosed-loop stability is successfully maintained by the reconﬁgured control system in\\nthe presence of intelligent cyber-attacks. Additionally, as cyber-attacks are detected\\nin time, the closed-loop state does not leave the stability region, and thus, the safety\\nsystem is not activated in this case.\\n\\n\\x0c8.5 Conclusions\\n\\n265\\n\\nFig. 8.8 Proﬁles of true process states when the six sensors of mass fraction are attacked at 3.22 h\\nby surge cyber-attacks; the attacks are detected at 3.28 h, and the process is re-stabilized at the\\nsteady-state by turning off upper-tier LMPC and using lower-tier PIs\\n\\n8.5 Conclusions\\n\\nIn this chapter, we presented a cyber-secure control architecture for nonlinear chem-\\nical processes that incorporates an upper-tier MPC and lower-tier explicit feedback\\ncontrollers. The lower-tier controllers contributed to the stabilization of nonlinear\\nprocesses, while the upper-tier LMPC used asynchronous networked sensor mea-\\nsurements that are susceptible to sensor cyber-attacks to improve closed-loop per-\\nformance. An integrated framework for safety and cyber-secure control systems was\\nalso discussed to ensure safe operation upon successful detection of cyber-attacks.\\nA neural-network-based detector was designed to efﬁciently identify the occurrence\\nof cyber-attacks and integrated with the two-tier control architecture to reconﬁgure\\nthe control system to stabilize the system at the steady-state. Neural-network-based\\ndetection algorithms were developed and implemented online for detecting common\\ntypes of cyber-attacks on single or multiple sensors. Speciﬁcally, we trained four\\nFNN models and implemented them in the closed-loop systems under nominal oper-\\nating conditions and operations with sensor noise. All of them were demonstrated\\n\\n\\x0c266\\n\\n8 A Two-Tier Control Architecture For Cybersecurity and Operational Safety\\n\\nto achieve a detection accuracy no less than 91%. Finally, we applied the proposed\\ndetector-integrated two-tier control system to a reactor-reactor-separator process, and\\ndemonstrated improved cybersecurity and robustness under the machine-learning-\\nbased detection methods and the two-tier control architecture.\\n\\n\\x0c', \"Pre-publication draft. Published version can be found at http://www.igi-global.com/journal/international\\x02journal-secure-software-engineering/1159 .\\nADVANCING CYBER RESILIENCE ANALYSIS WITH PERFORMANCE\\x02BASED METRICS FROM INFRASTRUCTURE ASSESSMENTS\\nFor submission to\\nInternational Journal of Secure Software Engineering, \\nSpecial Edition on Cybersecurity Scientific Validation\\nJuly 13, 2012\\nEric D. Vugrin (corresponding author)\\nSandia National Laboratories\\nP.O. Box 5800\\nMail Stop 1138\\nAlbuquerque, NM 87185-1138\\nPhone: (505)284-8494\\nFax: (505) 284-3850\\nEmail: edvugri@sandia.gov\\nJennifer Turgeon\\nSandia National Laboratories\\nP.O. Box 5800\\nMail Stop 1138\\nAlbuquerque, NM 87185-1138\\nPhone: (505) 284-3630\\nFax: (505) 284-3850\\nEmail: jturgeo@sandia.gov\\n3\\nABSTRACT\\nCyber resilience is becoming increasingly recognized as a critical component of comprehensive \\ncybersecurity practices. Current cyber resilience assessment approaches are primarily qualitative \\nmethods, making validation of their resilience analyses and enhancement recommendations \\ndifficult, if not impossible. The evolution of infrastructure resilience assessment methods has \\nparalleled that of their cyber counterparts. However, the development of performance-based \\nassessment methods has shown promise for overcoming the validation challenge. for \\ninfrastructure systems. This paper describes a hybrid infrastructure resilience assessment \\napproach that combines both qualitative analysis techniques with performance-based metrics. \\nThe qualitative component enables identification of system features that limit resilience, and the \\nquantitative metrics can be used to evaluate and confirm the effectiveness of proposed mitigation \\noptions. The authors propose adaptation of this methodology for cyber resilience analysis. A case \\nstudy is presented to demonstrate how the approach could be applied to a hypothetical system. \\nSubject headings: resilience, cybersecurity, performance-based metrics, quantitative, validation, \\nassessment\\n1. INTRODUCTION AND BACKGROUND \\nCybersecurity is generally acknowledged as a critical priority within the national, homeland, and \\nbusiness security communities. This sentiment has been echoed at the highest levels of the U.S. \\ngovernment, with President Obama (2009) stating that “cyber threat is one of the most serious \\neconomic and national security challenges we face as a nation.” \\nFortunately, the concept of cybersecurity is not new to the academic and research communities. \\nCyber security standards and guidelines have been developed (e.g., see Smart Grid \\nInteroperability Panel, 2010; IEEE, 2000, 2010a,b; NERC, 2002; ISO/IEC, 2000). These \\nstandards typically list best practices and provide guidance for securing various systems. \\nExisting standards generally focus on mitigating system vulnerabilities to prevent a successful \\nattack from occurring. Some guidelines, such as Guidelines for Smart Grid Cyber Security: \\nVolumes 1-3 (Smart Grid Interoperability Panel, 2010), recommend prioritizing vulnerability \\nmitigations by performing a risk assessment to determine which threats are of most significant \\nconcern. Within current standards, the primary focus is on preventing a successful attack. The \\ncurrent cybersecurity philosophy, as represented in these standards, centers on the detection and \\nprevention of an attack.\\nHowever, over the past decade, a small but emerging movement within the cybersecurity\\ncommunity has voiced the opinion that cybersecurity strategies must expand beyond the \\nprotection-centric focus to incorporate cyber resilience principles. Cyber threats are constantly \\nevolving and increasing as the number of cyber assets and system vulnerabilities continues to \\ngrow. As Goldman (2010) states, “The notion that we can achieve 100% protection is not only \\nunrealistic but also results in a false sense of security that puts our missions and businesses at \\nserious risk.” Franklin D. Kramer (2011), Vice Chair of the Atlantic Council and former \\nAssistant Defense Secretary for International Affairs, affirms that statement and adds that “we \\ncannot assume protection and prevention will be adequate. And so we need resilience. ”\\n4\\nSimilarly, the private sector has recognized the need for resilience, as evidenced by the launch of \\nthe World Economic Forum’s Cyber Resilience Initiative. This initiative is aimed at creating \\npartnerships within the public and private sectors to foster cyber resilience (World Economic \\nForum, 2012). Similar opinions are becoming more common with events such as the STUXNET \\nvirus, the Chinese attack on Google, and suspected attacks on power grids. Hence, many have \\ncalled for cyber resilience to become a primary system objective in cybersecurity activities.\\nCyber resilience can be described as a cyber system’s ability to function properly and securely \\ndespite disruptions to that system. Disruptions can be cyber or physical; they can also be \\nintentional, accidental, or random. Over the past decade, organizations such as the Carnegie \\nMellon University’s Software Engineering Institute and MITRE Corporation led efforts to \\ndevelop cyber resilience management and design practices. These ground-breaking efforts are\\nsignificant advances toward the development of resilient cyber systems. However, they have the \\nsame limitation that cybersecurity standards have: that is, they are descriptive methods that \\nrecommend approaches for increasing resilience, but the emerging cyber resilience standards\\nhave yet to be validated.\\nIn parallel to cyber resilience-related efforts, the infrastructure protection community is\\ndeveloping infrastructure resilience assessment methods. Similarities exist between the \\nevolutions of cyber and infrastructure resilience assessment methods. However, a class of \\ninfrastructure resilience assessment methods, termed performance-based assessment methods, \\novercame the validation limitation by evaluating system outputs rather than system structure and \\ndesign. By measuring the performance of infrastructure systems rather than system structure and \\nattributes, performance-based assessment methods address the central resilience issue: can the \\ninfrastructure system continue to deliver critical services in the presence of disruptive events?\\nThis paper presents a particular performance-based infrastructure resilience assessment \\nframework that shows promise for extension to cyber resilience. In the following section, the \\npaper reviews recent resilience assessment methods from the cyber and infrastructure \\ncommunities and the parallel evolution of their respective assessment methods. The paper then \\nintroduces a performance-based infrastructure resilience assessment framework developed at \\nSandia National Laboratories. An example application is included to demonstrate how the \\nframework could be applied to cyber systems. The paper concludes with recommendations for \\nfurther development of the framework and its customization to cyber systems. \\n2. RESILIENCE ASSESSMENT METHODS \\nResilience is not a new concept. Holling (1973) is generally credited with giving the first \\nsystems-based definition of resilience almost 40 years ago. Since that time, the concept has been \\nexplored in a number of different fields, with significant advances being made over the past \\ndecade for both cyber and infrastructure security. This section describes the latest cyber \\nresilience assessment methods and their parallel evolution in the field of infrastructure security.\\nResilience assessment methods for cyber systems can be separated into two categories. Cyber \\nresilience design methods consider primarily how system architecture and activities enhance the \\nresilience of the system to cyber threats. The second category, operational resilience assessment \\nmethods, takes a broader look at how business operations, in addition to system design, can \\n5\\nenhance resilience of the overall system that the cyber system supports. Operational resilience \\nmethods consider physical threats and accidents, in addition to cyber threats. For the purposes of \\nthis paper, the authors include both categories in a discussion of cyber resilience assessment \\nmethods because of the integral role that cyber systems have within the methods.\\nCyber Resilience Engineering Framework\\nGoldman (2010) and Bodeau and Graubart (2011) have described the Cyber Resiliency \\nEngineering Framework (CREF) developed as part of the Resilient Architecture for Mission \\nAssurance and Business Objectives (RAMBO) effort at the MITRE Corporation. The CREF is \\nintended to describe how to engineer cyber-resilient architectures. The ability to anticipate, \\nwithstand, recover, and evolve are listed as high-level goals. These goals are achieved by \\nmeeting eight cyber-resilience objectives: understand, prepare, prevent, continue, constrain, \\nreconstitute, transform, and re-architect. Objectives can be achieved by performing resilience \\npractices, such as adaptive response to an attack, deception, realignment, etc. Subsequent \\niterations have expanded the framework. Bodeau et al. (2012) have developed almost 300 \\nmetrics for consideration in resilience analyses. Hassell (2012) provides additional metric \\nconsiderations.\\nDespite the advancements of the CREF toward quantitative resilience analysis, it still does not \\nprovide a practical, tested approach for evaluating and validating the resilience of cyber systems.\\nFirst, with hundreds of metrics to choose from, the sheer volume is daunting; selection of the \\nappropriate set of metrics could be difficult for even a trained analyst. Second, many of the \\nproposed metrics focus on measuring an aspect of the system architecture. However, Bodeau et \\nal. (2012) do not indicate how that measurement ultimately affects the system’s ability to \\n“maintain an acceptable level of service,” i.e., cyber resilience as defined within the framework. \\nThird, the authors have been unable to find any documentation of how these metrics have been \\napplied in a quantitative resilience analysis. It is not clear whether the metrics should be \\naggregated into a single resilience metric or if they need to be considered independently. Bodeau \\net al. (2012) do not provide mathematical equations or frameworks that indicate how the metrics \\nshould ultimately be combined to provide a quantification of resilience. Hence, it is uncertain \\nhow simply or practically the metrics can be applied to actual cyber systems and attack \\nscenarios. These framework limitations make it very difficult to validate the expected benefits of \\nusing the CREF design principles.\\nIn its initial inception, the framework’s primary benefit is that it provides a means for structured \\ndiscussions on cyber resilience, according to Bodeau and Graubart (2011). Additional work on \\nmetric development is required before validation can be considered an additional benefit. \\nOperational Resilience Assessment Methods \\nThe Operationally Critical Threat, Asset, and Vulnerability Evaluation (OCTAVE) approach, a\\nsecurity self-assessment methodology that addresses information risk, was developed by the\\nCarnegie Mellon Software Engineering Institute (Alberts and Dorofee, 2001). The approach \\nattempts to balance the contributions that technology, individuals, and organizational structures \\nmake toward resilience of the overall organization. \\n6\\nOCTAVE consists of three high-level phases:\\n1. Build asset-based threat profiles. In the first phase, the organization identifies critical \\ninformation assets and procedures currently in place to protect those assets.\\n2. Identify infrastructure vulnerabilities. After identification of critical assets, the \\nanalysis team evaluates technology vulnerabilities that can result in negative impacts on \\ncritical assets.\\n3. Develop security strategy and plans. The final phase consists of evaluating the risks to \\nthe critical assets and determining how the organization will respond to and mitigate \\nthose risks.\\nDetailed guides were developed to assist the implementation of the methodology. These guides \\ndescribe individuals who should be represented on the analysis team; processes associated with \\neach phase; meeting schedules, durations, and objectives; materials (meeting slides and \\nworkbooks); and other information necessary for performing an OCTAVE evaluation. The \\nOCTAVE process is highly reliant upon the use of organizational subject matter experts as \\nmembers of the assessment team. In its formal application, it is a very thorough and time\\x02consuming process.\\nAlberts et al. published the original OCTAVE approach in 1999, and the OCTAVE criteria were \\nlater released in 2001 (Alberts and Dorofee, 2001). Given the level of rigor, time, and \\ninformation required for implementation, OCTAVE was originally developed for large \\ncompanies (more than 300 employees). OCTAVE-S was subsequently developed for smaller \\norganizations, and OCTAVE-Allegro was created to provide a stream-lined assessment that \\nrequired less time, expertise, and subject matter representatives (Woody et al., 2006). All three \\nversions are highly qualitative processes, though OCTAVE-Allegro contains a semi-quantitative \\ncomponent for considering relative risks. Ultimately, each approach provides organizations with \\na risk-based road map to addressing information security gaps. \\nThe CERT Resilience Management Model (CERT-RMM), Version 1.0, evolved from OCTAVE \\nresearch and was published in 2010. This CERT-RMM is a maturity model for managing \\noperational resilience, comprising the disciplines of security management, business continuity \\nmanagement, and aspects of information technology operations management. Model outputs \\nidentify gaps in processes that could be improved for better operational resilience. CERT-RMM \\nallows for a capability rating to be earned on implementation of each process area implemented \\nwithin an organization. These capability ratings provide a method for monitoring process \\nimprovements over time.\\nCaralli et al. (2010) define operational resilience as an “organization’s ability to adapt to risk that \\naffects its core operational capacities.” At a high level, CERT-RMM uses a holistic approach to \\nassess operational resilience. CERT-RMM includes four different categories of organizational \\nprocess areas. The engineering category includes six process areas such as controls management \\nand service continuity; the enterprise management category has seven process areas such as \\ncommunications and human resource management; the operations management category \\n7\\nincludes access management, knowledge and information management, and 7 other process \\nareas; and the process management category includes monitoring, measurement analysis, and \\ntwo other related categories. For each process area, the CERT-RMM includes (White, 2012):\\n1) Specific and generic goals;\\n2) Specific and generic practices that describe how to achieve those goals; and\\n3) Sub-practices that describe how to implement the practices.\\nUsing this structure, CERT-RMM provides a semi-quantitative method for assessing the \\nimplementation of the process areas. Implementation of each process area can be assessed a \\nLevel of 0, 1, 2, or 3 that corresponds to the degree with which the process in institutionalized. \\nLevel 0 indicates the lowest degree of institutionalization. Increasing levels indicate greater \\ndegrees on institutionalization. Level 3 is the best achievable level since greater \\ninstitutionalization is an indicator of repeatable and predictable processes (Caralli et al., 2010).\\nIn an attempt to measure and analyze operational resilience, Allen and Davis (2010) established \\nsix high-level objectives for managing operational resilience and a template for developing \\nmeasures that align with the six objectives. The template is based upon a core set of \\nmeasurement concepts established to provide a clear understanding of the theory behind the \\nmeasurement template. Allen and Curtis (2011) expanded upon this research by developing a list \\nof ten strategic measures derived from Allen and Davis’s objectives. Allen and Curtis also added \\nmeasures for each of the 26 CERT-RMM process areas. These measures allow an organization to \\nset priorities for its operational resilience and to establish baselines and measure improvements \\nfor those priorities. Strategic measures, used collectively, can provide a view of an organization’s \\noperational resilience. \\nThe measures established by Allen and Curtis are intended to quantify the current state of an \\norganization’s resilience as well as to identify resilience improvements resulting from new or \\nimproved processes. Interpretation of these measures is dependent upon the specific environment \\nfor which they were developed. These measures are not intended to compare resilience of one \\norganization’s activities to another, although one might implicitly make this comparison. \\nAdditionally, interpretation of these measures requires domain expertise in each of the CERT\\x02RMM process areas and generic practices.\\nTwo assessment methods were developed to accompany the CERT-RMM model. The Resilient \\nEnterprise Management Team (2011) developed the CERT-RMM Capability Appraisal Method \\n(CAM), which is based upon the Standard Capability Maturity Model Integration (CMMI) \\nAppraisal Method for Process Improvement (SCAMPI). A CAM appraisal provides capability \\nlevel ratings for organizations implementing CERT-RMM. The Compass tool was developed to \\nprovide companies with a quick assessment of their CERT-RMM implementation. Both of these \\nmethods require qualitative review of objective evidence to derive characterizations of model \\npractice implementation. \\nThe U.S. Department of Homeland Security (DHS) also developed a Cyber Resilience Review \\n(CRR) method that is derived from CERT-RMM principles. This method was developed through \\nthe Cyber Security Evaluation Program within DHS’s National Cyber Security Division. CRRs \\nfocus on operational resilience and are included as part of DHS recommendations for \\n8\\ncybersecurity activities to protect critical infrastructure and key resources (U.S. Department of \\nHomeland Security, 2012a). The CRR is an evaluation of an organization’s overall \\ncybersecurity management policies, practices, and procedures that provides repeatable results\\n(U.S. Department of Homeland Security, 2012b). Its output is a report that highlights strengths \\nand weaknesses within 10 domains similar to CERT-RMM process areas and across four asset \\ntypes: people, information, technology, and facilities.\\nThese primarily qualitative operational resilience assessment methods, especially OCTAVE and \\nCERT-RMM, have undergone extensive research and have been tested across industry. They \\nrequire detailed, contextual reviews of organizational assets by both business and technical \\nsubject matter experts. The outputs identify gaps in processes that could be improved to better \\norganizational resilience. However, these assessment methods do not provide an overall measure \\nfor operational resilience across a system, nor do they provide a measure for determining system \\nimpact and recovery efforts when crises do occur.\\nFrom a process implementation perspective, OCTAVE, CERT-RMM, and other operational \\nresilience assessment methods work well. They are highly structured and come with an \\nincredible amount of supporting materials that describe how to implement them. Additionally, \\nthe methods provide explicit information on how resilience could be improved. The primary \\nimplementation drawbacks are the effort and time required to apply the processes, although the \\nevolution of OCTAVE-Allegro, OCTAVE-S, Compass, and CAM Class B and C appraisals do \\nlessen that burden somewhat.\\nFrom a risk validation perspective, these methods are less than ideal. The methods rely primarily \\non qualitative and semi-quantitative assessments from subject matter experts. This reliance can \\nmake it difficult to defend and validate risk and resilience assessments. Limited quantification \\ncan also hinder attempts to prioritize improvement efforts. Funding to address all security gaps \\nrarely exists, so the ability to prioritize use of scarce resources is an important consideration. The \\nqualitative nature of these assessment methods makes prioritization a highly subjective endeavor. \\nFinally, because these methods do not provide a measure of how organizational performance will \\nimprove if certain efforts are undertaken, it is difficult to validate the effect the investments will \\nhave on the overall resilience of the organization’s operations. The addition of a measure to \\nsupport improvement prioritization could enhance the results provided from these assessment \\nmethods. \\nInfrastructure Resilience Assessment Methods\\nExamination of operational and cyber resilience assessment development over the past decade \\nshows a steady trend toward increasingly quantitative analysis. The OCTAVE and CREF\\nframeworks both started as primarily qualitative methods. OCTAVE-Allegro was subsequently \\ndeveloped and includes a semi-quantitative methodology that assigned numerical values to \\nqualitative risk features of the systems under study. The CERT-RMM followed and includes \\nalmost 60 pages of suggested metrics and measures. Bodeau et al. (2012) describe a similar \\nadvance by the CREF framework toward a more quantitative approach to resilience evaluation. \\n9\\nOver this same time period, infrastructure resilience assessment methods followed a similar \\ntrend. For example, the Multidisciplinary Center for Earthquake Engineering and Research’s \\n(MCEER’s) initial resilience methodology was a primarily qualitative approach. MCEER’s \\nTOSE framework described four resilience domains, Technical, Organizational, Social, and \\nEconomic (TOSE), and the four fundamental properties of resilience—robustness, redundancy, \\nresourcefulness, and rapidity—that contributed to resilience across these domains (Bruneau et \\nal., 2003). \\nA number of semi-quantitative indices have followed. Cutter et al. (2010) use 36 socioeconomic \\nvariables to calculate baseline resilience indicators for communities to evaluate the resilience of \\ncommunities to natural disasters. Pettit et al. (2010) used the Supply Chain Resilience \\nAssessment & Management (SCRAM) tool to assess supply chain resilience. The SCRAM tool \\nrelies on gathering information using a 152-question survey about a supply chain’s \\nvulnerabilities and capabilities. Fisher and Norman (2010) developed a resilience index for the \\nEnhanced Critical Infrastructure Protection Program. DHS and its protective security advisors \\n(PSAs) collect more than 1500 pieces of data for an infrastructure asset using the Infrastructure \\nSurvey Tool. These data are used to provide protective measure, vulnerability, and resilience \\nscores.\\nAlthough the infrastructure protection and cyber communities both have qualitative and semi\\x02quantitative resilience assessment methods, a third type of assessment approach, not found in the \\ncyber community, was developed for infrastructure resilience assessment. This set of approaches, \\ntermed performance-based resilience assessment methodologies, is usually quantitative and \\nestimates resilience by measuring the performance of a system in a particular scenario (i.e., a \\nparticular hazard or threat condition). Performance of a system is measured by metrics that vary \\nacross methodologies and applications, but the underlying logic of these methods is similar. \\nMost metrics can be distilled to a single metric that describes simply the resilience of a system, \\nand most metrics are used to compare the resilience of different systems. Rose (2007), Chang &\\nShinozuka (2004), and ASME-ITI (2010) have all proposed metrics for quantitatively measuring \\nthe resilience of a particular system. MCEER has further expanded the TOSE framework to \\ninclude a resilience loss calculation.\\nIn contrast to qualitative and quantitative methodologies, the performance-based methods \\nexamine direct observations of the performance of a system (or a simulated system) after a \\ndisruption. While qualitative assessment methodologies can be considered “a more holistic \\napproach” (ASME ITI, 2010) to assessing resilience, performance assessment methodologies \\noffer a more precise, validated approach. The qualitative assessment methodologies can be \\nthought of as predictions of how a system may exhibit resilience or explanations of why a system \\nexhibited resilience after the fact, while the performance-based methods provide validation of \\nresilience—a measure of how much resilience a system actually exhibited. This capacity for \\nvalidation is a significant gap in the set of existing cyber resilience assessment methods. Vugrin \\net al. (2010a,b; 2011a,b) have introduced a hybrid resilience assessment methodology that \\ncombines the strengths of qualitative and quantitative methods to address that gap. The hybrid \\napproach enables both the identification of system weaknesses and resilience enhancement \\nopportunities and a mechanism for measuring and validating the realized benefit of the \\nenhancements. The following section describes Vugrin et al.’s method.\\n10\\n3. A TWO-DIMENSIONAL, HYBRID RESILIENCE ASSESSMENT \\nFRAMEWORK\\nVugrin et al. developed an infrastructure resilience assessment framework that expands upon \\nprevious performance-based methods. The framework has four primary components:\\n1. A new definition of resilience that identifies system components required for a resilience \\nassessment; \\n2. A quantitative methodology that measures system resilience; \\n3. A qualitative methodology that can be used in place of, or to explain, quantitative results; \\nand \\n4. A resilience assessment process that formalizes the application of the resilience \\nframework.\\nApplication of the framework to an infrastructure system can provide infrastructure analysts \\nanswers to the following questions related to resilience:\\n1. What are the consequences resulting from decreased infrastructure performance \\noccurring after a disruptive event?\\n2. What are the costs associated with recovery from that event?\\n3. What are effective strategies for responding to disruptive events?\\n4. What preparations and investments should be made prior to the occurrence of a \\ndisruption?\\n5. What balance should be found between investment costs, recovery costs, and damage \\ncosts to enhance resilience, especially in a resource constrained environment?\\nDefining Resilience\\nVugrin et al. define resilience as follows:\\nGiven the occurrence of a particular disruptive event (or set of events), the \\nresilience of a system to that event (or events) is the ability to reduce efficiently\\nboth the magnitude and duration of the deviation from targeted system \\nperformance levels.\\nAs indicated in the definition, system performance is a key factor in evaluating resilience. Given \\nthe flexibility of many systems to adjust and reconfigure to a disruptive event, maintaining \\nsystem structure is not as important as maintaining system performance. Hence, measurement of \\nresilience includes evaluation of how a disruption affects system performance and causes \\nproductivity to decrease relative to targeted system performance levels.\\nThe concept of efficiency is a second dimension of resilience that is unique to this resilience \\ndefinition. Efficiency refers to the resource utilization that occurs during response and recovery \\nactivities that initiate after a disruption occurs; depending on the domain, these resources could \\nbe measured in dollars, repair man-hours, equipment, time, or similar metrics. In the event of a \\ndisruption that affects multiple system components, resources may not be available to repair all \\nimpacted components simultaneously. Systems may be competing for scarce resources; hence, \\nthe ability to recover efficiently will enhance the overall resilience of the system. All things \\n11\\nbeing equal, a system that recovers more efficiently than another should be considered more \\nresilient. Thus, Vugrin et al. assert that both system performance and efficiency measures must \\nbe considered in resilience assessment and measurement.\\nMeasuring Resilience\\nVugrin et al.’s definition of resilience leads to a mathematical calculation for resilience costs:\\ni.e., the comprehensive accounting of consequences resulting from a system disruption. The \\nresilience cost measurement approach requires quantification of two key dimensions: systemic \\nimpact (SI) and total recovery effort (TRE). \\nSI is the cumulative impact that a disruption has on system productivity and is measured by \\nevaluating the difference between a targeted system performance (TSP) level and the actual \\nsystem performance (SP) following the disruption. Figure 1(a) graphically represents systemic \\nimpact for a hypothetical system that has been disrupted. In this example, system performance \\ndecreases immediately following the disruptive shock that occurs at time t0. With the onset of \\nrecovery actions, performance levels first stabilize, then eventually increase, and ultimately \\nattain targeted system performance levels. At this point in time (tf), recovery is considered\\ncomplete. SI is quantified by calculating the area between the TSP and the SP curves. Equations\\n(1) and (2) demonstrate how to calculate SI if SP and TSP are represented as continuous or \\ndiscrete mathematical functions, respectively.\\nTSP levels represent a performance goal for the system and care should be used when selecting \\nthe TSP levels since they can significantly affect the calculation of SI. Selection of the TSP \\nlevels can be a subjective process. Frequently, TSP levels are set equal to nominal or pre\\x02disruption performance levels, indicating that the goal of recovery actions is to return the system \\nto its normal operating levels. TSP levels for emergency systems may actually exceed nominal \\nperformance levels since these systems are needed most during times of crisis. TSP levels for \\nsystems that are exceeding minimum performance levels at the time of a disruption may be lower \\nthan normal operating levels. Hence, the selection of TSP levels depends on the system \\nobjectives, operating levels at the time of the disruption, and other related factors.\\nIt should be noted that TSP levels are intended to represent performance goals, not minimum \\nperformance requirements. The SI quantity is intended to represent the impact of not performing \\nat a desired level. In some scenarios, individuals may want to assess a system’s ability to perform \\nabove a minimum requirement. Vugrin et al.’s resilience calculation methodology is not \\nappropriate for that type of analysis. At a minimum, the results would need to be interpreted \\ndifferently since a small SI value is preferable when defined with Equations (1) and (2). If SI is \\ncalculated as the difference between SP and minimum performance standards, the opposite is \\ntrue, i.e., increasingly large SI quantities indicate increasing levels of resilience. \\n\\uf05b \\uf05d\\n0\\n( ) ( ) .\\ntf\\nt\\nSI TSP t SP t dt \\uf03d \\uf02d \\uf0f2\\n(1)\\n12\\n\\uf028 \\uf029 \\uf028 \\uf029 \\uf028 1 \\uf029\\n1\\nf\\ni i i i\\ni\\nSI TSP t SP t t t\\n\\uf02d\\n\\uf03d\\n\\uf03d \\uf02d \\uf02d \\uf0e9 \\uf0f9 \\uf0e5\\uf0eb \\uf0fb\\n(2)\\nTRE represents the total resource usage from recovery activities that initiate after a disruptive \\nevent occurs. This quantity provides a measure of efficiency. After the disruption initiates, the \\nrecovery response begins and resources are expended in this effort. The TRE is represented by \\nthe area under the recovery effort (RE) curve in Figure 1(b). Equations (3) and (4) demonstrate\\nhow to calculate TRE if RE is represented as a continuous or discrete mathematical function.\\n\\uf05b \\uf05d\\n\\uf0f2\\n\\uf03d\\ntf\\nt\\nTRE RE t dt\\n0\\n( ) . (3)\\n\\uf028 \\uf029 \\uf028 1 \\uf029\\n1\\nf\\ni i i\\ni\\nTRE TRE t t t\\n\\uf02d\\n\\uf03d\\n\\uf03d \\uf02d \\uf0e9 \\uf0f9 \\uf0e5\\uf0eb \\uf0fb\\n(4)\\nVugrin et al. calculate the recovery dependent resilience (RDR) cost using Equation (5) to \\nmeasure resilience.\\n\\uf028 \\uf029\\nSI TRE RDR RE\\nNorm\\n\\uf02b \\uf0b4 \\uf061\\n\\uf03d\\n(5)\\nSince SI represents the performance impacts of the disruption and TRE represents the resources \\nand costs expended to recover from the disruption, the numerator in Equation (5) captures the \\ntotal impacts of the disruption. The parameter α in Equation (5) is a non-negative weighting \\nfactor that allows the analyst to assign the relative importance of the systemic impact and total \\nrecovery effort terms. Assigning a small positive value to α weighs the systemic impact more \\nheavily; a large positive value for α weighs the cost of recovery more heavily. To equally weight \\nSI and TRE, α is set to 1.\\nRDR is a unitless quantity that measures the total impacts of a disruption on a system under a \\nspecified recovery effort, RE.\\ni\\nThe RDR variable is a linear combination of SI and TRE. The \\ndenominator is a normalization factor that permits the comparison of the resilience of systems \\nwhose system performance levels may be of different magnitudes. Vugrin et al. recommend \\ncalculating Norm with Equation (6) or (7) when TSP can be represented as a continuous or \\ndiscrete mathematical function. These equations quantify the magnitude of the system by \\ncalculating the cumulative targeted system performance during the recovery period.\\n0\\n( )\\ntf\\nt\\nNorm TSP t dt \\uf03d \\uf0f2\\n(6)\\n\\uf028 \\uf029 \\uf028 1 \\uf029\\n1\\nf\\ni i i\\ni\\nNorm TSP t t t\\n\\uf02d\\n\\uf03d\\n\\uf03d \\uf02d \\uf0e5\\n(7)\\n13\\nRDR and resilience are inversely related; that is, larger RDR values imply larger impacts from \\nthe disruption, and therefore, lesser resilience. Smaller RDR values imply higher resilience.\\nBecause the RDR values are dimensionless quantities, they are most informative when used in a \\ncomparative manner. For example, RDR values can be used to compare the resilience of a system \\nbefore and after resilience-enhancing investments. A decrease in the RDR value would confirm \\nthe benefit of the investment; the magnitude of the decrease would indicate how much of a \\nbenefit. RDR values can also be used to compare the resilience of the same system to different \\ntypes of disruptions. Moreover, they can be used to compare the resilience of a system to a \\ndisruption under different recovery strategies. Each different recovery strategy will result in \\ndifferent SI and TRE values. The recovery strategy that results in the smallest RDR values will \\nprovide maximal resilience for the system.\\nAnalyzing Resilience\\nObjectively evaluating a system’s resilience and verifying the impact changes will have is an \\nimportant step in resilience analysis. It is equally important to understand the features of the \\nsystem that are constraining or enhancing resilience. Hence, Vugrin et al.’s assessment \\nframework contains a qualitative analysis component that can be used to explain the results of\\nquantitative measurements. The combination of performance-based quantitative methods and a \\nqualitative systems analysis results in a hybrid framework that can enable comprehensive \\nresilience assessment. \\nThe qualitative analysis is performed through consideration of system structures, characteristics, \\nand features. This portion of the framework uses three fundamental system capacities (absorptive \\ncapacity, adaptive capacity, and restorative capacity) to formulate how properties of a system can \\ndetermine system resilience, specifically by reducing SI and TRE. These capacities are affected \\nby resilience enhancement features; that is, the features of the system that are in place before a \\ndisruption and that affect one or more of the system’s capacities. Figure 2 indicates how the \\nresilience capacities contribute to system resilience and differ from each other. \\nAbsorptive capacity is the degree to which a system can automatically absorb the impacts of \\nsystem perturbations and minimize consequences with little effort. The absorptive capacity is an \\nendogenous feature of the system. Factors such as redundancy, separation, and robustness \\ncontribute to a system’s absorptive capacity. For example, physical and virtual separation of \\nredundant data centers can enhance resilience to both physical disruptions (e.g., floods, \\nearthquakes) and cyber attacks. Even redundancy in hardware, software, and services, as \\nGoldman (2010) recommends, would contribute to the absorptive capacity of the system and \\nultimately enhance resilience. \\nAdaptive capacity is the degree to which the system is capable of self-organization for recovery \\nof system performance levels. It is a set of properties that reflects actions that result from \\ningenuity or extra effort over time, often in response to a crisis situation. It reflects the ability of \\nthe system to change endogenously during the recovery period. Bodeau and Graubart (2011) list\\n“employing applications not previously presented to the adversary, repositioning of critical \\nassets, and changing the configuration of networks, systems, or applications” as examples of \\nadaptive responses that can enhance resilience to cyber threats. Utilization of uninterrupted \\n14\\npower supplies (UPSs) and backup diesel generators is a nonstandard practice during normal \\nbusiness operations. During a power outage, however, this change in operations can enhance \\nresilience to that outage. Using paper forms rather than electronic forms is a form of substitution \\nthat is normally more time-consuming and less efficient, but these adaptations could prove useful \\nif electronic systems are unavailable. Adaptive capacity is generally determined by a \\ncombination of human and automated activities. \\nRestorative capacity is the ability of a system to be repaired easily, and these repairs are \\nconsidered to be dynamic, beginning after the disruption initiates. Similar to adaptive capacity, \\nhuman and automated actions contribute to restorative capacity. Systems that have the ability to \\nself-segment and isolate compromised components can minimize system-wide damage and lead \\nto faster recovery. Software that enables an automated graceful degradation rather than a hard \\nshutdown can facilitate recovery. Preparedness through development, training, and testing of \\ncontingency plans enhance human responses that contribute to restorative capacities. Previous \\nexperience with disruptions can also help. \\nIdentifying resilience enhancement features and how they contribute to the resilience capacities \\nprovides an understanding of fundamental characteristics that contribute to resilience. The goal \\nof resilience enhancement should not necessarily be maximizing each resilience capacity. Rather, \\nthe goal should be finding the right combination of resilience enhancement features for the \\nsystem under consideration. The right combination of pre-disruption preparatory actions can \\ntarget the appropriate resilience enhancement features to increase the resilience of the system.\\nApplying the Process\\nThe final component of the resilience assessment framework is the process in which one applies \\nthe framework. The process consists of six primary steps that should be considered when \\napplying the framework (Figure 3). These steps include:\\n1. Define System(s): In the first step, the analyst must choose a system or systems and \\nidentify details of that system. Multiple systems may be identified if the analyst is \\ninterested in comparing systems. The analyst may answer questions such as “What \\nsystem is being considered?” and “What are the boundaries of the system?” Examples of \\nfactors to consider in the context of cyber systems include relationships between \\ndatabases, limitations on data sharing within an information technology (IT) system, \\naccess controls, and system architectures.\\n2. Define Scenario(s): The analyst should define a disruption scenario or multiple scenarios \\nif interested in comparing resilience across different events. Historical scenarios may be \\nbased on actual events, while hypothetical scenarios should be plausible, although not \\nnecessarily high-probability events. The analyst should consider how events in a scenario \\ndisrupt systems and what recovery processes might occur; that is, the analyst should \\nqualitatively identify system performance and recovery efforts. Examples of scenario \\nconsiderations for cyber systems could include evaluation of specific cyber and/or \\nphysically disruptive events; whether these events actually damage system components or \\nsimply render them non-functional; cascading impacts resulting from system or data \\n15\\ndependencies; and activities necessary to stabilize the system and ultimately get the \\nsystem back online.\\n3. Define Metrics: The previous step qualitatively identifies system performance and \\nrecovery efforts. Step 3 requires metrics that measure these processes be identified. \\nMetrics must be identified for system performance, targeted system performance, and \\nrecovery efforts. In general, any number of metrics can be found, but in practice there is \\nusually a single metric for system performance and corresponding targeted system \\nperformance, and multiple metrics for recovery effort. As noted by the CREF and CERT\\x02RMM, hundreds of possible metrics exist for cyber systems. Application response time \\nfor queries, mean and actual time to repair, mean and actual time between failures, and \\nmean and actual down time are possible metrics for consideration. However, when \\nattempting to identify the appropriate metric, it is important to recognize what \\nfunctionality the cyber system is intended to support. This caution is consistent with \\nBishop et al.’s (2011) argument that metrics for resilience need to be developed on a site\\x02by-site basis. Hence, in some cases, performance metrics may be more physical in nature. \\nFor example, power delivery might be a suitable performance metric for SCADA\\n(Supervisory Control and Data Acquisition) systems supporting the power grid.\\n4. Obtain Data: The fourth step is the collection of system performance and recovery data\\nfor the RDR calculations. Data can be obtained from:\\na. Modeling and simulation. If a numerical model exists that can be used to simulate \\ndisruption and recovery of the system, analysts can use the model to generate the \\nnecessary data.\\nb. Historical data. Disruption and recovery data from previous events may be recorded \\nand stored. Analysts can use these data to assess the resilience of the system to that \\nprevious event or to extrapolate system performance and recovery estimates for a \\nsimilar event.\\nc. Expert judgment. If modeling or historical data are not available, analysts can apply \\nexpert judgment to estimate the SI and TRE quantities. \\nThe flexibility to use any of these data sources for quantitative analysis is a strength of \\nthe assessment framework. However, the results of the analysis are only as good as the \\ndata being used. Hence, if expert judgment is the data source, data should be provided by \\nan individual who is knowledgeable and qualified to provide those estimates. \\n5. Calculate Resilience Costs: The fifth step calculates resilience costs according to the \\nEquations (1) – (7). Resilience costs are measures of relative resilience to a disruption; a \\nsystem/scenario with a higher resilience cost has lower resilience than a system/scenario \\nwith a lower resilience cost. \\n6. Perform Qualitative Assessment: The final step identifies resilience enhancement \\nfeatures that affect the resilience of a system and lead to the quantitative results. \\nIdentification of these features provides guidance on how a system can be improved to \\nbecome more resilient. This step may also identify behaviors of a system that were not \\n16\\nconsidered previously (especially identification of recovery efforts) in the resilience \\nanalysis and may lead back to previous steps.\\nIn some events, it may not be possible to acquire quantitative data for the resilience calculations.\\nThese instances should not prevent an analyst from attempting resilience assessment of the \\nsystem. Rather, proceed with the qualitative aspects of the analyses (all steps but 4 and 5) and \\ngain important understanding of the system.\\nVugrin et al. demonstrated how the resilience assessment framework can provide better \\nunderstanding of infrastructure resilience through application to numerous infrastructure \\nsystems. For example, Vugrin et al. used the framework to assess resilience of the national \\npetrochemical sector to various hurricane scenarios (2011a); to evaluate contingency strategies \\nfor military munitions production chains (Vugrin et al., 2010b); and to identify optimal recovery \\nstrategies for resource-constrained rail carriers in response to flooding events (Vugrin et al., \\n2011b). Vugrin et al. were able to identify a restoration approach that simultaneously decreased \\nrecovery time by 20 percent and decreased disruption costs by almost 40 percent. Most recently, \\nthe framework was used to inform the development of a resilience certification program for \\nbuildings. The general applicability of Vugrin et al.’s framework indicates that it could be \\nleveraged effectively in the context of cyber systems. The following section describes such an \\napplication.\\n4. A CASE STUDY\\nHuman resources (HR) systems are a cyber system that is often taken for granted. This oversight \\ncan result in serious security or functionality issues. Depending upon the organization, this \\nsystem may include a number of different databases that contain sensitive data about employees \\nand potential employees. Typical assets within this type of system include payroll, employee \\npersonally identifiable information, and recruiting records. This information is frequently shared \\nwith other systems and people within the company, such as security, management, medical, IT\\ngroups, and training groups. This frequent sharing increases the opportunities for unintended loss \\nor theft. If this information is compromised, it affects not just the organization that houses that \\ninformation, but the individuals whose information is affected. For these reasons, this resilience \\ncase study focuses on an HR database system.\\nConsider the following hypothetical scenario in which all numerical values are notional:\\n\\uf0b7 A relatively small company has a single HR database. This database includes personally \\nidentifiable information such as names, addresses, birth dates, and other sensitive \\ninformation. Other groups within the organization such as security, training and \\neducation, IT, management, and payroll access information from this database. Access to \\nthis information is on a need-to-know basis, so a limited number of people can view the \\ndata. Software systems that access this information must go through verification and \\nvalidation activities to ensure they are secure and have established limited access \\ncontrols. The database went through extensive testing to ensure that access to data was \\ncontrolled and that risk of potential data leaks was within an acceptable level. \\n17\\n\\uf0b7 To save money on start-up and maintenance costs, the company chose not to purchase a \\nbackup server or a vendor support contract for server hardware or software. The company \\nhas not developed emergency procedures to be performed if the server is compromised or \\nnon-functional for an extended period of time. These assumptions are somewhat extreme \\nbut, unfortunately, not unrealistic.\\n\\uf0b7 A new, untrained employee is assigned the task of ensuring that periods are inserted after \\nmiddle initials of customer names stored in the database. As a result of poor training, the \\nemployee ends up deleting records for a quarter of the customers. The employee stores \\nthe information for the remaining customers in a personal folder on a company repository \\naccessible to all employees.\\n\\uf0b7 The following morning (approximately 24 hours later), an employee notices the deleted \\nrecords and that sensitive information is stored in a generally accessible location. Fearing \\nthat the database has been hacked, the company takes the server offline to assess the \\ncause of the problems.\\n\\uf0b7 Due to the lack of vendor support and limited IT employees at the company, the company \\nis not able to determine the cause of the problem for 48 additional hours. The company \\nrealizes the issues were caused by human error and were not due to a malicious attack. \\nThe server is placed back online after sensitive information is removed from the \\ngenerally accessible folder. The company goes through a staged approach for restoring \\naccess to groups within the organization, so complete accessibility is not restored for \\nanother 48 hours. Adding the deleted customer files was completed within an additional \\n24 hours. At this point, the system is considered completely restored.\\nLosing server functionality had an adverse impact on business operations, and the company \\nincurred significant business interruption costs. This section describes how the company \\nmight perform a cyber resilience assessment using Vugrin et al.’s assessment approach to \\nenhance resilience to a similar event.\\nThe fundamental questions to be addressed in this analysis are:\\n\\uf0b7 What were the impacts and costs of the business interruption?\\n\\uf0b7 How resilient was the company to the interruption?\\n\\uf0b7 How could the company become more resilient to this type of interruption?\\nThese questions are addressed by going through the six-step resilience assessment process.\\n1. Define System(s): The system under consideration includes the HR server, the company \\nfunctions (sales, security, management, etc.) that depend on the server, the computer \\nnetworks relied upon by those company functions, and the HR staff who populate the \\nserver. \\n18\\n2. Define Scenario(s): This scenario includes an accidental disruption caused by an \\nuntrained employee. Improvement of cybersecurity would not have prevented the \\ndisruption. Human error resulted in loss of data and sensitive data being made accessible \\nto individuals who did not have a need to know. Business functions requiring access to \\nthe deleted customer records were halted for 24 hours. Although server access was \\nentirely prevented for another 24 hours, some dependent company functions were able to \\nrecover prior to access restoration through the use of paper records. Business functions \\nrequiring server access were brought back in a staged process, with complete access \\nrestored within another 48 hours. Total functionality was restored 24 hours later when the \\ndeleted records were replaced. Figure 4 shows how server functionality evolved during \\nthe recovery process. Loss of functionality resulted in business interruption costs. System \\nrestoration required a number of activities to occur that were not normally performed. In\\x02house IT staff worked overtime to identify the cause of the interruption and to restore the \\nserver. External IT consulting was brought in to assist, and because a support contract \\nwas not in place, this assistance came at a premium price. The overtime and external \\nconsulting costs were above and beyond regularly budgeted IT costs.\\n3. Define Metrics: To measure system impacts, the company selected company revenue\\n(Table 1). The targeted system performance was equated to the daily company revenue, \\nand system performance is the actual daily company revenue. Systemic impact is the \\ncumulative difference between the two quantities and can be considered the business \\ninterruption costs: i.e., costs associated with lost revenue and decreased productivity \\nresulting from the disruption. Other costs, such as opportunity costs and damage to \\nreputation, are possible metrics for systemic impacts, but as these are generally more \\ndifficult to estimate. It is assumed the company chose not to use these additional metrics. \\nTo measure the total recovery effort, the company uses the external IT consultant costs \\nand internal IT staff overtime labor charges. \\n4. Obtain Data: The company was able to use the invoice for the IT consultant and labor \\ncharging records to calculate the total recovery effort. The company inspects sales \\nrecords to obtain daily revenue amounts. Table 2 lists the IT consultant costs, overtime \\ncharges, and daily revenue amounts.\\n5. Calculate Resilience Costs: SI is calculated according to Equation (2) and determined to \\nbe $2,760. TRE is calculated by summing the recovery costs (Equation 4), so TRE is \\ndetermined to be $1,500. The variable \\uf061 is set equal to 1 because business interruption \\ncosts and recovery costs are considered equally important. Consequently, RDR costs are \\ncalculated to be 0.36, as shown in Equation (8).\\n\\uf028 \\uf029\\n2760 1 1500 0.36\\n12000\\nSI TRE RDR RE\\nNorm\\n\\uf02b \\uf0b4 \\uf02b \\uf0b4 \\uf061\\n\\uf03d \\uf03d \\uf03d\\n(8)\\n6. Perform Qualitative Assessment: The company performed an assessment of resilience \\nenhancement features that contributed to the interruption and delayed the recovery \\nprocess. Table 3 summarizes the results of that assessment.\\n19\\nThe lack of training is a key factor contributing to the disruption, so the company decided to \\nperform additional training to address this incident. The training ought to decrease the likelihood \\nthis incident would occur again, but the training cannot guarantee the incident or a similar one \\nwould never occur again. Hence, the following process improvement options were put forth to \\nsupplement the training:\\n\\uf0b7 Option 1 - Purchase a backup server: upon detection of the initial problem, the company \\ncould take the primary server offline and use the backup server. Because the backup \\nserver would contain static data and not allow updates, complete functionality could not\\nbe restored through the presence of a backup server. Expert judgment predicts that 90\\npercent functionality could occur through the use of a backup server. This option would \\nnot affect external consulting costs, overtime charges, and the length of time required to \\nrestore access to the initial server.\\n\\uf0b7 Option 2 - Purchase a vendor support contract: upon initial detection of the problem, the \\nvendor could be contacted. Expert judgment predicts that the vendor could identify the \\ncause of the problem within a day of the initial detection (as opposed to two days for the \\nbase case). Vendor support would negate the need for an external consultant, and \\nrestoration of server access would begin one day after detection of the problem rather \\nthan two days. The shorter overall recovery period would decrease overtime charges by \\n$400.\\n\\uf0b7 Option 3 - Develop a contingency plan: the primary benefit of the contingency plan is \\nthat it would facilitate the recovery process by decreasing the access and data restoration \\nprocess once the cause of the issue is identified. Expert judgment was used to estimate \\nthat access and data restoration could be completed in one day rather than three days. An \\nexternal consultant would still be required to identify the source of the interruption, but \\novertime charges would decrease by $400.\\n\\uf0b7 Option 4 - Combine Options 1, 2, and 3. No consultant is required and overtime charges \\nare decreased by $600.\\nFigure 5 illustrates the expected server functionality for each of the four options in the event that \\nthe incident occurs again. To determine the expected benefit from each of these options, the \\ncompany can recalculate the RDR values. Historical data are not available for these calculations, \\nbut for the observed interruption, each percent loss in functionality of the server resulted in an $8 \\nloss in revenue on average (Table 4). This relationship can be used to estimate revenue loss and \\nSI for each of the four options. Recovery costs and TRE values are shown in Table 5.\\nNot surprisingly, implementation of Option 4 results in the most resilient system (Table 6). RDR\\ncosts are a sixth of what they were in the initial scenario. SI and TRE values are decreased by\\nalmost 90 and 60 percent, respectively, and the length of the recovery period decreases from six\\nto three days, a 50 percent reduction. Option 1, use of the backup server, is the next most \\nresilient option because it results in the second smallest business interruption costs. The \\ndrawback of this option is that the total recovery still takes six days. Options 2 and 3 result in \\nnearly identical RDR values. The Option 3 SI value is slightly smaller than the respective Option \\n20\\n2 value, and complete recovery is achieved in one day less. However, Option 3’s higher recovery \\ncosts essentially offset the savings in business interruption costs.\\nHaving gone through the resilience assessment process, the company now has a comprehensive \\nunderstanding of what caused the interruption, what delayed recovery, the costs of the business \\ninterruption, recovery costs, options for enhancing the resilience of the company, and an analysis \\nof how effective those options would be. The company can now make informed decisions on \\nhow to prevent future interruptions and how to respond to the next one. \\n5. CONCLUSIONS AND SUMMARY\\nCyber resilience is increasingly recognized as an important component of comprehensive \\ncybersecurity practices. Cyber system managers should still strive to protect their systems \\nagainst malicious attacks, but they must also be prepared for situations in which their systems are \\ncompromised and disrupted. Current cyber resilience frameworks such as MITRE’s CREF and \\nthe Software Engineering Institute’s OCTAVE and CERT-RMM methods are effective at \\nidentifying system weaknesses and recommending improvements; however, these highly \\nqualitative approaches do not have the capacity to validate the effectiveness of the proposed \\nimprovements.\\nThe evolution of infrastructure resilience assessment methods paralleled the development of the \\ncyber resilience assessment methods. However, the additional development of performance\\x02based infrastructure resilience methods addressed the resilience validation issue. By focusing on \\nthe performance of a disrupted system, performance-based assessment methods address the \\ncentral infrastructure resilience question: how well does the system perform in the context of a \\ndisruption and how much better will it perform if recommended resilience enhancements are \\nimplemented? \\nThis paper describes a hybrid infrastructure resilience assessment methodology. It uses \\nperformance-based metrics to assess the impacts of a disruption. A qualitative analysis approach \\ncan then be used to evaluate system weaknesses and identify options for enhancing the system’s \\nresilience. The performance-based metrics can then be used again to validate the effectiveness of \\nthe options and to prioritize them. The paper discusses how this infrastructure resilience \\nassessment approach could be extended to cyber systems. Further, the assessment approach is \\napplied to a hypothetical cyber system to demonstrate the utility of the assessment approach. In \\nthis resilience analysis case study, an HR system is disrupted due to human error by an employee \\nof the company. (The resilience assessment framework is generic and can also consider \\nmalicious attacks.) The infrastructure resilience assessment framework is used to identify and \\nevaluate options for improving the resilience of the system. \\nThe challenge with applying the infrastructure resilience assessment framework to cyber systems \\nis that it has not been customized for cyber systems. Future development could create a cyber\\x02centric resilience assessment framework. The authors recommend the fusion of current cyber \\nresilience methods and infrastructure resilience assessment methods to incorporate the best of \\nboth approaches. For example, this new framework could combine OCTAVE’s structured cyber\\x02specific approach to identifying system weaknesses and system improvements with the resilience \\n21\\nmetrics of Vugrin et al. The resulting methodology would enhance cyber resilience assessment \\nand validation.\\n6. ACKNOWLEDGMENTS\\nThe authors thank Sharon O’Connor for her editorial assistance. This work was funded by the \\nSandia National Laboratories Laboratory Directed Research and Development program. Sandia \\nNational Laboratories is a multi-program laboratory managed and operated by Sandia \\nCorporation, a wholly owned subsidiary of Lockheed Martin Corporation, for the U.S. \\nDepartment of Energy's National Nuclear Security Administration under contract DE-AC04-\\n94AL85000.\\n\", 'C H A P T E R 1\\n\\nAn Introduction to National\\nSecurity and Cyberspace\\n\\nDerek S. Reveron\\n\\nI N ITS SHORT HISTORY, individuals and companies have harnessed cyberspace\\nto create new industries, a vibrant social space, and a new economic sphere that are\\nintertwined with our everyday lives. At the same time, individuals, subnational\\ngroups, and governments are using cyberspace to advance interests through mali-\\ncious activity. Terrorist groups recruit, train, and target through the Internet, orga-\\nnized criminal enterprises exploit ﬁnancial data with proﬁts that exceed drug\\ntrafﬁcking, and intelligence services steal secrets.\\n\\nToday individuals tend to pose the greatest danger in cyberspace, but nonstate\\nactors, intelligence services, and militaries increasingly penetrate information tech-\\nnology networks for espionage and inﬂuence. This is likely to continue in the future\\nas governments seek new ways and means to defend their interests in cyberspace and\\nto develop their own offensive capabilities to compete in cyberspace. As an early\\nexample, the Obama administration released International Strategy for Cyberspace in\\nMay 2011, which deﬁnes four key characteristics of cyberspace: open to innovation,\\nsecure enough to earn people’s trust, globally interoperable, and reliable.1 Ensuring\\nreliability against threats seems to dominate national security discussions today and\\nraises concerns when thinking about future warfare.\\n\\nSince the early 1990s analysts have forecast that cyberwar in the twenty-ﬁrst cen-\\ntury would be a salient feature of warfare. Yet, nearly twenty years later, individual\\nhackers, intelligence services, and criminal groups pose the greatest danger in cyber-\\nspace, not militaries. But the concept of using cyber capabilities in war is slowly\\nemerging. An example of this was the cyber attack that accompanied Russia’s inva-\\nsion of Georgia in 2008. As Russian tanks and aircraft were entering Georgian terri-\\ntory, cyberwarriors attacked the Georgian Ministry of Defense. Though it had a\\nminimal effect, the attack was a harbinger; future conﬂicts will have both a physical\\ndimension and a virtual dimension. While not destructive, the attacks were disrup-\\ntive. In the future, malicious code inﬁltrated through worms will disrupt communi-\\ncation systems, denial of service attacks will undermine governments’ strategic\\n\\n3\\n\\n.\\n\\nd\\ne\\nv\\nr\\ne\\ns\\ne\\nr\\n\\ns\\nt\\n\\nh\\ng\\ni\\nr\\n\\nl\\nl\\n\\nA\\n\\n.\\ns\\ns\\ne\\nr\\nP\\ny\\nt\\ni\\ns\\nr\\ne\\nv\\nn\\nU\\nn\\nw\\no\\n\\ni\\n\\nt\\n\\ne\\ng\\nr\\no\\ne\\nG\\n\\n.\\n\\n2\\n1\\n0\\n2\\n©\\n\\nt\\n\\nh\\ng\\ni\\nr\\ny\\np\\no\\nC\\n\\nCyberspace and National Security : Threats, Opportunities, and Power in a Virtual World, edited by Derek S. Reveron,\\n         Georgetown University Press, 2012. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/ryerson/detail.action?docID=1029588.\\nCreated from ryerson on 2022-05-03 01:12:47.\\n\\n \\n \\n \\n \\n \\n \\n \\n \\n\\x0c4 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . An Introduction to National Security and Cyberspace\\n\\nmessages, and logic bombs could turn out the lights in national capitals. This\\napproach was discussed during the 2011 NATO campaign in Libya, but was left\\nlargely in the conceptual phases.2\\n\\nAs a preview of what is to come, the 2010 Stuxnet worm was the ﬁrst worm\\nspeciﬁcally designed to attack industrial control systems.3 Had the worm not been\\ndetected, hackers could have obtained control of power plants, communication sys-\\ntems, and factories by hijacking the infected systems. Theoretically, this outside actor\\ncould manipulate a control system in a power plant to produce a catastrophic fail-\\nure. The source of the worm is purely speculative, but some experts saw this as the\\nﬁrst true cyber attack against Iran’s nuclear infrastructure and credit it for slowing\\ndown Iran’s program.4\\n\\nThe 2010 Quadrennial Defense Review foreshadowed the dangers of Stuxnet and\\nhighlighted that, although it is a man-made domain, cyberspace is now as relevant\\na domain for Defense Department activities as the naturally occurring domains of\\nland, sea, air, and space. The United States and many other countries, including\\nChina, Russia, Israel, and France, are preparing for conﬂict in the virtual dimension.\\nIn the United States, a joint cyber command was launched in 2010. With a modest\\ntwo thousand personnel at its headquarters, the command derives support from\\nﬁfty-four thousand sailors, eighteen thousand airmen, twenty-one thousand soldiers,\\nand eight hundred marines who have been designated by their services to support\\nthe emerging cyber mission. The head of US Cyber Forces, Gen. Keith Alexander,\\nsees future militaries using ‘‘cyberspace (by operating within or through it) to attack\\npersonnel, facilities, or equipment with the intent of degrading, neutralizing, or\\ndestroying enemy combat capability, while protecting our own.’’5 The 2011 National\\nMilitary Strategy directed joint forces to ‘‘secure the ‘.mil’ domain, requiring a resil-\\nient DoD cyberspace architecture that employs a combination of detection, deter-\\nrence, denial, and multi-layered defense.’’6 The Defense Department strategic\\ninitiatives for operating in cyberspace include the following:\\n\\n7 Treat cyberspace as an operational domain to organize, train, and equip so that\\nthe Defense Department can take full advantage of cyberspace’s potential.\\n7 Employ new defense operating concepts to protect Department of Defense net-\\n\\nworks and systems.\\n\\n7 Partner with other US government departments and agencies and the private\\n\\nsector to enable a whole-of-government cybersecurity strategy.\\n\\n7 Build robust relationships with US allies and international partners to\\n\\nstrengthen collective cybersecurity.\\n\\n7 Leverage the nation’s ingenuity through an exceptional cyberworkforce and\\n\\nrapid technological innovation.7\\n\\nWith this in mind, this book considers the current and future threats in cyber-\\nspace, discusses various approaches to advance and defend national interests in\\ncyberspace, contrasts the US approach with European and Chinese views, and posits\\na way of using cyber capabilities in war. To be sure, the nature of and the role for\\n\\n.\\n\\nd\\ne\\nv\\nr\\ne\\ns\\ne\\nr\\n\\ns\\nt\\n\\nh\\ng\\ni\\nr\\n\\nl\\nl\\n\\nA\\n\\n.\\ns\\ns\\ne\\nr\\nP\\ny\\nt\\ni\\ns\\nr\\ne\\nv\\nn\\nU\\nn\\nw\\no\\n\\ni\\n\\nt\\n\\ne\\ng\\nr\\no\\ne\\nG\\n\\n.\\n\\n2\\n1\\n0\\n2\\n©\\n\\nt\\n\\nh\\ng\\ni\\nr\\ny\\np\\no\\nC\\n\\nCyberspace and National Security : Threats, Opportunities, and Power in a Virtual World, edited by Derek S. Reveron,\\n         Georgetown University Press, 2012. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/ryerson/detail.action?docID=1029588.\\nCreated from ryerson on 2022-05-03 01:12:47.\\n\\n \\n \\n \\n \\n \\n \\n \\n \\n\\x0cD E R E K S . R E V E R O N . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5\\n\\ncyberwar is still under debate.8 But this book establishes a coherent framework to\\nunderstand how cyberspace ﬁts within national security.\\n\\nCyberspace Deﬁned\\n\\nWriter William Gibson coined the term ‘‘cyberspace’’ in a short story published in\\n1982. Once conﬁned to the cyberpunk literature and science ﬁction such as the\\nmovie The Matrix, cyberspace entered the real world in the 1990s with the advent of\\nthe World Wide Web. In 2003 the Bush administration deﬁned cyberspace as ‘‘the\\nnervous system of these [critical national] infrastructures—the control system of our\\ncountry. Cyberspace comprises hundreds of thousands of interconnected computers,\\nservers, routers, switches, and ﬁber optic cables that make our critical infrastructures\\nwork.’’9 Today, the US Defense Department deﬁnes it as ‘‘a global domain within the\\ninformation environment consisting of the interdependent network of information\\ntechnology infrastructures, including the Internet, telecommunications network,\\ncomputer systems, and embedded processors and controllers.’’10\\n\\nLike the physical environment, the cyber environment is all-encompassing. It\\nincludes physical hardware, such as networks and machines; information, such as\\ndata and media; the cognitive, such as the mental processes people use to compre-\\nhend their experiences; and the virtual, where people connect socially. When aggre-\\ngated, what we think of as cyberspace serves as a ﬁfth dimension where people can\\nexist through alternate persona on blogs, social networking sites, and virtual reality\\ngames. Larry Johnson, chief executive ofﬁcer of the New Media Consortium, predicts\\nthat over the next ﬁfteen years we will experience the virtual world as an extension\\nof the real one. Johnson believes that ‘‘virtual worlds are already bridging borders\\nacross the globe to bring people of many cultures and languages together in ways\\nvery nearly as rich as face-to-face interactions; they are already allowing the visualiza-\\ntion of ideas and concepts in three dimensions that is leading to new insights and\\ndeeper learning; and they are already allowing people to work, learn, conduct busi-\\nness, shop, and interact in ways that promise to redeﬁne how we think about these\\nactivities—and even what we regard as possible.’’11\\n\\nGone are the stereotypes of young male gamers that dominate cyberspace; those\\nthat inhabit virtual worlds are increasingly middle-aged, employed, and female. For\\nexample, the median age in the virtual world ‘‘Second Life’’ is thirty-six years old,\\nand 45 percent are women. Among Facebook users, about half are women.12 There\\nare more Facebook users aged twenty-six to thirty-four than there are aged eighteen\\nto twenty-ﬁve. The Internet has been the primary means of this interconnectivity,\\nwhich is both physical and virtual. Due to the highly developed economies and its\\nimportant role in the information technology sector, the highest Internet penetra-\\ntion rate is in North America. Yet, given its population size and rapid development,\\nAsia has the most users (see table 1.1).\\n\\n.\\n\\nd\\ne\\nv\\nr\\ne\\ns\\ne\\nr\\n\\ns\\nt\\n\\nh\\ng\\ni\\nr\\n\\nl\\nl\\n\\nA\\n\\n.\\ns\\ns\\ne\\nr\\nP\\ny\\nt\\ni\\ns\\nr\\ne\\nv\\nn\\nU\\nn\\nw\\no\\n\\ni\\n\\nt\\n\\ne\\ng\\nr\\no\\ne\\nG\\n\\n.\\n\\n2\\n1\\n0\\n2\\n©\\n\\nt\\n\\nh\\ng\\ni\\nr\\ny\\np\\no\\nC\\n\\nCyberspace and National Security : Threats, Opportunities, and Power in a Virtual World, edited by Derek S. Reveron,\\n         Georgetown University Press, 2012. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/ryerson/detail.action?docID=1029588.\\nCreated from ryerson on 2022-05-03 01:12:47.\\n\\n \\n \\n \\n \\n \\n \\n \\n \\n\\x0c6 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . An Introduction to National Security and Cyberspace\\n\\nTABLE 1.1\\nWorld Internet Users\\n\\nWorld Regions\\n\\nAfrica\\nAsia\\nEurope\\nMiddle East\\nNorth America\\nLatin America/Caribbean\\nOceania / Australia\\nWORLD TOTAL\\n\\nInternet Users\\n2011\\n\\n139,875,242\\n1,016,799,076\\n500,723,686\\n77,020,995\\n273,067,546\\n235,819,740\\n23,927,457\\n2,267,233,742\\n\\nPenetration\\n(% population)\\n\\nGrowth\\n2000–2011 (%)\\n\\n13.5\\n26.2\\n61.3\\n35.6\\n78.6\\n39.5\\n67.5\\n32.7\\n\\n2,988.4\\n789.6\\n376.4\\n2,244.8\\n152.6\\n1,205.1\\n214.0\\n528.1\\n\\nSource: Internet World Stats, www.internetworldstats.com/stats.htm.\\n\\nCyberspace and National Security\\n\\nThe link between national security and the Internet has been developing since the\\nClinton administration in the 1990s. Yet there are signiﬁcant differences between\\ntraditional domains such as airspace that make protecting cyberspace difﬁcult. To\\nbegin with, no single entity owns the Internet; individuals, companies, and govern-\\nments own it and use it. It is also arguable that there is not just one Internet but\\nmany. Governments also do not have a monopoly on operating in cyberspace. In\\ncontrast to heavily regulated airspace, anyone with a good computer or phone and\\nan Internet connection can operate there. And, making it more challenging for gov-\\nernments, most of the cyber expertise resides in information technology companies.\\nYet, all are affected equally by disruptions in cyberspace; a computer virus disruption\\nthat occurs through a commercial website can slow down the Internet for govern-\\nment and military users as well as for private citizens.\\n\\nAs it relates to war, the Internet is both a means and a target for militaries. Former\\nUS deputy defense secretary William J. Lynn underscored how important the infor-\\nmation infrastructure is to national defense. ‘‘Just like our national dependence [on\\nthe Internet], there is simply no exaggerating our military dependence on our infor-\\nmation networks: the command and control of our forces, the intelligence and logis-\\ntics on which they depend, the weapons technologies we develop and ﬁeld—they all\\ndepend on our computer systems and networks. Indeed, our 21st century military\\nsimply cannot function without them.’’13 Additionally, governments use the Internet\\nto shape their messages through media outlets hosted throughout the Web. US mili-\\ntary commanders use public blogs and operational units post videos to YouTube.\\nThis gives both the military and citizens unprecedented insight from pilots after\\nthey bomb a target, or from marines as they conduct humanitarian assistance. The\\n\\n.\\n\\nd\\ne\\nv\\nr\\ne\\ns\\ne\\nr\\n\\ns\\nt\\n\\nh\\ng\\ni\\nr\\n\\nl\\nl\\n\\nA\\n\\n.\\ns\\ns\\ne\\nr\\nP\\ny\\nt\\ni\\ns\\nr\\ne\\nv\\nn\\nU\\nn\\nw\\no\\n\\ni\\n\\nt\\n\\ne\\ng\\nr\\no\\ne\\nG\\n\\n.\\n\\n2\\n1\\n0\\n2\\n©\\n\\nt\\n\\nh\\ng\\ni\\nr\\ny\\np\\no\\nC\\n\\nCyberspace and National Security : Threats, Opportunities, and Power in a Virtual World, edited by Derek S. Reveron,\\n         Georgetown University Press, 2012. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/ryerson/detail.action?docID=1029588.\\nCreated from ryerson on 2022-05-03 01:12:47.\\n\\n \\n \\n \\n \\n \\n \\n \\n \\n\\x0cD E R E K S . R E V E R O N . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7\\n\\ntransparency is intended to reduce suspicion, counter deceptive claims made by\\nadversaries, and improve the image of the military. Yet there are limits to these poten-\\ntial advantages; the Pentagon is concerned that its personnel can also share too\\nmuch data through Facebook or project a poor image that runs counter to its efforts\\nthrough YouTube videos. Or, in illegal cases, military personnel can steal classiﬁed\\ndata and post hundreds of thousands of classiﬁed documents to sites like Wikileaks,\\nwhich can undermine national security.\\n\\nIn contrast to traditional warﬁghting domains such as land, air, or sea, govern-\\nments are not the only powers in cyberspace. Rather, individuals can readily harness\\ntechnology to compete on a global scale. And it is worth noting that virtualization\\nwill continue this trend of democratizing the Internet, giving individuals tremen-\\ndous power that was unthinkable even ten years ago. Satellite imagery used to be\\nhighly classiﬁed and limited by the US intelligence community, but now anyone can\\naccess imagery from an iPhone using Google Earth. Likewise, the complexity and\\ncost of building a nuclear weapon limits their production to governments, but the\\nsame cannot be said for the virtual weapon of mass destruction that can destroy data\\nand networks, undermine international credibility, and disrupt commerce. Malicious\\nactivity through worms, viruses, and zombies regularly disrupts Internet activity (see\\ntable 1.2). And there are already many examples of virtual activities impacting the\\nphysical world such as terrorists being recruited, radicalized, and trained on the\\nInternet; communications being severed; or power production being disrupted. Ille-\\ngal groups use cyberspace to move money, conceal identities, and plan operations,\\nwhich makes it extremely difﬁcult for the governments to compete. Consequently,\\ngovernments are increasingly concerned with the cyber domain as a new feature\\nwithin the national security landscape.\\n\\nIn some sense, there has always been an implicit national security purpose for the\\nInternet. After all, the Internet was originally conceived of and funded by one of the\\nDefense Department’s research organizations, then known as Advanced Research\\nProjects Agency (ARPA). Given the state of telecommunications and stand-alone\\ncomputer systems that existed in the 1960s, researchers wanted to create a reliable\\nnetwork where a user’s system or location was unimportant to his or her ability to\\nparticipate on the network. Charles Herzfeld, ARPA director from 1965 to 1967,\\nexplains the genesis of the network:\\n\\nThe ARPANET was not started to create a Command and Control System that would survive\\na nuclear attack, as many now claim. To build such a system was clearly a major military\\nneed, but it was not ARPA’s mission to do this; in fact, we would have been severely criticized\\nhad we tried. Rather, the ARPANET came out of our frustration that there were only a\\nlimited number of large, powerful research computers in the country, and that many research\\ninvestigators who should have access to them were geographically separated from them.’’14\\n\\nThis vision of a network became a reality in 1969 when a computer link was\\nestablished between the University of California–Los Angeles and Stanford Univer-\\nsity. At the time, the connection was called ‘‘internetworking,’’ which later was short-\\nened to the Internet. For thirty years, the Internet was largely the domain of\\n\\n.\\n\\nd\\ne\\nv\\nr\\ne\\ns\\ne\\nr\\n\\ns\\nt\\n\\nh\\ng\\ni\\nr\\n\\nl\\nl\\n\\nA\\n\\n.\\ns\\ns\\ne\\nr\\nP\\ny\\nt\\ni\\ns\\nr\\ne\\nv\\nn\\nU\\nn\\nw\\no\\n\\ni\\n\\nt\\n\\ne\\ng\\nr\\no\\ne\\nG\\n\\n.\\n\\n2\\n1\\n0\\n2\\n©\\n\\nt\\n\\nh\\ng\\ni\\nr\\ny\\np\\no\\nC\\n\\nCyberspace and National Security : Threats, Opportunities, and Power in a Virtual World, edited by Derek S. Reveron,\\n         Georgetown University Press, 2012. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/ryerson/detail.action?docID=1029588.\\nCreated from ryerson on 2022-05-03 01:12:47.\\n\\n \\n \\n \\n \\n \\n \\n \\n \\n\\x0c8 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . An Introduction to National Security and Cyberspace\\n\\nTerm\\n\\nBotnet\\n\\nLogic bomb\\n\\nTrojan horse\\n\\nVirus\\n\\nWorm\\n\\nZombie\\n\\nTABLE 1.2\\nCyber Threats Deﬁned\\n\\nDeﬁnition\\n\\nA network of zombie machines used by hackers for massive\\ncoordinated system attacks. Employing a botnet to send massive\\nsimultaneous requests to servers prevents legitimate use of the\\nservers and produces a denial-of-service attack.\\n\\nCamouﬂaged segments of programs that destroy data when certain\\nconditions are met.\\n\\nStealthy code that executes under the guise of a useful program\\nbut performs malicious acts such as the destruction of ﬁles, the\\ntransmission of private data, and the opening of a back door to\\nallow third-party control of a machine.\\n\\nMalicious code that can self-replicate and cause damage to the\\nsystems it infects. The code can delete information, infect\\nprograms, change the directory structure to run undesirable\\nprograms, and infect the vital part of the operating system that ties\\ntogether how ﬁles are stored.\\n\\nSimilar to a virus, a worm is distinctive for its ability to self-\\nreplicate without infecting other ﬁles in order to reproduce.\\n\\nA computer that has been covertly compromised and is controlled\\nby a third party.\\n\\nuniversities, colleges, and research institutes. But when Tim Berners-Lee and his\\ncolleagues created the World Wide Web in 1990, commercial and social applications\\nexploded. Within a few short years, companies such as Amazon (1995), Ebay (1995),\\nWikipedia (2001), Facebook (2004), and Khan Academy (2009) founded a new indus-\\ntry and changed the way we live and work. Ongoing trends in web development tools\\nsuggest that the gap between the virtual and physical worlds is indeed narrowing.\\n\\nAcademic and commercial companies were pioneers in harnessing the Internet,\\nand the government was a relative latecomer. Cyberspace ﬁrst emerged as a distinct\\nnational security policy area in 1998 when President Clinton signed Presidential\\nDecision Directive 63, which established a White House structure to coordinate gov-\\nernment and private action to ‘‘eliminate any signiﬁcant vulnerability to both physi-\\ncal and cyber attacks on our critical infrastructures, including especially our cyber\\n\\n.\\n\\nd\\ne\\nv\\nr\\ne\\ns\\ne\\nr\\n\\ns\\nt\\n\\nh\\ng\\ni\\nr\\n\\nl\\nl\\n\\nA\\n\\n.\\ns\\ns\\ne\\nr\\nP\\ny\\nt\\ni\\ns\\nr\\ne\\nv\\nn\\nU\\nn\\nw\\no\\n\\ni\\n\\nt\\n\\ne\\ng\\nr\\no\\ne\\nG\\n\\n.\\n\\n2\\n1\\n0\\n2\\n©\\n\\nt\\n\\nh\\ng\\ni\\nr\\ny\\np\\no\\nC\\n\\nCyberspace and National Security : Threats, Opportunities, and Power in a Virtual World, edited by Derek S. Reveron,\\n         Georgetown University Press, 2012. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/ryerson/detail.action?docID=1029588.\\nCreated from ryerson on 2022-05-03 01:12:47.\\n\\n \\n \\n \\n \\n \\n \\n \\n \\n\\x0cD E R E K S . R E V E R O N . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9\\n\\nsystems.’’15 The March 2005 National Defense Strategy identiﬁed cyberspace as a new\\ntheater of operations and assessed cyberspace operations as a potentially disruptive\\nchallenge, concluding that in ‘‘rare instances, revolutionary technology and associ-\\nated military innovation can fundamentally alter long-established concepts of war-\\nfare.’’ The 2008 National Defense Strategy explored the implications of this further,\\nassessing that small groups or individuals ‘‘can attack vulnerable points in cyber-\\nspace and disrupt commerce and daily life in the United States, causing economic\\ndamage, compromising sensitive information and materials, and interrupting criti-\\ncal services such as power and information networks.’’16 And the 2011 National Mili-\\ntary Strategy assessed that the cyber threat is expanded and exacerbated by lack of\\ninternational norms, difﬁculties of attribution, low barriers to entry, and the relative\\nease of developing potent capabilities.’’17 The 2012 strategic defense guidance identi-\\nﬁed one of the primary missions of the US armed forces as operating effectively in\\ncyberspace.18\\n\\nIn spite of recognizing vulnerabilities and threats to cyberspace, there are clear\\ngaps in both policy and law. There are no clear answers on important issues such as\\nhow to respond to cyber intrusions, whether computer network attacks constitute a\\nform of warfare, and whether the United Nations conception of self-defense applies\\nin cyberspace. Yet the threat remains ongoing. Former deputy defense secretary Wil-\\nliam Lynn said the Defense Department’s culture regarding cybersecurity issues\\nmust change because ‘‘we’re seeing assaults come at an astonishing speed—not\\nhours, minutes or even seconds—but in milliseconds at network speed.’’19 While the\\nPentagon has a plan to stop an air attack against the United States, there is no\\ncorresponding plan to reduce malicious activity on the Internet. Given privacy and\\nlegal concerns, it is also unclear what role the Defense Department can and should\\nplay in defending networks.\\n\\nIn an effort to understand the challenges and raise awareness of cyberspace, the\\nCenter for Strategic and International Studies bluntly warned in 2008, ‘‘America’s\\nfailure to protect cyberspace is one of the most urgent national security problems\\nfacing the new administration.’’20 In recognition of this, President Barack Obama\\ndeclared October 2009 to be national cybersecurity awareness month due to ‘‘our\\nNation’s growing dependence on cyber and information-related technologies, cou-\\npled with an increasing threat of malicious cyber attacks and loss of privacy.’’21 A\\nmonth later, a former NATO commander declared, ‘‘The cybersecurity threat is real.\\nAdversaries target networks, application software, operating systems, and even the\\nubiquitous silicon chips inside computers, which are the bedrock of the United\\nStates’ public and private infrastructure.’’22 Retired army general Wesley Clark and\\nPeter Levin argued that ‘‘all evidence indicates that the country’s defenses are already\\nbeing pounded, and the need to extend protection from computer networks and\\nsoftware to computer hardware is urgent. The US government can no longer afford\\nto ignore the threat from computer-savvy rivals or technologically advanced terrorist\\ngroups, because the consequences of a major breach would be catastrophic.’’23\\nFinally, the Department of Defense Strategy for Operating in Cyberspace highlighted\\n\\n.\\n\\nd\\ne\\nv\\nr\\ne\\ns\\ne\\nr\\n\\ns\\nt\\n\\nh\\ng\\ni\\nr\\n\\nl\\nl\\n\\nA\\n\\n.\\ns\\ns\\ne\\nr\\nP\\ny\\nt\\ni\\ns\\nr\\ne\\nv\\nn\\nU\\nn\\nw\\no\\n\\ni\\n\\nt\\n\\ne\\ng\\nr\\no\\ne\\nG\\n\\n.\\n\\n2\\n1\\n0\\n2\\n©\\n\\nt\\n\\nh\\ng\\ni\\nr\\ny\\np\\no\\nC\\n\\nCyberspace and National Security : Threats, Opportunities, and Power in a Virtual World, edited by Derek S. Reveron,\\n         Georgetown University Press, 2012. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/ryerson/detail.action?docID=1029588.\\nCreated from ryerson on 2022-05-03 01:12:47.\\n\\n \\n \\n \\n \\n \\n \\n \\n \\n\\x0c10 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . An Introduction to National Security and Cyberspace\\n\\n‘‘low barriers to entry for malicious cyber activity, including the widespread availabil-\\nity of hacking tools, mean that an individual or small group of determined cyber\\nactors can potentially cause signiﬁcant damage to both DoD and US national and\\neconomic security. Small-scale technologies can have an impact disproportionate to\\ntheir size; potential adversaries do not have to build expensive weapons systems to\\npose a signiﬁcant threat to US national security.’’24\\n\\nThe global security implications of this are profound. Whereas the Atlantic and\\nPaciﬁc Oceans and borders with Canada and Mexico can provide barriers to interna-\\ntional threats, the United States lacks comparable barriers in cyberspace. Strategic\\nthinking equates national security with global security in a world inhabited by\\nthreats without borders. US strategic thinking is not alone. Hamadoun Toure´, secre-\\ntary general of the United Nations Telecommunications Union has warned:\\n\\nThe next world war could take place in the cyberspace and this needs to be avoided. The\\nconventional wars have shown us that ﬁrst of all, there is no winner in any war and second,\\nthe best way to win a war is to avoid it in the ﬁrst place. So we need to plant the seeds for a\\nsafer cyberspace together. And it can only be done at the global level because the criminal\\nneeds no longer to be on the crime scene and you can attack many places at the same time\\nin the cyberspace.25\\n\\nWith these concerns in mind, the United Nations is working on a no-ﬁrst-strike\\npolicy for its members, which is reminiscent of nuclear-weapons-use policy. This\\napproach certainly makes sense given that the United Nations is organized around\\nthe nation-state concept, but it can have little effect on contemporary vulnerabilities\\nto the Internet, where many threats emanate from small groups and nonstate actors.\\nSecurity challenges in cyberspace are another indication that traditional nation-state\\napproaches to national security cannot address contemporary challenges like those\\nin cyberspace. Furthermore, there is an inherent deniability of Internet-based\\nattacks, which makes any agreement extremely difﬁcult to monitor or enforce.\\n\\nThreats to the Cyber Domain\\n\\nWhen attempting to examine cyber threats, the point of origin is very difﬁcult to\\ndetermine. Unlike a missile launch that has a discrete signature and geographic\\nlocation, those that employ cyber tactics can easily hide their origin, which makes\\nattribution extremely difﬁcult. James Lewis has argued, ‘‘Uncertainty is the most\\nprominent aspect of cyber conﬂict—in attribution of the attackers[’] identity, the\\nscope of collateral damage, and the potential effect on the intended target from\\ncyber attack.’’26 Without the ability to attribute to or assign blame for an attack,\\nrelying on threat of retaliation to prevent attacks is difﬁcult. Thus, when trying to\\nanalyze the threats to the cyber domain, it is best to take a comprehensive approach.\\nAccordingly, we can classify by actor, such as individual and government; by target,\\n\\n.\\n\\nd\\ne\\nv\\nr\\ne\\ns\\ne\\nr\\n\\ns\\nt\\n\\nh\\ng\\ni\\nr\\n\\nl\\nl\\n\\nA\\n\\n.\\ns\\ns\\ne\\nr\\nP\\ny\\nt\\ni\\ns\\nr\\ne\\nv\\nn\\nU\\nn\\nw\\no\\n\\ni\\n\\nt\\n\\ne\\ng\\nr\\no\\ne\\nG\\n\\n.\\n\\n2\\n1\\n0\\n2\\n©\\n\\nt\\n\\nh\\ng\\ni\\nr\\ny\\np\\no\\nC\\n\\nCyberspace and National Security : Threats, Opportunities, and Power in a Virtual World, edited by Derek S. Reveron,\\n         Georgetown University Press, 2012. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/ryerson/detail.action?docID=1029588.\\nCreated from ryerson on 2022-05-03 01:12:47.\\n\\n \\n \\n \\n \\n \\n \\n \\n \\n\\x0cD E R E K S . R E V E R O N . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\\n\\n11\\n\\nsuch as ﬁnancial sector or defense department; or by means, such as virus, worm, or\\ndenial of service.\\n\\nIn terms of the actor, those that use cyber tactics for nefarious purposes range\\nfrom individual hackers and organized criminal groups to intelligence services and\\ngovernments. Table 1.3 captures these sources of cyber insecurity, but it is important\\nto be careful. As Peter Singer notes, when\\n\\nit comes to talking about cyber attacks, senior defense leaders have lumped together teen-\\nagers defacing public DoD websites, disgruntled soldiers leaking documents, hackers stealing\\nindustry secrets, terrorists using YouTube and foreign military agents accessing classiﬁed\\nnetworks to plant worms, as if they were all one and the same, simply because their activities\\nall involved a digital series of 0s and 1s. This is akin to treating the threat posed by a teenager\\nwith a bottle rocket, a robber with a revolver, an insurgent with a bomb or a state with a\\ncruise missile as the same simply because they all involve gunpowder.27\\n\\nAs the diversity of actors illustrates, the barriers to entry for cyberspace are low.\\nOne only needs a good Internet connection, a decent computer, and the technical\\nknow-how to conduct attacks. Unfortunately, all three are cheap, which helps explain\\nwhy cyber intrusions have become commonplace. The head of the United Nations\\nInternational Telecommunications Union noted, ‘‘there is no such thing anymore as\\na superpower in the cyberspace because every individual is one superpower in itself\\nbecause it’s a human brain that makes a difference in this ﬁeld. And this is one\\nnatural resource that is equally distributed everywhere in the globe.’’28 Likewise, once\\nmalicious code is in the ‘‘wild’’ of cyberspace, it can be modiﬁed for other purposes\\nand be redirected against other targets. For example, those wishing to launch a ‘‘son\\nof Stuxnet’’ attack have the original Stuxnet as a starting point. In general reaction\\nto this phenomenon, Deputy Secretary of Defense Lynn summed up the challenge.\\n‘‘Once the province of nations, the ability to destroy via cyber means now also rests\\nin the hands of small groups and individuals.’’29 Thus, in cyberspace, human and\\nnational security are inextricably linked. In spite of this, there is genuine disagree-\\nment on whether cyber should be treated as a warﬁghting domain equivalent to air,\\nspace, land, and sea. This is based as much on the newness of cyberspace as on the\\nsecurity landscape that does not lend itself to easy divisions between acts of war and\\ncriminal acts. It seems that the debate remains on the nature of conﬂict begun after\\nthe Cold War and continued through the global war on terrorism; national security\\nchallenges cannot be neatly deﬁned between those that rise to the level of military\\nactivity and those that can be addressed through law enforcement.\\n\\nSo far criminals constitute the majority of bad actors as they take advantage of\\nthe Internet for nefarious purposes. Web-based attacks are the common source of\\nmalicious activity, which often happens by exploiting a vulnerable web application\\nor exploiting some vulnerability present in the underlying host operating system.\\nFor example, the 2010 Stuxnet worm exploited four vulnerabilities in Microsoft Win-\\ndows. In general, attackers concentrate their attacks for ﬁnancial gain by stealing\\n\\n.\\n\\nd\\ne\\nv\\nr\\ne\\ns\\ne\\nr\\n\\ns\\nt\\n\\nh\\ng\\ni\\nr\\n\\nl\\nl\\n\\nA\\n\\n.\\ns\\ns\\ne\\nr\\nP\\ny\\nt\\ni\\ns\\nr\\ne\\nv\\nn\\nU\\nn\\nw\\no\\n\\ni\\n\\nt\\n\\ne\\ng\\nr\\no\\ne\\nG\\n\\n.\\n\\n2\\n1\\n0\\n2\\n©\\n\\nt\\n\\nh\\ng\\ni\\nr\\ny\\np\\no\\nC\\n\\nCyberspace and National Security : Threats, Opportunities, and Power in a Virtual World, edited by Derek S. Reveron,\\n         Georgetown University Press, 2012. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/ryerson/detail.action?docID=1029588.\\nCreated from ryerson on 2022-05-03 01:12:47.\\n\\n \\n \\n \\n \\n \\n \\n \\n \\n\\x0c12 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . An Introduction to National Security and Cyberspace\\n\\nThreat Source\\n\\nIntelligence\\nservices\\n\\nTABLE 1.3\\nSources of Cyber Insecurity\\n\\nMotivation\\n\\nForeign intelligence services use cyber tools as part of their\\ninformation gathering and espionage activities. These include\\nexploitation and potential disruption or destruction of\\ninformation infrastructure.\\n\\nCriminal groups\\n\\nCriminal groups use cyber intrusions for monetary gain.\\n\\nHackers\\n\\nHacktivists\\n\\nDisgruntled\\ninsiders\\n\\nTerrorists\\n\\nHackers sometimes crack into networks for the thrill of the\\nchallenge or for bragging rights in the hacker community. While\\nremote cracking once required a fair amount of skill or computer\\nknowledge, hackers can now download attack scripts and\\nprotocols from the Internet and launch them against victim sites.\\nThus, attack tools have become more sophisticated and easier to\\nuse.\\n\\nThese groups and individuals conduct politically motivated\\nattacks, overload e-mail servers, and hack into websites to send a\\npolitical message.\\n\\nThe disgruntled insider, working from within an organization, is a\\nprincipal source of computer crimes. Insiders may not need a great\\ndeal of knowledge about computer intrusions because their\\nknowledge of a victim system often allows them to gain\\nunrestricted access to cause damage to the system or to steal\\nsystem data.\\n\\nTerrorists seek to destroy, incapacitate, or exploit critical\\ninfrastructures to threaten national security, cause mass casualties,\\nweaken the US economy, and damage public morale and\\nconﬁdence. The CIA believes terrorists will stay focused on\\ntraditional attack methods, but it anticipates growing cyber threats\\nas a more technically competent generation enters the ranks.\\n\\nSource: Government Accountability Ofﬁce, Statement for the Record to the Subcommittee on\\nTerrorism and Homeland Security, Committee on the Judiciary, US Senate; Cybersecurity: Continued\\nEfforts are Needed to Protect Information Systems from Evolving Threats, November 17, 2009.\\n\\n.\\n\\nd\\ne\\nv\\nr\\ne\\ns\\ne\\nr\\n\\ns\\nt\\n\\nh\\ng\\ni\\nr\\n\\nl\\nl\\n\\nA\\n\\n.\\ns\\ns\\ne\\nr\\nP\\ny\\nt\\ni\\ns\\nr\\ne\\nv\\nn\\nU\\nn\\nw\\no\\n\\ni\\n\\nt\\n\\ne\\ng\\nr\\no\\ne\\nG\\n\\n.\\n\\n2\\n1\\n0\\n2\\n©\\n\\nt\\n\\nh\\ng\\ni\\nr\\ny\\np\\no\\nC\\n\\nCyberspace and National Security : Threats, Opportunities, and Power in a Virtual World, edited by Derek S. Reveron,\\n         Georgetown University Press, 2012. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/ryerson/detail.action?docID=1029588.\\nCreated from ryerson on 2022-05-03 01:12:47.\\n\\n \\n \\n \\n \\n \\n \\n \\n \\n\\x0cD E R E K S . R E V E R O N . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13\\n\\nonline banking credentials and credit card information. Phishing has become a com-\\nmon way to steal ﬁnancial information by soliciting conﬁdential information from\\nan individual, group, or organization by mimicking (or spooﬁng) a speciﬁc brand.\\nTo counter this, cybersecurity specialists can lure hackers to spoofed computer sys-\\ntems to provide disinformation to attackers and study the attack style.\\n\\nThe United States and China are the top two countries of attack origin, account-\\ning for 23 percent and 4 percent, respectively, of worldwide activity (see table 1.4).30\\nGiven the large number of computers in the United States and China, it is not\\nsurprising that these two countries top the list of malicious activity. When broken\\ndown by region, there are some differences by type of infection.31 For example, 35\\npercent of trojans were reported from North America; 34 percent from Europe, Mid-\\ndle East, or Africa; 24 percent from Asia-Paciﬁc; and just 6 percent from Latin\\nAmerica. The Asia-Paciﬁc region dominated worm infections with 40 percent,\\nwhereas North America was just 13 percent. The increased proportion of virus infec-\\ntions was linked to the greater proportion of worms reported from the region\\nbecause viral infection is a common component of worms. It seems that antivirus\\nprograms are more prevalent in North America and that pirated operating systems\\nubiquitous elsewhere are more prone to infection.\\n\\nThe biggest threat to civilian infrastructure is through cyber attacks of supervi-\\nsory control and data acquisition (SCADA) systems. A SCADA system collects data\\nfrom remote systems and relays it to a central computer in what is usually a closed\\nloop requiring little in the way of human intervention. SCADA is widely used in\\nindustries that manage remote systems, such as electric power, trafﬁc signals, mass\\ntransit systems, water management systems, and manufacturing systems. Due to\\ntheir heavily automated nature, SCADA systems are especially susceptible to com-\\nputer attack. Control systems, signal hardware, controllers, networks, communica-\\ntions equipment and software are all vulnerable to determined adversaries.\\n\\n.\\n\\nd\\ne\\nv\\nr\\ne\\ns\\ne\\nr\\n\\ns\\nt\\n\\nh\\ng\\ni\\nr\\n\\nl\\nl\\n\\nA\\n\\n.\\ns\\ns\\ne\\nr\\nP\\ny\\nt\\ni\\ns\\nr\\ne\\nv\\nn\\nU\\nn\\nw\\no\\n\\ni\\n\\nt\\n\\ne\\ng\\nr\\no\\ne\\nG\\n\\n.\\n\\n2\\n1\\n0\\n2\\n©\\n\\nt\\n\\nh\\ng\\ni\\nr\\ny\\np\\no\\nC\\n\\nCyber and War\\n\\nCyber and war have been considered long before the current fascination with cyber-\\nwar began. Cyberwar was ﬁrst discussed at the Pentagon in 1977; offensive planning\\nbegan in 1981, and the 1991 war against Iraq saw the ﬁrst attempt to use malicious\\ncode in war. In 1993 John Arquilla and David Ronfeldt forecast that cyberwar in the\\ntwenty-ﬁrst century would be the equivalent of Nazi Germany’s highly successful\\nblitzkrieg operations in the twentieth century. In war, militaries would use ‘‘cyber-\\nspace (by operating within or through it) to attack personnel, facilities, or equipment\\nwith the intent of degrading, neutralizing, or destroying enemy combat capability,\\nwhile protecting our own.’’32 To date there has not been a cyberwar that meets this\\ndeﬁnition by producing signiﬁcant damage or political coercion. Instead, cyber\\nattacks have accompanied traditional warfare with limited impact. Defacement of\\ngovernment websites, denial-of-service attacks, and data stealing have been con-\\nducted over the Internet, but these do not constitute warfare. The doctrine and\\ncapabilities for cyberwar are still developing.33 But this may not be true for long, and\\n\\nCyberspace and National Security : Threats, Opportunities, and Power in a Virtual World, edited by Derek S. Reveron,\\n         Georgetown University Press, 2012. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/ryerson/detail.action?docID=1029588.\\nCreated from ryerson on 2022-05-03 01:12:47.\\n\\n \\n \\n \\n \\n \\n \\n \\n \\n\\x0cCopyright © 2012. Georgetown University Press. All rights reserved.\\n\\nTABLE 1.4\\nMalicious Activity by Country, July–September 2010\\n\\nRank\\n\\nLocation\\n\\nOverall\\nPercentage\\n\\nMalicious\\nCode Rank\\n\\nSpam Zombies\\nRank\\n\\nPhishing\\nWebsites\\nHost Rank\\n\\nBots Rank\\n\\n1\\n2\\n3\\n4\\n5\\n6\\n7\\n8\\n9\\n10\\n\\nUnited States\\nBrazil\\nIndia\\nGermany\\nChina\\nUnited Kingdom\\nTaiwan\\nItaly\\nRussia\\nCanada\\n\\n23\\n6\\n6\\n5\\n4\\n4\\n4\\n4\\n3\\n3\\n\\n1\\n6\\n2\\n11\\n3\\n4\\n23\\n21\\n15\\n8\\n\\n3\\n2\\n1\\n5\\n28\\n7\\n12\\n11\\n9\\n41\\n\\n1\\n4\\n—\\n2\\n7\\n3\\n—\\n—\\n6\\n5\\n\\n2\\n3\\n20\\n4\\n6\\n9\\n1\\n5\\n16\\n17\\n\\nSources: Symantec Intelligence Quarterly, July–September 2010; and Symantec Intelligence Report, January 2012.\\n\\nVirus\\nSource\\nRank\\n\\n1\\n—\\n3\\n—\\n—\\n2\\n—\\n—\\n—\\n10\\n\\nC\\nr\\ne\\na\\nt\\ne\\nd\\n\\nf\\nr\\no\\nm\\n\\nr\\ny\\ne\\nr\\ns\\no\\nn\\no\\nn\\n\\n2\\n0\\n2\\n2\\n-\\n0\\n5\\n-\\n0\\n3\\n\\n0\\n1\\n:\\n1\\n2\\n:\\n4\\n7\\n.\\n\\nC\\ny\\nb\\ne\\nr\\ns\\np\\na\\nc\\ne\\n\\na\\nn\\nd\\nN\\na\\nt\\ni\\no\\nn\\na\\n\\nl\\n\\nS\\ne\\nc\\nu\\nr\\ni\\nt\\ny\\n\\n:\\n\\nT\\nh\\nr\\ne\\na\\nt\\ns\\n,\\n\\nO\\np\\np\\no\\nr\\nt\\nu\\nn\\ni\\nt\\ni\\ne\\ns\\n,\\n\\na\\nn\\nd\\nP\\no\\nw\\ne\\nr\\n\\ni\\n\\nn\\n\\na\\nV\\n\\ni\\nr\\nt\\nu\\na\\n\\nl\\n\\nW\\no\\nr\\nl\\nd\\n,\\n\\ne\\nd\\ni\\nt\\ne\\nd\\n\\nb\\ny\\nD\\ne\\nr\\ne\\nk\\nS\\n\\n.\\n\\nR\\ne\\nv\\ne\\nr\\no\\nn\\n,\\n\\nG\\ne\\no\\nr\\ng\\ne\\nt\\no\\nw\\nn\\nU\\nn\\nv\\ne\\nr\\ns\\ni\\nt\\ny\\nP\\nr\\ne\\ns\\ns\\n,\\n\\ni\\n\\n2\\n0\\n1\\n2\\n.\\n\\nP\\nr\\no\\nQ\\nu\\ne\\ns\\nt\\n\\nE\\nb\\no\\no\\nk\\nC\\ne\\nn\\nt\\nr\\na\\nl\\n,\\n\\nh\\nt\\nt\\np\\n:\\n/\\n/\\ne\\nb\\no\\no\\nk\\nc\\ne\\nn\\nt\\nr\\na\\nl\\n.\\np\\nr\\no\\nq\\nu\\ne\\ns\\nt\\n.\\nc\\no\\nm\\n\\n/\\nl\\ni\\n\\nb\\n/\\nr\\ny\\ne\\nr\\ns\\no\\nn\\n/\\nd\\ne\\nt\\na\\n\\ni\\nl\\n.\\na\\nc\\nt\\ni\\no\\nn\\n?\\nd\\no\\nc\\nI\\nD\\n=\\n1\\n0\\n2\\n9\\n5\\n8\\n8\\n.\\n\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n\\x0cD E R E K S . R E V E R O N . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15\\n\\nsenior military leaders worry about US vulnerabilities created by an information\\ntechnology–based military and the potential irrelevance of current capabilities to\\ncyber threats.\\n\\nIn contrast to the defense establishment, other government civilian leaders are\\noffering an alternative vision. Jane Holl Lute, the deputy secretary of Homeland\\nSecurity, and Bruce McConnell, senior counselor at the Department of Homeland\\nSecurity wrote: ‘‘Conﬂict and exploitation are present there [on the Internet], to be\\nsure, but cyberspace is fundamentally a civilian space—a neighborhood, a library, a\\nmarketplace, a school yard, a workshop—and a new, exciting age in human experi-\\nence, exploration and development. Portions of it are part of America’s defense infra-\\nstructure, and these are properly protected by soldiers. But the vast majority of\\ncyberspace is civilian space.’’34 In other words, government must be careful about\\nmilitarizing cyberspace. Just as Americans would object to having a M1 tank at every\\nshopping mall, Americans do not relish US Cyber Command ‘‘patrolling’’ Amazon\\n.com or Facebook.\\n\\nWhile cyberwar has not yet occurred and civilians clearly dominate cyberspace,\\nthe military services have recognized the importance of cyberspace both in peace and\\nin war. For example, the air force has claimed cyberspace as one of its three operating\\ndomains (air and space are the others).35 The navy created the Fleet Cyber Command\\n(10th Fleet) and the director of national intelligence created a joint interagency cyber\\ntask force. At the same time, service capabilities are aggregated under the joint strate-\\ngic command, which is responsible for developing and implementing integrated\\noperations for defense and attack in the cyber domain. In thinking about the future,\\nthe United States military sees itself uncomfortably vulnerable in the cyber domain\\nand expects other countries to exploit it. Wesley Clark and Peter Levin argue: ‘‘There\\nis no form of military combat more irregular than an electronic attack; it is extremely\\ncheap, is very fast, can be carried out anonymously, and can disrupt or deny critical\\nservices precisely at the moment of maximum peril. Everything about the subtlety,\\ncomplexity, and effectiveness of the assaults already inﬂicted on the United States’\\nelectronic defense indicates that other nations have thought carefully about this\\nform of combat.’’36\\n\\nFor a number of reasons that include its economic growth and defense expendi-\\ntures, China is often identiﬁed as a likely cyberwar opponent. When speaking about\\nChina, Robert K. Knake noted that the Chinese military ‘‘plan[s] to thwart US\\nsupremacy in any potential conﬂict we get into with them. They believe they can\\ndeter us through cyber warfare.’’37 The Chinese military PLA Daily stated that\\n‘‘Internet warfare is of equal signiﬁcance to land, sea, and air power and requires its\\nown military branch,’’ and that ‘‘it is essential to have an all-conquering offensive\\ntechnology and to develop software and technology for net offensives . . . able to\\nlaunch attacks and countermeasures.’’38 The Chinese seem impressed and inspired\\nby US cyber capabilities and are closely following events. Ming Zhou, a China special-\\nist, noted that ‘‘information warfare is not just a theology, they can integrate it into\\nnation-state interests.’’39 Beyond China, a number of countries have sophisticated\\ncyber–national security capabilities, including Russia, Israel, India, and France.\\n\\n.\\n\\nd\\ne\\nv\\nr\\ne\\ns\\ne\\nr\\n\\ns\\nt\\n\\nh\\ng\\ni\\nr\\n\\nl\\nl\\n\\nA\\n\\n.\\ns\\ns\\ne\\nr\\nP\\ny\\nt\\ni\\ns\\nr\\ne\\nv\\nn\\nU\\nn\\nw\\no\\n\\ni\\n\\nt\\n\\ne\\ng\\nr\\no\\ne\\nG\\n\\n.\\n\\n2\\n1\\n0\\n2\\n©\\n\\nt\\n\\nh\\ng\\ni\\nr\\ny\\np\\no\\nC\\n\\nCyberspace and National Security : Threats, Opportunities, and Power in a Virtual World, edited by Derek S. Reveron,\\n         Georgetown University Press, 2012. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/ryerson/detail.action?docID=1029588.\\nCreated from ryerson on 2022-05-03 01:12:47.\\n\\n \\n \\n \\n \\n \\n \\n \\n \\n\\x0c16 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . An Introduction to National Security and Cyberspace\\n\\nBecause of this, the US military is wrestling over the meaning of this as it relates to\\nwarfare and sees cyberspace as critical to its operations, which requires defense.\\n\\nVolume Overview\\n\\nThe next chapter by Patrick Jagoda reminds us that our vocabulary and thinking\\nabout cyberwar are rooted in ﬁction. The scenarios depicted in science ﬁction might\\nexpand the parameters of our thinking and help us plan for previously unanticipated\\ncyber attacks. The chapter by Herbert Lin bounds imagination by explaining the\\ntechnical and operational considerations for conducting cyber attacks and cyber\\nexploitation. To bring practical insight, Steve Bucci considers the conﬂuence of cyber-\\ncrime and terrorism in chapter 4. This former army ranger and deputy assistant\\nsecretary of defense thinks that cyber threats can be grouped into seven categories\\nthat form a spectrum beginning with hackers and ending with nation-states.\\n\\nAs cyber tools become institutionalized into traditional defense establishments,\\nunderstanding the legal implications of this are important. In chapter 5 legal scholar\\nDavid P. Fidler sees the emergence of cyberspace as a new dimension for national\\nsecurity, military strategy and tactics, and conﬂict. This new dimension raises ques-\\ntions about how the international law regulating armed conﬂict operates in this new\\nrealm of realpolitik.\\n\\nIn chapter 6 Richard B. Andres explores cyber deterrence and the emergence of\\ncyber militias. With this foundation in deterrence, Jeffrey R. Cooper in chapter 7\\nconsiders the mechanisms to implement networked deterrence. This chapter builds\\non the ﬁnancial services concept of networked deterrence that rests on four elements:\\npenalty, futility, dependency, and counterproductivity. These elements provide a use-\\nful starting place for effective cyber deterrence. To augment and enhance these,\\nthis chapter adds two other components: intolerance and security cooperation.\\n\\nChapter 8 by Chris Demchak considers how cyberwar differs from ‘‘cybered’’ con-\\nﬂict. She writes, ‘‘The new normalcy of cybered conﬂict is its enduring potential\\nfor cascading unexpected outcomes anywhere across the deeply interconnected and\\ncomplex critical systems of a modern society.’’ In chapter 9, Brandon Valeriano and\\nRyan Maness place cyberwarfare in the context of international relations theory that\\nincreasingly hinges on cyber technologies for diplomacy, business, social relations,\\nand commerce. In chapter 10 James Joyner offers an exposition on European security\\nand cyberspace. While cybersecurity has moved to the forefront of national security\\nthinking in the United States as evidenced by the creation of several cyber–military\\ncommands, the same cannot be said among the advanced countries in Europe. Cyber-\\nsecurity is an immature issue in the European security community; furthermore,\\nEurope differs greatly from the United States on interpreting the signiﬁcance of\\ncyber attacks. What is a military issue in the United States is viewed almost as an\\nexclusively civil matter in Europe.\\n\\nIn chapter 11 Nikolas K. Gvosdev explains the implications of when the Russian\\n‘‘bear goes digital.’’ Although Russia was not one of the leaders in the digital revolu-\\ntion and compared to other industrialized countries still lags behind in the adoption\\n\\n.\\n\\nd\\ne\\nv\\nr\\ne\\ns\\ne\\nr\\n\\ns\\nt\\n\\nh\\ng\\ni\\nr\\n\\nl\\nl\\n\\nA\\n\\n.\\ns\\ns\\ne\\nr\\nP\\ny\\nt\\ni\\ns\\nr\\ne\\nv\\nn\\nU\\nn\\nw\\no\\n\\ni\\n\\nt\\n\\ne\\ng\\nr\\no\\ne\\nG\\n\\n.\\n\\n2\\n1\\n0\\n2\\n©\\n\\nt\\n\\nh\\ng\\ni\\nr\\ny\\np\\no\\nC\\n\\nCyberspace and National Security : Threats, Opportunities, and Power in a Virtual World, edited by Derek S. Reveron,\\n         Georgetown University Press, 2012. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/ryerson/detail.action?docID=1029588.\\nCreated from ryerson on 2022-05-03 01:12:47.\\n\\n \\n \\n \\n \\n \\n \\n \\n \\n\\x0cD E R E K S . R E V E R O N . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17\\n\\nand integration of the new technologies, it is trying to catch up. The Kremlin has\\nbegun to take much more seriously nonmilitary applications of power and force,\\nincluding a growing interest in cyberwar capabilities, and it is becoming aware of\\nRussia’s own vulnerabilities in these areas.\\n\\nNigel Inkster, writing in chapter 12, sees China as both exploitative and exploited\\nin cyberspace. His view is important since China is often recognized as posing the\\ngreatest cyber challenge to the United States. This has as much to do with realist\\npredictions about the inevitable conﬂict of great powers as it does with Chinese\\ncyber behavior. To make sense of this behavior, John B. Sheldon presents a theory of\\ncyber power in chapter 13. This is important because noted strategist Colin Gray\\nsees that ‘‘we lack adequate strategic theory to help guide practice [in cyberspace],’’\\nwhich is now on par with air, land, sea, and space.40\\n', 'Environmental Manager \\n\\nCybersecurity: \\nBuilding  Resilience from the Inside Out \\n\\nCybersecurity is no longer a far-fetched concept relegated to science fiction or \\nconspiracy theories. It is a major and growing global risk across all industry sectors \\n\\nKristina Drage-Arianson \\nand Don Crouch \\nLloyd\\'s Register \\n\\nG iven the increasingly cen \\n\\ntral role of digital technolo \\ngies,  data and connectiv \\nity,  cybersecurity is widely \\naccepted as a major risk to all indus \\ntries  and  society  as  a  whole.  Fur \\nthermore,  as  technology  becomes \\nmore  accessible,  the  skill  pool  of \\nassociated  \"dark  arts\"  expands  -\\nand  the  risks  increase  (Figure  1). \\nAccording  to  the  2018  Global  Risk \\nReport  from  the  World  Economic \\nForum  (www.weforum.org),  cyber \\nsecurity is the third-largest risk faced \\nby businesses. The report also esti \\nmates that cyber-crime activities will \\nincur costs of around $8 trillion over \\nthe  next  five years across the entire \\neconomy. Furthermore, findings from \\ntelecommunications giant Verizon, in \\nits  201 7  Breach  Investigations  Re \\nport,  found  that  95%  of  \"phishing\" \\nattacks  (disguised  emails  aimed  at \\nstealing  information)  that  led  to  a \\nbreach were  followed  by some  sort \\nof software installation  These points \\nunderline  the  fact  that  industries \\nmust  be  proactive  in  dealing  with \\ncybersecurity issues. \\n\\nThe view from the boardroom \\nToo  many  businesses  make  cyber \\nsecurity  a  priority  only  when  they \\nhave  been  attacked,  and  although \\nmany recognize the lack of adequate \\nresource allocation to this critical as \\npect of business resilience,  they also \\nadmit that they do not have enough \\nunderstanding  of the latest  informa \\ntion,  security  implications  and  their \\nown vulnerabilities. \\n\\nExecutives  are  beginning  to  rec \\nthose  individuals  re \\nognize \\nsponsible for cyberattacks are highly \\n\\nthat \\n\\nskilled,  are not con \\nstrained  by  the  law \\nand  are  driven  by  a \\nrange  of  motivating \\nfactors.  While  there \\nis  significant  activity \\nacross  many  indus \\ntries  to  mitigate  the \\npotential  impacts  of \\ncyberattacks,  many \\nexperts still  feel that \\nthe  level  of  cyber \\nresponse \\nsecurity \\nmay  be  insufficient \\nor misdirected. \\n\\nWhile \\n\\nadequate \\nmeasures  may  be \\nin  place  to  protect \\nagainst  data \\ntheft \\nand  hacking,  op-\\nremain \\nerations \\nvulnerable, \\nmak-\\ninterruptions  a \\ning \\nlikely  outcome \\nin \\nthe  event  of  a  cy \\nbersecurity  breach. \\nExperts  have  also  suggested,  for \\nexample, that most oil-and-gas and \\nchemical processing  companies  do \\nnot  yet  have  in  place  the  systems \\nto  pre \\nand  resources  required \\ncisely  determine  the  source  of  cy \\nberattacks,  or  with  what  frequency \\nthey  occur,  in  order  to  implement \\npreventative measures. \\n\\nThe  type  of data  being  stolen  is \\nparticularly  revealing.  While  sensi \\ntive  personal  information  like  finan \\ncial or health  records  remains  a key \\nfocus,  hackers  are  increasingly  tar \\ngeting  higher-value  data  relating  to \\ninfrastructure  systems  and  large  in \\ndustrial facilities. Based on  research \\nfrom  cybersecurity firm  FireEye  (Mil \\npitas,  Calif.;  www.fireeye.com),  18% \\nof the data exfiltrated through cyber \\nattacks in  Europe in 2016 related to \\ncompanies\\'  industrial  control  sys-\\n\\nCHEMICAL ENGINEERING  WWW.CHEMENGONLINE.COM  OCTOBER 2018 \\n\\nFIGURE 1. Cyber-crime is on the rise as digital technologies continue to \\nproliferate across the process industries, and malicious individuals be \\ncome more adept at targeting companies\\' vulnerabilities \\n\\ntems, building schematics and blue \\nprints, while a further 19% related to \\ntrade secrets. \\n\\nThe threat is real \\nThe  potential  for  performance  im \\nprovements  by  using  live  process \\ndata as  an  input  to an  operation  is \\nlargely  uncontested  in  operations \\nand  manufacturing.  On  the  whole, \\nit  is  understood  that  these  types  of \\ndata are  essential  to  improving  op \\nerational performance and that data \\ntechnologies  provide  opportunities \\nfor  more  accurate  risk  assessment \\nand control of safety-critical systems \\n(Figure 2). But statistics confirm that \\nthe threat  of unauthorized  data  ac \\ncess and cyber-crime is serious and \\ngrowing  -\\nand  hacking  of  these \\nsystems or data can  directly impact \\na compaoy\\' ability to comrol 11:..::::... \\n\\n\\x0csafety systems. \\n\\nAccording  to  the  Cost  of  Cyber \\nCrime  Report  from  the  Ponemon \\nInstitute (Traverse City, Mich.; INWW. \\nponemon.org), \\nthe  number  of \\nbreaches  is  up  by  an  average  of \\n27.4%  year  over  year,  and  86%  of \\ncompanies  around  the  world  re \\nported that they had experienced at \\nleast one cyber incident in 2017. \\n\\nIn  2012, \\n\\nthe  attacks  on  Saudi \\nAramco  and  Qatar\\'s  RasGas  entity \\nraised the profile of industrial cyber \\nsecurity.  At  Saudi  Aramco,  hackers \\nreplaced  data  on  hard  drives  with \\nan  image  of  a  burning  U.S.  flag, \\nprompting  the  then  U.S.  Secretary \\nof Defense Leon Panetta to label the \\nincident,  \"a  significant  escalation  of \\nthe  cyber threat.\" Two  years  later, it \\nwas reported that between 2010 and \\n2014,  hackers  had  stolen  source \\ncode  and  blueprints  to  U.S.  oil and \\nwater  pipelines,  as  well  as  power \\ngrids,  and  had  infiltrated  the  U.S. \\nDepartment  of  Energy\\'s  networks \\non  some  150  occasions.  More  re \\ncently, high-profile breaches at Sony, \\nU.K. \\ntelecommunications  provider \\nTalkTalk  and  others  have  acceler \\nated  and  amplified  concerns  about \\nthe  risks  associated  with  cyberat \\ntacks.  Understandably,  businesses \\nof all  sizes  are  looking  at  how they \\ncan improve their resilience. \\nimportant \\n\\nindustries \\nare  prepared  to  equip  themselves \\nwith  mitigation  measures  to  defend \\nagainst  cyberattacks.  As  industries \\nincreasingly  dependent \\nbecome \\nupon  digital  technologies,  opera \\ntional  and  technology  security  is  a \\nkey concern across all  sectors. \\nchemicals, \\nand \\n\\noil-and-gas, \\nThe \\nnuclear \\nrenewable-power-\\ngeneration  sectors  are  diverse  re \\ngarding  the  implementation  of  cy \\nbersecurity technologies.  Wind- and \\nsolar-power  generation  tend  to  be \\non  the  forefront  of  advanced  con \\nnectivity  and  analytics,  while  oil \\nand-gas  tends  to  lag  in  the  same \\ntechnology area. \\n\\nthat \\n\\nis \\n\\nIt \\n\\nWhile  the  information  technology \\n(IT),  data  management  and  com \\nmunication  ends  of  the  operational \\nspectrum have been seen as a major \\nopportunity for  cyber  theft  and  cor \\nruption,  this  focus  must  expand  as \\nindustries change.  To  date,  this has \\nbeen  a  focal  point  of  cybersecurity \\nefforts in all  energy and manufactur \\ning  sectors.  However,  the  next  big \\n\\nFIGURE 2. The increased availability of process data has significantly raised the bar for productivity and \\nefficiency, but use of these digital technologies can also expose companies to cyber-crimes \\n\\narea of cybersecurity concern for the \\noil-and-gas  and  chemical  process \\ning sectors is the rapid advancement \\nof connectivity among previously iso \\nlated operational technologies in the \\nfield  to  massive  data-management \\npathways. This is where cybersecu \\nrity efforts  now need  to  be  focused \\nso  that  machinery  and  objects  are \\nprotected \\nfrom  manipulation  and \\npotential compromise. \\n\\nThe highly organized nature of es \\npionage  malware  is  of special  con  \\ncern.  For  example,  Careto  (or  \"The \\nMask\"  when  translated  from  Span \\nish) was discovered in  2014 and be \\nlieved  to target government  bodies. \\nMore  recently,  The  Mask  has  been \\ndirected  at  energy  companies,  and \\nanother  such  threat,  known  as  the \\nPhantom  Menace,  aimed  to  com  \\npromise  the  control  systems  of  a \\nmarine vessel by stealing data. Mal \\nware can remain  in  the background \\nand  run  unknown,  and  then  pop \\nup when  triggered  at a  certain  time \\nor  by  an  event.  Malware  has  been \\nused  historically  for  stealing  confi \\ndential data  or taking over commu \\nnication  systems  and  using  them \\nas  a  backdoor  to  gain  access  to \\nother systems. \\n\\nAlongside  the  increased \\n\\nthreat \\nand  heightened  profile,  antivirus \\nsoftware  products  struggle  to  keep \\nup.  Most  virus  checkers  search \\nfor  and  detect  only  the  most  com \\nmon viruses and  malware. It  is  criti \\ncal for industries  to  re-evaluate and \\nfurther  develop  those  systems  for \\nthe  protection  of  important  assets \\nand infrastructure. \\n\\nIndeed, cybersecurity  is  still at an \\nearly  stage  of  development  across \\nmany industries,  and  not enough  is \\nknown  about  the  sources  and  fre \\nquency  of  attacks.  Of  course,  re \\nsponses  and  capabilities  vary,  with \\nsome  companies  committing  re \\nsources  and  focus  to  advancing  in \\nthis area. Other - usually smaller  -\\ncompanies lack the scale required to \\ndevelop and affect solutions, so they \\nwill look to external sources. \\n\\nHowever,  the  policies  and  strate \\ngies  being  developed  by  the  E.U., \\nU.K.  and  U.S.  governments on  how \\nto  manage  and  control  cybersecu \\nrity  will  hopefully help companies to \\nevolve.  Industry  regulators  for  each \\nsector  of  industry  have  worked  to \\ngenerate policies or directives based \\nfrom  strong  par \\non  information \\nticipants  in  the  cybersecurity  com \\nmunity.  Each  policy  specifically  ad \\ndresses infrastructure concerns that \\nare relevant  to that region\\'s citizens. \\nIt  will  take  constant  effort  in  perpe \\ntuity  to  ensure  a  company\\'s  infra \\nstructure stays as secure and stable \\nas  possible. Even  if present  policies \\nmay  be  sufficient  for current known \\nthreats, enhanced planning for long \\nterm  diligence  should  be  the  next \\nimmediate effort. \\n\\nConnectivity equals vulnerability \\nThe  increasing  digitalization  of  the \\nenergy, chemicals and marine indus \\ntries has elevated the risk associated \\nwith cyberattacks,  because hackers \\ncan  now access  data  and  systems \\nfrom the outside. \\n\\nIn  addition  to  hardware-based \\n\\n66 \\n\\nCHEMICAL EN GINEERING  WWW.CHEMENGONLINE.COM  OCTOBER 2018 \\n\\n\\x0cthen  pass it to  the next person,  and  so on  and  plug  it \\ninto  various  systems  or devices.  This  is obviously  not \\nsecure,  but  the  practice  continues,  since  using  USB \\ndrives  has  been  the routine  practice over and over for \\nthird  parties,  contractors,  equipment  manufacturers \\nand others. \\n\\nFor this  reason,  an  assessment should always include \\nhuman  and  social  factors, as well  as technical, process \\nand equipment aspects. This includes gaining a deep un \\nderstanding  of how people actually  behave,  rather  than \\nassuming that policy and procedure will manage the reality. \\n\\nfound \\n\\nAwareness through training \\nInformation  Security \\nThe  2018  Global  State  of \\nby  PricewaterhouseCoopers \\nSurvey \\nconducted \\n(PwC) \\nthe \\ntop  source  of  security  incidents.  Further,  it  is  esti \\nmated  that  upwards  of  90%  of  successful  cyberat \\ntacks  continue  to  succeed  because  of  human  error \\nthe  unwitting  actions  of anyone  in  any  role  within \\n-\\nan organization. \\n\\nthat  current  employees  remain \\n\\nThis is why an attitude of \"awareness through training\" \\nis  essential (Figure 3). Companies must work with  their \\npersonnel and engage in conversations with them about \\nthe  threats  that  are out  there.  More-effective employee \\ntraining is  a key factor in reducing the occurrence of cy \\nberattacks and the costs of dealing with breaches after \\nthey occur. \\n\\nFIGURE 3. Comprehensive cybersecurity training and practical demonstrations \\ncan decrease Inadvertent human error, which is one of the main enablers of \\nsuccessful cyberattackS \\n\\nthreats, software presents a different type of risk. A soft \\nCompanies  may employ  an  interactive  learning  plat-\\nware  tool  may be  tied  into  a company\\'s  vulnerable  in \\nformation , which could be,  for example, a data-logging  r--- -- - - - -- - - - -- - - -  \\nentity, the drilling control system  of an oil  rig  or even  a \\ncompany\\'s financial  information.  So,  if a cyber attacker \\ngained  access  through  the physical  elements  (such  as \\nports,  servers  and  so on),  now they  have access  to  a \\ncompany\\'s  financial  data  -\\njust  by  inserting  a  push \\nemail. Using a simple email, a virus can embed itself into \\nmetadata and continue to  spread.  In  this instance, the \\nvery specific nature  of the virus means that it  is  unlikely \\nto be detected by antivirus software. \\n\\nKnowledge-sharing is a defense \\nCybersecurity skills are vital for today\\'s industry. This means \\ntraining  or investing  in  specialist,  as well  as  operational, \\nteams, so that actions and processes are thoroughly con \\nsidered  in  the  context  of cybersecurity.  Comprehensive \\nprocedures to help companies tackle cybersecurity issues \\nmay include a complete overview of the systems, equip \\nment and personnel at a particular facility and a means of \\nevaluating which elements are most vulnerable to attacks \\nand  then  comparing  their condition  to international  and \\nregional standards. \\n\\nMost  cyber threats  today gain  access  to operational \\nsystems via connected personal and professional com  \\nputers.  The  most effective way  for  future  protection of \\ncritical infrastructure is to combine efforts and resources \\nto quickly identify common platforms for machine learn \\ning  and edge  computing  that  will  remove  the  need  for \\nhuman connectivity to operational technology systems. \\nAdditionally,  unintentional  potential  breaches  of  cy \\nbersecurity are common.  There have  been  several  no \\ntable  examples  where a  USB  drive  is  supposed  to be \\nscanned  before it  goes into any system at a petroleum \\nrefinery  or  other  facility.  A  person  may  use  the  drive, \\n\\nPart of the Quarter-Tum Valve Family \\n\\n(630) 941 ·7600 \\nwww.valmitic.com \\nvalvesOvalmatic.com \\n\\nFor de talla vlalt  adllnka.chemengonline.com/70311 ·29 \\n\\nCHEMICAL ENGINEERING  WWW.CHEMENGONLINE.COM  OCTOBER 2018 \\n\\n~ \\n\\n\\x0cthat  matter,  nation  - can  afford  to \\nignore the potential impacts of cyber \\nthreats  and  attacks  (Figure  4).  No \\nsector  of  the  economy  is  immune \\nfrom  attack,  whether  it  be  industry, \\ngovernment or the not -for-profit sec \\ntor.  The  best  effort  is  a  change  in \\nmindset,  particularly  between  gov \\nernment  and  industry,  emphasizing \\ncollaboration.  Staying  ahead  of the \\nadvancements  in  technology,  and \\nkeeping open communication chan \\nnels  for  potential  capabilities  to  ac \\ncess  any vulnerability in  any  part  of \\nan operation or a company\\'s supply \\nchain,  will  be  critical.  A  more  open \\nand rapid transfer of threat informa \\ntion  from  both  public  and  private \\nsectors  is  the  best  way  for  every \\none to keep progressing with  threat \\nmitigation.  While  cyber  criminals \\nbecome more sophisticated,  so too \\nmust  our  response  and  proactive \\ndefensive measures. \\n\\n• \\n\\nEdited by Mary Page Bailey \\n\\nAuthors \\n\\nKristina  Drage-Arianson  is  a \\nprincipal consultant and  the  de \\npartment  manager of  the  Lloyd\\'s \\nRegister Risk  Management  Con \\nsulting  business (Drammensveien \\n169. 0277  Oslo,  Norway; Phone: \\n+47 -400-03-500; Email: kristina. \\narianson@lr.org).  She \\njoined \\nLloyd\\'s  Register  straight  from \\ngraduating  with  a M.S. in  engi \\nneering  cy!Jernetics. During  her  12 years with  Lloyd\\'s \\nRegister, she has boon involved in a wide range of proj \\nects, mostly related  to  oil-and-gas  operations, where \\nshe helps clients make their businesses safer and more \\nreliable. Her key qualifications are within reliability and \\navailability studies.  in particular  for safety and  control \\nsystems. She has  also carried  out  a number of  other \\nsafety  studies,  including  risk  analyses  and  process \\nsafety studies. \\n\\nDon Crouch  is  global  technical \\nmanager  -\\nElectronic  Control \\nSystems at Lloyd\\'s Register (1330 \\nEnClave Pkwy #200, Houston, TX \\n77077;  Email:  don.crouch@lr. \\norg).  He also serves as the com \\npany\\'s lead for customer -fOCtJsed \\ncy!Jersecurity  development  and \\nsupport  in the  energy  sector. He \\nmanages field and  office person \\nnel who specialize  in  evaluating  industrial  automation \\ncontrol systems. assisting in correcting problems, pro \\nviding recommendations for improvement of equipment \\noperation  and  maintenance,  ensuring  adherence  to \\ngovernment  and  industry  regulations  and  reducing \\nequipment downtime. His expertise is in design, mainte \\nnance, diagnostics and repair of all levels of automated \\nelectronic  and  electrohydraulic  control  systems  from \\ncomponent level to full system integrations. With more \\nthan  25  years  of  experience  in automation. CrouCh \\nbegan his career training in electronics while serving in \\nthe U.S. Navy. Post·service employment included  Ray \\ntheon and Lockheed Martin. He is a participating mem \\nber of the Institute of Electrical and Electronic Engineers \\n~EEE) and the International Society of Automation (ISA). \\n\\nFIGURE 4. No sector of industry is immune to cyberattacks, and cyber criminals will continue to tailor \\ntheir skills to match trends in digital technologies. But companies can equip themselves with the knowl \\nedge and awareness to take proactive measures to safeguard their assets \\n\\nform  that allows  them  to tailor con \\ntent  to  suit  their  employees  and \\nspecific  critical  cyber  risks.  Ideally, \\nsuch  a training  platform  requires  no \\ncomplex  integration,  and  includes \\nthe  option  for  employees  to  also \\naccess  the  content  remotely \\nfor \\nincreased flexibility. \\n\\nAlso available are diagnostic tools \\nthat  can  assess  employees\\'  exist \\ning levels of security knowledge and \\nbuild  personalized \\nlearning  path \\nways. This allows companies to pro \\nvide the modules they think are nec \\nessary for different roles and levels of \\nknowledge.  This  tailored  approach, \\ntogether with regular built-in assess \\nments,  ensures  maximum  training \\neffectiveness,  increases  employee \\nengagement  and  improves  opera \\ntional efficiency. \\n\\nComprehensive  training  can  help \\nto  align  people,  processes  and \\ntechnology  with \\ntheir  company\\'s \\npriorities  and  risks,  including  threat \\nintelligence,  governance,  risk  and \\ncompliance, security testing, training \\nand strategy, managed security ser \\nvices and incident response. Under \\nstanding  the risk environment of the \\ndigital world can help to identity gaps \\nin  systems,  as  well  as  knowledge \\ngaps with inexperienced employees, \\nand bring  awareness and resilience \\nfor cyber threats to businesses. \\n\\nWhat will be the new norm? \\nWhat is on the horizon for the cyber \\nworld?  Cyber-domain  experts  are \\nseeing  a  lot  of  new  trends;  spe \\ncific  areas  that  are  evolving  include \\nincreased  exposure  due  to  inter \\nnet  of things  (loT}  technologies,  in-\\n\\ncreased  ransomware  attempts  and \\nexpanded  regulations.  Ransomware \\nattacks  may  threaten  to  release \\nsensitive  information  unless  terms \\nare met  or a certain  price is  paid  to \\nthe attacker. \\n\\nGlobally, nations and governments \\nare  responding  to  higher  levels  of \\ncyber-threat mitigation. For example, \\nSingapore\\'s  Minister  for  Communi \\ncations  and  Information  recently  in \\ntroduced  a  new  standalone  Cyber \\nsecurity Act.  Singapore is  reviewing \\nthe policy and legislative  framework \\nfor  cybersecurity.  The  Cybersecu \\nrity Act  reflects  the  Singapore  gov \\nernment\\'s  calibrated  and  balanced \\ntowards  countenancing \\napproach \\ncybersecurity threats. It is borne out \\nof  an  attempt  to  strike  a  balance \\nbetween  the  need  for  regulatory \\nauthorities  to designate,  investigate \\nand  receive  information  on  critical \\ninformation infrastructure and cyber \\nsecurity threats vis-a-vis the burdens \\nimposed on  companies and  private \\nindividuals in the IT industry. \\n\\nCyber  risks  are  rising,  and  soci \\nety\\'s technological advances appear \\nto  contribute  to  their  proliferation. \\nExperts suggest  that  beyond  indus \\ntrial  threats,  the  number  of  cyber \\nincidents \\ninvolving  goo-location \\nsystems  may  cause  disruptions  in \\nenergy supply chains  and  shipping, \\nas  well  as  risks  to  consumers  who \\nare reliant on  GPS-based  products. \\nFurthermore,  as  bitcoin  and  other \\ncryptocurrencies  become  more \\nwidely  adopted,  experts  expect \\nto  see  more  frequent  and  severe \\nransomware campaigns. \\n\\nClearly,  no organization  - or  for \\n\\n68 \\n\\nCHEMICAL ENGINEERING  WWVV.CHEMENGONLINE.COM  OCTOBER 2018 \\n\\n\\x0cReproduced with permission of copyright owner. Further reproduction\\n\\nprohibited without permission.\\n\\n\\x0c', 'Article\\n\\nCyber resilience: How important\\nis your reputation? How effective\\nare your people?\\n\\nNick Wilding\\nHead of Cyber Resilience, AXELOS Global Best Practice, UK\\n\\nBusiness Information Review\\n2016, Vol. 33(2) 94–99\\nª The Author(s) 2016\\nReprints and permission:\\nsagepub.co.uk/journalsPermissions.nav\\nDOI: 10.1177/0266382116650299\\nbir.sagepub.com\\n\\nAbstract\\nCybersecurity has been an increasing concern over the past few years, with a string of high-profile corporate cyberattacks\\nunderlining our growing dependency on secure data. This article argues that we need to move beyond the concept of\\ncybersecurity towards cyber-resilience. It outlines how an organization can approach preventing, detecting, responding to\\nand recovering from cyberattacks with minimal damage to their reputation and competitive advantage.\\n\\nKeywords\\nCyberattacks, cyber resilience, risk, information security\\n\\nIntroduction\\n\\n‘It takes 20 years to build a reputation and five minutes to ruin\\nit’ (Warren Buffett)\\n\\nBoard meetings will never be the same again! Since the\\nvery public cyberattack on TalkTalk in the UK in late\\nOctober 2015 and following numerous other high-profile\\nCEO apologies business leaders are now realizing the real\\ndamage that a cyberattack can have on their organization.\\nHard-won reputations, both corporate and personal, com-\\npetitive advantage and market value are all at risk.\\n\\nDirectors and non-exec directors in organizations of any\\nsize and in any sector increasingly regard cyberattack as one of\\nthe greatest risks they face. But typically, there remains a gap\\nbetween their awareness and understanding of the risk and\\nmanaging an informed cyber resilience strategy that helps to\\nenable rather than hinder the business and its operations. The\\nboard have to be asking the right questions to really understand\\nhow their cyber risks are affecting their mission, customer\\ntrust, intellectual property, commercially sensitive informa-\\ntion and their operational capabilities. The risks of doing\\nnothing are too great. Critically, they need to understand the\\nrole all their people must play in protecting what’s most\\nimportant to the boardroom.\\n\\n24 hours can be a very long time for a board in managing a\\ncyber crisis in the critical glare of international press and\\nmedia.\\n\\nThe questions will keep coming: Who has been affected\\nby the attack? What information has been lost? How did\\nthe attack happen? Where was the information and how\\nwere you protecting it? When did you know about the\\nattack? What steps are you taking to mitigate the risk and\\nminimize the harm felt by your customers? Simple ques-\\ntions but difficult to answer effectively in front of the\\ncameras. One of the facts for any board dealing with a\\ncrisis following an attack is that they won’t know all the\\nfacts. Is this a situation you want to face and are you\\nready?\\n\\nRarely a week goes by without us watching or reading\\nabout the latest organization who is dealing with an embar-\\nrassing cyberattack in the media. The harsh reality in\\ntoday’s totally connected age is that no organization can\\n\\nThe impact of cyberattacks\\n\\nThe impacts of a successful cyberattack can be devastating.\\nIt’s been said that a week is a long term in politics – today,\\n\\nCorresponding author:\\nNick Wilding.\\nEmail: nick.wilding@axelos.com\\n\\n\\x0cWilding\\n\\n95\\n\\never be bulletproof, no organization can ever say that\\nthey’re safe from attack and no organizations or individual\\nis immune from being targeted. All leadership teams need\\nto understand that they are being attacked, have been com-\\npromised and that these risks they face will continue to\\nevolve, adapt and become more persistent. As Ian Living-\\nston, former Chief Executive of the BT Group, said at\\nDavos in January 2013: ‘There are two types of CEO, those\\nthat know their systems are being hacked – and those that\\ndon’t. For pretty much any company I’ve come across, it\\nshould be one of the top three risks’. Cyberattacks are now\\nbusiness as usual and cyber resilience should be a standard\\nagenda item at board meetings.\\n\\nGlobal investment on cybersecurity technologies is con-\\ntinuing to rise. Global investment is security technologies\\ncontinues to rise but the threat landscape also continues to\\nadapt and evolve. Symantec in their ‘Internet Security\\nThreat Report’ published in April 2016 (https://www.sy-\\nmantec.com/content/dam/symantec/docs/reports/istr-21-\\n2016-en.pdf) state:\\n\\nSymantec discovered more than 430 million unique new\\npieces of malware in 2015, up 36 percent from the year\\nbefore. Perhaps what is most remarkable is that these num-\\nbers no longer surprise us. As real life and online become\\nindistinguishable from each other, cybercrime has become a\\npart of our daily lives. Attacks against businesses and\\nnations hit the headlines with such regularity that we’ve\\nbecome numb to the sheer volume and acceleration of\\ncyber threats.\\n\\nThere’s something missing between our continued\\ninvestment in and expectation that technology can solve\\nour problem and the growing number of attacks.\\n\\nTom Farley, President of the New York Stock Exchange,\\nsaid in his introduction to ‘Navigating the Digital Age: the\\ndefinitive cybersecurity guide for directors and officers’ in\\n2015:\\n\\nIt is important companies remain vigilant, taking steps to\\nproactively and intelligently address cybersecurity risks within\\ntheir organisation. Beyond the technological solutions devel-\\noped to defend and combat breaches, we can accomplish even\\nmore through better training, awareness and insight on human\\nbehaviour. Confidence, after all, is not a measure of technolo-\\ngical systems, but of the people who are entrusted to manage\\nthem.\\n\\nVerizon’s 2015 Annual Data Breach report highlighted\\none stark fact. The great majority – estimated to be 90 per\\ncent – of successful cyberattacks succeed because of\\nhuman error. Anyone in any organization, irrespective of\\ntheir role or seniority, can enable an attack to succeed\\ntypically through their unwitting actions. Cyberattackers\\nhave the upper hand – they only need to be successful once.\\n\\nAll your people have to be aware and capable to make the\\nright decisions every time they’re exposed to different\\ncyber risks. How confident are you that your people are\\ndisplaying the appropriate behaviours and understand the\\npractical things they need to do to effectively protect the\\ninformation and systems that are most precious and valu-\\nable to you?\\n\\nFrom cyber security to cyber resilience\\n\\nOrganizations need to be thinking about cyber resilience\\nnot just cyber security. Cyber resilience can be described\\nas the ability of any organization to prevent, detect,\\nrespond and recover from the impacts of an attack with\\nminimal damage to their reputation and competitive\\nadvantage.\\n\\nSo how resilient are organizations? Recent research by\\nthe Ponemon Institute, among 450 security and IT profes-\\nsionals around the world, reported that only 29 per cent of\\norganizations rate their cyber resilience as high. Only\\n15 per cent of respondents reported collaboration in the\\norganization as excellent and nearly one-third said colla-\\nboration was poor or non-existent.\\n\\nThe challenge appears clear. All our people must be\\nplaying a more significant and specific role in our organi-\\nzational resilience. How many times do we read or hear that\\nour staff are our weakest link? Yet, they are only as weak as\\nthe strength of the awareness learning we provide them –\\ndoes it engage?, is it relevant to the learner?, does it provide\\nsimple, practical guidance? and is it focused on giving them\\nthe confidence to change their existing behaviours and to\\ndiscuss incidents with their colleagues?.\\n\\nThe sad truth is that most organizations typically edu-\\ncate their people in their annual information security\\nawareness e-learning. It’s widely acknowledged that this\\nyearly, compliance ‘tick-box’ approach to learning fails\\nto engage and has little or no impact on your people’s cyber\\nbehaviours.\\n\\nCan e-learning really change behaviours? Yes. But not\\nin its current form – a one-off course, required once,\\ndesigned once, delivered once, completed once and forgot-\\nten at once. The annual one-off course usually takes over an\\nhour to complete. It ignores some simple rules for effective\\n\\n\\x0c96\\n\\nBusiness Information Review 33(2)\\n\\nlearning. Over 100 years ago Hermann Ebbinghaus, an\\neminent German psychologist pioneered the experimental\\nstudy of memory and is known for identifying the ‘forgetting\\ncurve’. He found that 40 per cent of information presented as\\nlearning is forgotten in the first 20 minutes, more than half of\\nall information is forgotten after one hour and only a fifth of\\nall information is remembered after one day.\\n\\nWith cyberattacks now targeting and threatening our\\nmost sensitive and valuable information forgetting sadly\\nis no longer an option. Ignorance isn’t a defence anymore.\\nThe risks and impacts are too great.\\n\\nIn this vital area of staff training and development, one\\nsize doesn’t fit all. The current ‘all staff, once a year’\\napproach, simply does not influence or change behaviours.\\nAt best, it reminds us of some essentials, at worst, it’s\\ntreated as unnecessary, a distraction and as something I\\nhave to do . . . or else. Annual e-learning will not instil\\nand sustain the cyber resilient behaviours that employees\\nneed today. We’re trying to ‘programme’ our people in the\\nsame way we programme computers to do certain things, in\\ndefined ways at certain times. This approach doesn’t work\\nwith people.\\n\\nInstead, there needs to be a range of learning techniques\\nthat truly engage all our people, embedding and sustaining\\nthe resilient behaviours required to more effectively protect\\nan organization’s most sensitive and valuable information\\nand systems.\\n\\nWhat generally dictates the capability and performance\\nof anyone, working anywhere is the relevance and effec-\\ntiveness of the training and learning they’re given and the\\nbehaviours they adopt as a result of this. During January\\n2016, AXELOS RESILIA carried out research with IPSOS\\nMori among those responsible for information security\\nawareness learning in their organizations. We wanted to\\nfind out how well prepared the UK’s workforce is for a\\ncyberattack in the companies they work for. The results\\nwere telling.\\n\\nWhile it was positive to note that 99 per cent of business\\nexecutives responsible for cyber awareness learning said that\\ninformation security awareness learning is ‘important to\\nminimise the risk of security breaches’, less than a third of\\nthem (28 per cent) judged their organization’s cyber security\\nawareness learning as ‘very effective’ at changing staff\\nbehaviour. A similar minority (32 per cent) were ‘very con-\\nfident’ that the learning is relevant to staff, while 62 per cent\\nwere only ‘fairly confident’ that their learning is relevant.\\n\\nThis comparatively low level of corporate confidence in\\nthe ability of people to deal with a potential cyberattack is\\nsimply not good enough in an era where cybercrime has\\nbecome ‘business as usual’. It reflects either a lack of\\nunderstanding, or a state of denial, about the impact that\\na successful cyberattack can have on a business: reputa-\\ntional damage, loss in competitive advantage and disrupted\\noperations. Organizations cannot continue accepting this\\nlevel of employee awareness and competence in the face\\n\\nof sophisticated cybercriminals who are constantly adapt-\\ning their methods to target our most sensitive and precious\\ninformation and systems.\\n\\nImagine how your customers would respond if told that\\n‘we’re fairly confident that your precious information is\\nsafe from attack’. Equally, reporting to a board of direc-\\ntors that the level of confidence in the organization’s\\ninformation security awareness is only ‘fair’ would be\\ngiven short shrift. If UK company boards are not asking\\nthose responsible about the current effectiveness of their\\nawareness learning among their people and what is being\\ndone to improve their cyber resilience, then they should\\nbe. Now!\\n\\nWe need to understand that we all learn differently and\\nat different speeds. We need to provide the awareness that\\nprovides our people with the confidence to share and dis-\\ncuss experiences, to get involved in the learning, to cham-\\npion resilience and to learn and adapt.\\n\\nThat’s why the picture of preparedness painted by our\\nresearch suggests that the current, compliance-based\\napproach relied upon by the majority of organizations’ cur-\\nrent approaches is failing.\\n\\nA new approach is required – one where information\\nsecurity or cyber awareness learning is conceived of a con-\\ntinuous, ongoing and sustainable campaign over time. Just\\nas our technical security controls will evolve and adapt to\\nsuit changing cyber threats and vulnerabilities, so we need\\nto ensure all our people maintain their awareness and are\\nprovided with the appropriate, practical guidance on a con-\\ntinual basis that fits the needs and requirements of the\\nparticular organization.\\n\\nThere are some simple guiding principles to ensuring\\nyour cyber awareness learning campaign remains effective\\nand engaging:\\n\\n1. People pay attention to leaders: Getting the buy-in\\nand involvement of those at the top can highlight\\nthe positive benefits of resilient behaviours, assist in\\nrewarding and inspiring all staff and illustrate just\\nhow seriously the leadership team is committed to\\nprotecting their organizations’ most sensitive infor-\\nmation and systems.\\n\\n2. Memories are fragile: Always plan to reinforce,\\nrefresh and evolve the learning content and\\ndelivery techniques with your staff on a regular\\nbasis. Combining engaging online learning con-\\ntent and formats with offline activities such as\\nlive events, competitions, surveys and team\\nlearning sessions can help sustain and instil\\nthe understanding and importance of new\\nbehaviours.\\n\\n3. People learn differently: Develop your campaign\\naround a lively mix of different online formats –\\ngames, animation, simulations and videos – to\\nenable different people to choose their preferred\\n\\n\\x0cWilding\\n\\n97\\n\\nlearning style but ultimately all providing the same\\nlearning outcomes. Exploiting the latest develop-\\nments in game play, for example, assist in immer-\\nsing the learner in the problem and helps to provide\\nsimple, pragmatic advice for how to ‘beat’ the\\nattack.\\n\\n4. People remember stories over facts: Critically\\nensure you fix a message in your learner’s minds\\nby appealing to their hearts. Great campaigns have\\ngreat stories to tell. The cyberattack stats are clear\\nto see for anyone and yet organizations remain\\n\\nhighly vulnerable to even the simplest attacks. Talk\\nabout business impacts and consequences not tech-\\nnology and jargon.\\n\\n5. A great example of this is ‘Whaling for Beginners’,\\na short story thriller written for RESILIA that fol-\\nlows the journey made by Jim Baines, the CEO of a\\nUS packaging company as he realizes just how cat-\\nastrophic a cyberattack can be and how easily hard-\\nwon reputations and competitive advantage can be\\nirreparably damaged. (More on Whaling for Begin-\\nners is given below.)\\n\\n6. Use every mean at your disposal: Always stay agile,\\nalways adapt, fine tune, pilot new techniques and\\nreact quickly to the latest attack stories and how\\nthey affect your people. Also consider identifying\\nteam ‘champions’ and ‘mentors’ who you can\\ninvolve in the design not just in doing the learning.\\nThis has been seen to help build a powerful culture\\nfrom the bottom-up not just from the top-down.\\n\\nAs phishing attacks and social engineering continue to\\naccount for the large majority of successful cyberattacks,\\ninfluencing and improving human behaviours must sit at\\nthe heart of any effective cyber resilience strategy and\\nresponse. The future success of an organization will depend\\non their people recognizing their part in the operational\\nhealth of the organization and feeling valued in that\\nresponsibility.\\n\\nRESILIA Awareness Learning modules provide your\\npeople with the knowledge, skills and confidence to adopt\\nnew behaviours designed to grow your firm’s cyber\\nresilience.\\n\\nUsing a range of innovative learning tools and tech-\\nniques, RESILIA Awareness focuses on building, main-\\ntaining and measuring the effectiveness of the awareness\\nlearning provided to the workforce. The approach taken by\\nRESILIA Awareness Learning is different for a number of\\nreasons:\\n\\n(cid:2) It provides ongoing, short, practical advice that\\n\\nminimizes day-to-day disruption.\\n\\n(cid:2) Its adaptive and personalized content can be\\nmatched to learner preferences for how they learn.\\n(cid:2) It offers engaging, competitive and fun content for\\n\\neffective learning.\\n\\n(cid:2) It provides measurable outcomes for an organization\\nand their people based on skills and knowledge\\nimprovement.\\n\\n(cid:2) It can meet existing compliance requirements of reg-\\n\\nulatory bodies as appropriate.\\n\\nThe RESILIA Awareness solution is continually devel-\\noped to ensure the content provided and techniques used to\\n\\n\\x0c98\\n\\nBusiness Information Review 33(2)\\n\\ndeliver the learning remain up-to-date, relevant and role\\nand sector specific. The suite of learning includes:\\n\\n(cid:2) Phishing\\n\\n(cid:2) Information handling\\n\\n(cid:3) Understand how different types of information\\n\\nshould be stored, shared and destroyed.\\n\\n(cid:2) Remote and mobile working\\n\\n(cid:3) Understand how phishing emails are used to\\nsteal sensitive information, launch cyberattacks\\nand how to prevent them.\\n\\n(cid:3) Understand the risks of using removable media,\\nwhen it should be used and what precautions to\\ntake to protect sensitive information.\\n\\n(cid:2) Social engineering\\n\\n(cid:3) Understand how our willingness to help others is\\nabused by criminals to launch cyberattacks.\\nUnderstand how to recognize a social engineer-\\ning attack and how to avoid them.\\n\\n(cid:2) Online safety\\n\\n(cid:3) Understand the basics of how to work safely and\\nresponsibly online and how to protect sensitive\\ninformation when browsing.\\n\\n(cid:2) Social media\\n\\n(cid:3) Understand how to use social media (Facebook,\\nTwitter, LinkedIn, blogs, etc.) securely and\\nresponsibly.\\n\\n(cid:2) Bring your own device (BYOD)\\n\\n(cid:3) Understand what risks these bring and what basic\\nmeasures should be taken to protect you and your\\nemployer and their clients’ sensitive information.\\n\\n(cid:2) Removable media\\n\\n(cid:3) Understand risks of using removable media,\\nwhen it should be used and what precautions to\\ntake to protect sensitive information.\\n\\n(cid:2) Password safety\\n\\n(cid:3) Understand how to use, how to create strong pass-\\nwords and how to help prevent your password\\nbeing compromised to gain unauthorized access\\nto sensitive information and critical services.\\n\\n(cid:2) Personal information\\n\\nWhile the level and quality of the cyber awareness learn-\\ning is clearly alarming, so is the misplaced confidence in\\ntechnology to prevent cyber breaches. Wherever there are\\npeople in an organization – from the executive suite to the\\nshop floor – there are vulnerabilities.\\n\\nAdopting a new approach to cyber awareness learning\\nacross your whole organization and wider partner/supplier\\necosystem will provide greater resilience and tangible busi-\\nness value. By designing, implementing and managing\\neffective and regular awareness learning:\\n\\n(cid:2) reduce your risk of a successful and damaging\\n\\ncyberattack;\\n\\n(cid:2) grow a cyber-smart and engaged workforce;\\n(cid:2) have an effective, efficient and consistent delivery\\n\\nmechanism;\\n\\n(cid:2) have an effective cyber control that addresses your\\n\\npeople-based cyber risk and\\n\\n(cid:2) have an effective, consistent and efficient addition to\\n\\nyour security controls environment.\\n\\n(cid:3) Understand what constitutes personally identifi-\\nable information and what your responsibilities\\nare to help keep this sensitive information secure.\\n\\nIn their Cyber Risk Oversight for Boards the US\\nNational Association of Corporate Directors stated in\\n\\n\\x0cWilding\\n\\n99\\n\\n2015: ‘‘Cyber resilience is a serious corporate risk issue\\naffecting virtually all levels of significant business activ-\\nity.’’ Ultimately, as one director put it: ‘Cybersecurity is a\\nhuman issue’.\\n\\nAs Gary Warzala, senior vice president and chief infor-\\nmation security officer at PNC Bank, a leading US retail\\nbank, has said: ‘Cyber resilience comes down to having an\\norganisation of people who are cyber aware, curious, ask-\\ning the right questions, actively and continually engaged in\\nlearning and who are not just ticking the box’.\\n\\nWithout all of this it is just a matter of time before you’ll\\nbe expected to respond to a successful attack or significant\\ndata breach. Where would you rather be?\\n\\nDeclaration of Conflicting Interests\\nThe author(s) declared no potential conflicts of interest with\\nrespect to the research, authorship, and/or publication of this\\narticle.\\n\\nFunding\\nThe author(s) received no financial support for the research,\\nauthorship, and/or publication of this article.\\n\\nAuthor biography\\n\\nNick Wilding is Head of Cyber Resilience at AXELOS Global\\nBest Practice – a joint venture company set up in 2013 and\\nco-owned by the UK Government and Capita plc – which owns\\nand develops a number of best practice methodologies, including\\nITIL1 and PRINCE21 used by organizations in more than\\n150 countries to enable them to work and operate more effec-\\ntively. He is responsible for RESILIA™ Global Best Practice –\\na portfolio of cyber resilience best practice publications, certified\\ntraining, all staff awareness learning and leadership engagement\\ntools designed to put the ‘human factor’ – your people – at the\\ncentre of your cyber resilience strategy, enabling you to effec-\\ntively recognize, respond to and recover from cyberattacks.\\n\\n\\x0c', 'BMJ 2017;358:j3179 doi: 10.1136/bmj.j3179 (Published 2017 July 06)\\n\\nPage 1 of 4\\n\\nAnalysis\\n\\nANALYSIS\\n\\nCybersecurity and healthcare: how safe are we?\\nRising cybersecurity threats to healthcare require policy makers to tackle fragmented governance,\\nto develop and implement security standards, and to help organisations to improve their resilience,\\nsay Guy Martin and colleagues\\n\\nGuy Martin clinical research fellow 1, Paul Martin honorary principal research fellow 2, Chris Hankin\\ndirector 2, Ara Darzi director of the Institute of Global Health Innovation 1, James Kinross senior\\nlecturer in surgery 1\\n\\n1Department of Surgery and Cancer, Imperial College London, 10th Floor QEQM Building, St. Mary’s Hospital, Praed Street, London W2 1NY, UK;\\n2Institute for Security Science and Technology, Level 2 Admin Office, Central Library, Imperial College London, South Kensington Campus, London,\\nUK\\n\\nHealthcare systems around the world have rightly identified the\\nhuge potential for digital technology to improve clinical\\noutcomes and transform care delivery.1 But the recent WannaCry\\nmalware attack has once again highlighted cybersecurity as a\\ncritical patient safety issue requiring urgent solutions.\\nCybercrime—a universal challenge\\n\\nCyberattacks usually steal money, data, or intellectual property,\\nbut increasingly the aim is to cause overt disruption or political\\nimpact. They are often transnational and state sponsored;\\nattributing them to individuals can be difficult. Many attacks\\nare undetected or unreported, and only a small minority enter\\nthe public domain; among recent examples are the major\\nbreaches at TalkTalk, Mossack Fonseca, the US Democratic\\nNational Committee, and Yahoo. The global cost of cybercrime\\nin 2014 was estimated to be $575bn (£440bn; €500bn).2\\n\\nCybercrime and healthcare\\n\\nHealthcare faces even larger cyber risks than other sectors\\nbecause of inherent weaknesses in its security posture. It is one\\nof the most targeted sectors globally; 81% of 223 organisations\\nsurveyed, and >110 million patients in the US had their data\\ncompromised in 2015 alone.3 4 Only half of these providers think\\nthat they are capable of defending themselves from cyberattack,\\nand there has been a 300% increase in attacks in the past three\\nyears,3 5 For those conducting cyberattacks the healthcare sector\\nis an attractive target for two simple reasons: it is a rich source\\nof valuable data, and it is a soft target. The current and emerging\\ncyber risks to healthcare are outlined in box 1.\\n\\nThe healthcare sector is usually targeted for financial gain;\\ncybersecurity aims to protect the confidentiality, integrity ,and\\navailability of valuable healthcare data. Protecting\\nconfidentiality means ensuring that sensitive information,\\n\\nespecially identifiable data, does not reach the wrong people.\\nIn 2015 criminals stole 80 million records from Anthem, a US\\nhealth insurance company. Given that individual medical records\\nare traded on the “dark web” for around $50, this breach had a\\nmarket value of a billion dollars or more.6 Medical records,\\nespecially those in the US, are worth much more on the black\\nmarket than credit card details because they contain multiple\\npermanent identifiers and financial information.4 Unlike credit\\ncards, these identifiers cannot be reset, and a person’s records\\nmight contain enough information to open bank accounts, obtain\\nloans, or acquire a passport. Protecting integrity means ensuring\\nthe accuracy and trustworthiness of data, and protecting\\navailability means maintaining reliable access to the data and\\nto the systems used to process and store the data.\\n\\nThe fallout from the global WannaCry ransomware attack in\\nMay 2017 is still settling; it reportedly affected around 200 000\\nsystems in more than 150 countries.7 Around 50 hospitals in the\\nUK were directly affected, and many more pre-emptively shut\\ndown their computer systems causing considerable disruption—\\naffecting care delivery, compromising patient safety, and\\npotentially eroding trust. The attack used a prevalent type of\\nmalware known as ransomware; a malicious piece of software\\nthat encrypts the victim’s data, blocks access to them, and\\nthreatens to publish or delete them unless a ransom is paid. The\\nonly way to regain access to the infected computer and data is\\nto pay the ransom or to wipe the system and retrieve a backup.\\n\\nThe WannaCry attack, though hugely disruptive, did not\\nspecifically target the healthcare sector, but this has not always\\nbeen the case. In 2016 a ransomware attack on the Hollywood\\nPresbyterian Medical Center shut down its network for 10 days,\\npreventing staff from accessing medical records or using medical\\nequipment until the hospital paid the ransom (reportedly 40\\nBitcoins, or about $17 000).8 The infection is thought to have\\ntaken place through a “phishing” email. These are the\\n\\nCorrespondence to: J Kinross j.kinross@imperial.ac.uk\\n\\nFor personal use only: See rights and reprints http://www.bmj.com/permissions\\n\\nSubscribe: http://www.bmj.com/subscribe\\n\\n\\x0cBMJ 2017;358:j3179 doi: 10.1136/bmj.j3179 (Published 2017 July 06)\\n\\nPage 2 of 4\\n\\nANALYSIS\\n\\nBox 1: Common and emerging cyber threats in healthcare\\n\\nData theftfor financial gain—stealing personal data for the purposes of monetary gain; for example, names, addresses, social security\\ndetails, financial information\\n\\nData theft for impact—theft and public release of sensitive medical information; for example, celebrities, politicians, or other high profile\\npeople\\n\\nRansomware—using malware to block users from their data or systems or to delete data unless a fee is paid\\n\\nData corruption—deliberate corruption of data , such as altering test results, for political or personal gain\\n\\nDenial of service attacks—disruption of a network or system by flooding it with superfluous requests, motivated by blackmail, revenge,\\nor activism\\n\\nBusiness email compromise—creating fake personal communications for financial gain; for example, obtaining fraudulent payments or\\npersonal information\\n\\nThe unwitting insider—substantial disruption to systems or the loss of data owing to the unintentional actions of staff using outdated\\nand at-risk systems\\n\\ncommonest means of delivering malware and are hard to defend\\nagainst. Even in security conscious organisations, the click rate\\non a well crafted phishing email can be up to 30%.4 Ransomware\\nhas affected other hospitals: one English hospital was forced to\\ncancel all operations and transfer patients for two days in\\n2016,9 10 and Boston Children’s Hospital and hospitals in\\nGermany have also been targeted.11 Freedom of information\\nrequests in the UK found that in 2015-16 up to half of NHS\\ntrusts were hit by ransomware in the preceding year.12 Despite\\nthese well publicised attacks and the availability of security\\npatches, the warnings went largely unheeded resulting in the\\nmajor disruption caused by WannaCry.\\n\\nAlthough the healthcare sector is usually targeted for financial\\ngain, other motives have also been reported. In 2016 1.28 million\\nrecords from the Australian Red Cross Blood Service that\\ncontained large amounts of sensitive information, including\\ndonors’ at-risk sexual behaviour, were posted on a public website\\nfor no clear motive but to expose security flaws.9 13 Cyberattacks\\nare also used for political impact—most notably in the recent\\nattacks against the World Anti-Doping Agency, in which the\\nmedical records of prominent athletes were released.14 Hackers\\nlinked to the militant group Islamic State have directly targeted\\nNHS websites for propaganda purposes.15 Other scenarios in\\nwhich high profile people are targeted to damage their\\nreputations are easy to imagine.\\n\\nWhy is healthcare so vulnerable?\\n\\nThe vulnerability of healthcare to cyberattack reflects a\\ncombination of factors, notably limited resources, fragmented\\ngovernance, and cultural behaviours. Compared with other\\nsectors, such as financial services, healthcare has chronically\\nunderinvested in information technology (IT) infrastructure.\\nMany NHS organisations spend as little as 1-2% of their annual\\nbudget on IT, compared with 4-10% in other sectors,16 and use\\nmany run-on legacy systems that are no longer supported.\\nIndicative of this low level of investment many NHS trusts are\\nstill using Windows XP, an operating system that Microsoft\\nstopped supporting in 2014.17\\nIn addition, cybersecurity experts are in short supply, and cash\\nstrapped healthcare organisations cannot afford to pay the market\\nrate for their services. Fragmented governance is another big\\nproblem, leading to a lack of clarity over who is responsible for\\nsecuring systems and data. The UK healthcare sector comprises\\nmany thousands of distinct entities, and clear accountability and\\nresponsibility for cybersecurity at a national level are lacking.\\nFinally, the culture of healthcare understandably focuses on\\ncaring for patients, even at the expense of security. One\\nsymptom of this patient first culture is the widespread sharing\\nof passwords—a practice that makes sense but undermines\\nsecurity.\\n\\nWhat does the future hold?\\n\\nSo far, attacks on healthcare have principally been for financial\\ngain; the integrity of data has not been compromised. But we\\nface the prospect that, intentionally or unwittingly, it will be.\\nConsider the harm that could be caused by altering blood groups\\nor test results.\\n\\nAnother worrying prospect is that of malicious cyberattacks on\\nmedical devices. In 2014 more than 300 medical devices were\\nidentified as being at risk.4 In 2016 patients were warned of a\\nvulnerability that could allow hackers to take control of the\\nAnimas OneTouch insulin pump.18 Barnaby Jack, a well known\\nhacker, has shown how to hack a Medtronic insulin pump to\\ndeliver a lethal insulin dose with a remote control.19 Risks such\\nas these seem set to rise with the rapid growth in consumer,\\nwearable, and mobile technologies.4-21\\nPoor cybersecurity also has major financial and reputational\\nrisks for healthcare. Every European institution, including\\nhealthcare providers, should be thinking about the implications\\nof the General Data Protection Regulation, which comes into\\neffect in 2018. Among other things, the regulation makes it\\nmandatory to report security breaches within 72 hours;\\nnon-compliance can result in a fine of up to €20m or 4% of\\nannual global turnover.22 The UK has had little central guidance\\nor leadership on how organisations can meet these\\nresponsibilities. Another worry is that large scale compromises\\nof patient data might undermine public confidence, making\\npatients more reluctant to share their data with clinicians or\\nresearchers.23 24\\n\\nWhat can the healthcare sector do?\\n\\nCybersecurity can never be 100% effective, and the threat to\\nhealthcare is an unavoidable new reality. But individuals and\\norganisations can take practical steps to protect themselves and\\nto reduce the effects of an attack.\\n\\nAn ultimate aim of cybersecurity should be to strengthen\\nresilience. Resilient organisations are less likely to have their\\nsecurity breached and suffer less harm when breaches do occur.\\nA simple approach to improving resilience is by maintaining\\nsecure and up-to-date backups so that an attack will not result\\nin the permanent loss of data. In the case of a cyberattack on\\nPapworth Hospital in 2016, a ransomware infection fortuitously\\nhappened just after the daily backup, so no data were lost.25\\nMore generally, good cybersecurity should be incorporated into\\nthe design of new IT projects from the outset and should be\\ninherent in all healthcare systems. Security that is bolted on, or\\nworse still, thought about only after a major incident is often\\nmore expensive and less effective.\\n\\nAnother mechanism for enhancing resilience is insurance—a\\nrapidly growing business with global sales of $2.75bn in 2015.26\\n\\nFor personal use only: See rights and reprints http://www.bmj.com/permissions\\n\\nSubscribe: http://www.bmj.com/subscribe\\n\\n\\x0cBMJ 2017;358:j3179 doi: 10.1136/bmj.j3179 (Published 2017 July 06)\\n\\nPage 3 of 4\\n\\nANALYSIS\\n\\nThe rising costs might cause insurance companies to tread with\\ncaution in future, but the right insurance regime can drive\\nimprovements by providing financial incentives for organisations\\nto take better care of themselves. Healthcare providers need to\\nfind cost effective ways to protect themselves against the\\npotentially crippling costs of cyberattacks, in much the same\\nway as they do with the costs of clinical negligence.\\nCybersecurity can be further bolstered by national support for\\nincident management, organisational preparedness, and threat\\nadvice. The mechanisms for providing such support are\\nbeginning to emerge—for example, the CareCERT initiative\\nthe UK.27\\nIn addition to strengthening resilience, we need to develop\\ncommon security standards that are relevant to the healthcare\\nsector. Many general standards exist for cybersecurity, such as\\nthe CIS Critical Controls,28 NIST 800-53,29 and ISO27001.30\\nThe UK National Cyber Security Centre offers expert guidance\\non how organisations can protect themselves and grow\\nresilience, including their “10 steps to cybersecurity” (box 2).31\\nThese principles are linked to the UK government’s Cyber\\nEssentials Scheme, which provides guidance and an entry level\\nassurance framework to help mitigate common risks.32 Standards\\nare only helpful if they are relevant and are used. Currently, no\\nstandards are specifically designed for the healthcare sector and\\nnone is routinely or consistently applied. Fragmented\\ngovernance, huge interconnectivity, widespread access, the lack\\nof regulatory pressure on security, and limited resources indicate\\na need for healthcare specific cybersecurity standards and\\nsolutions.\\n\\nUS Congress recently established a task force to assess how the\\nhealthcare sector can protect itself from cyberattack, streamline\\nits leadership and create incentives for organisations to update\\ntheir networks.33 For the NHS to apply these lessons, NHS\\nDigital must take ownership and responsibility, deploying\\npractices well established in other industries, such as penetration\\ntesting, and developing sector specific standards so that local\\nresilience can be objectively measured, assessed, and\\nbenchmarked. Moreover, it must develop a national prevention\\nstrategy, consider introducing a centralised “cash for clunkers”\\nprogramme to provide organisations with additional funding or\\nincentives to replace outdated hardware and systems, and be\\nempowered to create and mandate local and national response\\nplans for cyber major incidents. Cybersecurity preparedness\\nand resilience must also be integrated into local and national\\nquality metrics—for example, through the Care Quality\\nCommission, to drive improvements and to explicitly hold local\\nand national leaders to account.\\n\\nConclusions\\n\\nThe healthcare sector is complex, fragmented, and chronically\\nshort of resources, yet it holds large amounts of sensitive and\\nvaluable data in vulnerable systems. Cybersecurity is not just\\nabout protecting data; it is fundamental for maintaining the\\nsafety, privacy, and trust of patients. Effective cybersecurity\\nmust become an integral part of healthcare systems, a pillar of\\nregulation, and the subject of future research strategies. We\\nmust urgently develop practical standards and solutions that are\\nspecific to the healthcare sector, agree clear lines of\\nresponsibility and governance, and commit appropriate resources\\nto the provision of adequate security.\\n\\nContributors and sources: Guy Martin is a surgeon and clinical research\\nfellow in the department of surgery at Imperial College London. James\\nKinross is a surgeon and senior lecturer in the department of surgery\\n\\nat Imperial College. Paul Martin is honorary principal research fellow at\\nthe Institute for Security Science and Technology at Imperial College\\nLondon and adviser to Context Information Security. Chris Hankin is\\nthe director of the Institute for Security Science and Technology and\\nprofessor of computing science at Imperial College London. Ara Darzi\\nis the Paul Hamlyn chair of surgery at Imperial College London. James\\nKinross, the corresponding author is the guarantor of the article.\\n\\nCompeting interests: The authors have read and understood BMJ policy\\non declaration of interests and declare no conflicts of interest.', '\\nCybersecurity in Health Care\\nEric D. Perakslis, Ph.D.\\n\\nMost of us are aware of cyber-\\n\\nthreats — if not because of \\npersonal experience, then thanks \\nto  a  barrage  of  news  stories. \\nWe’ve  read  that  many  of  our \\nbanks, credit-card companies, and \\nfavorite retailers have been hacked \\nand that tens of millions of con-\\nsumers  had  their  personal  finan-\\ncial information stolen during the \\n2013 holiday season. In addition, \\nlast year brought stories of suc-\\ncessful cyberintrusion at the Food \\nand  Drug  Administration  (FDA) \\nand  of  the  theft  of  the  designs \\nof  major  U.S.  military  weapons \\nsystems by foreign governments. \\nHealth care data and infrastruc-\\nture are at least as vulnerable as \\nmost financial and military data. \\n\\nAnd  beyond  the  pecuniary,  reg-\\nulatory,  and  reputational  risks \\nassociated with data and identity \\ntheft  lie  even  graver  threats  to \\nhealth  care  infrastructure  and \\npatient safety.\\n\\nIn a recent study, a whopping \\n94%  of  health  care  institutions \\nreported  having  been  victims  of \\ncyberattacks.1 To date, cybercrime \\nagainst health care has manifest-\\ned  as  four  specific  threats:  data \\nloss,  monetary  theft,  attacks  on \\nmedical  devices,  and  attacks  on \\ninfrastructure. Some cybercrimi-\\nnals  are  motivated  by  financial \\ngain, whereas others seek to ob-\\ntain intellectual property or con-\\nsumer  information,  to  damage \\nan  institution’s  reputation,  or  to \\n\\nmake  a  political \\nstatement \\nthrough  “hacktivism.”  The  pri-\\nvacy  and  security  rules  put  in \\nplace  by  the  Health  Insurance \\nPortability and Accountability Act \\n(HIPAA)  have  raised  awareness \\nof  the  importance  of  protecting \\npersonal health information and \\nhave provided a regulatory frame-\\nwork  to  encourage  compliance \\n— but compliance does not nec-\\nessarily  translate  into  security. \\nThe  fact  is  that  most  current \\nHIPAA  protection  strategies  rely \\non standard technological meth-\\nods of isolating critical data, but \\nthis  recent  study  indicates  that \\nmany  attackers  are  bypassing \\nthese types of protections and do \\nnot require stealth techniques to \\n\\n395\\n\\nn engl j med 371;5 nejm.org july 31, 2014PERSPECTIVE\\x0cdo  so.  There  is  a  substantial \\nknowledge  and  focus  gap  be-\\ntween  the  technology  domain \\nand  the  regulatory  compliance \\ndomain that needs to be closed.\\n\\nHealth  care  institutions  face \\nparticularly  high  financial  risk \\nfrom  data  theft,  owing  to  both \\ntheir liability profile and the vol-\\nume and variety of data they col-\\nlect  and  store.  Of  the  16  indus-\\ntries  studied  by  the  Ponemon \\nInstitute,  a  research  center  fo-\\ncused on privacy, data protection, \\nand  information  security  policy, \\nhealth  care  incurred  the  highest \\nper-record cost when a data loss \\noccurred: an estimated $233. The \\nmean for all industries was $136 \\nper record, with the retail indus-\\ntry  incurring  the  lowest  cost,  at \\n$78  per  record.2  Costs  include \\nthose  for  legal  actions,  recovery, \\nsecurity-control investments, and \\nextended  credit-protection  ser-\\nvices  for  victims.  If  these  esti-\\nmated costs applied to the Well-\\nPoint  data  breach  of  2009–2010, \\nin  which  security  flaws  left  the \\npersonal  and  health  information \\nof more than 600,000 health-plan \\nenrollees  openly  accessible,  the \\ntotal  cost  would  be  in  the  bil-\\nlions — dwarfing the $2 million \\nthat  WellPoint  had  to  pay  in \\nHIPAA  fines.  Within  the  health \\ncare industry, 72% of recent ma-\\nlicious traffic, viruses, and simi-\\nlar  attacks  have  been  directed \\nagainst  hospitals,  clinics,  large \\ngroup  practices,  and  individual \\nproviders,  with  the  remaining \\n28%  being  spread  among  pro-\\nvider organizations, health plans, \\npharmaceutical  companies,  and \\nother  entities;  in  other  words, \\nhealth  care  delivery  is  being  ag-\\ngressively and specifically targeted.\\nIn  addition  to  finding  ways \\nto protect against data theft, the \\nhealth  care  industry  must  focus \\non the other cyberthreats: finan-\\ncial theft, interference with med-\\n\\nical devices, and attacks on criti-\\ncal infrastructure. Financial theft \\noften  resembles  data  theft,  and \\nanalogous  protections  are  re-\\nquired. The recent theft of $1.03 \\nmillion from the payroll accounts \\nof  a  Washington  hospital,  per-\\npetrated  by  hackers  in  Ukraine \\nand  Russia  aided  by  more  than \\n100  accomplices  in  the  United \\nStates, shows how sophisticated \\nand  extensive  such  attacks  have \\nbecome.3\\n\\nBut threats to medical devices \\nand critical infrastructure may be \\nof  even  greater  concern  because \\nof  their  potential  effects  on  pa-\\ntient  health  and  safety.  Patients \\nare especially at risk from attacks \\nthat could disrupt critical medical \\ninfrastructure,  disrupt  commu-\\nnications  and  services,  interfere \\nwith medical devices, or alter or \\nfalsify critical data or make them \\nunavailable.  The  “internet  of \\nthings,” which connects physical \\nequipment, such as patient moni-\\ntors, that contains sensors or ac-\\ntuators  and  is  programmed  elec-\\ntronically,  has  enabled  remote \\nand  distributed  access  to  many \\ndiagnostic  and  treatment  capa-\\nbilities  within  health  care  insti-\\ntutions, but such connectivity has \\nalso  created  opportunity  for  at-\\ntacks. Since 2009, the Department \\nof  Veterans  Affairs  has  tracked \\nhundreds of infections of devices \\nby  computer  viruses  and  other \\nmalicious programs. Fortunately, \\npatient  safety  has  not  yet  been \\ncompromised, but the disruption \\nand costs to patients and provid-\\ners have been substantial.4\\n\\nA  dramatic  increase  in  cyber-\\nintrusions  and  attacks  on  medi-\\ncal devices has caused regulators \\nto take notice. The FDA issued a \\nsafety  communication  in  June \\n2013  entitled  “Cybersecurity  for \\nMedical Devices and Hospital Net-\\nworks,” and a cross-agency work-\\ning  group  involving  representa-\\n\\ncybersecurity in health care\\n\\ntives  of  the  FDA,  the  Office  of \\nthe  National  Coordinator  for \\nHealth  Information  Technology, \\nand the Federal Communications \\nCommission has released a report \\ncalling  for  increased  private-sec-\\ntor  involvement  and  a  risk-based \\nregulatory framework — but does \\nnot  define  that  framework  fur-\\nther.  Unfortunately,  burdensome \\nand slow-moving regulation could \\ngreatly increase costs and possi-\\nbly obscure emerging threats. The \\nhealth  care  community  would \\ntherefore  be  wise  to  heed  this \\ncall from regulators and join ac-\\ntively in the dialogue.\\n\\nThe  Ponemon  study  suggests \\nthat organizations that focus ad-\\nequately on improving their cyber-\\nsecurity  posture,  hire  and  em-\\npower a chief information security \\nofficer,  and  build  strong  inci-\\ndence-response  capabilities  can \\nreduce  their  potential  financial \\nrisk from data breaches by 42%. \\nAn organization’s security posture \\nencompasses  a  complex  mix  of \\ntechnological,  operational,  and \\nprocedural elements that is often \\ndifficult  to  truly  understand,  let \\nalone  improve.  It  isn’t  always \\nclear  whether  the  focus  at  any \\ngiven moment should be on mod-\\nernizing technology, training per-\\nsonnel, providing physical securi-\\nty, or some combination of these \\naspects.  None  of  these  tasks are \\neasy, inexpensive, or quick; priori-\\ntization  and  a  clear  strategy  are \\nessential.\\n\\nAn active learning approach is \\nrequired to make prioritized cyber-\\nprotection  strategies  and  tactics \\nfocused and successful. This ap-\\nproach requires the ability to un-\\nderstand  the  complex  interplay \\nand  dynamics  among  outside \\nthreats,  inherent  vulnerabilities, \\nspecific risks, and the system’s re-\\nsilience, all of which must be un-\\nderstood in the particular context \\nof the health care delivery setting \\n\\n396\\n\\nPERSPECTIVEn engl j med 371;5 nejm.org july 31, 2014\\x0cif  feasible  solutions  are  to  be \\nfound.  Although  we  cannot  pre-\\ndict exactly what an adversary will \\ndo,  we  can  take  control  of  our \\nown  environments,  and  we  must \\nwatch potential adversaries closely.\\nJust as public health strategies \\nhave  been  developed  to  detect \\nand  track  emerging  epidemics, \\nidentify population risks and vul-\\nnerabilities, and prevent or ame-\\nliorate adverse effects, analogous \\napproaches  can  be  used  to  im-\\nprove cybersecurity in health care \\ndelivery organizations. First, ac-\\ntive  and  real-time  surveillance \\nand communication of emerging \\ncyberthreats  could  be  used  to \\nprofile threats and ultimately in-\\nfluence public policy and preven-\\ntion.  Second,  risk-based  analysis \\nand  modeling  that  take  into  ac-\\ncount  current  and  possible \\nthreats,  the  resulting  risks,  and \\nthe  vulnerabilities  and  resilience \\n\\nof  the  information  system  can \\nguide policy development. Third, \\neffective regulation may  help  en-\\nsure  the  fidelity  of  medical  de-\\nvices; finding the right balance by \\nestablishing security without cre-\\nating  yet  another  expensive  and \\ndistracting  set  of  compliance \\nstandards will require prior defi-\\nnition  by  stakeholders  (patients, \\nproviders,  and  institutions)  — \\nperhaps in a forum hosted by the \\nInstitute of Medicine, to build on \\nits  reports  on  privacy  and  data \\nsecurity.5\\n\\nThe threats of cyberattack are \\nclear and present in health care. \\nIt  is  time  to  organize,  convene, \\nand focus in a way that that truly \\nprotects  our  patients,  providers, \\nand institutions. Technology has \\nunquestionably  improved  health \\ncare. Let’s be sure that its prom-\\nised  benefits  continue  to  be  de-\\nlivered safely.\\n', 'Connections: The Quarterly Journal \\nISSN 1812-1098, e-ISSN 1812-2973 \\n\\nPolicy Article \\n\\nMarie Baezner, Connections QJ 19, no. 1 (2020): 63-72 \\nhttps://doi.org/10.11610/Connections.19.1.06  \\n\\nCybersecurity in Switzerland: Challenges and the \\nWay Forward for the Swiss Armed Forces \\n\\nMarie Baezner \\n\\nCenter for Security Studies, ETH Zurich \\n\\nAbstract: The cybersecurity policy of Switzerland is focused on enhancing \\ncompetencies and knowledge, investing in research and the resilience of \\ncritical infrastructures, threat monitoring, supporting innovation, promot-\\ning standards, and increasing awareness – all in the framework of public-\\nprivate,  inter-regional,  and  international  cooperation.  The  armed  forces \\nsupport this policy by developing threat intelligence and attribution capa-\\nbilities, readiness to undertake active measures in cyberspace, and to en-\\nsure operational availability under any circumstances. \\n\\nKeywords:  cyber  risks,  cybersecurity  strategy,  resilience,  crisis  manage-\\nment, law enforcement, cyber defence, cyber operations. \\n\\nPolicy Highlights \\n\\nLike in any other European state, cybersecurity has grown in importance in Swiss \\npolitics. And although Switzerland’s cybersecurity and defense policies are still a \\nwork in progress, the nation has made tremendous efforts in getting cybersecu-\\nrity policies, roles, and responsibilities right. \\n\\nPublished in 2018, the “National Strategy for the Protection of Switzerland \\nagainst Cyber Risks” 1 is the main policy document that guides Swiss ambitions \\nand replaced the 2012 strategy.2 Overall, the strategy sets seven strategic goals \\n\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n\\x0cMarie Baezner, Connections QJ 19, no. 1 (2020): 63-72 \\n\\nand ten spheres of action. The goals can be summarized as preparing Switzerland \\nto face the cyber risks of tomorrow head-on, by building up cybersecurity com-\\npetencies, crisis management structures, strengthening resilience, and facilitat-\\ning international cooperation. \\n\\nThe strategy is accompanied by an implementation plan,3 which was the re-\\nsult of three consultations with the main stakeholders in the Swiss cybersecurity \\nlandscape. While the  steering  of  the  strategy  is  centrally  organized,  its  imple-\\nmentation is decentralized with a clear distribution of roles. The implementation \\nplan sets out specific measures to implement the ten spheres of action defined \\nin the 2018 strategy. It also clarifies responsibilities, outlines quantifiable objec-\\ntives, and maintains a schedule to evaluate implementation progress. \\n\\nThe Swiss Reporting and Analysis Centre for Information Assurance (MELANI) \\nis the institution responsible for writing and implementing the strategy, and in-\\nforming the Swiss population and the private sector on any new cyber threats. \\n\\nAnother important document is the Cyber Defense Action Plan 2017 for the \\nFederal Department of Defense, Civil Protection and Sport (DDPS). The Action \\nPlan defines the role of the DDPS, the Federal Intelligence Service (FIS), and the \\narmed forces within the Swiss cybersecurity landscape. Overall, their role is to \\nprotect the DDPS’ networks and critical infrastructures from cyber threats, con-\\nduct military and intelligence cyber operations, and support civilian critical infra-\\nstructures in case of a major cyberattack. \\n\\nThe Swiss political landscape has undergone considerable changes during the \\npast few years. In 2016, the Federal Council published its report on Swiss security \\npolicy,4 which underlined the risks caused by information technologies and the \\nchanging  nature  of  conflict  with  regard  to  cyberspace.  The  Swiss  Parliament \\npassed a new intelligence law, which came into force in 2017,5 and the military \\n6 was revised in 2018 to allow the armed forces to have the means to protect \\nlaw \\ntheir networks and conduct offensive cyber countermeasures. The Federal Coun-\\ncil also recently launched a Federal Council Cyber Committee as a driver for in-\\n\\nhttps://www.isb.admin.ch/dam/isb/en/dokumente/ikt-vorgaben/strategien/ncs/ \\nStrategie%20zum%20Schutz%20der%20Schweiz%20vor%20Cyber-Risiken.pdf.  \\n\\n \\n\\x0cCybersecurity Challenges for the Swiss Armed Forces \\n\\ncreased centralization in the cybersecurity sphere, which is unusual for Switzer-\\nland.  As  a  federal  state, the  preference  is to  leave  a  certain  leeway to the  26 \\ncantons and the private sector. The Cyber Committee is also in charge of moni-\\ntoring the implementation of the national cybersecurity strategy. \\n\\nThese political developments show that the Swiss government takes cyber-\\nsecurity issues seriously by treating them at the highest political levels. The Fed-\\neral Council has also created a Cyber Security Competence Centre, which func-\\ntions as a single point of contact for all cybersecurity issues at the national level. \\nIt also coordinates the implementation of the national strategy. Finally, the latest \\ndevelopment has been the nomination of a delegate for cybersecurity who not \\nonly steers the cybersecurity strategy but also heads the special federal commit-\\ntee on cybersecurity and represents the Swiss Confederation in other commit-\\ntees. \\n\\nPolicy Challenges \\n\\nThe National Strategy for the protection of Switzerland against cyber risks tackles \\na broad set of cybersecurity issues. As such, it encompasses the development of \\ntechnical capabilities, streamlining education, fighting cybercrime, strengthen-\\ning  the  military,  increasing  international  cooperation,  and  raising  awareness. \\nWhile the strategy is specifically focused on cybersecurity, it also naturally aligns \\nwith Switzerland’s national security policy of 2016, the Federal Council’s strategy \\nfor a digital Switzerland 2018, the national strategy on critical infrastructure pro-\\ntection 2018-2022, and integrates the recent changes in the intelligence and the \\nmilitary law. \\n\\nOverall,  the  strategy  underlines  the  necessity  of  developing  public-private \\npartnerships and closely engaging with the private sector on the one hand and \\ninsists on the subsidiary role of the state on the other. With regard to the armed \\nforces, the strategy mentions the need to develop defensive capabilities but also \\nto ensure the armed forces’ ability to undertake active measures in cyberspace. \\nThese active measures are understood as ways and means to disturb, prevent, \\nor slow down an adversary targeting Swiss critical infrastructure. Additionally, \\nthe strategy also specifies that Switzerland has an active role to play in shaping \\ncyber norms at the international level and cooperate with other nations. Finally, \\nthe strategy underlines the importance of raising public awareness of cyberse-\\ncurity  issues.  The  strategy  covers  all  of  these  elements  in  the  following  ten \\nspheres of action: \\n\\n1.  Building competencies and knowledge \\n\\no  Measure 1: monitoring of trends in technological innovations  \\no  Measure 2: improvement of the research and education in cyberse-\\n\\ncurity  \\n\\no  Measure 3: establishment of frameworks that would encourage in-\\n\\nnovation in cybersecurity \\n\\n2.  Threat landscape \\n\\n65 \\n\\n \\n \\n\\x0cMarie Baezner, Connections QJ 19, no. 1 (2020): 63-72 \\n\\no  Measure  4:  improvement  and  extension  of  capabilities  in  analysis \\n\\nand presentation of the cyber threat landscape \\n\\n3.  Resilience management \\n\\no  Measure 5: improvement of the resilience of critical infrastructures \\no  Measure 6: improvement of the resilience of the federal administra-\\n\\ntion networks \\n\\no  Measure  7:  improvement  of  the  resilience  of  cantons’  networks \\n\\nthrough information and experience sharing \\n\\n4.  Standardization/Regulation \\n\\no  Measure 8: definition and introduction of minimum standards to im-\\n\\nprove network resilience \\n\\no  Measure 9: start of a review on an obligation to report cyber inci-\\n\\ndents \\n\\no  Measure 10: more involvement of Switzerland in international gov-\\nernance  of  the  Internet  to  ensure  the  development  of  a  free  and \\ndemocratic Internet \\n\\no  Measure 11: establishment of expert groups to evaluate regulations \\n\\nregarding cybersecurity \\n\\n5. \\n\\nIncident management \\no  Measure 12: development of MELANI as a Public-Private Partnership \\no  Measure 13: offering MELANI services to all types of enterprises \\no  Measure 14: development of the collaboration between the Swiss \\n\\ngovernment and other centers of competence \\n\\no  Measure 15: establishment of a process to clearly define responsi-\\nbilities in cyber incident management within the federal administra-\\ntion \\n\\n6.  Crisis management \\n\\no  Measure 16: integration of cyber experts in crisis management cells \\n\\nto foster collaboration with the private sector, if needed \\n\\no  Measure  17:  organization  of  joint  exercises  in  crisis  management \\nwith  the  integration  of  cybersecurity  elements  in  larger  exercises \\nand the organization of cyber-specific exercises \\n\\n7.  Prosecution \\n\\no  Measure 18: establishment of a table of the current cybercrime vio-\\n\\nlations in Switzerland \\n\\no  Measure 19: enhancement of the collaboration between the various \\ncompetence centers and the national network of investigators spe-\\ncialized in cyber criminality \\n\\n66 \\n\\n \\n \\n\\x0cCybersecurity Challenges for the Swiss Armed Forces \\n\\no  Measure 20: development of the education for law enforcement to \\nbuild knowledge regarding the prosecution of cybercriminal cases \\no  Measure 21: modification of the current structure of federal offices \\nin charge of criminal affairs to establish a new Central Office on the \\nfight against cyber criminality to enhance collaboration among can-\\ntons in cases of cyber criminality \\n\\n8.  Cyber defense \\n\\no  Measure 22: development of threat intelligence and attribution ca-\\n\\npabilities  \\n\\no  Measure 23: ensuring the armed forces’ abilities to undertake active \\nmeasures in cyberspace in accordance with the new legal basis  \\no  Measure 24: development of the armed forces to ensure their oper-\\n\\national availability in all circumstances \\n\\n9.  Active positioning of Switzerland in international cybersecurity policy \\n\\no  Measure 25: involvement of Switzerland in early discussions in in-\\n\\nternational forums concerning cybersecurity \\n\\no  Measure 26: enhancement of international cooperation to improve \\n\\ncapabilities and information sharing in cybersecurity \\n\\no  Measure 27: establishment of bilateral and multilateral dialogs on \\n\\nforeign security policies regarding cybersecurity \\n\\n10.  Public impact and awareness-raising \\n\\no  Measure 28: implementation of a communication strategy for the \\n\\nstrategy \\n\\no  Measure 29: raising awareness in the public about cyber risks. \\n\\nThe ten spheres of action and the enclosed measures mostly seek to develop \\nexisting structures and fill the gaps that have been identified in the 2012 national \\nstrategy.  The  main  differences  between  the  2018  and  2012  strategy  concern \\nthree  spheres  of  action.  The  first  difference  concerns  crisis  management  and \\nawareness-raising. In the 2018 strategy, the population, small and medium en-\\nterprises, and cantons have been included among the target groups, while in the \\n2012 strategy, the focus was only on critical infrastructure operators. The second \\ndifference refers to the standardization and regulation. The 2018 strategy men-\\ntions an examination of a possible obligation to report cyber incidents and the \\nevaluation and introduction of minimum standards for IT security in critical in-\\nfrastructure. These new measures echo the European Union Network and Infor-\\nmation Security (NIS) directive. The third difference relates to cyber defense. The \\n2018  strategy  includes  the  armed  forces’  role  and  responsibilities  while  they \\nwere almost totally absent from the first strategy. \\n\\nSimilar  to  the  National  Strategy  for  the  protection  of  Switzerland  against \\ncyber risks, the Cyber Defense Action Plan (PACD) 2017 recognizes the need for \\na comprehensive approach to cybersecurity. The PACD 2017 acts as a roadmap \\n\\n67 \\n\\n \\n \\n\\x0cMarie Baezner, Connections QJ 19, no. 1 (2020): 63-72 \\n\\nfor the DDPS to reinforce its cyber capabilities. The document seeks to highlight \\n7 and national cyber defense \\nlessons learned from the RUAG cyberattack in 2016 \\nexercises. The PACD 2017 identifies five major fields in which the DDPS needed \\nto make progress: strategic management, developing operational means, build-\\ning support from the militia structure, improving collaboration with higher edu-\\ncation and the private sector, and finding the workforce. The PACD 2017 men-\\ntions that since 2016 the DDPS has already started to take measures such as im-\\nplementing  an  Information  Security  Management  System  (ISMS)  according  to \\nthe ISO 27000 series of standards and modernizing its systems and network in-\\nfrastructure. The PACD 2017 is very transparent about the resources it needs to \\nachieve its objectives. \\n\\nPolicy Implementing Structures and Whole-of-Nation Context \\n\\nSwitzerland  is  one  of  the  most  federalized  and  decentralized  countries  in  the \\nworld. A large number of tasks are left to the cantons to manage, including edu-\\ncation and law enforcement. This decentralization is sometimes perceived as a \\nchallenge and/or restriction for the federal government to tackle new issues like \\ncybersecurity. Actually, the past years have shown that the trend on the issue of \\ncybersecurity has been a move toward more centralization at the federal level. \\nCoordination  structure.  With  the  new  strategy,  Switzerland  has  set  up  a  new \\noverarching structure with the Federal Council Cyber Committee, the cyber se-\\ncurity delegate, and the Cyber Security Competence Centre. All these new insti-\\ntutions play a role in the coordination of cybersecurity at the federal level: \\n\\n• \\n\\nFederal Council Cyber Committee:  The Committee  is  composed  of  the \\nheads of the Federal Department of Finance, the DDPS, and the Federal \\nDepartment  of  Justice  and  Police  (FDJP).  The  Committee  meets  four \\ntimes a year and its role is to monitor the implementation of the national \\ncybersecurity strategy; \\n\\n•  Cyber Security Delegate: The Federal Council is responsible for choosing \\nthe Cyber Security Delegate. The Delegate is responsible for steering the \\nagenda of the Swiss Confederation at the federal level regarding cyber-\\nsecurity issues. The Delegate heads internal committees on cybersecu-\\nrity and represents Switzerland in other committees in Switzerland; \\n•  Cyber Core Group: The group reports to the Federal Council Cyber Com-\\nmittee and is responsible for enhancing the collaboration between the \\nthree  sectors:  cybersecurity,  cyber  defense,  and  criminal  prosecution. \\nThe group is in charge of ensuring a joint threat assessment and super- \\n\\n\\n \\n \\n\\x0cCybersecurity Challenges for the Swiss Armed Forces \\n\\nFigure 1: Federal Cyber Risk Organization. \\n\\nvises through federal entities the management of cyber crises involving \\nseveral Federal Departments;  \\n\\n•  NCS Steering Committee: The Committee reports to the Federal Council \\nCyber  Committee  and  ensures  that  the  implementation  of  measures \\nfrom the strategy stays coordinated. The NCS Steering Committee also \\nhelps with suggestions for further policy developments; \\n\\n•  Cyber Security Competence Centre: The Centre is subordinate to the Fed-\\neral  Department  of  Finance  and  includes  MELANI.  The  Centre  is  the \\nsingle point of contact for cybersecurity issues at the federal level and \\nensures the coordinated implementation of the strategy. \\n\\nMilitary roles and responsibilities: The armed forces are part of the DDPS. Their \\nrole  is  to  protect  and  defend  their  own  networks  and  critical  infrastructure \\nagainst cyberattacks, to support the FIS in responding to cyberattacks targeting \\ncivilian critical infrastructures, and to maintain capabilities in cyberspace in case \\nof  war.  The  conditions  for  the  armed  forces  to  support  the  FIS  in  defending \\nagainst cyberattacks are very strict and the armed forces would only be involved \\nas additional help. The Electronic Operations Centre (EOC) is the main actor for \\nmilitary cyber defense in the DDPS. The EOC is responsible for fulfilling the afore-\\nmentioned tasks and collaborates with the FIS with regard to critical infrastruc-\\nture. The EOC is composed of military and civilian personnel, the military con-\\nscripts working at the EOC report to the Command Support Brigade 41. With the \\nrevision of the military law, the armed forces can now conduct offensive cyber \\ncountermeasures with the authorization of the Federal Council. \\nLaw enforcement role and responsibilities: \\n\\n69 \\n\\n \\n \\n \\n \\n\\x0cMarie Baezner, Connections QJ 19, no. 1 (2020): 63-72 \\n\\n•  Cantonal police forces: Fighting cybercrime or cyber-enabled crimes is \\nthe role of cantonal police forces. Each canton allocates resources and \\norganizes its fight against cybercrime as it desires. The Canton of Zurich \\nbuilt a Cyber Security Center and is one of the cantons that invests the \\nmost in fighting cybercrime. On the other hand, smaller cantons have \\nmore limited resources and may not be able to build centers like in the \\nCanton of Zurich. Cantonal police forces coordinate and exchange infor-\\nmation on  cybercrime  in  various  national  platforms  such  as the  Swiss \\nConference of Chiefs of Cantonal Police, the Conference of Directors of \\nCantonal Departments of Justice and Police, the Swiss Security Network \\nor the newly created Cyberboard, whose role it is to keep an overview \\non the cybercriminal violations in Switzerland; \\nFederal  Police  (Fedpol):  Fedpol  is  responsible  for  fighting  organized \\ncrime, coordinating relations with foreign police forces, protecting peo-\\nple and buildings under the responsibility of the Swiss Confederation, \\nand coordinating the identification processes (e.g., passports, IDs, immi-\\ngration). Regarding cybercrime, Fedpol is only responsible for investigat-\\ning cybercrime cases that fall under the jurisdiction of the Swiss Confed-\\neration  (i.e.,  cybercrime  linked  to  the  areas  of  responsibilities  men-\\ntioned above); \\n\\n• \\n\\n•  Office of the Attorney General of Switzerland: The Attorney General is in \\ncharge of prosecuting cybercriminal cases that fall under the jurisdiction \\nof the Swiss Confederation. \\n\\nIntelligence role and responsibilities: The Federal Intelligence Service (FIS) is in \\ncharge  of  the  counterintelligence  and  attribution,  supports  critical  infrastruc-\\ntures targeted by cyberattacks, fights against terrorism in cyberspace, and con-\\nducts awareness-raising campaigns about cyber espionage. Until 2017, the FIS \\nwas limited to defensive measures in cyberspace. With the new law, the FIS has \\nthe legal basis to conduct offensive cyber countermeasures against infrastruc-\\ntures located outside Switzerland after authorization by the head of the DDPS \\nwho needs to confer with the heads of the FDFA and the FDJP first.8 \\nFederal Department of Foreign Affairs (FDFA) role and responsibilities: The Secu-\\nrity Policy Division of the Federal Department of Foreign Affairs is responsible for \\ndiplomatic measures like participating in international forums about cybersecu-\\nrity norms, the development of international treaties on cybersecurity issues and \\nInternet governance.  \\n\\nPolicy Implementation \\nInternational cooperation: While Switzerland is neutral, it does not refrain from \\ncooperating  bilaterally  or  multilaterally  with  other  countries.  Switzerland  has \\n\\n\\n\\x0cCybersecurity Challenges for the Swiss Armed Forces \\n\\nshown that it is aware that cybersecurity issues cannot be tackled alone. Regard-\\ning cybersecurity, Switzerland mainly collaborates through its intelligence ser-\\nvice, its armed forces, and the FDFA. Since 2019, Switzerland is also a contrib-\\nuting partner of the NATO Cooperative Cyber Defence Centre of Excellence (CCD-\\nCOE) in Tallinn. This partnership allows Switzerland to access knowledge, infor-\\nmation, and training but also to participate in various activities offered by the \\nCCDCOE.9 Switzerland already took part in various international exercises such \\nas Locked Shields, Crossed Swords, Cyber Coalition, Cyber Storm, and Cyber Eu-\\nrope. Switzerland also collaborates and exchanges regularly with its neighbors \\nand other states regarding cyber threat intelligence and practices.  \\n\\nThrough the FDFA, Switzerland is involved internationally to promote the de-\\nvelopment  of  international  cyber  norms  in  organizations  like  the  UN  and  the \\nOSCE. Switzerland participates in the United Nations Governmental Group of Ex-\\nperts (UN GGE) and chairs the Open-ended Working Group (OEWG). Switzerland \\nwants to contribute to the discussion on the respect and application of interna-\\ntional law in cyberspace and to establish trust among states regarding cyberse-\\ncurity issues. Finally, Switzerland promotes itself and Geneva as a discussion plat-\\nform for cybersecurity issues. \\nEngagement of private sector/NGOs/academia: In 2018, the DDPS launched the \\nCyber Defense Campus (CYD Campus), whose role is to serve as a research and \\ndevelopment hub connecting the armed forces, academia, and the private sec-\\ntor. The CYD Campus is part of Armasuisse, the Federal Office for Defense Pro-\\ncurement, located in the DDPS. The CYD Campus is developing offices at the EPFL \\nin Lausanne and the ETH in Zurich. The objective is to be as close as possible to \\nstartups  and  innovation,  to  monitor  new  technologies  and  talents,  to  do  re-\\nsearch, and to train talents.10 The CYD Campus should reach its full capacity by \\nthe end of 2020. \\n\\nThe DDPS also collaborates with the Swiss Academy of Engineering Sciences \\n(SATW) to map research and development projects on cybersecurity in Switzer-\\nland. Additionally, DDPS assigned research projects on technical and non-tech-\\nnical topics linked to cybersecurity to higher education institutions. \\n\\nFinally, the DDPS supports cyber competitions such as the 9/12 Strategy Chal-\\nlenge organized by the Geneva Centre for Security Policy (GCSP) and the Swiss \\nCyber Storm, to promote the field of cybersecurity and to find talents. \\nConscription army: In August 2018, the Swiss armed forces launched a cyber de-\\nfense training program for conscripts. The training program has the long-term \\n\\n\\n \\n \\n \\n\\x0cMarie Baezner, Connections QJ 19, no. 1 (2020): 63-72 \\n\\nobjective to train 600 conscripts to become cybersecurity specialists that will be \\nintegrated into a cyber defense battalion.11 \\n\\nThe Way Forward \\n\\nBecause cybersecurity issues will continue to be significant challenges for states, \\nSwitzerland  should  continue  with  its  recent  developments  and  improvements \\nthat started during the past three years. Switzerland’s latest initiatives and poli-\\ncies relating to cybersecurity are new and it is still too early to evaluate and no-\\ntice their effects. Time will tell if these measures will help Switzerland to face the \\ncybersecurity  challenges  of  tomorrow.  However,  recent  measures  will  remain \\nimportant for Switzerland in the coming years. International cooperation will re-\\nmain significant because of the cross-border nature of cybersecurity. These chal-\\nlenges cannot be tackled alone and, therefore, Switzerland should continue to \\ncooperate bilaterally and multilaterally. The cyber defense training program will \\nregularly bring conscripts in the future cyber defense battalion. These new cy-\\nbersecurity specialists will contribute to building capabilities and would benefit \\nfirst  the  Swiss  armed  forces  but  also  the whole  society when they  go  back to \\ntheir civilian life. Overall, Switzerland should continue its momentum and carry \\non with the implementation of its strategy and the buildup of its capabilities in \\nthe military and civilian institutions. \\n\\nDisclaimer \\n\\nThe views expressed are solely those of the contributing author and do not rep-\\nresent official views of the PfP Consortium of Defense Academies and Security \\nStudies Institutes, participating organizations, or the Consortium’s editors. \\n\\nAbout the Author \\n\\nMarie Baezner is a Researcher in the Cyber Defense Team of the Center for Se-\\ncurity Studies. She holds an MA in International Security from the University of \\nBath, United Kingdom, and a BA in International Relations (Political Science and \\nInternational Law) from the University of Geneva. Before joining the CSS, Marie \\nBaezner has worked for the Command Support Basis of the Swiss Armed Forces \\nand the Swiss Armed Forces Peace Support Mission in Kosovo. Marie Baezner’s \\nresearch  focuses  on  cyber  incidents  and  cyber  aspects  of  current  conflicts.  E-\\nmail: marie.baezner@sipo.gess.ethz.ch. \\n\\n \\n \\n \\n \\n \\n \\n \\n\\x0cReproduced with permission of copyright owner.\\n\\nFurther reproduction prohibited without permission.\\n\\n\\x0c', \"5/2/22, 10:17 PM Emotional Reactions to Cybersecurity Breach Situations: Scenario-Based Survey Study - PMC\\nhttps://www-ncbi-nlm-nih-gov.ezproxy.lib.ryerson.ca/pmc/articles/PMC8156130/?report=printable 1/28\\nJ Med Internet Res. 2021 May; 23(5): e24879.\\nPublished online 2021 May 12. doi: 10.2196/24879: 10.2196/24879\\nEmotional Reactions to Cybersecurity Breach Situations: Scenario-Based Survey Study\\nMonitoring Editor: Rita Kukafka\\nReviewed by Ariel Teles and Valentina Franzoni\\nSanja Budimir, PhD, Johnny R J Fontaine, PhD, Nicole M A Huijts, PhD, Antal Haans, PhD, George Loukas, PhD, and Etienne B Roesch, PhD\\nDepartment of Work, Organization and Society, Faculty of Psychology and Educational Sciences, Ghent University, Ghent, Belgium,\\nDepartment for Psychotherapy and Biopsychosocial Health, Faculty of Health and Medicine, Danube University Krems, Krems an der Donau, Austria,\\nEindhoven University of Technology, Eindhoven, Netherlands,\\nUniversity of Greenwich, London, United Kingdom,\\nCentre for Integrative Neuroscience and Neurodynamics, School of Psychology and Clinical Language Sciences, University of Reading, Reading, United Kingdom,\\nSanja Budimir, Department of Work, Organization and Society, Faculty of Psychology and Educational Sciences, Ghent University, Henri Dunantlaan 2, Ghent, Belgium, Phone:\\n32 09 264 64 56, Email: sanja.budimir@ugent.be.\\nCorresponding author.\\nCorresponding Author: Sanja Budimir sanja.budimir@ugent.be\\nReceived 2020 Oct 9; Revisions requested 2020 Dec 14; Revised 2021 Feb 5; Accepted 2021 Mar 16.\\nCopyright ©Sanja Budimir, Johnny R J Fontaine, Nicole M A Huijts, Antal Haans, George Loukas, Etienne B Roesch. Originally published in the Journal of Medical Internet\\nResearch (https://www.jmir.org), 12.05.2021.\\nThis is an open-access article distributed under the terms of the Creative Commons Attribution License (https://creativecommons.org/licenses/by/4.0/), which permits unrestricted\\nuse, distribution, and reproduction in any medium, provided the original work, first published in the Journal of Medical Internet Research, is properly cited. The complete\\nbibliographic information, a link to the original publication on https://www.jmir.org/, as well as this copyright and license information must be included.\\nAbstract\\nBackground\\n1,2 1 3 3 4 5\\n1\\n2\\n3\\n4\\n5\\n5/2/22, 10:17 PM Emotional Reactions to Cybersecurity Breach Situations: Scenario-Based Survey Study - PMC\\nhttps://www-ncbi-nlm-nih-gov.ezproxy.lib.ryerson.ca/pmc/articles/PMC8156130/?report=printable 2/28\\nWith the ever-expanding interconnectedness of the internet and especially with the recent development of the Internet of Things, people are in‐\\ncreasingly at risk for cybersecurity breaches that can have far-reaching consequences for their personal and professional lives, with psychological\\nand mental health ramifications.\\nObjective\\nWe aimed to identify the dimensional structure of emotion processes triggered by one of the most emblematic scenarios of cybersecurity breach,\\nthe hacking of one’s smart security camera, and explore which personality characteristics systematically relate to these emotion dimensions.\\nMethods\\nA total of 902 participants from the United Kingdom and the Netherlands reported their emotion processes triggered by a cybersecurity breach sce‐\\nnario. Moreover, they reported on their Big Five personality traits, as well as on key indicators for resilient, overcontrolling (internalizing prob‐\\nlems), and undercontrolling (aggression) personality types.\\nResults\\nPrincipal component analyses revealed a clear 3-dimensional structure of emotion processes: emotional intensity, proactive versus fight/flight re‐\\nactions, and affective versus cognitive/motivational reactions. Regression analyses revealed that more internalizing problems (β=.33, P<.001), re‐\\nsilience (β=.22, P<.001), and agreeableness (β=.12, P<.001) and less emotional stability (β=–.25, P<.001) have significant predictive value for higher\\nemotional intensity. More internalizing problems (β=.26, P<.001), aggression (β=.25, P<.001), and extraversion (β=.07, P=.01) and less resilience\\n(β=–.19, P<.001), agreeableness (β=–.34, P<.001), consciousness (β=–.19, P<.001), and openness (β=–.22, P<.001) have significant predictive value\\nfor comparatively more fight/flight than proactive reactions. Less internalizing problems (β=–.32, P<.001) and more emotional stability (β=.14,\\nP<.001) and aggression (β=.13, P<.001) have significant predictive value for a comparatively higher salience for cognitive/motivational than affec‐\\ntive reactions.\\nConclusions\\nTo adequately describe the emotion processes triggered by a cybersecurity breach, two more dimensions are needed over and above the general\\nnegative affectivity dimension. This multidimensional structure is further supported by the differential relationships of the emotion dimensions\\nwith personality characteristics. The discovered emotion structure could be used for consistent predictions about who is at risk to develop long\\x02term mental well-being issues due to a cybersecurity breach experience.\\nKeywords: cybersecurity breach victims, emotions, personality, mental health, Internet of Things\\n5/2/22, 10:17 PM Emotional Reactions to Cybersecurity Breach Situations: Scenario-Based Survey Study - PMC\\nhttps://www-ncbi-nlm-nih-gov.ezproxy.lib.ryerson.ca/pmc/articles/PMC8156130/?report=printable 3/28\\nIntroduction\\nBackground\\nThe increasing number of Internet of Things devices (IoT) and their diverse application in private and work lives offer unlimited possibilities for a\\nconnected life. However, this has also extended the scope of security breaches and cybercriminal behavior [1]. As cyberattacks became more and\\nmore focused on specific companies and individual users [2,3], they increasingly create technological, economic, social, and psychological chal‐\\nlenges. Because of the deep penetration of IoT in personal lives, cybersecurity breaches on such devices can have far-reaching personal conse‐\\nquences. Work and livelihood can be disturbed, personal and social spheres can be altered, and these changes can sometimes be irrevocable. The\\nmost direct psychological effects of such events, which are intrinsically relevant to the personal goals of the user, are the emotional responses they\\nelicit [4,5]. A leading security company reported that negative emotions including anger, annoyance, frustration, upset, and a feeling of being\\ncheated are the common reactions to being a victim of cybercrime [6]. These emotional experiences could develop into long-term, far-reaching psy‐\\nchological turmoil [7-10]. Despite their central role in psychological well-being, very little is known about emotional reactions in the context of cy‐\\nbersecurity breaches. In this study, we (1) explore victims’ emotion processes by employing a scenario study with a cybersecurity breach on a\\nsmart security camera, which is one of the most telling examples of invasion of privacy by unauthorized entrance in the private sphere [11,12], (2)\\nexplore which personality characteristics predict interindividual differences in emotional reactions to this cybersecurity breach; and (3) designed\\nthe explorative research in such a way to generate replicable findings.\\nEmotionProcesses\\nIn emotion research, participants are often asked to report on their own emotions by evaluating emotion and affect terms (eg, the frequently used\\nPositive and Negative Affect Schedule [PANAS] [13]). While this type of research can generate very interesting findings, it does not allow re‐\\nsearchers to unearth the emotion processes these affect terms refer to. To get a comprehensive view of the emotion processes that can be elicited\\nby cybersecurity breaches, emotions are currently studied on the basis of the componential emotion approach [14]. This approach has emerged as\\nan overarching conceptual framework within the scientific field of emotion research. According to this approach, emotions are conceptualized as\\nprocesses that are elicited by goal-relevant events and consist of an interplay between 5 major components: appraisals, action tendencies, bodily\\nresponses, expressions, and subjective feelings [5]. Each component has a function. Appraisals are the evaluation of the eliciting event against one’s\\ngoals, needs, and values. Action tendencies refer to the preparation and direction of adaptive action. Bodily responses refer to physiological changes\\nthat prepare the body for actual action. Expressions are the facial, vocal, and gestural reactions through which the ongoing emotion process is com‐\\nmunicated. Through subjective feelings, the individual becomes aware of the ongoing emotion process. These feelings are often communicated with\\nthe use of emotion and affect terms. Moreover, emotion processes are evolutionary-shaped processes that have evolved from reflex-like reactions to\\ndynamic processes open to regulation [5,14]. All aspects of the emotion process can be regulated, from the impulsive reactions to the cognitive eval‐\\nuations. Having flexible emotion processes allows us to better adapt to our environment [15].\\n5/2/22, 10:17 PM Emotional Reactions to Cybersecurity Breach Situations: Scenario-Based Survey Study - PMC\\nhttps://www-ncbi-nlm-nih-gov.ezproxy.lib.ryerson.ca/pmc/articles/PMC8156130/?report=printable 4/28\\nThis componential emotion approach is especially promising for studying emotional experiences, as it has been demonstrated across cultural and\\nlinguistic groups that the 5 components, as well as regulation are encoded in daily language. First in 3 samples from the United Kingdom,\\nSwitzerland, and Belgium [16] and later in 31 additional samples from 24 countries and representing 20 languages (such as Chinese and Japanese)\\n[14], it was demonstrated that 142 emotion features representing the 5 emotion components and regulation systematically constitute the meaning\\nof 24 frequently used emotion terms [14]. The componential emotion approach forms not only a comprehensive theoretical framework but also\\nrepresents how people naturally think and talk about their emotions.\\nThus, to fully understand emotion dynamics, it is important to go beyond feeling and emotion terms and study all emotion components and regula‐\\ntion processes. In this study, the dimensions that structure the emotion processes elicited by a cybersecurity breach of a smart security camera are\\nexploratively identified by taking all emotion components as well as regulation into account.\\nPersonCharacteristics andEmotional Reactions\\nTo better understand the emotion dimensions involved in this scenario, we evaluate whether and how characteristics of personality are related to\\nthe reported emotional experience. To this end, we have worked with 2 broad personality models that have been shown in the past to relate to emo‐\\ntional functioning: the Big Five personality model [17] and the resilient/overcontrolled/undercontrolled personality type model [18,19].\\nBig Five Personality Model In the first model, personality is described by the Big Five broad personality traits: extraversion, emotional stability, con‐\\nscientiousness, agreeableness, and openness [17]. These traits have been shown to relate to the duration of emotional states and frequency of spe‐\\ncific emotional experiences [20]. A very common finding is that extraversion is positively associated with positive affect and emotional stability neg‐\\natively with negative affect [21]. Additionally, associations of personality traits with emotion regulation were demonstrated in several studies [22-\\n24]. For instance, extraversion, conscientiousness, and openness were predictive for problem solving and cognitive restructuring, while agreeable‐\\nness was predictive for social support and cognitive restructuring [22-24].\\nResilient/Overcontrolled/Undercontrolled Personality Type Model The second personality model classifies people into 3 broad personality types\\n[18,19]. Resilient people are characterized by a tendency to effectively adapt to changes and have the ability to recover well from stress and nega‐\\ntive emotional arousal. Overcontrolled people are introverted and emotionally sensitive but also dependable. They are more likely to experience\\nsadness and fear and are at risk of developing internalizing complaints such as depression and anxiety. Undercontrolled people are low on agree‐\\nableness and conscientiousness and high on aggressiveness and delinquency. They are more likely to experience anger and are at risk to develop\\nexternalizing problems.\\nGender and Age Next to these personality predictors, we have also looked at the relationships with gender and age. Overall gender differences in\\nemotional reactions have been observed, with females having more intense emotional reactions compared with males [25-28]. Regarding age, a\\ngeneral decrease of negative affective experiences [29] and increase of healthier emotion regulation strategies [30-32] have been observed\\nthroughout the life span.\\n5/2/22, 10:17 PM Emotional Reactions to Cybersecurity Breach Situations: Scenario-Based Survey Study - PMC\\nhttps://www-ncbi-nlm-nih-gov.ezproxy.lib.ryerson.ca/pmc/articles/PMC8156130/?report=printable 5/28\\nReplicability\\nIn light of the replicability crisis in psychology [33] and because of the explorative nature of this research with the innovation to root the study of\\nemotional experiences in the componential emotion approach, the study was executed in two samples from different countries (United Kingdom\\nand the Netherlands) speaking different languages (English and Dutch). Moreover, participants in each country received at random one of two ver‐\\nsions of the cybersecurity breach scenario. In one version, the smart security camera showed obvious signs of a cybersecurity breach (nonambigu‐\\nous condition), and in the other version, it showed unclear signs (the ambiguous condition) that could also potentially be caused by other factors\\n(eg, a bug in the software). By adding the latter scenario, the ecological validity of the research was increased, as in daily life it is also often unclear\\nwhether or not a dysfunction of internet-connected devices is due to a cybersecurity breach.\\nMethods\\nSample\\nA total of 1045 participants were recruited through Qualtrics panel, 524 participants from the United Kingdom and 521 participants from the\\nNetherlands. Before the data analyses, participants showing signs of not properly answering questions were removed. One of the strongest indica‐\\ntors that the validity of responses is at stake is nondifferentiation of the responses [34]. All participants who gave the same response on at least\\n75% of the GRID items and on 70% of the International Personality Item Pool 50 (IPIP-50) questionnaire items deviated from most participants in\\nscale use and were removed (n=143 deleted cases). This left 902 participants for the analyses. Sample characteristics are presented in Table 1.\\nProcedure\\nThe Qualtrics project team organized and coordinated data collection. They recruited samples from both countries based on their Qualtrics panel of\\nparticipants. Quotas for samples were predefined and balanced by country of residence, gender, and scenario with age range limited from 18 to 65\\nyears. An online questionnaire, located on the Qualtrics survey platform, was presented to participants remotely by sending them a survey link.\\nEach participant electronically signed an online informed consent form prior to completing the questionnaire. Participants had the opportunity to\\ncomplete the questionnaire within a 1-week period. The average duration of questionnaire completion was 15 minutes. Each participant was pre‐\\nsented with an introduction explaining what IoT devices are and specifically what a smart security camera is. This was followed by the presentation\\nof one of the two scenarios (ambiguous or nonambiguous, see complete instructions in Multimedia Appendix 1). Each participant thus evaluated\\nonly randomly assigned one scenario.\\nMeasures\\n5/2/22, 10:17 PM Emotional Reactions to Cybersecurity Breach Situations: Scenario-Based Survey Study - PMC\\nhttps://www-ncbi-nlm-nih-gov.ezproxy.lib.ryerson.ca/pmc/articles/PMC8156130/?report=printable 6/28\\nEmotion Assessment Participants were asked to imagine they experienced one out of two cybersecurity breach scenarios. Scenario 1, which repre‐\\nsented the ambiguous condition, was formulated as follows: “Imagine that you bought a smart security camera for your home. After some time, you\\nnotice that the shutter on your smart security camera starts opening and closing without your instruction, several times for a few minutes, then it\\nstops for a minute and starts again opening and closing several times and then it stops.” In the nonambiguous condition (scenario 2), the formula‐\\ntion was “Imagine that you bought a smart security camera for your home. After some time, you notice that the shutter on your smart security cam‐\\nera opens without your instruction and the camera rotates toward you and then starts following your movement.”\\nParticipants were subsequently asked to report the emotional reactions they would have in the situation presented using the Cybersecurity GRID\\nquestionnaire (Multimedia Appendix 2). This is an adjusted version of the GRID instrument that was used to study the meaning of emotion words\\nacross cultural and linguistic groups [14] and is based on the componential emotion approach [5] including the assessment of the 5 emotion com‐\\nponents and emotion regulation. In order to determine and operationalize relevant features of the emotion processes in the specific context of cy‐\\nbersecurity breaches, we executed a preliminary qualitative survey. In this survey, 130 participants reported on their real or expected emotional re‐\\nactions in cybersecurity breach situations (either from first-hand experience or based on a third-party experience). Participants’ reports included a\\nbrief description of the cybersecurity breach situation and the emotional reactions they had or would have had in that situation (referring to each\\nof the 5 emotion components and regulation). The new Cybersecurity GRID questionnaire was based on those emotion features that were reported\\nby at least 15% of the participants. The Cybersecurity GRID contains 76 items (19 appraisals, 16 action tendencies, 11 bodily reactions, 8 expres‐\\nsions, 14 subjective feelings, and 8 emotion regulation strategies). Each emotion feature was evaluated on the 7-point Likert scale commonly used\\nin survey research ranging from 1 (strongly disagree) to 7 (strongly agree) [35].\\nIPIP-50 IPIP-50 [17] is a validated instrument that measures the Big Five personality factors. Participants rated how accurately each statement de‐\\nscribed them on a 5-point Likert scale ranging from 1 (very inaccurate) to 5 (very accurate). Person mean-centered scores were calculated for IPIP\\nitems and reversed according to instructions. Each factor showed good to very good internal consistency (Cronbach alpha): extraversion: α=.85,\\nagreeableness: α=.83, conscientiousness: α=.79, emotional stability: α=.83, and for openness: α=.72.\\nDepression, Anxiety, and Stress Scale–21 Item The Depression, Anxiety, and Stress Scale–21 Item (DASS-21) assesses internalizing problems, which\\nis a key feature of the overcontrolled personality type. It is a shortened 21-item version of the Depression, Anxiety, and Stress Scale [36]. Items are\\nrated on a 4-point scale ranging from 0 (does not apply at all) to 3 (applies very much). The total DASS-21 sum scores showed high internal consis‐\\ntency, α=.96.\\nShort-Form Buss-Perry Aggression Questionnaire The Short-Form Buss-Perry Aggression Questionnaire [37-39] assesses aggression, which a key\\nfeature of the undercontrolled personality type. It is a short version of the Buss-Perry Aggression Questionnaire [40] and consists of 21 items rated\\non a 5-point scale ranging from 1 (extremely uncharacteristic of me) to 5 (extremely characteristic of me). The scale showed a high internal consis‐\\ntency, α=.92.\\nEgo Resilience Scale The Ego Resilience Scale [41,42] is a short, revised version of the Ego-Resiliency Scale [43], measuring self-reported resilience\\non 10 items on a 4-point scale ranging from 1 (does not apply at all) to 4 (applies very strongly). The Cronbach alpha of the total score was .78.\\n5/2/22, 10:17 PM Emotional Reactions to Cybersecurity Breach Situations: Scenario-Based Survey Study - PMC\\nhttps://www-ncbi-nlm-nih-gov.ezproxy.lib.ryerson.ca/pmc/articles/PMC8156130/?report=printable 7/28\\nEthical Approval\\nEthical approval was obtained from the ethical committee of Ghent University, Faculty of Psychology and Educational Sciences in 2017 (number\\n2016/67).\\nResults\\nInternal Structure of Emotional Reactions\\nPrincipal component analyses were applied to identify the major dimensions of variability among 76 emotion features. To avoid confusion between\\nemotion components from a substantive point of view and principal components obtained from analysis, the latter will be referred to as dimensions\\nin the remainder of the text.\\nTo identify the number of dimensions, 3 criteria were used: (1) the scree plot based on the Eigenvalues (Multimedia Appendix 1), (2) interpretabil‐\\nity, and (3) replicability for each language, scenario, and gender (Multimedia Appendix 1). The theoretically best interpretable rotation was se‐\\nlected. A highly stable and well-interpretable 3-dimensional structure was identified that accounted for 48% of the total variance (see Table 2 for\\nthe highest loading features on each dimension and Multimedia Appendix 1 for the full loading matrix).\\nOn the first dimension, accounting for 31% of variance, all emotion features have a positive loading, with the subjective experiences loading highest\\n(eg, I would feel panic, I would feel upset). The higher participants score on this dimension, the more intense negative emotion processes are\\nelicited by the scenario. Therefore, this dimension is named emotional intensity.\\nThe second dimension, accounting for 12% of variance, is a bipolar dimension. One pole is defined by proactive action tendencies to deal with the\\ncybersecurity breach (eg, I would want to regain control over the device/account, I would want to find a solution and fix the problem). The other\\npole is defined by fight/flight action tendencies (eg, I would want to take revenge, I would want to isolate myself physically) and features from other\\ncomponents that indicate distress (eg, I would have pain in the chest). Therefore, this dimension is labeled proactive versus fight/flight.\\nThe third dimension, accounting for 5% of the variance, is also bipolar. All appraisal and action tendency features (eg, I would think “It is not safe\\nthat this device is connected to the Internet”) have a nonnegative loading, while all subjective experience, bodily reaction, expression, and regula‐\\ntion features (eg, I would try to calm myself down) have a nonpositive loading on this dimension. This dimension is labeled affective versus\\ncognitive/motivational.\\nPredictors of Emotional Reactions\\n5/2/22, 10:17 PM Emotional Reactions to Cybersecurity Breach Situations: Scenario-Based Survey Study - PMC\\nhttps://www-ncbi-nlm-nih-gov.ezproxy.lib.ryerson.ca/pmc/articles/PMC8156130/?report=printable 8/28\\nThe scores on each of the 3 identified emotion dimensions were regressed on the personality characteristics. As the Big Five indicators and the re‐\\nsilience, overcontrolled, and undercontrolled indicators show both theoretical and empirical overlap (and the differences and similarities between\\npersonality models do not form the focus of this research), their predictive value was investigated separately. Hierarchical linear regression analy‐\\nses were performed. In the baseline model (model 1), the predictors are country of residence, scenario, gender, and age (with United Kingdom, am‐\\nbiguous situation, and women being the reference categories). In the second model the personality characteristics were added as predictors: the\\nBig Five personality traits in model 2a and the indicators for resilience, overcontrolled, and undercontrolled personality types in model 2b.\\nEmotional Intensity In model 1 (Table 3), it was observed that United Kingdom (β =–.20, P<.001), women (β =–.14, P<.001), and those\\nimagining the unambiguous scenario (β =.12, P<.001) reported the highest emotional intensity. Model 1 accounted for 8% of the variance\\n(F =18.28; P<.001). In model 2a (Table 3), it was observed that less emotionally stable (β=–.25, P<.001) and more agreeable (β=.12, P<.001)\\nparticipants reported a higher emotional intensity. Model 2a additionally accounted for an additional 5% of the variance (F =14.64; P<.001).\\nModel 2b (Table 3) showed that those reporting more internalizing problems (β=.33, P<.001) and more resilient participants (β=.22, P<.001) re‐\\nported a higher emotional intensity. Model 2b additionally accounted for 17% of the variance (F =66.32; P<.001).\\nProactive Versus Fight/Flight More fight/flight reactions were reported by younger participants (β =–.26, P<.001), by men (β =.16, P<.001),\\nand by participants responding to the unambiguous scenario (β =.09, P=.006). Model 1 (Table 4) accounted for 9% of the variance\\n(F =22.59; P<.001). In model 2a (Table 4), it was observed that less agreeable (β=–.34, P<.001), less conscientious (β=–.19, P<.001), and less\\nopen (β=–.22, P<.001) but more extraverted (β=.07, P=.02) participants showed more fight/flight reactions. Model 2a accounted for an additional\\n32% of the variance (F =68.57; P<.001). In model 2b (Table 4), it was observed that less resilient participants (β=–.19, P<.001) and participants\\nwith more internalizing problems (β =.26, P<.001) and more aggression (β=.25, P<.001) reported more fight/flight reactions. Model 2b ac‐\\ncounted for an additional 24% of the variance (F =62.82; P<.001).\\nAffective Versus Cognitive/Motivational Model 1 (Table 5) showed that for older participants (β =.21, P<.001), men (β =.13, P<.001), and Dutch\\nparticipants (β =.08, P=.01), the cognitive/motivational reactions were more salient. The model accounted for 7% of the variance\\n(F =18.02; P<.001). Only emotional stability was a significant predictor of the salience of cognitive motivational reactions in model 2a (β=.14,\\nP<.001). Model 2a (Table 5) accounted for an additional 2% of the variance (F =10.57; P<.001). In model 2b, it was observed that more aggres‐\\nsion (β=.13, P=.01) and less internalizing problems (β=–.32, P<.001) related to a comparatively higher salience of cognitive/motivational than affec‐\\ntive reactions. Model 2b (Table 5) accounted for an additional 5% of the variance (F =18.06; P<.001).\\nDiscussion\\nInternal Structure\\nThe first and foremost goal of this study was to investigate the structure of emotional reactions in one of the most emblematic situations of cyberse‐\\ncurity breaches of the upcoming IoT devices—the hacking of one’s smart security camera—by looking at the full emotion process that can be\\nelicited by this situation. Not a 1-dimensional but a 3-dimensional structure clearly emerges.\\nTheNetherlands man\\nunambiguous\\n4,901\\n9,901\\n7,901\\nage man\\nunambiguous\\n4,901\\n9,901\\nDASS\\n7,901\\nage man\\nTheNetherlands\\n4,901\\n9,901\\n7,901\\n5/2/22, 10:17 PM Emotional Reactions to Cybersecurity Breach Situations: Scenario-Based Survey Study - PMC\\nhttps://www-ncbi-nlm-nih-gov.ezproxy.lib.ryerson.ca/pmc/articles/PMC8156130/?report=printable 9/28\\nOn the first dimension, all emotional reactions are loading positively. With the subjective experience items loading the highest on this dimension,\\nthis general intensity dimension can be best interpreted as a negative affectivity dimension, comparable to, for instance, the frequently used nega‐\\ntive affectivity scale of the PANAS [13].\\nThe second dimension represents the relative salience of proactive versus fight/flight action tendencies. This second dimension underlines the cen‐\\ntral status of action tendencies for the concept of emotion [44,45]. From an evolutionary perspective, emotion processes are phylogenetically\\nshaped processes that quickly prepare the organism for action. However, depending on the concrete situation, these elicited action tendencies can\\nbe more or less constructive. In the new internet environment where we interact from a distance, acting aggressively or withdrawing are not adap‐\\ntive reactions. One often does not know who is responsible and one’s life depends more and more on participating in this interconnected online\\nworld. Only the proactive tendencies to stop what is happening and to better protect oneself can be considered adaptive and lead to constructive\\nresults.\\nThe third dimension describes the relative salience of cognitive/motivational versus affective (expression, bodily reactions, regulation, and feelings)\\nfeatures. Possibly, this finding can be linked to the different levels of consciousness with which appraisals can occur [46]. When the appraisals are\\nmade consciously, one can focus more on what one feels inclined to do and should do. When the appraisals are made unconsciously, the way the\\nemotion is felt and expressed becomes more salient rather than what has elicited the emotion.\\nWhen the second and third dimensions are combined, a distinction emerges that has been referred to in the stress and coping literature as prob‐\\nlem-focused versus emotion-focused coping [47] (Figure 1). The proactive tendencies in the upper-left quadrant correspond with problem-focused\\ncoping. The bodily reactions, subjective feelings, and expressions in the lower-left quadrant indicate that one is overwhelmed and regulation is\\nrequired.\\nThis 3-dimensional structure is highly replicable: exactly the same structure was found across the two versions of the security breach scenario,\\nacross the two countries with their respective languages, and across the two genders (Multimedia Appendix 1).\\nPredictors of EmotionDimensions\\nThe second goal was to explore whether personality characteristics predict the empirically identified emotion dimensions, and, if that is the case,\\nwhich ones (Tables 3-5). The general finding is that the broad personality characteristics from both personality models relate differentially to the 3\\nemotion dimensions, which confirms that these emotion dimensions are indeed each capturing valid aspects of the emotion processes.\\nBig Five Personality Model The two most predictive personality traits are emotional stability and agreeableness. In line with the well-documented\\nnegative relationship between emotional stability and negative affectivity [22-24], we observed that emotionally stable participants scored lower\\non the general emotion dimension and reported a higher salience of the affective components. Agreeable participants showed more proactive ac‐\\ntion tendencies and tended also to score a bit higher on the general emotion dimension. It is possible that agreeable people, who value warm inter‐\\npersonal relationships, appraise negatively intended actions by others, like hacking, as more relevant while at the same time are less inclined to re‐\\nact aggressively, which frees more energy to deal constructively with the situation. Moreover, agreeable people are more likely to use cognitive re‐\\n5/2/22, 10:17 PM Emotional Reactions to Cybersecurity Breach Situations: Scenario-Based Survey Study - PMC\\nhttps://www-ncbi-nlm-nih-gov.ezproxy.lib.ryerson.ca/pmc/articles/PMC8156130/?report=printable 10/28\\nstructuring and problem-solving approaches [22-24]. Conscientiousness and openness only predicted proactive tendencies. Being diligent, efficient,\\nand orderly, which are characteristics of conscientious people, might help to focus on the action tendencies that can provide support in effectively\\ndealing with the situation. The relationship with the personality trait openness was a bit less self-evident. As IoT is a recent and fast-developing\\nfield, people who are more curious and open are possibly more likely to understand the full implications of cybersecurity breaches and act accord‐\\ningly. Extraversion, which has been found in the literature to be predictive of positive but not negative affectivity [22-24], was virtually unrelated to\\nthe emotion dimensions (with the exception of a very small although statistically significant relationship with fight/flight tendencies, probably due\\nto the fact that extravert people tend to express their emotions more) [48].\\nResilient/Overcontrolled/Undercontrolled Personality Type Model Internalization problems, which are important characteristics of an overcon‐\\ntrolled personality type, predicted a higher general emotional intensity, more fight/flight tendencies, and a comparatively higher salience of the af‐\\nfective components. This finding indicates that people who are already vulnerable do not succeed in adequately dealing with the emotional experi‐\\nence. Interestingly, resilience, a characteristic of well-functioning people [43], not only predicts more proactive tendencies but also a higher general\\nintensity of emotional reactions and a higher salience of the affective components. Possibly because resilient people can cope better with stressors,\\nthey are less defensive and more willing to appraise the seriousness of the situation and accept their own emotional reactions. Finally, aggression,\\nas an indicator of an undercontrolled personality type, is especially predictive of fight/flight action tendencies and relates to a slightly higher\\nsalience of the cognitive/motivational components. People who are high on aggression are more willing to blame others and are primed on aggres‐\\nsive reactions [49,50].\\nGender and Age In addition to the personality predictors, we also found that gender and age played a role. Women had a tendency to have more\\nemotionally intense and affective reactions, while men were more likely to show fight/flight reactions. This is in line with earlier findings that fe‐\\nmales generally have more intense emotional reactions [25-28], experience more emotions in situations of cyberbullying [51], and have more anxi‐\\nety in situations of hacking [52] and that males tend to react more aggressively [53].\\nWe also found that older individuals were more prone to have proactive and cognitive/motivational reactions, which fits the observation that older\\nindividuals have less negative affective experiences and healthier emotion regulation strategies [29-32]. Additionally, intra-individual differences in\\nemotional reactions to cybersecurity breaches are organized and structured in exactly the same way for males and females (Multimedia Appendix\\n1).\\nAmbiguous/Nonambiguous Conditions While the two cybersecurity scenarios showed exactly the same 3-dimensional structure of emotional reac‐\\ntions, quantitative differences were observed, with the nonambiguous situation eliciting more intense and more fight/flight emotional reactions.\\nThe nonambiguous situation is possibly experienced more as though one is confronted with a natural person in real life. The situation becomes\\nmore relevant for one’s goals and elicits more fight/flight action tendencies rather than the more adaptive proactive reactions.\\nCountry Finally, while the emotion structure is the same in the two countries, we observed less intense reactions and a higher salience of\\ncognitive/motivational reactions in the Dutch as compared with the UK sample. A speculative explanation could be that the emblematic example of\\nthe hacking of a smart security camera has received more media coverage in the United Kingdom [54-57] than in the Netherlands, which has made\\nthese scenarios more emotionally salient in the United Kingdom.\\n5/2/22, 10:17 PM Emotional Reactions to Cybersecurity Breach Situations: Scenario-Based Survey Study - PMC\\nhttps://www-ncbi-nlm-nih-gov.ezproxy.lib.ryerson.ca/pmc/articles/PMC8156130/?report=printable 11/28\\nPrincipal Findings\\nIn this study, only the direct emotional reactions to a cybersecurity breach scenario have been studied. A question for future research is whether\\nand to what extent these immediate emotional reactions set the stage for further mental health problems. Being exposed to hacking has been linked\\nto psychopathology [58-61] in the literature and even to suicide in the media [9]. Based on the discovered emotion structure, very different dynam‐\\nics can be predicted with respect to the role that a hacking situation will play in a person’s life in the longer run.\\nThose with intense emotional reactions, fight/flight action tendencies, and salient affective components are probably more likely to stay confronted\\nwith the situation and its negative ramifications. They experience the situation as emotionally highly relevant, but they tend to react in a way that\\ndoes not resolve the challenges created by the problem. Moreover, they are additionally confronted with affective reactions that need to be regu‐\\nlated and thus require extra energy. This combination can be considered the psychologically least adaptive reaction, which sets the stage for further\\nmental health complaints.\\nThose who have no or little negative emotional reactions can only be partially considered better off. They do not have to deal with the negative\\nemotional reactions themselves but also lack the inherent pressure created in the emotion process to take action. Emotions are relevance detectors\\n[5]. Appraising the situation as threatening with its ensuing negative emotional reactions can motivate appropriate action and can therefore be con‐\\nsidered adaptive. This interpretation is also supported by the finding that resilient people score higher on the general intensity dimension.\\nThe most adaptive emotional reaction can be considered to be a negative emotional reaction in which the proactive and constructive action tenden‐\\ncies and cognitive-motivational components are the most salient. Such a reaction pattern implies that the seriousness of the situation is adequately\\nappraised and thus that the emotions play their role as relevance detectors. At the same time, actions are prepared that maximize an effective reso‐\\nlution of the situation without the person being overwhelmed by the affective reactions.\\nLimitations\\nOne of the limitations of this study is that the causal conclusions about the long-term mental health consequences of a cybersecurity breach cannot\\nbe investigated with a scenario methodology based on anticipated emotional experiences. However, as experimental research of real emotional ex‐\\nperiences is impossible or at least highly limited in this area due to ethical considerations (it is unethical to actually invade the privacy of people by\\nhacking their security camera), scenarios offer an ethically viable and direct way to study the structure of emotional reactions in this uncharted do‐\\nmain. As this study was conducted in Western Europe, further cultural generalizability is yet to be demonstrated. Future research can also study the\\necological validity, generalizability, and long-term mental health implications of these findings. Another limitation is the use of self-assessment in‐\\nstruments. While some emotion components can only be studied through self-assessment (like subjective feelings and cognitive appraisals), other\\ncomponents can be studied by objective data (like psychophysiological and expressive changes). In future research, it would be interesting to com‐\\nplement self-reported data with such objective data.\\nConclusion\\n5/2/22, 10:17 PM Emotional Reactions to Cybersecurity Breach Situations: Scenario-Based Survey Study - PMC\\nhttps://www-ncbi-nlm-nih-gov.ezproxy.lib.ryerson.ca/pmc/articles/PMC8156130/?report=printable 12/28\\nWith the increasing interconnections through the internet and especially the recent development of IoT, people are much more at risk of experienc‐\\ning cybersecurity breaches. Becoming a victim of cybersecurity breaches, with possibly far-reaching consequences for one’s personal and profes‐\\nsional life, is becoming more and more likely. When all components of the emotion processes elicited by such cybersecurity breaches are investi‐\\ngated, a replicable 3-dimensional structure emerges that goes beyond the well-known negative affectivity dimension. These dimensions relate dif‐\\nferentially to broad personality characteristics, which further validates the need for a multidimensional representation. Depending on the position\\nof the emotional reaction on these three dimensions, very different predictions can be made about the long-term mental health implications of\\nhacking experiences. With this study, a key process that links the occurrence of a cybersecurity breach situation with possible long-term mental\\nhealth effects has been mapped out.\\nAcknowledgments\\nThis study is part of a larger research project, Emotion Psychology Meets Cyber Security in IoT Smart Homes (Cocoon), funded by EU FP7 CHIST\\x02ERA funding scheme (European Coordinated Research on Long-term Challenges in Information and Communication Sciences & Technologies ERA\\x02NET) corresponding to grants FWO project G0H6416N-FWOOPR2016009701 and EPSRC EP/P016448/1 and NWO project no.651.002.002. Many\\nthanks to native speaker Arpine Hovasapian, PhD, for proofreading the paper. We thank her for her valuable contribution to the manuscript.\\nAbbreviations\\nDASS-21 Depression, Anxiety and Stress Scale–21 Item\\nIoT Internet of Things\\nIPIP-50 International Personality Item Pool 50\\nPANAS positive and negative affect schedule\\nAppendix\\nMultimedia Appendix 1\\nSupplement.\\n5/2/22, 10:17 PM Emotional Reactions to Cybersecurity Breach Situations: Scenario-Based Survey Study - PMC\\nhttps://www-ncbi-nlm-nih-gov.ezproxy.lib.ryerson.ca/pmc/articles/PMC8156130/?report=printable 13/28\\nMultimedia Appendix 2\\nCybersecurity GRID.\\nFootnotes\\nContributed by\\nAuthors' Contributions: SB and JRJF substantially contributed to analyses and interpretation of data, drafted the article, and gave final approval of the version to be published.\\nSB, JRJF, NMAH, AH, GL, and EBR substantially contributed to conception of the study and design and acquisition of data, critically revised the manuscript for important intellec\\x02tual content, and gave final approval of the version to be published.\\nConflicts of Interest: None declared.\", '2018 10th International Conference on Cyber Conflict\\nCyCon X: Maximising Effects\\n\\nT. Minárik, R. Jakschis, L. Lindström (Eds.)\\n\\n2018 © NATO CCD COE Publications, Tallinn\\n\\nPermission  to  make  digital  or  hard  copies  of  this  publication  for  internal \\nuse within NATO and for personal or educational use when for non-profit or \\nnon-commercial purposes is granted providing that copies bear this notice \\nand a full citation on the first page. Any other reproduction or transmission \\nrequires prior written permission by NATO CCD COE.\\n\\nDeveloping Collaborative \\nand Cohesive Cybersecurity \\nLegal Principles\\n\\nJeff Kosseff1 \\nAssistant Professor of Cybersecurity Law\\nUnited States Naval Academy\\nAnnapolis, MD, United States\\n\\nAbstract:  Legal  discussions  about  combatting  global  cyber  threats  often  focus \\non  international  cybercrime  arrangements  or  the  application  of  the  law  of  war  to \\ncyberspace. While these discussions are vital, policy-makers and scholars have not \\ndevoted adequate attention to creating a global legal framework to bolster the defenses \\nof public and private infrastructure. Due to the interconnected nature of cyberspace \\nand  the  cross-border  impacts  of  attacks,  inadequate  security  in  one  country  could \\nharm another.\\n\\nTo  build  cyber  strategies  that  rely  in  part  on  defense  and  deterrence  by  denial, \\ngovernments  should  also  focus  both  on  the  security  of  their  systems  and  those  of \\nthe  private  sector.  Industry  has  been  the  target  of  some  of  the  most  destructive \\ncyberattacks  worldwide.  Guiding  international  principles  for  a  cyber  security  legal \\nframework would help nations to build effective laws that reduce the likelihood of \\nsuccessful attacks, and increase resilience after attacks occur. Moreover, international \\ncollaboration  on  cybersecurity  laws  provides  multinational  companies  with  a  more \\ncoherent legal framework. A patchwork of hundreds of different international security \\nrequirements is not only burdensome for companies, but it increases the potential for \\nvulnerabilities, particularly if the company operates in countries with less stringent \\ncybersecurity requirements.  \\n\\nThis  paper  sets  out  the  need  for  nations  to  discuss  common  legal  principles  for \\npromoting and regulating cybersecurity, similar to the privacy principles articulated \\n\\n\\n\\n\\n\\x0cin the Organization for Economic Cooperation and Development’s Fair Information \\nPractices in 1980. As a starting point for discussion, this paper suggests four goals \\nof  common  international  principles  for  cybersecurity  law:  (1)  modernization \\nof  cybersecurity  laws;  (2)  uniformity  of  legal  requirements;  (3)  coordination  of \\ncooperative  incentives  and  coercive  regulations;  and  (4)  supply  chain  security. \\nAlthough  cybersecurity  laws  will  always  vary,  international  coordination  could \\nimprove their efficacy by providing some degree of consistency. A dialogue also could \\nhelp policy-makers learn from other nations’ cybersecurity successes and failures.\\n\\nKeywords: cybersecurity; cooperation; principles; cybercrime; data security\\n\\n1. IntroductIon\\n\\nOver the past decade, there has been great progress on international cooperation to \\ncombat  cybercrime  and  build  on  norms  to  deter  and  deny  states  that  leverage  the \\nasymmetric  nature  of  cyber  operations. All  of  these  discussions  are  vital  and  must \\ncontinue on the international stage. However, international legal discussions also must \\naddress cybersecurity law.  \\n\\nAt  the  outset,  this  Paper  defines  “cybersecurity  law,”  as  the  term  is  often  used \\ninterchangeably to describe regulation of the private sector’s computer systems and \\nnetworks, federal programs that assist the private sector, cybercrime statutes and the \\nlegal norms of cyberwar. For the purposes of this paper, I broadly define cybersecurity \\nlaw as domestic laws that seek to promote the confidentiality, integrity and availability \\nof public and private computer systems, networks and information.2 This expansive \\ndefinition applies equally to governmental regulations and public-private partnerships \\nand to incentives that have the ultimate goal of improving cybersecurity.\\n\\nImproving the cybersecurity of public and private systems has two primary national \\nsecurity benefits. First, hardened defenses help to reduce or eliminate harm caused \\nby an aggressor. Second, cybersecurity is an important part of a framework to deter \\nattacks, provided that the aggressor is aware of the strong defenses. While deterrence \\nby  punishment is  an  important component of  a  cyber  strategy,  so  too  is  deterrence \\nby  denial.  Cyber  deterrence  requires  nations  to  ensure  that  their  laws  provide \\nadequate assistance and incentives for cybersecurity of both government and private \\ninfrastructure. Too often, the security of the private sector is missing from the greater \\ndiscussion of national cybersecurity.3 Governments worldwide have recognized the \\n\\n\\n\\x0cneed for private companies to protect their data and cyber infrastructure. The private \\nsector  controls  vast  amounts  of  infrastructure  that  are  vulnerable  to  cyberattacks, \\nmaking the private sector’s cybersecurity important not only to nations’ economies, \\nbut also to their national security.4 \\n\\nThe interconnected nature of cyber threats – in which an attack in one country could \\ncause harmful spill-over effects in another country – provides policy-makers with a \\ncompelling reason to improve cybersecurity laws globally. To do so, nations should \\ncollaborate and articulate core principles for cybersecurity, just as the Organization \\nfor Economic Cooperation and Development (OECD) did for privacy law nearly four \\ndecades ago when it developed its Fair Information Practices. \\n\\nThis paper then draws on examples of successful cybersecurity laws and partnerships \\nworldwide to outline some goals of a global cybersecurity legal framework:\\n\\n•  Modernization of cybersecurity laws to address current threats;\\n•  Uniformity of legal and regulatory requirements;\\n•  Coordination of cooperative cybersecurity programs and regulatory \\n\\nobligations; and\\nSupply chain security. \\n\\n• \\n\\nCybersecurity often involves an alignment of public-sector and private-sector interests. \\nAccordingly,  cybersecurity  law  should  move  from  the  outdated,  purely  punitive \\nmodel  of  privacy  law  to  a  collaborative  and  cooperative  framework.  I  refer  to  this \\nmodel  as  “collaborative  cybersecurity  law,”  a  mixture  of  incentives,  public-private \\npartnerships, and tailored regulations that is designed to improve cybersecurity as a \\nwhole.\\n\\nFor this paper, collaborative cybersecurity law has two equally important applications. \\nFirst,  the  public  and  private  sectors  should  collaborate  to  determine  the  most \\neffective  legal  frameworks  to  build  defenses  and  resilience.  Second,  governments \\nshould collaborate at the local, state/province, and national levels to ensure that their \\nrequirements  and  incentives  are  aligned  to  the  common  goal  of  protecting  global \\ncyber infrastructure. Cyberspace does not have clearly defined geographic or public/\\nprivate boundaries. Nor should the defense of cyberspace.\\n\\nI  do  not  suggest  the  creation  of  a  single  set  of  cybersecurity  laws  to  apply  across \\nall nations; such a task would be a fool’s errand, as countries have a wide range of \\ntort, constitutional, and administrative laws that would prevent a single law across all \\njurisdictions. Jurisdictions such as the United States tend to favor cybersecurity laws \\n\\n\\n\\x0cthat promote free expression over other interests, while jurisdictions such as those in \\nEurope tend to favor privacy protection. Rather than attempt a uniform set of laws, \\ncountries should develop a set of shared core cybersecurity values to apply as they \\ndevelop laws to address cybersecurity threats via laws, regulations, and government \\nprograms. \\n\\nIn short, this paper argues that nations must broaden their conception of the international \\ncybersecurity dialogue. While the ongoing discussions regarding cyberwarfare norms \\nare essential, it is only one piece of the much larger solution to improving the security \\nof cyberspace. Nations must also develop a cohesive strategy to secure both public \\nand private cyber information and infrastructure through regulations and incentives. \\n\\n2. the global ImPact of InadeQuate \\ncybersecurIty\\n\\nCyber threats are not always confined to geographic borders. Many of the most damaging \\nand persistent cyberattacks have targeted systems and data in multiple countries. The \\nattacks target not only military systems or civilian government computers, but often \\nalso  home  systems  that  are  operated  by  the  private  sector.  With  the  private  sector \\ncontrolling critical infrastructure such as logistics, telecommunications, and financial \\nsystems globally, the cybersecurity of both the public and private sector is crucial to \\nadequate defense. \\n\\nThe pervasive global nature of cyber threats can be seen in botnets, which use infected \\ncomputers  to  amass  power  to  launch  devastating  attacks.  As  botnets  infect  more \\ncomputers, they cause more damage, such as forcing websites offline and interrupting \\ncritical services.5 The Internet of Things era has exponentially increased the number \\nof devices connected to the Internet. Botnets have commandeered these devices, in \\npart due to the inadequate security measures on many IoT devices.6 \\n\\nFor instance, in October 2016, the Mirai botnet, consisting of hundreds of thousands \\nof infected devices, knocked some of the most popular websites in the world offline \\nby targeting Dyn, a domain name system management service.7\\n\\nBotnets demonstrate the international impact of inadequate cybersecurity. Consider, \\nfor example, a webcam that is manufactured in Germany with inadequate password \\nprotections. If a consumer in the United States uses that webcam, it could be used in a \\n\\n\\x0cbotnet that shuts down a website in New Zealand. New Zealand alone cannot address \\nthe botnet problem by regulating the security of Internet of Things devices.  \\n\\nLikewise,  the  WannaCry  ransomworm  demonstrates  the  interconnected  nature  of \\ncyber threats. WannaCry was initially found on European businesses’ computers on the \\nearly morning of May 12, 2017. The files on infected computers were encrypted, and \\nthe computer operators received a demand for bitcoin in exchange for the encryption \\nkey, though paying the ransom did not always guarantee decryption of the files. The \\nransomworm rapidly spread. In all, WannaCry infected more than 200,000 computers \\naround the world.8\\n\\nWannaCry  was  so  malicious  and  pervasive  because  it  spread  using  EternalBlue, \\nan  exploit  that  allows  malware  to  spread  in  Windows  operating  systems.  Hackers \\nallegedly stole EternalBlue from the U.S. National Security Agency.9 The U.S. and \\nUK authorities have attributed WannaCry to North Korea.10\\n\\nAccording  to  the  European  Union Agency  for  Network  and  Information  Security, \\nonce a computer was infected with WannaCry, it would scan public Internet Protocol \\naddresses for other external networks to infect.11 Rather than merely spreading across \\na  company’s  internal  network,  WannaCry  used  its  infected  computers  to  find  and \\ntarget other vulnerable networks.12\\n\\nWannaCry  and  Mirai  demonstrate  the  globally  interconnected  nature  of  harms \\nassociated  with  cyberattacks.  The  attacks  demonstrate  that  an  attack  that  initially \\nfocuses  on  one  geographic  region  can  have  immediate  and  damaging  spill-over \\neffects into other countries. Therefore, it is in a nation’s interests to secure not only \\nthe computers within its geographic boundaries, but the systems and networks across \\nthe globe. \\n\\n3. the need for legal PrIncIPles to ImProVe \\nglobal cybersecurIty\\n\\nEnhanced cybersecurity of a nation’s infrastructure plays two critical roles in cyber \\nstrategy. First, it reduces or eliminates the risk of harm from an attempted attack by \\nbolstering defenses. Second, the known existence of the attack may deter the attacks \\nfrom ever occurring. \\n\\nSam Jones, Timeline: How the WannaCry Cyber Attack Spread, FINANCIAL TIMES (May 14, 2017). \\nIbid.\\n\\n\\x0cDeterrence strategy has two components: deterrence by punishment and deterrence \\nby  denial.13  Deterrence  by  denial  consists  of  strategies  that  both  resist  attacks  and \\nhelp recovery from attacks once they have occurred (known as “resilience.”).14 For \\neffective  cyber  deterrence  by  denial,  the  private  sector  must  both  secure  its  own \\nsystem and networks and develop secure products throughout the supply chain. As \\nDorothy Denning summarized in 2016:\\n\\nCybersecurity  aids  deterrence  primarily  through  the  principle \\nof  denial.  It  stops  attacks  before  they  can  achieve  their  goals. \\nThis  includes  beefing  up  login  security,  encrypting  data  and \\ncommunications, fighting viruses and other malware, and keeping \\nsoftware updated to patch weaknesses when they’re found.\\n\\nBut even more important is developing products that have few if \\nany  security  vulnerabilities  when  they  are  shipped  and  installed. \\nThe Mirai botnet, capable of generating massive data floods that \\noverload  internet  servers,  takes  over  devices  that  have  gaping \\nsecurity  holes,  including  default  passwords  hardcoded  into \\nfirmware  that  users  can’t  change.  While  some  companies  such \\nas Microsoft invest heavily in product security, others, including \\nmany Internet-of-Things vendors, do not.15\\n\\nNations can promote such cybersecurity measures by enacting effective regulations \\nand creating public-private partnerships. Defending against attacks helps to mitigate \\nthe  overall  harm.16  However,  a  single  nation’s  laws  are  likely  to  be  insufficient  to \\nadequately  shore  up  its  cybersecurity.  The  cyber  vulnerabilities  in  Country A  may \\nlead to negative consequences in Country B, and Country B has limited ability, acting \\nalone,  to  impose  consequences  for  inadequate  cybersecurity  in  Country A.  That  is \\nwhere an international dialogue on cybersecurity is vital. \\n\\nEven to the extent that some cyberattacks are strictly local, an international dialogue \\nabout cybersecurity laws can allow nations to share lessons about their experiences \\nwith government programs, regulations, and laws. Unlike other areas of law that have \\ncenturies of empirical evidence to support or reject their adoption, cybersecurity law \\nneeds  to  address  the  rapidly  evolving  threat  landscape.  If,  for  instance,  requiring  a \\nparticular safeguard is effective, nations could share these experiences in determining \\nbest practices. \\n\\n\\x0cIn both the areas of cybercriminal law17 and cyberwarfare,18 international experts and \\npolicy-makers  have  at  least  attempted  to  find  areas  of  broad  agreement.  However, \\ncriminal laws and warfare norms and guidelines often address responses to cyberattacks \\n(i.e., criminal prosecutions or military action). While these are absolutely vital to a \\ncomprehensive cybersecurity framework, they are only part of the solution. Laws and \\nregulations also should seek to bolster defenses to prevent attacks from succeeding in \\nthe first place. \\n\\nThe  Council  of  Europe’s  Convention  on  Cybercrime  (the  Budapest  Convention) \\nsets  minimum  requirements  for  computer  crime  statutes  in  participating  nations \\nand  provides  for  mutual  assistance  in  investigating  and  prosecuting  cybercrimes. \\nThis  cooperation  and  harmonization  is  necessary  because  of  the  global  nature  of \\ncybercrimes, and the criminal is often located in a different country from the target.19  \\nBy harmonizing cybercrime laws, the Budapest Convention reduces the likelihood of \\nsome countries becoming “safe havens” for cybercriminals.20 However, the Budapest \\nConvention has been criticized for being unsuccessful and overall not helping to crack \\ndown on cybercrime.21 It has not been adopted outside of a majority of Council of \\nEurope members and the United States. When Russia, North Korea, Iran, China, and \\nother non-members often are the sources of cyber-attacks, the Budapest Convention \\nprovides the target countries with little recourse. Moreover, criminal law alone is not \\nalways sufficient to prevent attacks in cyberspace due to the challenges of attributing \\nattacks with certainty.22 While the Budapest Convention plays an important role in \\nharmonizing at least some cybercrime laws in some countries, it is not a panacea.23\\n\\nIn some respects, there are even more benefits to coming to a consensus on international \\ncybersecurity law than in criminal law. The Budapest Convention is of limited utility \\nbecause many of the most pernicious attacks are perpetrated from nations that are not \\nparties to the Convention; laws that effectively promote the cybersecurity of public \\nand private systems and networks, however, provide incremental worldwide benefits, \\neven if they have not been adopted by the handful of nations that are the sources of \\nthe attacks. Consider, for example, a cybersecurity regulatory framework that bolsters \\nresistance  and  reduces  the  spread  of  botnets  by  75  percent  in  countries  that  have \\nadopted its safeguards. If half of the nations were to adopt the framework, the overall \\n\\n\\n\\x0cstrength  of  a  botnet  likely  would  weaken  because  it  would  not  be  as  successful  in \\npropagating. \\n\\nSimilarly, the growing body of scholarship that applies jus ad bellum and jus in bello \\nto cyberwarfare is absolutely essential to our understanding of acceptable responses \\nto  cyberattacks  and  it  helps  to  inform  deterrence  strategies.  Understanding  the \\napplication of jus ad bellum to cyberspace is essential in informing a deterrence by \\npunishment strategy. The two editions of the Tallinn Manual have provided a forum for \\nan International Group of Experts on the law of war to articulate both commonalities \\nand  differences  in  views  about  how  their  field  applies  in  cyberspace.24  Although \\nthe Tallinn Manual does not represent the official views of a single organization or \\nstate,25 it is one of the greatest steps in articulating commonalities and differences in \\ninternational cyber law.26\\n\\nLikewise, from 2016-17, the United Nations Group of Government Experts attempted \\nto reach an agreement on norms of cyber issues such as international humanitarian law \\nand the right of self-defense. However, those discussions failed to lead to a consensus, \\nas  some  participants  had  very  different  views  on  the  fundamental  international \\nnorms.27  Indeed,  such  consensus  will  be  difficult  or  impossible  for  norms  related \\nto  jus  ad  bellum  and  jus  in  bello.  But  such  issues  should  not  be  the  only  focus  of \\ninternational discussions. Global norms for domestic cybersecurity issues could play \\nan equally vital role in securing cyberspace. \\n\\nThe cybersecurity of a nation’s infrastructure may play a significant role in its response \\nto a cyberattack, as the success or failure of cyberdefense often determines whether a \\ncyber act constitutes an unlawful use of force.28 Consider, for instance, a cyberattack \\nby Iran on a portion of the U.S. power grid that is operated by a private company. If \\nthe utility has installed sufficient safeguards, the attack may be nothing more than a \\nnuisance  that  causes  little  damage.  If,  however,  the  attack  succeeds,  it  could  cause \\nsignificant  economic  loss,  and  perhaps  even  personal  injury.  Those  two  outcomes \\nwould  warrant  very  different  responses  under  international  warfare  norms.  Just  as \\n\\n\\x0cthe international legal community has attempted to develop common ground as to the \\napplication of the law of war to cyber, so too should the community develop principles \\nthat guide the protection of cyber infrastructure. \\n\\nEfforts to develop transnational common ground on cybercrime law and cyberwarfare \\nnorms  will  not  solve  all  of  the  complex  international  legal  problems  associated \\nwith  threats,  though  they  are  necessary  components  of  the  overall  approach  to \\ncybersecurity.  Moreover,  both  efforts  provide  roadmaps  for  international  dialogues \\nabout  cybersecurity  laws  that  deter  by  denial.  The  Budapest  Convention  and  the \\nTallinn Manual demonstrate that it is possible for nations with different values to at \\nleast agree on some core principles for cyberspace. Both the Budapest Convention’s \\nformal  attempts  at  proscribing  specific  cybercrime  laws  and  the  Tallinn  Manual’s \\nattempts  to  narrate  common,  nonbinding  interpretations  are  essential  as  nations \\nconfront growing cyber threats.\\n\\nAlthough there is not currently a universal set of cybersecurity principles outside of \\nthe cybercrime and cyberwarfare contexts, an analogue exists in the privacy arena and \\ndemonstrates the utility of setting forth a core set of shared legal values for technology \\nlaw.  In  1980,  the  OECD,  an  economic  development  organization  consisting  of  35 \\nnations, published the OECD Guidelines on the Protection of Privacy and Transborder \\nFlows of Personal Data, the centerpiece of which was the OECD Fair Information \\nPractices.29\\n\\nDrawing on robust discussions among participating countries, OECD developed the \\nfollowing eight general principles for information privacy: collection limitation; data \\nquality; purpose specification; use limitation; security safeguards; openness; individual \\nparticipation; and accountability.30 The Guidelines have been revised only once, in \\n2013. Each of the eight principles provides a broad framework under which nations \\ncould  choose  how  to  best  regulate  privacy.  For  instance,  the  collection  limitation \\nprinciples state that “[t]here should be limits to the collection of personal data and any \\nsuch data should be obtained by lawful and fair means and, where appropriate, with \\nthe knowledge or consent of the data subject”.31\\n\\nBroad principles such as this allow for some standardization across nations; yet they \\nalso provide countries with the flexibility to adhere to these principles within their \\nexisting legal systems and policy preferences.32 The OECD Guidelines have helped \\n\\n\\n\\x0cto shape the contours of privacy laws around the world, even beyond the 34 OECD \\nmember nations.33  \\n\\nThe  OECD  Guidelines  are  privacy-focused,  though  the  document’s  Security \\nSafeguards  Principle  states  that  personal  data  “should  be  protected  by  reasonable \\nsecurity  safeguards  against  such  risks  as  loss  or  unauthorized  access,  destruction, \\nuse,  modification  or  disclosure  of  data”.  The  supplemental  memorandum  for  the \\n2013 revisions suggests that these safeguards include data security breach notification \\nrequirements.  Although  this  principle  touches  on  a  cybersecurity  issue,  it  focuses \\non personal information security and does not adequately address the full range of \\ncybersecurity threats, as discussed in the next section. Privacy and cybersecurity are \\noften lumped into the same category of law and share some common issues, but they \\neach present different challenges and should be individually addressed.34 While the \\nprotection of personal information certainly is part of cybersecurity, other threats, such \\nas the theft of trade secrets or attacks on cyber-physical systems, are not adequately \\naddressed by privacy law.35 Cybersecurity law should promote not only the privacy \\nof personal data, but also the protection of systems and data from attacks that could \\ninterrupt economies or threaten national security. \\n\\nThis  is  not  to  suggest  that  the  OECD  framework  has  perfectly  aligned  the  privacy \\nlaws and regulations of all member nations. Far from it. The European Union views \\nprivacy as a fundamental human right, and therefore its privacy laws, including the \\nnew General Data Protection Regulation, are often far more stringent than those of \\nother jurisdictions. However, the OECD Principles, at the very least, give participating \\nnations a basis on which to find some commonalities and a general framework for \\ndiscussing and debating privacy issues. \\n\\n4. goals for InternatIonal cybersecurIty \\nlegal PrIncIPles\\n\\nBecause  nations  have  had  few  robust  and  meaningful  discussions  about  how  to \\npromote and regulate cybersecurity via legal frameworks, it would be impossible to \\npropose a comprehensive set of principles to guide governments globally. \\n\\n\\x0cThis part sets out the goals of global cybersecurity legal standards and a few areas to \\nbegin discussions among nations as they determine how best to address cybersecurity \\nchallenges via laws and regulations. To be clear, I do not suggest that this should serve \\nas the list of international cybersecurity principles. Such a framework would require \\nsignificant multilateral discussion and assessments of both the cybersecurity threats \\nand the legal capabilities and constraints to address those threats. Rather, these four \\ngoals are broad topic areas that serve as a starting point for an international discussion \\nabout common principles. \\n\\nA. Modernizing Laws to Address Current Cybersecurity Threats\\nThe laws in many nations do not adequately address some of the newer cybersecurity \\nthreats, as the laws are outgrowths of pre-Internet legal fields such as privacy torts and \\ncriminal law. International norms could help guide nations as they adjust their laws to \\nthe current threat landscape. \\n\\nOne of the core concepts in the cybersecurity field is the CIA Triad: confidentiality, \\nintegrity, and availability of data, systems, and networks.36 Confidentiality protects \\ninformation  from  unauthorized  access.37  Integrity  ensures  that  the  information  is \\naccurate  and  systems  function  as  intended.38 Availability  guarantees  uninterrupted \\naccess to information and systems.39 An effective cybersecurity program will advance \\nall three goals.\\n\\nUnfortunately, cybersecurity law is often conflated with data security and privacy laws \\nthat have been on the books for many years or decades. This results in a focus on the \\nconfidentiality of personal information, which is the primary security-related concern \\nof  privacy  law. Without  a  doubt,  that  is  an  important  concern,  but  it  overlooks  the \\nconfidentiality of other critical but non-personal information, such as corporate trade \\nsecrets or classified government information. For instance, many jurisdictions require \\ncompanies to notify individuals and regulators about disclosure of certain categories \\nof  personal  information,  and  data  security  requirements  often  apply  to  particularly \\nsensitive types of personal information such as medical records. \\n\\nPrivacy law cares little about integrity or availability, nor do any data security laws \\nthat are largely an outgrowth of privacy laws. Data security regulations, for example, \\noften address the unauthorized access to or acquisition of data. These laws typically \\ndo little to address attacks on availability (such as ransomware) or attacks on integrity \\n(such as website defacement or modifications to database systems that cause physical \\nimpacts, such as explosions in gas lines).40\\n\\n\\n\\n\\x0cLaws should, of course, continue to protect confidentiality. Protecting confidentiality \\nand  privacy  is  not  mutually  exclusive  with  protecting  integrity  and  availability. \\nIndeed, many of the concerns regarding interference in the 2016 American election \\nboil down to breaches of confidentiality: the hacks of John Podesta’s email account \\nand the Democratic National Committee’s servers. However, confidentiality should \\nnot be the exclusive focus, particularly in the age of cyber-physical systems and the \\nInternet of Things, when everyday devices are increasingly connected to the Internet \\nand could be vulnerable to attacks. A modern cybersecurity framework must address \\nthese threats as well as data breaches.  \\n\\nIn addition to promoting all three prongs of the CIA triad, cybersecurity laws should \\nbe forward-looking and should minimize harm from future cyberattacks. Ideally, such \\nlaws would require companies and governments to bolster defenses to a point where \\nthe attacks do not succeed. However, it is highly unlikely that any legal system would \\nentirely prevent all attacks. For that reason, a modern cybersecurity legal framework \\nshould also strive to improve resilience – the ability of a company or government to \\nquickly recover after an attack has occurred.41 \\n\\nB. Uniformity of Regulations\\nRegulation  of  the  private  sector  plays  a  key  role  in  securing  cyber  infrastructure. \\nCompanies that have some of the most critical cyber infrastructure operate in many \\ncountries. Those companies, therefore, are subject to hundreds of legal regimes at the \\nlocal, state/province, and national levels. To the greatest extent possible, cybersecurity \\nregulations  should  be  standardized  across  governments  to  improve  the  ease  and \\nlikelihood of compliance. International norms could help to guide that uniformity.\\n\\nFor instance, companies are subject to dozens of data breach notification laws at the \\nstate/province and national levels, all varying in terms of the specific requirements \\nthat they impose as to what types of personal data trigger the notification requirements \\nand  the  forms  that  the  notices  must  take.42 The  breach  notice  laws  apply  based  on \\nthe residency of the individuals whose data was breached. Thus, a company that has \\ncustomers throughout the world must comply with all of these requirements in the \\ndays  following  a  breach.  Such  compliance  can  be  time-consuming,  and  can  divert \\nattention from efforts to remedy the harms caused by the breach and prevent further \\nintrusions.43\\n\\nPolicy-makers  at  the  international  level  could  help  strive  toward  such  uniformity \\nby  adopting  standards  that  could  be  the  basis  of  private  sector  requirements,  and \\njurisdictions  should  aim  for  uniformity  among  the  regulations  of  state,  provincial, \\n\\n\\n\\x0cand local governments. The European Union’s GDPR, for example, aims to improve \\nuniformity  among  European  Union  members  by  imposing  a  single  comprehensive \\nset of requirements for privacy and security practices when dealing with European \\nresidents’ personal information.44\\n\\nComplete  global  uniformity  of  cybersecurity  laws  is  impossible,  as  countries  will \\ndiffer in their legal constraints and values regarding issues such as privacy, expression, \\nand security. For instance, in Europe, privacy is a fundamental human right,  while \\nthe  United  States  is  more  likely  to  balance  privacy  with  other  interests  such  as \\nfree  expression.45  However,  even  some  movements  toward  similar  cybersecurity \\nregulations would be useful in providing companies with more effective pathways to \\ncomply with the global patchwork of laws. \\n\\nC. Coordination of Coercive and Cooperative Laws \\nCybersecurity laws should contain a mixture of punitive regulations and incentives \\nto  promote  private  sector  security.  Regulations  will  always  play  an  important  part \\nin  bolstering  companies’  cybersecurity.  However,  cybersecurity  differs  from  other \\nregulated  areas  in  that  the  government’s  goals  are  often  generally  aligned  with  the \\ngoals  of  a  company.  A  rational  chief  executive  does  not  want  their  company  to \\nexperience a denial of service attack or data breach, nor does a rational government \\nofficial. \\n\\nFor that reason, there is great room for collaboration between the public and private \\nsectors. Such collaboration should form part of a broader strategy for bolstering the \\ncybersecurity of public and private infrastructure.\\n\\nFor instance, governments across the world are increasingly improving and expanding \\ntheir cyber threat information sharing programs, which allow the private and public \\nsectors  to  exchange  information  and  collaborate  to  reduce  the  spread  and  damage \\nof  cyberattacks.  In  the  European  Union,  the  2016  NIS  Directive  requires  member \\nstates to establish Computer Security Incident Response Teams that monitor, share, \\nand collect information about cyber threats and “establish cooperation relationships \\nwith  the  private  sector”.46  Likewise,  in  late  2015,  the  U.S.  Congress  passed  the \\nCybersecurity Information Sharing Act, which provides companies with limited legal \\nimmunity  for  sharing  cyber  threat  information  and  defensive  measures  with  other \\ncompanies  and  the  federal  government’s  threat  information  sharing  program.  The \\nstatute has been called “the first major piece of cybersecurity legislation enacted into \\n\\n\\x0claw  that  seeks  to  directly  address  the  relationship  between  the  private  and  public \\nsectors”.47 An international dialogue on such efforts could establish best practice for \\nsuch threat-sharing efforts and might also lead to more effective means of exchanging \\ncritical threat information internationally. \\n\\nCybersecurity education also requires collaborative efforts from both the public and \\nprivate  sectors.  It  includes  general  awareness  campaigns  to  reduce  the  success  of \\nphishing and other social engineering attacks, as well as more advanced collegiate and \\ngraduate school training to build a cybersecurity workforce. For instance, the Israeli \\nNational Cyber Bureau has developed a plan both to build cybersecurity awareness \\namong the general public,48 and the EU’s NIS Directive requires each member state to \\nadopt a strategy that addresses “education, awareness-raising and training programs \\nrelating to the national strategy on the security of network and information systems”.49  \\n\\nGovernments could also provide financial incentives, such as tax credits and research \\nand  development  funding,  to  encourage  potential  targets  to  invest  large  sums  of \\nmoney and staffing to bolster their cybersecurity. Because many high-profile targets \\nare multi-national corporations, international coordination on incentives such as tax \\ncredits would be particularly useful in developing a global strategy. \\n\\nInternational norms to improve cybersecurity education are particularly useful with \\na global information technology workforce. Nations could determine any particular \\nskill  shortages  within  cybersecurity  and  align  educational  programs  accordingly. \\nMoreover,  international  principles  could  help  to  guide  and  improve  cybersecurity \\nawareness  campaigns  to  reduce  the  likelihood  of  cybersecurity  attacks  succeeding \\ndue to human error. \\n\\nD. Secure Throughout the Supply Chain\\nJust as cybersecurity threats arise due to the global interconnection of networks and \\nsystems,  they  also  often  arise  because  products  and  services  rely  on  a  number  of \\ncomponents  developed  around  the  world  and  inadequate  security  of  a  component \\ncan make an entire product or service vulnerable. Countries have individually begun \\naddressing the supply chain in a thoughtful manner. For instance, in 2008, the United \\nStates began its Comprehensive National Cybersecurity Initiative, which recognized \\nthe need for “partnership with industry to develop and adopt supply chain and risk \\nmanagement standards and best practices”.50 However, the Initiative recognized that \\nsupply chain cybersecurity is not merely a problem that arises from U.S. companies: \\n\\n\\n \\n\\x0c“Risks  stemming  from  both  the  domestic  and  globalized  supply  chain  must  be \\nmanaged in a strategic and comprehensive way over the entire lifecycle of products, \\nsystems and services.”51\\n\\nInternational standards for supply chain cybersecurity would be particularly useful, as \\nproducts may rely on technology that is manufactured in many nations. A substantive \\ndialogue between governments and industry could develop best practices for supply \\nchain  cybersecurity,  which  could  be  used  as  the  basis  for  national  or  regional \\ncybersecurity  laws.  Such  standardization  could  improve  the  overall  security  of \\nproducts and services while increasing the ease of compliance. \\n\\n5. conclusIon\\n\\nThis  paper  argues  that  nations  should  broaden  their  cyber  discussion  beyond \\ncyberwarfare  and  attempt  to  improve  the  patchwork  of  domestic  laws  that  seek  to \\nimprove the cybersecurity of public and private infrastructure and information. Nations \\ncannot address cybersecurity threats merely by developing domestic legal rules that \\nfail to account for the laws and programs in other nations. An international framework \\nfor  cybersecurity  would  help  nations  to  align  their  regulations  and  public-private \\npartnerships  to  address  threats  that  often  know  no  borders.  Effective  cybersecurity \\nlaws require collaboration between governments worldwide and between the public \\nand  private  sectors. Although  nations  will  continue  to  carve  out  their  own  paths,  a \\nproductive  international  dialogue  would  help  policy-makers  to  find  some  common \\nground on effective cybersecurity laws and programs. \\n', 'BMJ 2017;357:j2375 doi: 10.1136/bmj.j2375 (Published 2017 May 17)\\n\\nPage 1 of 2\\n\\nEditorials\\n\\nEDITORIALS\\n\\nEffective cybersecurity is fundamental to patient safety\\nThe NHS must reduce its vulnerability and build resilience against future cyber attacks\\n\\nGuy Martin clinical research fellow 1, James Kinross senior clinical lecturer 1 1, Chris Hankin director 2\\n\\n1Department of Surgery and Cancer, Imperial College London, London, UK; 2Institute for Security Science and Technology, Imperial College London,\\n\\nThe global WannaCry ransomware attack has had a\\ndisproportionate effect on the UK healthcare sector, highlighting\\nthe poor state of cybersecurity in the NHS and the failure to\\nrecognise it as a fundamental matter for patient safety.\\n\\nWannaCry is trojan malware designed to extort money by\\nholding files to ransom. It exploits a known vulnerability in the\\nWindows operating system that was initially identified and\\npatched by Microsoft in March 2017, with a further patch\\nreleased after the event.1 2 The attack is widely reported to have\\nused system exploits released by the hacker group the Shadow\\nBrokers but originating from the US National Security Agency.\\nOnce a computer is infected the malware creates encrypted\\ncopies of files before deleting the originals; the only way to\\nretrieve affected data is to pay the bitcoin ransom. Computer\\nsystems across more than 150 countries have been infected, and\\nonly the fortuitous intervention of a 22 year old researcher who\\nidentified and activated a kill switch in the malware has\\nprevented further spread and disruption.2 3\\nIt is not yet clear exactly how many organisations in the NHS\\nhave been affected, or to what extent. It’s reported that around\\n50 trusts were directly affected, and some severely so. Many\\nmore hospitals pre-emptively shut down computer systems,\\nsubstantially escalating the effect of the attack. Either way, the\\noutcome was an unprecedented disruption of clinical care that\\ncompromised patient safety and caused a potentially dangerous\\nerosion in public trust of electronic health records and the NHS.\\nThe fact that we are unable to accurately measure the effect of\\nthis attack is a further indictment of the failings in NHS\\ncybersecurity.\\n\\nOne certainty in cybersecurity is that there will be more attacks,\\nand some of those attacks will succeed. So why was the NHS\\nso severely affected, and how can we reduce the likelihood and\\nimpact of future attacks? There have been many recent\\npublicised attacks on healthcare organisations around the world,\\nincluding the Hollywood Presbyterian Medical Center, the\\nAustralian Red Cross Blood Service, and two NHS\\ntrusts—Lincolnshire and Goole and Barts Health.4-6 The health\\nsecretary, Jeremy Hunt, was warned last year by the Care\\nQuality Commission and the national data guardian, Fiona\\n\\nCaldicott, of the cyber risks to the NHS 7; these warnings have\\ngone largely unheeded.\\nBetter protection\\n\\nCyber risk has three elements: threat, vulnerability, and impact.\\nRegular and secure backup means lost or encrypted data can be\\neasily replaced, greatly reducing the effect. However, effective\\nmitigation against cyber risk requires long term investment in\\ninfrastructure and people. The implicit approach of the UK\\ngovernment and NHS leadership over a long period has been\\nto ignore the chronic risk of cybersecurity. This has resulted in\\na prolonged time at risk, akin to a ticking time bomb. Many\\nNHS trusts are still using Windows XP, which has not been\\nsecure since the government chose not to extend the £5.5m\\n(€6.4m; $7m) support deal with Microsoft in 2015,8 while\\naround £1bn of infrastructure funding that supports IT has been\\ntransferred to prop up everyday activities.9 Many NHS\\norganisations spend as little as 1-2% of their annual budget on\\nIT, compared with 4-10% in other critical sectors, with only a\\nsmall proportion of that going on security.10\\nEffective cybersecurity also requires good governance. The\\nmultistranded response to this latest incident—in which Hunt\\nhas remained largely quiet—underlines the extremely\\nfragmented governance of cybersecurity in the NHS. This is a\\ncore issue underpinning the recent attack and affects healthcare\\nmore profoundly than other critical sectors such as financial\\nservices, energy, or central government. Lack of clarity over\\ngovernance results in the buck being passed from one\\norganisation to another—NHS Digital, National Cyber Security\\nCentre, Department for Health, NHS Trusts—with no clear\\naccountability at a national level for managing what is self\\nevidently a national problem. Merely repeating the mantra that\\nthe government has invested £1.9bn in cybersecurity will not\\nremediate today’s problems, or give assurance that the NHS\\nwill be better placed to protect itself in future.\\n\\nThe cybersecurity threat to healthcare is an unavoidable new\\nreality. The recent attack, while hugely disruptive, could have\\nbeen much worse: malware can easily be equipped to erase or\\nalter data, and an attack by a country during a conflict may have\\nan even greater impact. The NHS must reduce its vulnerability\\nand build resilience as a matter of urgency. The digitalisation\\n\\nCorrespondence to: C Hankin c.hankin@imperial.ac.uk\\n\\nFor personal use only: See rights and reprints http://www.bmj.com/permissions\\n\\nSubscribe: http://www.bmj.com/subscribe\\n\\n\\x0cBMJ 2017;357:j2375 doi: 10.1136/bmj.j2375 (Published 2017 May 17)\\n\\nPage 2 of 2\\n\\nEDITORIALS\\n\\nof healthcare is unquestionably the future, but this digital\\ntransformation needs a grown-up and credible strategy that\\nconsiders the risks and the benefits; effective cyber security is\\na fundamental prerequisite for patient safety. This attack is a\\nwake-up call.\\n\\nCompeting interests: We have read and understood BMJ policy on\\ndeclaration of interests and have no relevant interests to declare.\\n', 'Global cybersecurity governance:  \\nA constitutionalist analysis\\n\\ni n g o l f   p e r n i c e\\n\\nAlexander von Humboldt Institute of Internet and Society, Französische Straße 9, 10117 Berlin, Germany\\n\\nEmail: pernice@hiig.de\\n\\nAbstract:  With the progressive digitisation and use, in particular, of the internet of \\nthings and artificial intelligence by industries, commerce, financial services, science \\nand education, the public administration, health services as well as individuals, our \\nsociety and daily life gets more and more dependent on the security of the net: \\ncybersecurity. The new risks are self-made, a threat to almost everybody and new \\nin kind. And they have a global dimension. For the difficulty of attribution of cyber \\nattacks traditional concepts of deterrence and defence are not a solution. Given \\nthe new conditions of the ‘digital constellation’ this article aims at exploring \\ninstruments and methods of cybersecurity governance in a broad sense, learning \\nfrom internet governance and taking a constitutional perspective. It is based upon \\nshared responsibility, resilience and citizens’ participation in the making and future \\napplication of an inclusive global rule-making system. Multi-stakeholder mechanisms \\nare combined with deliberative processes, standardisation and legislative action. In \\naccordance with the principles of global constitutionalism this new framework of \\nglobal  rule  generation  would  emerge  as  a  common  democratic  instrument  of \\npeople to meet common challenges in addition and complementary to action for \\ncybersecurity at the local, regional, national and supranational levels.\\n\\nKeywords:  cybersecurity; digitisation; internet governance; global \\nconstitutionalism; regulation\\n\\nI. Introduction : Security in the digital constellation\\n\\nDigitisation and the internet are changing our world, lives and society. \\nThey allow real-time business transactions and the functioning of financial \\nmarkets worldwide. They provide quasi unlimited access to information, \\nand allow real time communication beyond borders. Equal, safe and, \\npreferably,  free  access  to  the  internet  is  becoming  a  condition  for \\neverybody’s participation in the markets, in social life and in politics. This \\nincludes access to culture, education and knowledge, to social networks \\nand discussion platforms, to electronic markets and e-services. Open data \\n\\n112\\n\\nGlobal Constitutionalism (2018), 7:1, 112–141 © Cambridge University Press, 2018doi:10.1017/S2045381718000023\\x0cGlobal cybersecurity governance  113\\n\\nand e-government allow a new and closer relationship between citizens \\nand public administration.1\\n\\nThe  internet  is  also  a  medium  of  transparency,  communication, \\nparticipation and open public political discourse worldwide; frameworks, \\nplatforms and forums for open discursive processes of standard- and norm-\\nsetting on a multi-stakeholder basis are offered, as we already know from \\ninternet governance, and methods of e-democracy and e-voting based upon \\nblock-chain or other technologies are making political processes more \\ninclusive and trustworthy. As outlined in another piece of work,2 the internet \\neven gives our imagination a perspective for developing a constitutional \\nframework for commonly generated and accepted rules at the global level \\non issues requiring global regulation. Global constitutionalism3 seems best \\nto  conceptualise  the  legal  perspective  of  the  process  from  which  this \\nframework may emerge, even in the absence of a pouvoir constituant in the \\ntraditional sense. It is about democratically legitimate procedures for taking \\ndecisions on issues that are beyond the reach of national politics and \\nsovereignty. Common rules on the operation and use of the internet are just \\nsome of these issues, which also include policies against climate change and \\nthe preservation of peace and security worldwide. The digital revolution and \\nthe internet allow us to think beyond traditional limits of what constitutes \\nthe present world order, with a view to constitutionalising in a democratic \\nway the so far fragmented system of international law and global governance.\\nDespite all its benefits, however, the digital revolution also has a flip side: \\ncyber-attacks, new threats and risks for security, for data protection, privacy \\nand other human rights. This is the ‘dark side’ of digitisation. The Snowden \\nrevelations have alarmed us about new forms of mass-surveillance by \\nintelligence services, activities that have been perceived as an inacceptable \\nthreat to the privacy and freedom of people. Other attacks are directed \\nagainst critical infrastructures, governmental institutions, private enterprises, \\nand even hospitals and military systems. The ransomware attacks across \\nmany countries called WannaCry and NotPetya are but two examples of the \\npublicly very visible cyber-attacks rolling around the globe.4 In a speech of \\n\\n\\n14 February 2017, the German Minister of Research and Education said that \\nthe annual damage caused by cyber-attacks to German industry is estimated \\nat 50 billion Euros.5 The latest news has come from the German Ministry of \\nDefence: they registered 284,000 cyber-attacks against IT equipment of the \\nBundeswehr during the first nine weeks of this year.6 A new Cyber-Defence-\\nCorps created this spring by the German government will consist of 13,500 \\nIT-soldiers and specialists, and is supposed to grow further.7\\n\\nThe more governments become aware of the risks attending digitisation, \\nsuch as cyber threats or foreign surveillance practices, the more often we \\nhear calls for ‘digital sovereignty’.8 Yet, digital sovereignty, understood as \\nan aspect of national sovereignty, is not the solution, at least as long as an \\nopen and free internet is regarded as beneficial to our societies. The internet, \\nboth with its benefits and risks, is borderless from the outset. There is \\nnothing that seems to be more at odds with traditional concepts of state \\nsovereignty, thus, than the internet. Neither individual states, nor even the \\ninternational community have control over it. Given its rapid spread and \\npopularity worldwide, substituting the internet by other technologies does \\nnot seem to be a realistic option. Nor have states an interest to cut themselves \\noff or to establish their own system;9 an alternative would not offer what the \\ninternet makes possible: global communication based upon a common \\ntechnology (protocol).10 One of the key conditions of its functioning, the \\ndomain name system, has developed in the form of, and is governed by a \\nprivate corporation, ICANN, that has found recognition globally and was \\nnot in the past nor will it in future be controlled by one state.11 In spite of \\n\\n\\nall  attempts  of  states  to  taking  over  some  control  for  their  respective \\nterritory,12 and in spite of the many tools developed for geo-blocking or \\ncontent filtering with a view of protecting national intellectual property \\nrights, public order13 and, perhaps, in future even national democratic \\nprocesses from foreign in information operations,14 it is questionable whether \\nnational  law  and  physical  coercion  will  prevail,  as  suggested  by  Jack \\nGoldsmith and Tim Wu in 2006 talking about ‘the bordered Internet’.15 What \\nMilton Mueller rightly calls the ‘mismatch between its global scope and the \\npolitical and legal institutions for responding to societal problems’ (original \\nemphasis),16 as he argues, leads to more or less effective strategies of \\n‘alignment’,  but  not  to  a  fragmentation  of  the  internet.17  National \\nregulation and law enforcement regarding content, or data protection and \\nprivacy, for the protection of intellectual property, or the public order \\nlimits the use or even access to the internet, but accepts the internet as a \\nglobal communication infrastructure. And with regard to cybersecurity \\neven ‘alignment’ does not seem to be an effective tool against cyber-attacks \\nfrom anywhere in the world.\\n\\nWith the increasing density of relations among people around the globe \\ndue  to  better  information  and  communication,  on  the  one  side,  and \\ngrowing global challenges for which global response is required, on the \\nother, and in spite of all divergencies regarding access to the internet, \\ndigital literacy and technological adaptation around the world, not to \\nspeak of the remaining ‘digital divide’, the digital society is becoming \\nglobal step by step, and so must be governance and the regulation of the \\ninternet to protect public goods and ensure security in compliance with \\nour common values.\\n\\n\\nFollowing some recent incidents of terrorism, Theresa May is calling for \\n‘international agreements with allied democratic governments to regulate \\ncyberspace to prevent the spread of extremist and terrorism planning’.18 \\nYet, regulating the internet or cyberspace is not, as experiences shows, \\neasily reached by international agreements. What is needed is, instead of \\ndigital sovereignty or international cooperation, a new global constitutional \\napproach to governance and regulation, based upon digital competence, \\nresilience and diligence, coupled with awareness of the risks of digitisation. \\nWhat I would call the ‘digital constellation’, much more drastically than \\nJürgen Habermas’ postnational constellation19, is global; it is incompatible \\nwith  the  idea  of  national  sovereignty  and  affecting  the  whole  of  (the \\nglobalised) society.20\\n\\nLooking  closer  at  cybersecurity,  we  discover  that  particularly  in  \\nthe world of security policies, digitisation has brought about dramatic \\nstructural  changes.  Traditional  patterns  need  to  be  revisited.  The \\nfollowing observations seek to highlight some of the characteristics to \\nbe  borne  in  mind  when  assessing  possible  strategies  of  cybersecurity \\ngovernance.\\n\\n  1.   Cybersecurity is a concern of the individual user, and of businesses or \\nundertakings at the micro-level, as much as of the society as a whole, \\nstates and supra- and international organisations at the macro-level. \\nCommunication and traffic systems, energy and water supply, even \\npublic services like education, health, police and government, can all \\nbe hit by cyber-attacks and cyber crime. We are, all of us, potential \\nvictims.\\n\\n  2.   Similarly,  all  of  us  are  potential  attackers.  The  origin  of  threats  to \\ncybersecurity can be states, or governments, but also organisations, \\nterrorist movements or individual hackers. One person alone can cause \\ndamage that in former times only an army or similar organisations were \\n\\n\\nable  to  produce.  Unknowingly  and  unwillingly,  by  using  unprotected \\ndevices, all of us may even support DDos attacks or botnet actions.21\\n\\n  3.   The quality and impact of cybersecurity threats range from the functioning \\nof private IT-systems to the functioning of critical infrastructures of great \\ngeographical extent. Even nuclear plants and defence systems are not safe: \\nif the entire electricity grid is hit for more than a short period of time, the \\nentire system of communication and supply services risks breaking down. \\nThe result could be chaos.\\n\\n  4.   The distinction between external and internal (cyber-)security policies \\nhas  lost  its  meaning.  Threats  to  cybersecurity  can  have  external  or \\ninternal, state or private, sources. As long as the problem of attribution \\nremains unsolved, defence is a questionable concept and, in particular, \\ncyber-deterrence or retribution and ‘hack-back’ are not viable options.\\n\\n  5.   The world of nation states as sovereign entities arranging their relations \\nthrough international law is being challenged: a single state cannot \\ngovern even the essential conditions of security for its citizens on its \\nown. The global scale of the internet with all its benefits, instead requires \\nglobal mechanisms for protection against cyber-attacks, for setting up \\ncommon rules and for ensuring law enforcement.\\n\\nTalking about cybersecurity governance relates to aspects dealt with in the \\nframework of internet governance, but with the focus on security it reaches \\nin much broader issues of general policies. The recent impressive study by \\nKarine Bannelier and Théodore Christakis, ‘Cyber-Attacks – Prevention-\\nReactions’ emphasises the ‘extreme complexity of the problem, marked  \\nby the great diversity of the actors involved’.22 Cybersecurity literature, \\n\\n \\n\\x0c118  ingolf pernice\\n\\nso far, looks at specific incidents, instruments or legal questions. The aim \\nof the present article is to take a broader perspective and relate the five \\nobservations made above to the question of governance, with a view to \\nreducing this complexity. To this end, multilevel and, as an element of it, \\nglobal constitutionalism is taken as a normative theory that informs and \\nallows  to  frame  a  model  of  governance  that  includes  legitimate  rule-\\nmaking at the global level as it would not be possible without the internet \\nand, simultaneously, ensures that the internet itself is regulated and can be \\ntrusted as an communication infrastructure for not only economic but also \\ndemocratic processes at all levels.\\n\\nTo be sure, the term ‘governance’ used in the present context is not \\nidentical with the term ‘government’. It is understood in a broader sense \\nand generally means the processes of coordination of behaviour in society \\nby multiple actors and factors.23 What emerges from governance, as a \\nresult, cannot be determined in advance. We can talk about governance \\neven if there is not a single government acting, but many, and if there are \\nother actors participating, like individuals, business enterprises, civil society \\norganisations etc. This is what represents our present world order: our \\nliving conditions are emerging from a process in which state governments \\nand many other actors and agencies are interacting, in the attempt also to \\nmanage critical moments, uncontrolled developments and factors that \\ninfluence the human condition and behaviour.\\n\\nOne  of  these  factors  is  the  progressive  use  of  IT  and  the  internet.  \\nIn parallel, there is an increasing threat to cybersecurity and trust, which \\nare both, in turn, conditions for the application of these technologies. \\nCybersecurity  governance  encompasses  all  processes  of  coordination \\nregarding  cyberspace  when  new  threats  arise  hand  in  hand  with  the \\nadoption of new technologies and the introduction of new IT services for \\npublic and private use. Better understanding the specific threats and risks, \\ntheir possible sources and our shared responsibility for cybersecurity and \\npeace (section II) helps us better to assess the type of instruments available \\nfor preserving cybersecurity (section III). As it appears, the present toolbox \\nfails to allow effective response to the increasing threats. Exploring some \\ncornerstones of a system of cybersecurity governance in the light of global \\nconstitutionalism, however, seems to offer new perspectives for making \\ncyberspace a safer place (section IV).\\n\\n\\nII. Assessing cyber threats and responsibilities\\n\\nThreats to cybersecurity are a self-made evil in our society, an evil that \\nseems to be spreading at the same speed at which applications of IT are \\nincreasingly determining our daily life. Cybersecurity threats differ from \\nthose involved in traditional security issues, in particular with regard \\nto the problem of attribution. The risks we are taking thus compel us \\nto revisit our notion of responsibility for the cyber threats we are facing \\nas a result of adopting these new technologies.\\n\\nCyber threats – self-made evil\\n\\nToday, there is no safe place in cyberspace. Cybersecurity policies have \\nto seek effective protection for the individual as well as for the proper \\nfunctioning of our economic, social and political systems. With the internet \\nof things, we are becoming even more dependent, in matters of everyday \\nlife,  on  the  security  of  the  devices  and  services  offered  by  IT  and  the \\ninternet. Smart homes and smart energy, electronic banking and financial \\nmarkets, digital traffic regulation and autonomous cars, industry 4.0 or \\nautomated decision-making on taxation and in other fields of administration \\non their way to becoming ‘smart government’24 are but a few examples of \\napplications through which we are making ourselves dependent upon \\nfunctioning IT. In particular, the protection of critical infrastructures is \\nkey to the functioning of our societies, but so is the multitude of individually \\nused  hard-  and  software  applications,  machine  learning  and  artificial \\nintelligence that are increasingly determining our daily life and work.\\n\\nWe have allowed the internet in our digital society to play the role that \\noxygen plays in our daily life; stupidly, perhaps. The more we are dependent \\nupon  it,  the  more  we  have  to  take  cybersecurity  seriously.  Before  we \\nbecome engaged in developing cyber armaments, however, with the effect \\nof potentially increasing the threats to our security, it would seem to be \\n\\nwise  to  better  study  and  understand  the  risks.  The  first  insight  is  the \\ncorrelation between the increased use of IT and the increased risks we \\ncreate, far beyond the IT systems strictu sensu. The more we make our \\nsocieties dependent on safely functioning IT-related products, processes \\nand structures, the more cybersecurity will be in demand.\\n\\nCyber defence and attribution\\n\\nNational  security  and  defence  policies,  as  we  know  from  history,  are \\ndirected against a potential or real enemy. The government of another \\ncountry deciding to invade our country by sending troops and tanks, \\nsupported by naval and air forces may try to strike down our defences, \\nwalls, troops etc and to subject our country and people to foreign authority. \\nCyberwar and cyber-attacks are different. Nothing and nobody needs to \\nmove or invade; the attack works on the inside – simply through some \\nsignals or messages on the net from anywhere in the world – but the \\ndestructive effects can be similar. A cyber-attack might prepare the ground; \\nit might be the first step followed by more classical warfare. It might be for \\nother purposes. Who knows? And who knows where the attack is coming \\nfrom? It could be a state, or an individual, or a terrorist organisation acting \\nfrom within our own country or from outside it.\\n\\nThe  problem  of  attribution  remains  unresolved.25  In  spite  of  great \\nefforts – and some apparent success as in the case of the North Korean attack \\non Sony – there seems to be no technical solution to the problem yet.26 Talking \\nabout ‘cyber-deterrence’ and ‘self-defence’ against a determined offender in \\nthe traditional sense, thus makes little sense, except cases where the attacker \\nreveals reliably his or her identity. And even if we could qualify, legally, \\na cyber-attack of a certain gravity as an ‘armed attack’ in the sense of Chapter \\nVII and, in particular, Article 51 of the UN Charter, who should we take \\nmeasures to restore peace, or self-defence, against?\\n\\nWe thus need a conceptual change in security thinking. We also need to \\nrevisit our legal concepts and practical approaches to preserve international \\n\\npeace and security in the digital constellation. This includes considering \\nwho is – or should be – responsible for the preservation of peace in the \\ndigital age.\\n\\nShared responsibilities for cybersecurity and peace\\n\\nAs everybody is a potential victim and a potential attacker in cyberspace, we \\nfind ourselves back in a Hobbesian ‘state of nature’27 – potentially a war \\nof everybody against everybody. The answer of the contractualists in political \\nphilosophy was the social contract: the individual authorises the state to \\nensure security, if necessary by violence, while the state is bound to respect \\nfundamental  rights  and  constitutional  principles  like  the  democratic \\nparticipation of the individual and the rule of law. Security, both internal and \\nexternal, is the ultimate justification and responsibility of the sovereign state.\\nThis was the approach during the seventeenth, eighteenth and nineteenth \\ncenturies. Eventually, terrible wars of the twentieth century told us that a new \\napproach was needed. The idea of European integration, presented by Jean \\nMonnet, can safely be taken as a revolutionary step ahead, giving us a period \\nof almost 70 years of peace in the EU.28 The new approach means that public \\nauthority is shared among diverse levels of responsibility for diverse areas of \\naction, in accordance with the principle of subsidiarity. It adds new sovereign \\npowers in areas that are beyond the reach of national policies. This seems to \\nbe the greatest achievement of political thinking in the twentieth century!\\nSimilar creativity is needed in the twenty-first century for what I call the \\nthe digital constellation. States play a key role in preserving peace, but the \\ndigital constellation not only presents new opportunities, but also entails a \\nnew risk environment.29 The responsibility of states includes what Bannelier \\nand Christakis call ‘cyber-diligence’: protection against and prevention of \\ncyber-attacks on and from the national territory.30 But more is necessary. \\nStates  are  only  one  of  the  instruments  available  to  help  us  organise \\ncybersecurity  and  so  preserve  cyber  peace  –  ‘us’  meaning  the  digital \\n\\n\\nsociety, which is not national, not European or American, but is becoming \\nglobal.\\n\\nIs it possible to understand cybersecurity and peace not only as our common \\ninterest but, beyond this, as our shared responsibility? If we want to benefit \\nfrom the new information technologies globally, can we excuse ourselves and \\nescape from taking responsibility at this level? Thus, the question is: how can \\nwe conceptualise our shared responsibility for cybersecurity and peace at the \\nglobal level? Let me offer an answer that is ‘all inclusive’: a multilevel and \\nmulti-stakeholder system of cybersecurity governance, a system that includes \\nall stakeholders: the individual citizen and civil society, business enterprises, \\nand public authorities, from the local up to the global level.\\n\\nIII. Ensuring cybersecurity and peace: The toolbox\\n\\nAllocating responsibilities for cybersecurity to actors or institutions is one \\nthing; the instruments for achieving cybersecurity and peace are another. \\nThis concerns the cybersecurity toolbox, with different roles for the diverse \\nactors.  While  each  of  the  tools  is  described  separately  hereafter,  the \\nperspective of cybersecurity governance implies that their interaction and \\nsynergies  are  what  only  can  make  them  effective.  The  holistic  approach \\nconceptualising the diverse tools as part of one coherent system or strategy, \\nwith private actors and public authorities acting hand in hand, seems to \\nenable achieving the necessary results.\\n\\nIndividuals: Self-protection, resilience, participation\\n\\nAs individuals and users of the internet, we cannot leave it up to only the \\npublic authorities to protect us. There is no such thing as an internet police \\nforce. Self-protection is necessary, possible and crucial. Self-protection in \\ndigital matters means education, digital literacy, care with our passwords, \\nawareness and attention when we are purchasing and using hardware and \\nsoftware. Self-protection means the application of firewalls, regular updating \\nof  software,  frequent  backups,  the  responsible  choice  and  use  of  devices, \\nmaking sure that they are protected against, and not abused by hackers. \\nSelf-protection in some cases adds to the cybersecurity of others too.\\n\\nResilience is a priority. As a general concept ‘resilience’ means robustness \\nas well as flexibility and adaptability.31 It is about the quality of hardware \\nand software. It may be costly but it pays off. Certain precautions, such as \\n\\nupdating software in order to increase robustness, can easily be taken by \\neverybody. Regular backups allow the private user to protect themselves \\nagainst the loss or destruction of documents or software.\\n\\nIn contrast, self-defence in the form of ‘wild’ hack-back32 is not a tool \\napplicable among private parties,  if it is a tool at all. For deterrence, \\ncriminal law, and for compensation delict law exist and apply in cyber-\\nrelations as in other areas of personal security, without exception. But, \\nagain, how can we determine exactly who the attacker is?\\n\\nAn almost forgotten tool in the hands of the citizens is active participation \\nin the political processes and multi-stakeholder bodies with the aim of \\nenhancing cybersecurity. This includes discourse and pressure through \\ncivil society organisations, but also the use of information, transparency \\nand control, made available by the internet, in order to press for more \\nsecurity and to hold political leaders and institutions accountable for their \\nactions or omissions.\\n\\nBusiness enterprises: Product design, alert systems, security-\\nengineering, standards\\n\\nBusinesses should intensify efforts to support individual self-protection and \\nto provide their own self-defence and security. No unprotected hardware \\ndevice should be put on the market. Systems of bug detection and security \\nupdates for software should be mandatory. Enterprises have set up and \\nshould adhere to private systems for mutual information on cyber-attacks \\nand  sharing  of  best  practices,33  such  as  ‘Threat-Exchange’  offered  by \\nFacebook34 and the German DCSO.35 Such systems should stretch across \\nborders and become global. Privacy- and security-engineering36 must be \\npart of the product development of all industries and have to be intensified. \\nTechnical standardisation in IT areas should focus also on privacy and \\nsecurity by design so as to meet basic security requirements.\\n\\nAs  global  players,  private  enterprises  should  proactively  engage  in \\nthe  framing  of  structures  to  enhance  cybersecurity.  In  some  form  of \\nself-regulation they could establish globally applicable codes of conduct \\nregarding privacy, data- and cyber-security and so set general standards for \\n\\nprivacy- and security-engineering and establish technical safety requirements. \\nA more audacious proposal is the trilogy of Microsoft with Brad Smith \\ncalling  for  the  adoption  of  a  ‘Digital  Geneva  Convention  to  protect \\nCyberspace’ as a legally binding instrument for states37, supported by a \\n‘Tech Accord’ among business enterprises requiring them not to support \\n‘offensive cyber operation’, to protect customers, and to bolster first-response \\nefforts.38  The  third  pillar  is  the  proposal  to  establish  an  ‘Attribution \\nOrganisation’ as a ‘private-sector-led, independent and transparent’ body \\nto provide a ‘foundation of a fact-based, global dialogue about the nature \\nof significant cyber-attacks’.39 The tasks of this organisation would be \\nlimited  to  attribution  only,  while  incident  response  and  enforcement \\nwould remain the responsibility of the states.40 However, the establishment \\nof such an organisation would presuppose that attribution is possible. \\nNo evidence, however, exists for this hypothesis.\\n\\nPublic authorities: Constitutional duties, European and \\ninternational cooperation\\n\\nStates  play  a  special  role  in  cybersecurity.  In  a  constitutional  perspective, \\nfundamental rights and principles are providing the framework for security \\npolicies: while limiting governments in their actions, they are also requiring \\nlegislators and governments to take action. The tools for public authorities \\nat national, European and international level are diverse in impact and reach, \\nranging from awareness-raising and promoting best practices, legislation and \\nthe establishment of cybersecurity agencies, new forms of military defence, \\nintelligence and intergovernmental cooperation, to cooperation within \\ninternational organisations and through international treaties.41\\n\\nConstitutional frame: Fundamental rights and principles\\n\\nIn  2008  the  German  Federal  Constitutional  Court  established,  in  its \\nfamous case regarding online searches, a new fundamental right relating to \\ncybersecurity:\\n\\n\\nThe general right of personality (Article 2.1 in conjunction with Article \\n1.1 of the Basic Law [Grundgesetz – GG ]) encompasses the fundamental \\nright to the guarantee of the confidentiality and integrity of information \\ntechnology systems.42\\n\\nFundamental rights protect the individual against public authority, and the \\nCourt found the right to integrity of information technology systems violated \\nin the case on online searches.43 But they are also an expression of values to \\nbe given effect by the legislator and may, thus, legitimise restrictions of other \\nfundamental rights. This equally applies to Article 6 of the European Charter \\nof Fundamental Rights, the guarantee of the ‘right to liberty and security of \\nthe  person’,  a  wording  similar  to  that  of  Article  5(1)  ECHR.  The  ECJ \\nunderstands the guarantee of the confidentiality and integrity of information \\ntechnology systems as a full subjective right of the individual,44 and refers to \\nArticle 6 of the Charter laying down ‘the right of any person not only to \\nliberty, but also to security’, in order to emphasise, in its 2014 ruling on the \\ncase Digital Rights Ireland, that security constitutes an objective of general \\ninterest and, in particular,\\n\\nthat  the  retention  of  data  for  the  purpose  of  allowing  the  competent \\nnational authorities to have possible access to those data, as required by \\nDirective 2006/24, genuinely satisfies an objective of general interest.45\\n\\nThe fundamental right to security so legitimises legislation that, within the \\nlimits  of  proportionality,  imposes  restrictions  on  other  fundamental \\nrights, like data protection. Given this broad interpretation, the right to \\nsecurity under Article 6 of the Charter means that if it is not a subjective \\nright of the individual to be protected by the courts, at least it establishes \\na fundamental principle compelling governments and legislators to promote \\ncybersecurity  and  to  make  sure  that  cybersecurity  is  taken  seriously  by \\nbusinesses and individuals.46\\n\\nArticle 9(1) of the International Covenant on Civil and Political Rights \\n(1966)  providing  for  ‘everyone  …  the  right  to  liberty  and  security  of \\n\\n\\nperson’  should  be  interpreted  in  the  same  way:  it  compels  states  and \\norganisations to take action on cybersecurity and, in implementing this \\nduty, to engage in international cybersecurity cooperation.\\n\\nLegislation and agencies\\n\\nAt a European and national level, one important focus of legislative activities \\nis rules on general information, warning and cooperation requirements in \\nthe event of cyber-attacks. The EU’s Agency for Network and Information \\nSecurity (ENISA) was set up in as early as 2004, and since then has provided \\nexpertise and encouraged cooperation between national authorities. It is \\nnow responsible for supporting the implementation of the new Directive \\n2016/1148 ‘concerning measures for a high common level of security of \\nnetwork and information systems across the Union’ (NIS). This Directive \\nmainly provides for national cybersecurity strategies, cooperation and trust \\namong national authorities within a ‘computer security incident response \\nteams  network’  (‘CSIRTs  network’).  It  also  establishes  security  and \\nnotification requirements for operators of essential services and for digital \\nservice providers. It is to be transposed into national law by May 2018, \\nthough much of its contents is already in place in some Member States. In \\nGermany the ‘Federal Office for Information Security’ (BSI) was established \\nas early as 1991, and the new ‘IT-Security Act’ of 2016 largely implements \\nthe requirements of the Directive.47\\n\\nCyber crime is another area in which action has already been taken. The \\nTreaty of Lisbon established a new competence of the EU to harmonise \\nlegislation on computer crime.48 Directive 2013/40/EU on attacks against \\ninformation systems is a first, but important, step to combat cyber crime \\nand to protect cybersecurity EU-wide. Data security is mentioned as one of \\nthe principles of data protection under Article 5(1)f GDPR, and Articles \\n32 to 34 of this Regulation impose on the controllers and processors of \\ndata not only the duty to ensure security of the data in their possession but \\nalso to notify personal data breaches to the supervisory authority and to \\n\\n‘Positive Verpflichtungen unter der EMRK: Unentbehrliches Element einer gemeineuropäischen \\nGrundrechtsdogmatik,  leeres  Versprechen  oder  Grenze  der  Justiziabilität?’  in  (2014)  74 \\nZeitschrift  für  ausländisches  öffentliches  Recht  und  Völkerrecht  187–213,  also  at  <http://\\nwww.zaoerv.de/74_2014/74_2014_2_a_187_214.pdf>.\\n\\nthe data subject. With a view to the possible damage for the data-subject \\nor reliability of databases caused by manipulation or destruction of data \\nthe integrity of data is becoming a major concern also of cybersecurity and \\nneeds particular attention.\\n\\nMore is possible and necessary, however. Products are often put on the \\nmarket  without  necessary  checks  to  ensure  their  safe  application  and \\nsecurity.49  Attackers  abuse  them  for  DDos  attacks  without  the  owners \\nbeing aware of it. This cannot be accepted. Specific IT-related regulation \\non product safety and product liability needs to be adopted. But users too \\nare to be made liable for damages arising from negligent or improper use \\nof devices that do not meet minimum safety requirements, or for failing to \\nregularly update their system as required. Insurers will assess the risks and, \\naccordingly, fix the amount of fees to be paid. Only at this point will the \\nreal cost of IT systems including cybersecurity become visible.\\n\\nThis  regulation  should  go  hand  in  hand  with  new  legislation  on \\ntechnical requirements for IT products regarding cybersecurity (including \\ncertification – CE-label). With the competence the EU has for the internal \\nmarket, consumer and data protection, the EU should – and indeed seems \\nto intend to – take the necessary measures.50\\n\\nCyberspace and military defence\\n\\nStates have recognised cyberspace as a new dimension of military defence, \\napart from land troops, the air force and the navy. This adds to the notion \\nof cyberwar as a war in the proper meaning of the term. Some states are \\nalready spending billions of dollars not only on cyber defence but also on \\noffensive  cyberwar  technology.  Is  this  necessary  in  order  to  understand \\nthreats better, as a basis for defining effective strategies of defence? As has \\nalready  been  stated,  with  regard  to  the  problem  of  attribution,  classical \\nconcepts of response, hack-back and deterrence are questionable. Many \\nstates are not advanced in cyber defence. Bannelier and Christakis state in \\ntheir preparatory study that ‘the technical capabilities of the digital giants \\nand  their  economic  strength  are  not  commensurate  with  those  of  many \\nStates, especially the less technologically advanced ones’.51\\n\\nMore  importantly,  the  question  of  whether  offensive  capabilities \\nreally  add  to  cybersecurity  remains  an  open  question.  As  a  matter  of \\nreason and humanity, international agreements have been reached to ban \\nchemical and biological weapons and to limit, at least, nuclear armaments. \\nAccordingly, for the costs of a new arms race and the unforeseeable new \\nrisks of damages for the civilian population, cyberwar is not an option and \\nshould be banned, while taxpayers’ money should be invested in strategies \\nand  technology  of  resilience  that  make  cyber-attacks  impossible  or,  at \\nleast, ineffective.\\n\\nCybersecurity intelligence\\n\\nCould intelligence activities be part of such strategies? Tapping internet \\ncables  and  nots  worldwide  or  other  activities  may  help,  one  day,  to \\nfinding  the  origins  of  attacks,  at  least  geographically.  New  German \\nlegislation passed in 2015 includes provisions for powers of the Foreign \\nIntelligence Service (BND) to detect serious risks of international cyber-\\nattack.52  But  the  definition  of  these  powers  is  vague  and  general;  in \\naddition, action on foreign territory is not excluded. But what country \\nwould accept, in the absence of a cooperation agreement, such intelligence \\naction led by foreign services on its own national territory? The Snowden \\nrevelations  are  a  warning.  In  the  name  of  national  security,  the  NSA \\ndestroyed trust on a global scale. A legal regime containing clear limitation, \\nstrict control and cooperation should replace unilateral national action. \\nCommon  intelligence  with  close  parliamentary  oversight  should  be \\nestablished  for  well-defined  purposes,  including  cybersecurity,  at  the \\nEuropean level.53 Similarly, as a matter of common concern, joining all \\nefforts at cybersecurity intelligence is a matter to be considered at the \\ntransatlantic and even at the global level, with due regard, however, to \\neffective privacy and data protection.\\n\\n\\nThe work of international organisations on cybersecurity\\n\\nStates are already cooperating on cybersecurity within the framework of \\ninternational organisations. The most important of these organisations is, \\nof course, the UN. The result of a Russian initiative in 1998 and established \\nunder  resolutions  of  the  UN  General  Assembly,54  the  Global  Group  of \\nExperts on Cybersecurity (GGE) has, since 2004, been reporting to the \\nUN  Secretary  General  on  issues  of  priority  and  national  strategies  for \\ncybersecurity.55 While these reports contain important observations on the \\nrisks  and  on  recent  developments,  and  confirm  the  full  application  of \\ninternational law to cyberspace (2013), they remain too general in their \\nconclusions and recommendations. As a result, the GGE has been harshly \\ncriticised for its poor ‘real world impact’, and it has been suggested that it \\nshould become more inclusive, ‘involving more stakeholders and producing \\noutcomes  that  really  shape  policy,  reflecting  the  realities  of  the  cyber \\ngame’.56 Its work, nonetheless, can be understood as an important effort \\nto implement UN General Assembly Resolution 64/211 recognising ‘that a \\nrobust global culture of cybersecurity needs to be encouraged, promoted, \\ndeveloped and vigorously implemented’.57 The 2017 Report, promised to \\nbe adopted and published in September 2017, has not been accomplished. \\nToo controversial seem to have been the views of the participating states \\non questions of self-defence, the possible abuse of rights where the problem \\nof  attribution  persists,  or  the  question  of  openness  or  sovereign  control \\nover the national information space, if all countries had been ready to find \\nconsensus. Perhaps it was too ambitious to envisage agreement on ‘how \\ninternational law applies to the use of information and communications \\n\\n\\ntechnologies by states’, as the GGE was tasked, or things like confidence- \\nand capacity-building at the UN level.58 Or the GGE, a group of experts \\nfrom national governments, even at this high level, is simply not a body that \\ncan produce far-reaching political or legal commitments of the international \\ncommunity as needed for effective protection of cybersecurity.\\n\\nAnother important international organisation dealing with questions \\nof cybersecurity is the International Telecommunications Union (ITU).59  \\nA fundamental role given to the ITU by WISIS and the ITU governors is ‘to \\nbuild confidence and security in the use of Information and Communication \\nTechnologies (ICTs)’. The ITU runs a Global Cybersecurity Index (GCI), \\nwhich  is  a  multi-stakeholder  initiative  monitoring  the  cybersecurity \\ncommitments  of  different  countries.  Already  in  2007  it  launched  the \\nGlobal  Cybersecurity  Agenda  (GCA)  establishing  a  ‘framework  for \\ninternational cooperation aimed at enhancing confidence and security \\nin the information society’. ITU is also active in standardisation, with \\nvaluable work such as setting up the ‘Focus Group on Smart Sustainable \\nCities’. In 2015 this group produced a technical report of high quality on \\n‘cybersecurity,  data  protection  and  cyber  resilience  in  smart  sustainable \\ncities’.60  Yet,  binding  regulation  on  the  technology  or  the  use  of  the \\ninternet  and,  in  particular,  related  to  cybersecurity  is  not  among  the \\npowers of ITU.\\n\\nInternational conventions\\n\\nIn contrast, an international agreement can have legally binding effect, at \\nleast upon the participating states that ratified it. Few conventions have \\nbeen  concluded  at  a  regional  or  international  level  for  the  purposes  of \\ncybersecurity. A first important achievement was the Budapest Convention \\non Cyber Crime of November 2001. It entered into force on 1 July 2004 \\nand  requires  the  criminalisation  of  all  kinds  of  computer-  and  internet-\\nrelated offences for the, so far, 54 contracting parties.\\n\\nAnother  prominent  example  is  the  African  Union  Convention  on \\nCyber Security and Personal Data Protection, adopted in June 2014.61 \\n\\nThis is a remarkable step towards coordinated action, combining privacy \\nand  security  in  one  document  and  imposing  effective  action  on  the \\ncontracting parties, including, in Article 26, the establishment of a ‘Culture \\nof  Cybersecurity’.62  The  role  of  governments  is  defined  here  to  ‘provide \\nleadership  for  the  development  of  the  cyber  security  culture  within  its \\nborders’, although in Article 27 the Convention also addresses ‘cybersecurity \\ngovernance’ under the leadership of the governments, the establishment of \\nan institutional framework and international cooperation (Article 28).\\n\\nThe Microsoft initiative of a ‘Digital Geneva Convention to protect \\nCyberspace’, already mentioned, has not yet received sufficient attention. \\nIt is meant to prohibit cyber-attacks on critical infrastructures, or causing \\ndamage to the global economy or to cloud-based services, causing major \\nglobal disruption. It bans hacking personal accounts or ‘private data held \\nby journalists and private citizens involved in electoral processes’ and \\nrequires states to refrain from inserting or requiring ‘backdoors in mass-\\nmarket commercial technology products’ etc.63 The many issues covered \\nhere reflect general concerns of cybersecurity and should guide upcoming \\nnegotiations at the international level. In spite of strong lobbying of Brad \\nSmith for this project also at the 2017 IGF in Geneva,64 this initiative does \\nnot seem to have received sufficient support by the governments.\\n\\nThese are promising initiatives, although they fail, if in force, either to \\ngo far enough in terms of providing concrete substance or to cover, as is \\nneeded, the territories of all countries and so to being effective at the global \\nlevel.  The  experience  is,  that  negotiation  and  ratification  procedures  of \\ninternational conventions are most time-consuming and often take many \\nyears.  This  is  particularly  true  in  sensitive  areas  like  internet  regulation \\nand cybersecurity. Technical developments are many times quicker than \\nwhat governments can negotiate. Finally, international agreements, once \\nin force, often suffer from the reluctance of states to completely carry \\nout their duties. Compliance procedures, as known from international \\n\\n\\nenvironmental protection regimes like the Montreal Protocol on Subtances \\nthat Deplete the Ozone Layer65 or the Åarhus Convention,66 are difficult \\nto achieve and of limited effect.\\n\\nIn the absence of effective means of enforcement and judicial protection, \\nthus, new additional methods are needed to ensure cybersecurity at all \\nlevels. Given the shared responsibility of individuals, business enterprises, \\nand state governments, with their respective tools and powers, an inclusive \\nmulti-stakeholder model of cybersecurity governance should be considered \\nas the way forward.\\n\\nVI. A framework for global cybersecurity governance\\n\\nAs has been shown above, with regard to security threats and also the \\nresponsibilities and instruments for providing cybersecurity, at present \\nthere is neither one single system nor any systematic approach for resolving \\nthe (self-made) problems that are arising with the increasing dependence of \\nour societies on a secure and functioning internet. The picture, instead, is one \\nof great complexity and deep fragmentation, while the risks are increasing. \\nAfter examining the international law and cooperation on cybersecurity, the \\nstudy of Bannelier and Christakis lists the organisations and forums dealing \\nwith cybersecurity, reaching the conclusion that: ‘The problem, however, is \\nthat the proliferation of these initiatives in very diverse fora does not \\nnecessarily reflect good governance of cybersecurity.’67\\n\\nGovernance, as has already been mentioned, means the coordination of \\nbehaviour in society by multiple actors and factors.68 Today, there is nobody \\nto govern or even to coordinate the system as a whole. Social scientists \\nmay discern mechanisms and processes of a certain regularity from which \\nsome  kind  of  coordination  appears  to  be  emerging.  Such  studies  are \\nimportant, but not sufficient. They may reveal that, in fact, there is little \\ncoordination. As a constitutionalist, and with an eye on the obligations \\narising from the above-mentioned fundamental principle of security, I am \\nlooking at the normative side and the question of how to organise effective \\nmechanisms and processes of coordination.\\n\\nRegulation presupposes a regulator. We have regulators at the national \\nand at the EU level, but nothing comparable exists in transatlantic relations, \\nand even less so at the global level. Governance includes regulators and \\nregulation, but it is not limited to them. Institutions, bodies and platforms \\nthat already exist may need to be supplemented by other mechanisms and \\nprocesses  of  cybersecurity  governance  in  order  to  overcome  complexity \\nand fragmentation. The question, therefore, is what are – or what could \\nbe  –  processes  of  governance  that  might  produce  globally  binding  rules \\nmaking cybersecurity a reality. With regard to the legitimacy of such rules \\nthe task is to identify some elements of a constitution of global cybersecurity \\ngovernance.\\n\\nIn order to approach this task, some lessons can be learned from the \\nexisting mechanisms of multi-stakeholder governance, the work of which \\nis – and should be – organised in a close dialogue with expert groups, \\ninstitutions and networks. As the internet now offers new conditions for \\ntransboundary discourses and will-formation at a global level, it seems \\npossible  to  develop  further  the  existing  structures  towards  an  emerging \\nglobal constitutional framework for setting rules on cybersecurity.\\n\\nMulti-stakeholder governance mechanisms\\n\\nCybersecurity governance can be understood as a specific sector of internet \\ngovernance,  insofar  as  the  latter  is  handled  by  private  and/or  multi- \\nstakeholder  organisations  or  platforms,  such  as  ICANN  for  domain \\nadministration, IETF or ISO for standardisation and, more generally, the \\nIGF as an open and global platform for the discussion of the most salient \\nissues of internet governance. One of these issues is cybersecurity. While, \\nexcept for the functioning of the domain name system, ICANN does not \\nseem to be a key player in cybersecurity matters, IETF, ISO and the IGF \\ncertainly are.\\n\\nThe IETF and the ISO are setting technical standards which, though \\nnot binding, are of key importance to the interoperability and functioning \\nof  the  internet.  For  years  now,  explicit  descriptions  of  effects  on \\ncybersecurity have been one of the requirements that RfC’s (requests for \\ncomments, instruments published by IETF as standards) have to meet, \\nand RfC’s have had to indicate the measures they take to ensure that \\nsecurity is taken care of in the implementation of the proposed technical \\nstandards. While IETF specialises in technical protocols like TCP/IP, the \\nwork of the International Standards Organisation (ISO) has a broader \\nscope.  ISO  has  issued  numerous  standards  for  cybersecurity  analysis, \\nengineering and management. The question is how to make sure that a \\ncertain level of protection is respected by these standards, allowing them \\nto be implemented on a global scale.\\n\\n\\x0c134  ingolf pernice\\n\\nThough  the  IGF  does  not  take  decisions,  the  expertise  and  views \\nexpressed at its sessions may be relevant for the establishment of such \\nminimum requirements as the first stage of a normative process for globally \\napplicable standards. The IGF has existed since 2006, having been established \\nby the UN Secretary General at the request of WSIS. Its mandate was \\nrenewed for another ten years in 2015.69 The discussions at the IGF are \\nopen to all stakeholders present or participating online. Cybersecurity was \\nthe first subtheme of the IGF in 2015,70 and it seems also to be a priority \\nissue at the December 2017 meeting in Geneva.71 The further work of IGF \\nshould focus on the minimum requirements for IT products and the ways \\nin which these can be met and concretised by standardisation, following \\nthe model of the ‘new approach’ adopted years ago by the EU for internal \\nmarket  harmonisation.72  The  discussions  held  at  IGF  are  an  important \\nsource of mutual information on best practices and experiences, the IGF \\nprovides room for deliberation and opinion-building and so can constitute \\na  useful  basis  for  the  next  steps  of  a  normative  process,  as  described \\nbelow.73\\n\\nExpert groups, institutions and networks\\n\\nThe IGF, however, is not the only platform to take up and discuss the \\nissues  of  cybersecurity.  At  the  Munich  Security  Conference  in  February \\n2017 the ‘Global Commission on the Stability of Cyberspace’ was launched \\nby the Dutch government together with the Hague Centre for Strategic \\nStudies and the EastWest Institute.74 It was announced as ‘a global body \\nformed to convene key global stakeholders to develop proposals for norms \\nand policy initiatives to improve the stability and security of cyberspace’. \\n\\n\\nFor  some  years  now,  the  Dutch  National  Cyber  Security  Centre  has \\nbeen  organising  the  ‘International  One  Conferences’  with  experts  on \\ncybersecurity.75 A ‘Commonwealth CyberSecurity Forum ‘17’ was held \\nin London in March 2017.76 These and other initiatives and discussions in \\nacademic circles are gradually creating an informal network of practitioners, \\npoliticians and scientists that provide expertise and inform politics bottom \\nup through a global deliberative process.\\n\\nSpecial attention is deserved by the Tallinn Manual on the International \\nLaw applicable to Cyber Warfare (2013). This is the result of the work of \\nan expert group working under the auspices of NATO, with ‘the unofficial \\ninput of many States and over 50 peer reviewers’. This manual provides us \\nwith a number of important definitions, rules and profound advice relating \\nto cyber warfare.77 It seems, therefore, to represent the state of the art on \\nalmost all relevant questions, including the definition of terms like ‘armed \\nattack’ or ‘threat to international peace’, the concepts of sovereignty, state \\nresponsibility, attribution and human rights, and how to protect civilians \\nin cyberwar contexts, as well as more concrete issues like at what point the \\nUN Security Council would be called upon to take action in the event of a \\ncyber-attack under Chapter VII of the Charter of the United Nations.78 \\nA second edition of the Tallinn Manual was issued in 2017, now also \\ncovering legal peacetime regimes.79 These works are of great value for the \\nlegal assessment of state action and responsibilities, even if they do not \\nset binding rules but simply contribute to clarification of the existing \\ninternational law with regard to cyber issues.\\n\\nThe problem with these studies, however, is that they do not overcome \\nthe traditional war-logic but, instead, strive to adapt the patterns of war \\nand the law of war to the digital constellation. This is important, but it \\nmay not achieve what is needed for cybersecurity.\\n\\nEmergence of a global framework for rules on cybersecurity\\n\\nPeople, stakeholders and experts active in the diverse forums and platforms \\nfocusing on cybersecurity not only meet and network with each other \\nregularly but also produce a vast amount of knowledge, experience and \\ncreative thinking. New ideas flow from one forum to another and eventually \\nbecome more or less accepted principles and some sort of shared common \\nsense. Stakeholders learn from it, and knowingly or not, integrate what \\nthey ‘bring home’ from such discussions into their respective work. This \\nway, they may ultimately inform government action or even legislative \\nproposals. Much of it, though, is left to coincidence.\\n\\nThere may be many ways to organise these deliberative processes more \\nsystematically, so as to achieve more coordinated and thus more effective \\nresults. To be sure, the process should be based upon, and controlled by, \\npublic deliberation in order to receive democratically rooted legitimacy: \\ncitizens of the states should be involved and understand themselves as global \\ncitizens taking responsibility and having the final say, while it should be for \\nthe UN Secretary General to take responsibility for setting up a framework \\nof coordination. The process should be fully transparent and based upon a \\nbroad, open global discourse actually made possible by the internet.80\\n\\nBased upon already existing structures and processes and, in particular, \\ncybersecurity policies at national and regional levels, a new model of a \\ncomplementary normative process will be developed for cybersecurity \\ngovernance at the global level, which is (a) built upon internet-enabled \\nopen information and deliberation that will serve as (b) a fundament for \\nthe establishment of bodies to elaborate and adopt a set of principles on \\ncybersecurity to be (c) further concretised and made legally binding by \\ncombined processes of standardisation and legislation, while (d) more \\ngeneral  globally  binding  norms  will  have  to  be  agreed  in  the  form  of \\ninternational conventions with the UN bodies taking responsibility for the \\ncoordination and supervision of the processes aiming at the adoption of \\nglobally applicable rules, the application of which (e) special UN bodies \\nwould monitor and courts at all levels would have to give effect to in \\nindividual cases.\\n\\n(a) Deliberation: The Internet Governance Forum. The IGF is, meanwhile, \\na well-established multi-stakeholder global platform for open discussion \\nof central issues related to the internet and its proper functioning. Its work \\n\\n\\nis  coupled  with  similar  national  forums  or,  at  the  European  level: \\nEURODIG. One section of their work should be developed to deal with \\nthe special issue of cybersecurity at all levels, as required – and guided – by \\nthe constitutional principle of security. It should systematically consider \\nand,  eventually,  recommend  appropriate  use  of  all  the  instruments \\nmentioned above as being part of the cybersecurity toolbox. Awareness, \\nexpertise and creative ideas on appropriate measures for consideration \\nmay emerge from these discussions.\\n\\n(b) Principles: The model of NETmundial. On this basis, and drawing from \\nthe  lessons  learned  in  these  forums,  special  multi-stakeholder  bodies \\nshould be established for articulating and concretising general principles \\nfor cybersecurity with minimum requirements for products and normative \\nguidelines to be translated, at the next stage, into globally applicable \\nstandards and legislation. NETmundial or the civil-society-born initiative \\nfor a Charter of Digital Fundamental Rights of the European Union81 \\ncould serve as a model for such bodies. Similarly, the leading tech and \\ninternet-related industries should convene with users and other civil society \\norganisations to agree upon globally applicable codes of conduct to guide \\nstandardisation and legislative processes. If a broad consensus could be \\nachieved within such forums on certain basic principles, guidelines and \\nsecurity requirements, this outcome should be subject to scrutiny by the \\nIGF together with the general public, and revisited and further developed \\nas necessary before they are finally adopted by the forum of origin for \\ntransmission to the standardisation or legislative bodies or organisations \\nat national, supranational and international level.\\n\\n(c) Standards and regulation: IETF, ISO and legislators. IETF and ISO have \\nproved to be an excellent framework for setting technical standards as a \\nbasis for interoperability, and they should focus on privacy- and cybersecurity \\nengineering even more. Specifically with regard to cybersecurity, a close \\ninteraction of private standard-setting and legislative processes should be \\nestablished. As with the system proposed in the EU’s ‘new approach’, \\nwhich has already been mentioned,82 this could lead to a burden-sharing \\nbetween legislators on the one hand, who would be responsible for setting \\nup, on the basis of the principles adopted by the bodies described, minimum \\nsecurity  requirements  for  products  and  services,  and  standardisation \\nbodies like IETF or ISO on the other, which would turn these requirements \\n\\n\\ninto technical norms to be met by products or terms of services before they \\nare put on the markets.\\n\\nAs far as principles focusing on the behaviour of states and governments, \\na similar kind of standardisation could be initiated at the international \\nlevel within the framework of the UN. Concrete rules could take the form \\nof soft law giving effect to the right to security as granted under Article 9 \\n(1) of the International Covenant on Civil and Political Rights. A Global \\nDeclaration on State Duties and Responsibilities for Cybersecurity could \\nlay down such essential requirements for states in respect of a ban of cyber \\nwarfare, responsibilities for cyber-attacks from their territory, mutual \\ninformation and support in the event of cyber-incidents, and the enforcement \\nof rules applicable to industry and individuals.\\n\\n(d) International conventions and supervision: What role for the UN? Based \\nupon the principles and guidelines elaborated within the framework of \\nIGF and a forum like NETmundial, and a Global Declaration as mentioned \\nabove, it seems possible to elaborate, as a next step in the normative \\nprocess, international conventions on the concrete obligations of states \\nregarding their own behaviour as well as the adoption of national strategies \\nand legislation relating to the protection and enforcement of cybersecurity. \\nThe Budapest Convention gives a hint for where to go, but there is a need \\nnot only to establish rules on cybercrime that are applicable globally so to \\nensure law enforcement in all states irrespective of where the crimes are \\ncommitted, but also for binding law on other aspects of cybersecurity.\\n\\nFurthermore, as cybersecurity is an issue that may eventually have a \\nbearing on national security and international peace, it is time to consider \\nseriously what role the UN Security Council should take in this regard. At \\nleast some supervisory powers should be given to this body, though it \\nshould be for the UN Secretary General to coordinate law-making and \\nsupervision at this level.\\n\\n(e) Monitoring and enforcement of rules and rights. Enforcement of the \\ngenerally  accepted  rules  on  cybersecurity  will  have  to  be  ensured  by \\nnational authorities, perhaps under the supervision of UN bodies like \\nthe GGE, to be further developed into a special agency, organised as a \\nmulti-stakeholder body and acting as the key authority of a compliance \\nmechanism  as  well  as  a  political  forum  in  charge  of  monitoring  the \\neffects  of  existing  rules  and  elaborating  proposals  for  revision.  More \\nimportantly, courts at the national and international level will have to \\nplay an increasing role, as soon as the relevant cybersecurity law comes \\ninto effect and, in particular, individual rights emerge from well-organised \\ngovernance processes wordwide.\\n\\n\\x0cGlobal cybersecurity governance  139\\n\\nTowards global (multilevel) constitutionalism\\n\\nThe  present  outline  of  a  model  framework  for  global  cybersecurity \\nregulation certainly does not represent what we commonly understand \\nas  a  Constitution.  Nevertheless,  it  is  suggested  here  that  a  discussion  \\non  possible  developments  should  be  commenced  from  which  a \\nconstitutional  setting  for  democratically  legitimate  regulation  at  the \\nglobal level could emerge. It is similar to the concept of ‘transnational \\npopular  sovereignty’  developed  by  Milton  Mueller  with  a  view  to \\novercoming  the  ‘mismatch  between  internet  territory  and  political \\nterritory’ already mentioned.83 But the aim is not to ‘detach information \\npolicy from the state today’ and construct a global polity based upon \\n‘net nationalism’ with ‘a people of the internet’, as he sees the system \\nof ICANN.84 Nor is it to conceive a ‘community formed in and around \\ninternet  connectivity’  displacing  ‘specific  pieces  of  territorial  states’ \\nauthority  over  global  communication’  with  the  aim  that  ‘national \\ngovernments  have  no  sovereignty  over  content  and  to  gradually  de-\\nlegitimize these efforts’ (of blocking and filtering access to websites and \\napplications).85  In  contrast,  the  aim  is  to  provide  people  with  an \\ninstrument  for  effective,  democratically  legitimate  action  on  matters \\nbeyond the reach of individual states more generally. Internet governance \\nand,  more  particularly,  cybersecurity  governance,  is  only  one  issue. \\nThe  term  ‘constitutional’  is  understood  not  to  imply  a  state-like \\nstructure but an additional level of action through the establishment of \\ninstitutions and processes that are rooted in the will of, and ultimately \\ndriven by, the citizens, defining themselves as global citizens with regard  \\nto  such  forums,  bodies  and  institutions  that  are  vested  with  specific \\npowers for the achievement of objectives determined in the constituent \\ntexts through political processes in which they participate with the aim \\nof setting globally applicable rules. Multilevel constitutionalism86 is the \\nnormative theory that permits us to conceptualise such a constitutional \\nframework, not as a centralised system of power at the global level, but \\nas  part  of  a  composed  constitutional  system  encompassing  national, \\nsupranational and global elements, so as to reflect the shared responsibilities \\nof citizens and actors at the diverse levels.87\\n\\nGlobal  rule  generation  as  one  part  of  governance,  and  of  global \\ncybersecurity  governance  in  particular,  as  an  activity  accepted  by  the \\nglobal citizens as being democratically legitimate, would require inclusive \\nprocesses  of  will  formation  and  decision-making  that  do  not  replace  but \\nbuild upon national political and legislative processes, while adding a new, \\ncomplementary level of action, control and judicial review. It would allow \\nfor the kinds of policies required by global challenges like cybersecurity and \\nshould be guided by globally agreed fundamental rights or principles like \\nthe principle of (cyber-)security. Accordingly, an emerging constitutional \\nframework of cybersecurity governance would build upon existing national, \\nsupranational  and  international  institutions  and  processes.  It  would  be \\ncomplementary to them and be limited to issues that are beyond the control \\nof states.\\n\\nGiven the potential of the internet with regard to real-time information, \\neducation, deliberation and participation in political processes across \\nborders, it is not impossible in the long run to imagine democratic decision-\\nmaking at the global level on the concrete rights and duties not only of \\nstates but also of individuals and business enterprises. Such global decision-\\nmaking could lead to the creation of regulations that are legally binding \\nworldwide and may intervene where self-regulation and other forms of \\nprivate ordering remain ineffective. E-democracy, in particular, is key to \\nthis development of global constitutionalism,88 and it could, in future, \\nsupplement the existing toolbox of cybersecurity governance.\\n\\nV. Conclusion\\n\\nThe digital revolution is posing new challenges that require responses that are \\nbeyond the reach of national policies. States alone are unable to ensure \\ncybersecurity. Individuals, business, (tech) academia and public authorities \\nshare a common responsibility. And action is required at all levels: local, \\nregional, national, supranational and global. Thus, in the ‘digital constellation’ \\neffective cybersecurity governance includes all actors and all levels of action. \\nIt also requires a vision of regulation at global level, for which this article \\ndevelops some elements along the lines of global (multilevel) constitutionalism.\\n\\n\\nOn the subject of constitutionalism and a legal framework for global \\ncybersecurity governance, it should be stressed, first of all, that globally \\nrecognised human rights must be the foundation and a leading point of \\nreference in the respective normative processes. Human dignity and personal \\nfreedoms,  privacy  and  private  property  are  just  some  of  these  rights.  \\nIn particular, they include the protection of personal data and privacy. On \\nthe other hand, the constitutional right to security – or better: a fundamental \\nprinciple of security89 – is an incentive and guideline for action taken to \\neffectively protect cybersecurity at all levels.\\n\\nAs a means of effectively containing cyber-risks, recourse to digital \\nsovereignty is not the solution. The internet is global, and so must be the \\nframework providing protection for its security and functioning. As – and \\nas long as – the attribution of cyber-attacks and threats is technically \\nimpossible, deterrence and hack-back are not an option.\\n\\nInstead,  responsible  risk  assessment,  of  the  kind  that  would  be  a \\nprecondition for any insurance scheme, as well as diligence in the selection \\nand purchase of products and services, resilience through backups and the \\nregular updating of all devices, are the first and foremost requirements \\nto  make  cyberspace  a  safer  place.  But  more  is  needed  to  achieve  this \\nobjective: digital competence and specialised expertise in all disciplines \\nis required – and must be developed further. Engineers and computer \\nscientists,  economists,  social-  communication  and  political  scientists, \\neven philosophers, psychologists and legal scientists are called upon to \\njoin in an interdisciplinary discourse on the best solutions in technology, \\nas well as governance and regulatory processes. This is the way to progress \\nin knowledge and to better inform the political processes.\\n\\nThe number of cyber-attacks is increasing, and so is awareness of the \\nrisks,  and  raising  awareness  of  the  shared  responsibility  of  all  actors \\nfor  cybersecurity  is  becoming  a  priority.  Furthermore,  business,  user \\norganisations  and  general  political  processes  should  quickly  focus  \\non appropriate technical standards and certification on cybersecurity, \\nwhile legislation is needed not only on information and alert systems \\nbut  also  on  private  responsibility  and  product  liability  and  adequate \\ninsurance. Such normative processes should be undertaken at all levels, \\nincluding the global level. For their democratic organisation at the global \\nlevel,  establishing  a  constitutional  framework  of  global  cybersecurity \\ngovernance, the internet itself can play a crucial role.\\n', \"Journal  of  Business  Continuity  &  Emergency  Planning  Volume  15  Number  3\\n\\nExercising cyber resilience: The Finnish \\nexperience\\n\\nReceived (in revised form): 22nd October, 2021\\n\\nAntti Nyqvist\\n\\nChief of Preparedness, General Secretary, Digipool, National Emergency Supply Organization, \\nFinland\\n\\nTero Oittinen\\n\\nSenior Advisor, Cyber Resilience, Training and Exercises, Digipool, National Emergency Supply \\nOrganization, Finland\\n\\nAntti  Nyqvist  is  Chief  of  Preparedness  and \\nGeneral  Secretary  of  Digipool,  a  network \\nof  companies  operating  under  the  umbrella \\nof  the  Finnish  National  Emergency  Supply \\nOrganization  to  coach  businesses  in  prepar-\\nedness  and  continuity  planning  in  the  field \\nof  cyber  security.  Antti  has  extensive  experi-\\nence in software project and service portfolio \\nmanagement.\\n\\nis  responsible \\n\\nTero Oittinen is a Senior Advisor at Digipool, \\nwhere  he \\nfor  educational \\ncontent  and  exercises  to  improve  the  cyber \\nresilience  of  companies.  Tero  has  extensive \\nexperience  in  the  software  business  —  from \\nfull-stack  development  to  project  manage-\\nment and software delivery.\\n\\nAbstrAct\\nTogether,  the  Finnish  National  Emergency \\nSupply  Agency  and  Digipool  are  developing \\nexercises to improve the nation’s cyber security. \\nThis paper provides examples of these exercises \\nand explains how they contribute to companies’ \\nemergency  response  and  business  continuity \\nplans. The paper also describes how the model \\nis being developed to further improve continuity \\nand  emergency  planning  in  the  area  of  cyber \\nresilience.\\n\\nKeywords:  exercise,  resilience,  prepar-\\nedness, continuity, cyber, partnership\\n\\nINTRODUCTION\\nThe  Finnish  National  Emergency  Supply \\nAgency  (NESA)  is  a  central  government \\norganisation operating under the Ministry \\nof  Economic  Affairs  and  Employment  of \\nFinland. NESA is responsible for planning \\nand  operations  related  to  the  mainte\\xad\\nnance  and  development  of  supply  chain \\nsecurity  in  Finland.  As  part  of  its  remit, \\nNESA  seeks  to  improve  business  con\\xad\\ntinuity  and  emergency  planning  among \\ncritical Finnish companies.\\n\\nNESA  is  a  relatively  small  organisa\\xad\\ntion, employing approximately 50 experts. \\nTo  support  communication  with  the \\napproximately  1,500  providers  of  critical \\ninfrastructure  in  the  country,  NESA  has \\nestablished  an  emergency  supply  organis\\xad\\nation  known  as  NESO  —  a  network  of \\ncompanies divided into 16 sector\\xadspecific \\n‘pools’. Each pool consists of critical com\\xad\\npanies  and  officials  from  its  sector  and \\nis  dedicated  to  further  preparedness  and \\ncontinuity planning through, among other \\nthings, development projects and exercises. \\nThis  setup  also  serves  to  develop  coop\\xad\\neration  between  the  public  and  private \\nsectors in Finland.\\n\\nDigipool \\n\\nthese  pools. \\nis  one  of \\nAlthough  Digipool  is  dedicated  to  the \\nimprovement  of  continuity  and  prepar\\xad\\nedness  planning  within  the  information \\n\\nAntti Nyqvist\\n\\nTero Oittinen\\n\\nDigipool,\\nNational Emergency Supply \\nOrganization,\\nEteläranta 10,\\nHelsinki 00130,\\nFinland\\n\\nE-mail: digipooli@\\nteknologiateollisuus.fi\\n\\nJournal of Business Continuity  \\n& Emergency Planning\\nVol. 15, No. 3, pp. 277–283\\n© Henry Stewart Publications, \\n1749–9216\\n\\nPage  277\\n\\n\\x0cExercising  cyber  resilience:  The  Finnish  experience\\n\\nand  communications  technology  (ICT) \\nsector,  it  also  provides  support  to  other \\nsectors  due  to  the  fact  that  ICT  prepar\\xad\\nedness  is  an  essential  part  of  any  sector’s \\nbusiness  continuity  or  emergency  plans. \\nDigipool  supports  its  member  companies’ \\nefforts  to  make  their  supply  chains  more \\nrobust,  for  example  through  contractual \\nagreements  with  subcontractors.  This  is \\nespecially  important  for  furthering  emer\\xad\\ngency  planning  and  business  continuity \\nplanning among widely networked compa\\xad\\nnies, which rely heavily on subcontractors, \\nespecially in the area of ICT services\\n\\nDigipool companies take part in NESA \\nDigital Security 2030 (DT2030) develop\\xad\\nment programme by providing development \\nideas or targets for projects to ensure that \\nthe  results  support  critical  infrastructure \\nproviders  to  improve  their  preparedness \\nand business continuity planning.\\n\\nBoth NESA and Digipool work in close \\ncooperation  with  Finnish  Transport  and \\nCommunications Agency National Cyber \\nSecurity Centre (NCSC\\xadFI). The centre is \\nalso  an  essential  actor  in  developing  ICT \\npreparedness  in  Finnish  companies  and \\nprovides  support  and  materials  for  cyber\\xad\\nrelated exercises.\\n\\nTHE SIGNIFICANCE OF EXERCISING\\nMost  of  the  largest  companies  in  Finland \\nalready  have  business  continuity  plans,  so \\ntheir main focus is on continuous develop\\xad\\nment and predicting technological changes \\nthat  are  likely  to  impact  on  operations \\nrelated  to  the  cyber  environment.  Small \\ncompanies, by contrast, can differ consider\\xad\\nably in the extent to which they recognise \\nthe  importance  of  digital  security.  This \\nmeans  the  task  of  pool  organisations  has \\nshifted from preaching about the necessity \\nof business continuity planning to coaching \\ncompanies on how to improve their plan\\xad\\nning, and how digital security fits into this. \\nFor this, exercising is by far the best tool.\\n\\nDigipool  provides  companies  with \\ninformation on how to develop their own \\nplans. One method for this entails showing \\ncompanies  how  well\\xadprepared  organi\\xad\\nsations  have  built  exercising  into  their \\nstandard  order  of  business.  This  requires \\nexercising  on  multiple  levels  so  as  to \\ndetect potential challenges on the horizon \\nthat may arise due to certain incidents or \\ndisturbances  within  the  operating  envi\\xad\\nronment.  This  is  often  referred  to  as  a \\nframework of exercises.\\n\\nFRAMEWORK OF EXERCISES\\nThe  framework  of  exercises  requires  at \\nleast  four  tiers  of  exercise,  ranging  from \\nsmall internal exercises to large\\xadscale inter\\xad\\nnational  exercises,  and  from  technical  to \\ntabletop  exercises.  Templates  are  avail\\xad\\nable  for  companies  to  conduct  their  own \\ninternal  exercises,  as  well  as  larger\\xadscale \\nexercises  with  multiple  external  stake\\xad\\nholders.  The  exercise  model  provides \\ninformation on all of these.\\n\\nThe framework of exercises provides an \\nexercise  pathway  for  Finnish  companies. \\nEvery step of this path aims to build on the \\nadvances  made  in  the  previous  step.  The \\nprocess then culminates with one last test \\nin the form of a high\\xadlevel exercise.\\n\\nTHE FIRST TIER\\nInternal  exercises  constitute  the  first  tier \\nof  the  framework.  These  exercises  —  in \\nwhatever form they might take — should \\nbe  part  of  every  company’s  day\\xadto\\xadday \\nsecurity  operations  or  part  of  their  basic \\nfor  operational  development. \\nroutine \\nTechnical exercises involve practising how \\nto  defend  critical  ICT  systems  or  exer\\xad\\ncises on how to recover from an incident. \\nThese range from firing up a system from \\nits backups on a regular basis to scenario\\xad\\nbased exercises on how to detect anomalies \\nand respond accordingly.\\n\\nPage  278\\n\\n\\x0cIn addition to technical exercises, crisis \\ncommunication  and  information\\xadsharing \\nexercises  contribute  greatly  to  improving \\na  company’s  resilience  to  cyber  incidents. \\nAccording to Digipool’s 2020 survey into \\nthe cyber maturity of Finnish companies, \\nthe internal flow of information is one of \\nthe  most  important  issues  for  companies \\nto develop in order to improve their busi\\xad\\nness  continuity  and  preparedness.  Among \\nother  things,  exercising  can  overall  reveal \\nglitches  in  processes  that,  once  addressed, \\nwill decrease the cost of incidents or even \\nprevent loss of income.\\nOnce  companies \\n\\nstart  considering \\nwhere  to  start  exercising,  the  topic  of \\nidentification \\ncritical  business  process \\nbecomes central to the discussion. Critical \\nbusiness  processes  are  those  that  are  most \\nimportant  to  protect  and  hence  must  be \\ngiven priority. In other words, any exercise \\nthat  involves  an  incident  affecting  such \\nprocesses  is  a  step  towards  greater  resil\\xad\\nience. Risk management processes should \\nprovide  information  on  the  various  pos\\xad\\nsible  threats  to  critical  processes  and  how \\nto  recognise  those  threats.  This  area  is \\nimportant  to  exercise  in  order  to  recover \\nmore  quickly  and,  ideally,  avoid  process \\ndowntime.  The  identification  of  critical \\nbusiness  processes  is  also  vital  to  supply \\nchain  resilience.  When  a  critical  process \\nhas been subcontracted, exercising is very \\nimportant  for  developing  the  subcon\\xad\\ntracting relationship (a second tier issue).\\n\\nThe  NCSC\\xadFI  has  developed  lots  of \\nmaterials  for  companies  to  conduct  their \\nown cyber exercises, in addition to com\\xad\\nplementary services for anomaly detection \\n—  both  of  which  require  regular  exer\\xad\\ncising.  As  ICT  companies  typically  have \\nhigh employee turnover, exercising should \\nbe part of the induction process for newly \\nrecruited personnel. NCSC\\xadFI also offers \\ncompanies  tools  for  self\\xadevaluation  on \\ncyber  maturity  to  help  them  get  started \\ntheir  practices  and \\nwith  developing \\n\\nprocesses.  All  these  materials  are  publicly \\navailable.\\n\\nFinnish consulting companies have also \\ndeveloped a wide range of cyber exercises. \\nThere  are  lots  of  companies  providing \\ndifferent  levels  of  tailored  exercise,  from \\ntechnical to information\\xadsharing and crisis \\ncommunication.  Services  are  also  avail\\xad\\nable  to  support  companies  to  get  started \\nwith  cyber  exercising,  and  many  compa\\xad\\nnies  run  regular  exercises  for  customers. \\nDigipool  endorses  the  development  of \\nnew businesses in the field of ICT themed \\nexercising.\\n\\nTHE SECOND TIER\\nThe  second  tier  of  exercising  pertains  to \\nsector\\xadspecific cyber exercises, which basi\\xad\\ncally means exercising with subcontractors \\nor  customers,  or  with  other  companies \\nin  the  same  industry  sector.  This  is  most \\nimportant for those critical sectors that are \\nnot subject to the same level of regulation \\nas certain other critical sectors.\\n\\nOne  form  of  tier  2  exercising  involves \\nexercising  with  peers.  The  non\\xadtech\\xad\\nnical  tabletop  exercises  offered  by  the \\nInformation\\xadsharing  and  Analysis  Centre \\n(ISAC)  group  provide  a  great  example \\nof  this.  NCSC\\xadFI  is  an  active  participant \\nin  many  ISAC  groups  and  encourages \\ncompanies to engage in exercising within \\nthese groups. When multiple organisations \\ncome  together  to  face  simulated  cyber \\nincidents, it creates a forum that facilitates \\nthe  sharing  of  best  practices  in  incident \\nresponse methods and enables participants \\nto  observe  first\\xadhand  the  communica\\xad\\ntion  principles  needed  in  cyber  crises. \\nFurthermore,  as  these  exercises  are  con\\xad\\nducted  with  peers  from  the  same  field  of \\nindustry, participants will be able to share \\nsector\\xadspecific information on resilience.\\n\\nSecond\\xadtier  technical  exercises  are  also \\nregularly  hosted  by  Jyvsectec  (the  Cyber \\nSecurity  Research,  Development  and \\n\\nNyqvist  and  Oittinen\\n\\nPage  279\\n\\n\\x0cExercising  cyber  resilience:  The  Finnish  experience\\n\\nTraining Center). Jyvsectec’s ‘cyber ranges’ \\nmodel  the  systems  typically  used  in  mul\\xad\\ntiple  critical  sectors  and  can  be  used  for \\nany tier of exercise. For example, Finnish \\nofficials  arrange  annual  exercises  for  their \\norganisations to exercise and develop their \\ncontinuity  plans  and  preparedness.  The \\nranges  also  host  sector\\xadspecific  exercises, \\nfor example for the energy and healthcare \\nsectors, so that officials and companies can \\nexercise together.\\n\\nTHE THIRD TIER\\nThe  third  level  of  exercising  concentrates \\non  cross\\xadsectoral  critical  infrastructure, \\nwhich is to say nationally significant crit\\xad\\nical  services  that  depend  on  actors  from \\nmultiple fields of industry.\\n\\nThis part of the framework of exercises \\nrequires the identification of critical inter\\xad\\ndependencies and processes. EU directives \\npertaining to the security of network and \\ninformation  systems  and  the  resistance \\nof  critical  entities  inform  the  basic  list \\nof  critical  processes,  to  which  are  added \\nany previously identified critical processes. \\nAlthough some exercises have been estab\\xad\\nlished, they are yet to be conducted on a \\nregular basis. They also need to be set up \\nto develop critical operational capabilities.\\nAn  example  of  a  third\\xadtier  exercise \\ncould  be  a  regional  or  municipal\\xadlevel \\nexercise involving energy sector and water \\nsupply  companies  and  officials.  Although \\nthere  is  already  significant  cooperation \\nand  information\\xadsharing  between  these \\nsectors, the need to exercise on cyber inci\\xad\\ndents is growing, as failure to prepare for \\nthe  loss  of  certain  digital  processes  could \\nresult in fatalities on a regional scale.\\n\\nOne reason why this tier of exercises is \\nyet  to  be  trained  to  a  satisfactory  level  is \\nbecause while the identification of critical \\nsupply  chains  in  one  sector  is  relatively \\neasy,  it  is  much  harder  to  identify  the \\ninterdependencies  between  two  discrete \\n\\nsectors that constitute a critical asset when \\nconsidered together.\\n\\nTHE FOURTH TIER\\nThe  fourth,  and  perhaps  highest,  tier \\nof  exercising  comprises  wide\\xadscale  or \\nnational\\xadlevel  exercises \\nfor  developing \\ncontinuity or emergency planning, which \\naim  to  level  out  situational  awareness \\namong both companies and officials.\\n\\nThis level is the final test in the pathway \\nto resilience — companies that have been \\ninvolved  in  exercises  on  all  tiers  should \\nbe familiar with the various aspects of the \\nincreasingly  complex  cyber  environment. \\nExercises at this level provide the icing on \\nthe  cake,  insomuch  as  they  incorporate \\nkey  aspects  from  the  lower\\xadtier  exercises \\nalong with the last nuggets of information \\nnecessary when planning for continuity or \\nemergencies.\\n\\nAt  this  level,  most  of  the  exercises  to \\nimprove  continuity  and  emergency  plan\\xad\\nning  in  the  area  of  cyber  resilience  are \\ndesigned  for  government  officials  rather \\nthan business entities.\\n\\nTHE TIETO EXERCISE\\nTIETO is a biannual large\\xadscale informa\\xad\\ntion\\xadsharing  and  crisis  communications \\nexercise  initially  designed  by  the  Finnish \\ndefence  forces  but  now  organised  by \\nDigipool  due  to  its  present  emphasis \\non  ICT  preparedness  among  private \\ncompanies.\\n\\nThe  focus  of  the  exercise  typically \\nchanges from one critical sector to another, \\nwith  nationally  significant  critical  supply \\nchain companies invited to exercise cyber \\nincidents with their service providers and \\nofficials. In addition to these organisations, \\ncertain  other  disciplines,  including  ICT \\nand  physical  security,  enjoy  permanent \\nrepresentation  on  these  exercises,  as  do \\nmedia  companies  and  relevant  officials \\n\\nPage  280\\n\\n\\x0csuch  as  the  Office  of  the  Ombudsman, \\nNCSC\\xadFI,  police  and  defence  forces.  In \\naddition  to  sector\\xadspecific  officials,  the \\nTIETO20  exercise  had  participants  from \\nsuch  critical  sectors  as  food  production, \\nresale  and  delivery,  logistics,  oil  and  gas \\nand water supply.\\n\\nTIETO  exercises  commence  with  a \\nseries  of  seminars,  complete  with  home\\xad\\nwork,  so  that  participants  can  familiarise \\nthemselves  with \\ntheir  organisations’ \\nexisting  plans  and  agreements.  These \\nparticipants will be business leaders, direc\\xad\\ntors,  public  relations  or  communications \\nofficers, IT directors, managers, and other \\nexperts. The simple goal is to identify the \\ninformation  that  must  be  documented  in \\nthe  various  organisations’  continuity  or \\nemergency plans.\\n\\nIn the seminars, participants learn about \\nthe  kinds  of  topics  that  every  company \\nmust  consider.  This  will  include,  among \\nother  things,  awareness  campaigns,  crisis \\ncommunications,  identification  of  crit\\xad\\nical  (business)  processes,  legislation  to \\nconsider  during  cyber  incidents  (and  in \\ncontracting), expectations, available third\\xad\\nparty  support,  and  a  model  to  support \\ncooperation during wide\\xadscale cyber inci\\xad\\ndents. The latter model describes existing \\nstructures  for  cooperation  (such  as  the \\nISAC  groups)  and  the  roles  of  various \\nofficials.\\n\\nThe  cooperation  model  emphasises \\nthe  importance  of  the  various  lines  of \\nthat  companies  must \\ncommunication \\nestablish  with  officials  to  be  able  to  form \\nsituational  understanding.  During \\nthe \\nthree\\xadday  game  phase  of  the  TIETO20 \\nexercise,  the  teams  filed  over  70  crime \\nreports  to  the  police,  200  information \\nsecurity reports to NSCS\\xadFI and some 40 \\nreports  relating  to  the  EU  General  Data \\nProtection Regulation to the Office of the \\nOmbudsman.  Companies  also  filed  EU \\nNetwork and Information Security (NIS) \\nreports to sector officials and NCSC\\xadFI.\\n\\nThe three\\xadday role\\xadplaying exercise has \\na background story — a state\\xadof\\xadthe\\xadworld \\ndescription, which is pieced out to almost \\n200  independent  news  publications.  The \\npieces  of  news  are  published  to  the  par\\xad\\nticipants via a hardened software platform. \\nNews is published as simulated social media \\nposts,  traditional  news  media  web  pages \\nor  television  news  broadcasts  (created  by \\nthe  Finnish  broadcasting  company,  YLE). \\nThe  game  setting  progresses  from  a  rela\\xad\\ntively stressful but largely lifelike situation \\nto  an  increasingly  tense  scenario.  This  is \\nachieved through the injection of multiple \\nbackground  stories  with  such  actors  as \\nforeign  nations,  terrorists,  advanced  per\\xad\\nsistent  threat  groups  and  other  criminal \\nelements taking advantage of the complex \\nsituation.  All  the  while,  the  game  teams \\nmust react, communicate and share infor\\xad\\nmation and tips to survive the situation.\\n\\nThe  exercise  is  arranged  together  with \\nthe  Finnish  broadcasting  company,  YLE, \\nwhich  not  only  provides  the  simulated \\nmedia  broadcasts,  but  also  takes  part  in \\norder  to  exercise  its  emergency  broad\\xad\\ncasting system and create media broadcasts \\njust  as  it  would  during  a  real\\xadlife  crisis. \\nThese  broadcasts  also  include  interviews \\nwith  the  various  participants,  which  par\\xad\\nticipants must also prepare for. Concurrent \\nwith  this,  the  companies  involved  in  the \\nexercise also make public announcements \\nvia  the  various  communication  channels \\navailable during the game.\\n\\nThe game phase of the exercise is unique \\n—  in  the  miniature  society  modelled  for \\nthe exercise, the government officials play \\nthemselves  while  the  company  represent\\xad\\natives  represent  an  imaginary  company \\ninvented for the exercise. These made\\xadup \\ncompanies have descriptions of their busi\\xad\\nnesses and contracts with other companies \\nand  with  government  officials,  and  the \\ngame  is  played  according  to  the  restric\\xad\\ntions  or  obligations  stipulated  in  those \\nagreements.\\n\\nNyqvist  and  Oittinen\\n\\nPage  281\\n\\n\\x0cExercising  cyber  resilience:  The  Finnish  experience\\n\\nThe  basic  goal  of  the  game  is  to  share \\nall  information  necessary  to  survive  the \\ncrisis  or  to  recover  from  the  complica\\xad\\ntions and to identify the possible obstacles \\nto  information\\xadsharing,  with  a  view  to \\ngetting the companies to formulate a plan \\nof how to respond in the event of a cyber \\nincident.\\n\\nTo  ensure  exercise  participants  all  have \\nthe  same  level  of  situational  awareness  or \\nunderstanding  necessary  for  the  training, \\nit  is  usually  necessary  to  arrange  sepa\\xad\\nrate  information\\xadlevelling  sessions.  For \\nthe TIETO20 exercise, however, the role \\nof  the  ISAC  groups  was  adjusted.  The \\ngroups  held  regular  meetings  and  shared \\ninformation on the situation through chat \\nchannels  and  other  information\\xadsharing \\nsoftware platforms. This was seen as a useful \\nmethod for communicating in a crisis and \\nhelped  companies  endure  the  situation \\nand  even  avoid  the  worst\\xadcase  scenario. \\nThe NCSC\\xadFI participated in most of the \\ngroups, providing them with information \\nthat officials gathered through the official \\nreporting  channels.  This  process  helped \\nto  spread  the  situational  awareness  more \\nevenly among the exercise participants.\\n\\nThe  exercise  has  everything:  it  helps \\ncompanies develop their plans and to con\\xad\\nsider  the  information  they  need  to  act  in \\nan  interdependent  network  of  companies \\nand  officials  —  to  communicate,  share \\ninformation  and  to  receive  it  —  and \\nit  helps  the  officials  get  closer  to  com\\xad\\npanies,  enhancing  cooperation  between \\nthe  public  and  private  sector,  as  well  as \\nbetween officials, and most of all, it helps \\nbuild resilience to cyber crises at a national \\nlevel.\\n\\nSUMMARY\\nThe concept of the framework of exercises \\nis only in its early stages and there is much \\nstill  to  be  developed.  Nevertheless,  the \\nefforts put into establishing this framework \\n\\nare paying off already, most notably in the \\nway  it  provides  such  an  effective  channel \\nto encourage the private sector to invest in \\npreparedness and become more resilient to \\ncyber threats.\\n\\nThe  first  tier  of  the  framework  is  well \\nestablished,  with  numerous  companies \\nin  the  private  sector  offering  services  to \\nother companies, along with support from \\nofficials  such  as  NCSC\\xadFI.  Companies \\ncan  now  access  abundant  materials  and \\nsupport  to  help  them  make  exercising  a \\nregular process to support the continuous \\ndevelopment  of  security  practices  and \\ncontinuity.\\n\\nThe  second  tier  is  also  well  estab\\xad\\nlished, with many companies now adding \\nrequirements  for  resilience  testing  exer\\xad\\ncises into their subcontracting agreements. \\nThere  are  also  sector\\xadspecific  exercises \\nwhere organisations can share their expe\\xad\\nriences with their peers.\\n\\nFor  the  time  being,  third\\xadtier  exercises \\nremain  scarce  and  need  to  be  developed \\nin  the  near  future.  Critical  infrastructure \\ninterdependencies  need  closer  examina\\xad\\ntion in order to identify new opportunities \\nfor cross\\xadsectoral exercising.\\n\\nlooking  relatively  healthy \\n\\nFourth\\xadtier  exercises,  by  contrast, \\nare \\nthanks \\nto  the  availability  of  existing  exercises. \\nNonetheless, there are other topics to con\\xad\\nsider besides cyber incidents, and these will \\nrequire their own national\\xadlevel exercises. \\nMeanwhile,  the  existing  exercises  will \\nneed to widen their scope to include more \\ncompanies  and  align  with  the  evolving \\nnature  of  Finland’s  private  sector.  Given \\nthat cyber crime does not respect national \\nborders,  national\\xadlevel  exercises  such  as \\nTIETO must expand to incorporate inter\\xad\\nnational  interdependencies  and  will  need \\nto  include  multinational  cooperation  in \\nfuture cycles.\\n\\nNESA  and  Digipool  will  provide \\nsupport  and  help  in  any  way  they  can  to \\nenable  the  delivery  of  essential  exercises \\n\\nPage  282\\n\\n\\x0cNyqvist  and  Oittinen\\n\\nin  the  various  tiers  of  framework.  New \\nexercises  within  the  model  will  focus  on \\nthe unique nature of many critical supply \\nchains and their ICT\\xadrelated dependencies \\nor  dependencies  on  other  companies  and \\n\\nofficials.  By  exercising  in  a  coordinated \\nmanner  via  this  web  of  interconnected \\nentities,  companies  position  themselves \\nbetter  to  withstand  whatever  life  throws \\nat them.\\n\\nPage  283\\n\\n\\x0cCopyright of Journal of Business Continuity & Emergency Planning is the property of Henry\\nStewart Publications LLP and its content may not be copied or emailed to multiple sites or\\nposted to a listserv without the copyright holder's express written permission. However, users\\nmay print, download, or email articles for individual use.\\n\\n\\x0c\", 'India Review\\n\\nISSN: (Print) (Online) Journal homepage: https://www.tandfonline.com/loi/find20\\n\\nHacked IT superpower: how India secures its\\ncyberspace as a rising digital democracy\\n\\nHannes Ebert\\n\\nTo cite this article: Hannes Ebert (2020) Hacked IT superpower: how India secures its cyberspace\\nas a rising digital democracy, India Review, 19:4, 376-413, DOI: 10.1080/14736489.2020.1797317\\n\\nTo link to this article:  https://doi.org/10.1080/14736489.2020.1797317\\n\\nPublished online: 01 Oct 2020.\\n\\nSubmit your article to this journal \\n\\nArticle views: 539\\n\\nView related articles \\n\\nView Crossmark data\\n\\nCiting articles: 1 View citing articles \\n\\nFull Terms & Conditions of access and use can be found at\\nhttps://www.tandfonline.com/action/journalInformation?journalCode=find20\\n\\n\\x0cINDIA REVIEW                                                \\n2020, VOL. 19, NO. 4, 376–413 \\nhttps://doi.org/10.1080/14736489.2020.1797317\\n\\nHacked IT superpower: how India secures its cyberspace as \\na rising digital democracy\\n\\nHannes Ebert\\n\\nKEY WORDS \\nIndia; Cyber Security; Cyber \\nConflict; Cyber Terrorism; \\nInternet Governance\\n\\nABSTRACT\\nWhy  has  India  developed  into  one  of  the  world’s  top  targets \\nand  sources  of  cyber  attacks  despite  possessing  a  strategic \\nedge  in  information  and  communications  technology  (ICT)? \\nIndia has one of the most competitive ICT industries and work-\\nforces,  largest  global  sourcing  and  fastest  growing  e-com-\\nmerce  markets,  and  second \\nlargest  and  fastest  growing \\ninternet  user  base,  and  is  a  leader  in  using  ICT  to  provide \\ngovernance services, yet its economic and political information \\ninfrastructures  have  been  disproportionality  affected  by  cyber \\nattacks.  This  article  traces  the  evolution  of  cyber  threats  to \\nIndia’s  national  security  and  identifies  drivers  of  the  national \\nand  international  policies  the  Indian  state  has  adopted  to \\naddress these threats in the past two decades. It finds evidence \\nfor  a  growing  gap  between  the  ideation  and  implementation \\nof  cyber  security  legislation  and  policy,  which  is  rooted  in  the \\npolitical  constraints  inherent  in  India’s  state  capacity-building \\nefforts, reluctance to engage in multistakeholder coordination, \\nand  struggles  to  yield  gains  from  its  hedging  diplomacy  in \\nglobal  cyber  security  negotiations.  For  the  Security  Studies \\nscholarship  on  the  sources  of  cyber  insecurity,  these  findings \\nhighlight the need to further study the links between different \\ntypes of cyber capacity, state structure and political systems as \\nwell  as  the  specific  conditions  under  which  quickly  digitizing \\ndemocracies  can  effectively  translate  their  ICT  capacities  and \\nregulations  into  greater  cyber  resilience.\\n\\nAs a result of its economic, societal and political digital advances over the past \\nthree  decades,  India  has gradually  become  a  self-proclaimed  and  recognized \\n“information  technology  (IT)  superpower”  and  “info-nation”.1  Extensive \\ncomputerization  of  services  under  then-Prime  Minister  Rajiv  Gandhi  in  the \\nlate 1980s and high cost competitiveness triggered a rapid growth of India’s IT \\nservices, software export and IT-enabled Business Process Outsourcing (BPO) \\nindustry, rising from 1.2% of India’s gross domestic product (GDP) in 1998 to \\n7.7  percent  in  2017.2  Consequently,  India  emerged  as  the  leading  sourcing \\ndestination  for  the  global  IT  industry,  accounting  for  more  than  half  of  the \\nmarket  by  fiscal  year  2017–18.3  India’s  e-commerce  market  was  the  world’s \\n\\nhebert@gmfus.org\\n\\nCONTACT Hannes Ebert \\nThe author is grateful for comments on drafts of this article by the anonymous reviewers and by Elsa Kania, Travis \\nSharp, David Ucko as well as the participants of the 2018 Annual Indian Security Studies Workshop at the Center for \\nthe Advanced Study of India, University of Pennsylvania, in particular Michael Horowitz and Rohan Mukherjee.\\n© 2020 Taylor & Francis\\n\\n\\x0cINDIA REVIEW\\n\\n377\\n\\nfastest growing and its technology start-up sector the world’s third largest by \\n2016  and  2017  respectively.4  In  addition,  India  has  produced  a  surplus  of \\nskilled  IT  workers,  with  the  IT  sector  employing  a  workforce  of  3.9  million \\ndirectly and 12 million indirectly in 2017.5  This highly educated, technologi-\\ncally skilled workforce has provided India with one of the world’s largest IT \\nand cyber security talent pools.6\\n\\nMeanwhile,  a  dramatic  reduction  of  costs  of  mobile  devices  and  internet \\naccess  enabled  an  exponential  growth  of  India’s  internet  population.  In  2016, \\nwhile internet usage remained low compared to other emerging economies and \\nhighly concentrated  in urban areas, India  recorded by far  the highest internet \\nusage growth rate of any large economy, with its online population estimated to \\nhave  grown  by  30.5  percent  to  34.8%  of  the  population  or  462.1  million  (see \\nFigure 1). The Indian state harnessed this economic edge and growing internet \\nuser base and became a “leader in using IT for e-government and public service \\ndelivery”  by  initiating  ambitious  digitization  efforts,  establishing  the  world’s \\nlargest  repository  of  citizens’  biometric  data  (Aadhaar,  or  “foundation”)  and \\nmoving the Indian economy toward cashless, digital payments.7\\n\\nYet,  the  IT  superpower  has  struggled  to  effectively  secure  its  information \\nand  communication  networks  from  increasing  threats.  As  an  op-ed  in  The \\nNew York Times observed in April 2018, “India loves data but fails to protect \\nit”.8  The  limited  accessible  evidence  that  exists  strongly  suggests  that  cyber \\nattacks by state, terrorist and criminal actors against individuals and institu-\\ntions  –  including  on  critical  infrastructures  such  as  air  traffic  control  and \\nmilitary e-mail systems, financial markets and nuclear facilities – has grown at \\na disproportionate pace and scale considering India’s substantial human and \\ntechnological  resources  in  comparison  to  other  states  at  a  similar  stage  of \\ndigital  development.  Why  has  India  been  unable  to  harness  its  strategic  IT \\nedge to effectively secure its cyberspace?\\n\\nFigure 1. The proliferation of internet access*. * Source: Internet Live Stats, “Internet Users,” 2018, \\nhttp://www.internetlivestats.com/internet-users/. Data for 2015 and 2016 are estimated.\\n\\n050100150200250300350400450500MillionFigure 1. The prolifera(cid:127)on of internet access*Internet users inIndia\\x0c378\\n\\nH. EBERT\\n\\nWhile most states have struggled to address the security risks posed by rapid \\ndigitization, India has been disproportionately targeted – despite its leading IT \\ntalent  pool  and  sector  and  its  related  reliance  on  secure  cyberspace.  This \\npattern  runs  counter  to  assumptions  on  the  links  between  state  capacities \\nand  the  effectiveness  of  cyber  security  policies  in  the  existing  Security \\nStudies scholarship on cyber security.9 The apparent gap between the growing \\nvolume and severity of threats to India’s networked systems and its ability to \\nrespond  to  or  manage  them  has  not  been  adequately  addressed  by  this \\nliterature,  which  has  focused  on  great  power  cyber  conflict  between  the  US, \\nChina  and  Russia  and  ignored  rising  powers  such  as  India.  This  article \\naddresses this gap by drawing on the conceptual debates within the Security \\nStudies scholarship on how to measure and explain cyber security capabilities \\nand threats. It reviews publicly available primary resources and presents novel \\nevidence  on  the  evolution  of  cyber  threats  and  policies  in  India  acquired \\nthrough interviews with key policy-makers, civil society activists and experts \\nin New Delhi in 2018. This paper contends that studying the evolution of cyber \\nsecurity threats and policies as well as the links between domestic constraints \\nand international behavior in a state such as India, perceived as a “swing state” \\nin global cyber security governance, improves our understanding of the con-\\nditions under which the cyber security landscape is developing. Given the lack \\nof data, conducting inductive, descriptive case study research is imperative to \\nbuild  hypotheses  on  the  links  between  state  capacities  and  cyber  security \\neffectiveness in rapidly digitizing democracies.\\n\\nThe paper is divided into three sections. The first section traces the evolu-\\ntion of the primary threats to India’s cyber security in the past two decades, \\nincluding cyber conflict, terrorism and crime. The second section analyzes the \\nIndian state’s national and international responses to these threats, examining \\nkey factors that enabled and inhibited their formulation and implementation \\nsince the Indian parliament’s approval of the Information Technology Act in \\n2000  –  the  central  point  of  reference  for  subsequent  legislation.  Finally,  the \\nconclusion will discuss the implications of this case study for how digitizing \\ndeveloping democracies manage the dilemma of growing cyber capacity and \\nthreats and for policy expectations regarding the international cyber security \\narchitecture.\\n\\nCyber security threats: conflict, terrorism and crime\\n\\nIn the past two decades, Indian information and communications systems and \\nthe  information  contained  therein  have  been  increasingly  damaged,  used \\nwithout authorization or modified, and exploited.10  One authoritative obser-\\nver  of  India’s  national  security  noted  that  India  has  become  “an  inviting \\nlaboratory  for  anyone  wanting  to  test  out  cyber  warfare  techniques”.11 \\nAvailable data suggests that India has become a top destination for and source \\n\\n\\x0cINDIA REVIEW\\n\\n379\\n\\nTable 1. Cyber security incidents handled by CERT-In.\\nYear\\n2004\\n2005\\n2006\\n2007\\n2008\\n2009\\n2010\\n2011\\n2012\\n2013\\n2014\\n2015\\n2016\\n2017\\n2018\\n\\nNumber of incidents\\n23\\n254\\n552\\n1,237\\n2,565\\n8,266\\n10,315\\n13,301\\n22,060\\n71,780\\n130,338\\n49,455\\n50,362\\n53,081\\n208,456\\n\\nAnnual growth factor\\n-\\n11.04\\n2.17\\n2.24\\n2.07\\n3.22\\n1.25\\n1.29\\n1.66\\n3.25\\n1.88\\n0.38\\n1.02\\n1.05\\n3.9\\n\\nSource:  Author’s  compilation  based  on  CERT-In  “Indian  –  Computer \\nEmergency  Response  Team.  Annual  Reports,”  2019,  https://www.cert- \\nin.org.in/s2cMainServlet?pageid=PUBANULREPRT.\\n\\nof cyber attacks not only in absolute but also in relative terms as a percentage \\nof  affected  networks,  computers  and  individuals.  Cyber  security  incidents \\nreported  by  system  administrators  and  monitored  and  analyzed  by  India’s \\nComputer  Emergency  Response  Team  (CERT-In),  founded  in  2004,  rose \\nexponentially from 23 in 2004 to 208,456 in 2018 (see Table 1).12 The number \\nof cyber attacks against Indian networks had reportedly increased by 117% in \\n2015,  compared  to  a  39%  average  increase  globally.13  Between  March  and \\nMay  2019  alone,  the  National Critical  Information Infrastructure  Protection \\nCenter (NCIIPC), established in January 2014, noted that 3.314 vulnerabilities \\nwere reported in India’s critical information infrastructures (CII).14 The most \\ntargeted and vulnerable CII was the banking and finance sector, followed by \\nthe government, health and power sectors.15\\n\\nBy 2009, India had replaced China and Russia as the world’s most targeted \\nstate; at that point, almost eighty per cent of IT executives in India reported \\nlarge-scale  DDoS  attacks,  yet  their  companies  exhibited  one  of  the  lowest \\nsecurity adoption rates.16  India’s rate of malware infection has also exceeded \\nglobal averages, being the third-worst affected among G20 countries and the \\nworst  affected  of  all  BRICS  (Brazil,  Russia,  India,  China,  and  South  Africa) \\nmember states between 2012 and 2014.17 More recently, IT security company \\nMalwarebyte  listed  India  among  the  world’s  top  ten  countries  with  most \\nconsumer  malware  detections.18  By  comparing  the  level  of  cyber  security \\nacross  60  countries  in  2019  by  accounting  for  proportional  indicators  such \\nas the percentage of mobiles and computers affected by malware software and \\nthe percentage of telnet attacks, the technology review company Comparitech \\nfound that India ranked among the 15 least “cybersecure” countries.19 India’s \\nnetworks  might  become  even  more  targeted  with  the  increasing  use  of \\n\\n\\x0c380\\n\\nH. EBERT\\n\\nemerging technologies such as artificial intelligence (AI). In November 2017, \\ncyber  security  company  Darktrace  Inc.  detected  one  of  the  world’s  earliest \\ninstances  of  an  AI-powered  attack  in  India,  using  malware  that  learned  and \\naltered  its  methods  while  spreading,  warning  that  “India  is  a  place  where \\nnewer  AI  attacks  might  be  seen  for  the  first  time,  simply  because  it  is  an \\nideal  testing  ground  for  those  sorts  of  attacks”.20  Moreover,  the  country  has \\nquickly developed into the major source of global spam and future waves of \\nDDoS attacks.21  For instance, a New York Times report revealed in 2017 that \\nIndian  networks  have  been  used  as  a  major  base  for  North  Korean  cyber \\noperations.22\\n\\nThese cyber incidents exposed the vulnerabilities of India’s information and \\ncommunications systems. India’s internet access proliferation and digitization \\nhave come at the expense of a secure cyber ecosystem, as the rapid transfor-\\nmation has been heavily dependent on relatively low-cost and insecure hard- \\nand software components. Government and industry actors have persistently \\nrelied on outdated low-technology practices and security standards, and indi-\\nviduals  have  been  made  insufficiently  aware  of  the  risks  inherent  in  digital \\napplications.\\n\\nIndia’s multiple ethnic, political and religious faultlines as well as its highly \\ndigitized  electoral  process  offer  low-hanging  fruits  for  “cyber  influence \\noperations”.23  Recurrent  tests  revealed  structural  weaknesses  in  India’s  elec-\\ntronic voting machines and digitally maintained voter systems that could be \\nexploited  to  alter  national  and  state  election  results.24  The  Indian  govern-\\nment’s zeal in digitizing has further increased public and private information \\nand communication networks’ vulnerabilities.25  These in-built vulnerabilities \\nhave been increasingly exploited by nation-states, terrorist outfits and criminal \\nhackers in the past two decades.\\n\\nCyber conflict: India in the fifth domain\\n\\nCyberspace  has  emerged  as  a  new  “operational  domain”  and  critical  infra-\\nstructure  defense  is  now  a  national  security  priority  for  numerous  govern-\\nments.  Several  states  have  acquired  capabilities  to  engage  in  subversion, \\nespionage  and  sabotage  for  informational,  defensive  or  offensive  purposes. \\nThese  external  cyber  capabilities  range  from  low-level  scanning,  intrusion, \\ninformation  dissemination  and  collection  with  only  minimal  and  informa-\\ntional impact to high-level information manipulation, DDoS attacks, advanced \\npersistent threat (APTs), sabotage, retaliation, preemption, counterattack and \\ncyber force with disruptive or damaging, potentially lethal impact.26  As high- \\nlevel  state-sponsored  cyber  operations  proliferate,  old  fears  of  a  looming \\n“cyber  war”  are  again  being  stirred.27  However,  so  far,  even  the  highest- \\nimpact  incidents  have  not  resulted  in  massive  death,  critical  national  infra-\\nstructure destruction or critical national economic  disruption, and therefore \\n\\n\\x0cINDIA REVIEW\\n\\n381\\n\\ndid  not  per  se  constitute  acts  of  war.28  State-sponsored  cyber  attacks  have \\nconstituted  a  less  attributable  and  technologically  more  advanced  continua-\\ntion of tested subversion, espionage and sabotage strategies rather than stand- \\nalone  acts  of  novel  warfare,  and  have  predominantly  taken  place  within \\nestablished interstate rivalries.29\\n\\nSimilarly,  India’s  cyber  security  environment  has  thus  far  been  character-\\nized  not  by  “cyber  war”  but  by  “cyber  conflict”,  defined  as  “the  use  of \\ncomputational  technologies  for  malevolent  and  destructive  purposes  to \\nimpact,  change,  or  modify  diplomatic  or  military \\nin \\na particularly challenging cyber security environment. Existing evidence sug-\\ngests that India’s enduring interstate conflicts have increasingly involved the \\nuse  of  information  and  communications  technology  (ICT)  as  the  rivals’ \\nexternal  cyber  capabilities  and  vulnerabilities  have  grown,  albeit  to  different \\ndegrees. As Valeriano and Maness note, India has been involved in three out of \\nthe  20  interstate  rivalries  that  have  engaged  in  cyber  conflicts  globally  as  of \\n2014, namely with China, Pakistan and Bangladesh.31\\n\\ninteractions”,30 \\n\\nChina, with whom India has had unresolved territorial disputes that have \\nregularly  escalated  since  their  border  war  in  1962,  has  developed  highly \\ncompetitive cyber capabilities, in certain areas on par with the US, that pose \\nthe greatest cyber threat to India’s national security.32 These range from a large \\nworkforce of cybersecurity professionals in state institutions and an extensive \\ncollective  of  cyber  militias  to  a  highly  integrated  cyber  operations  structure, \\ncyber  information  warfare  skills  and  military  assets  in  pivotal  technologies \\nsuch as artificial intelligence (AI), quantum computing and quantum encryp-\\ntion. Over the past decade, China has leveraged these cyber capabilities against \\nIndia, most prominently for espionage purposes.33  While cyber attacks ema-\\nnating from China have been difficult to attribute, as they are relayed through \\nproxy  servers  and  Virtual  Private  Networks  (VPN),  numerous  intrusions  of \\nsensitive  Indian  governmental,  military  and  commercial  information  net-\\nworks  have  been  traced  back  to  Chinese  IP  addresses  or  have  been  publicly \\nexploited  for  foreign  policy  purposes  by  the  Chinese  government.34  While \\n“patriotic  hackers”  with  suspected  links  to  the  Chinese  state  have  regularly \\nengaged in low-level defacements and APTs with the goal of exposing India’s \\nvulnerabilities,  the  majority  of  cyber  attacks  emanating  from  China  have \\nfocused on espionage on national security issues.35\\n\\nIn March 2009, Canada-based researchers for the first time publicly exposed \\na  case  of  Chinese  cyber  espionage  against  Indian  networks  nicknamed \\n“Ghostnet”.36  The attack constituted a malware-based electronic surveillance \\nring allegedly operating from computer servers largely on the island of Hainan \\nthat had infiltrated at least 1,295 government and embassy computers in 103 \\ncountries,  primarily  targeting  the  Tibetan  community  in  India  and  covertly \\ngathering  information  from  the  Dalai  Lama’s  private  offices.37  While  the \\nCanadian  researchers  cautioned  against  concluding  that  the  Chinese \\n\\n\\x0c382\\n\\nH. EBERT\\n\\ngovernment  was  necessarily  involved,  researchers  from  the  University  of \\nCambridge  found  evidence  that  Ghostnet  fed  actionable  intelligence  to  the \\npolicy and security services, suggesting state involvement.38  Even the former \\ngroup of  investigators acknowledged that the Chinese  government exploited \\nthe incident for strategic-intelligence and military purposes.39  One year later, \\nin  April  2010,  the  Canada-based  researchers  discovered  “Shadow  Network”, \\nan India-focused spy operation run from China’s Sichuan Province that was \\neven  more  sophisticated  and  difficult  to  detect  than  “Ghostnet”.40  Through \\n“Shadow  Network”,  intruders  stole  high-level  classified  and  restricted  docu-\\nments from India’s national security, diplomatic, and military systems, focus-\\ning in part on the security situation in India’s North-East and, again, on the \\nCentral  Tibetan  Administration.41  Both  the  technological sophistication  and \\nprimary  targets  suggested  the  involvement  or  approval  of  the  Chinese \\ngovernment.\\n\\nIn  subsequent  years,  the  frequency  of  cyber  attacks  with  China  as  the \\nsuspected  state  sponsor  has  constantly  grown.42  The  networks  of  the  Indian \\narmy’s  Eastern  Sector  formations  and  India’s  Eastern  Naval  Command,  in \\ncharge of naval activities in the South China Sea, and India’s Defense Research \\nand  Development  Organization  (DRDO)  were  breached  in  2010,  2012  and \\n2013,  respectively.  Indian  agencies  dealing  with  border  security  such  as  the \\nMinistry of Home Affairs (MHA), DRDO and the Indo-Tibetan Border Police \\nwere also frequently targeted.43  China’s evolving edge in AI has the potential \\nto  further  elevate  the  impact  of  such  cyber  attacks.  Moreover,  the  above- \\nmentioned  vulnerability  of  India’s  democratic  processes  and  institutions \\noffer  a  future  target  for  China’s  growing  cyber  information  warfare \\ncapabilities.44\\n\\nIndia’s  high  and  still  growing  level  of  dependence  on  Chinese  electronics \\nand ICT imports render its networks structurally vulnerable to Chinese cyber \\noperations.  China  has  become  the  dominant  investor  in  the  ICT  markets  in \\nIndia, Asia and along its Belt and Road Initiative (BRI) project. Over 60% of \\nhardware and software used in India by BSNL, India’s largest broadband and \\nlandline  telephony  provider,  was  reportedly  sourced  by  Chinese  companies \\nHuawei  and  ZTE  in  2018.45  Increasing  control  over  ICT  gives  China  the \\npotential  to  shape  the  cyberspace  regimes  evolving  across  Asia,  but  also  to \\nsurveil  populations,  disrupt  infrastructure,  and  exploit  existent  digital  plat-\\nforms to spread misinformation.46 While India has officially prohibited the use \\nof  Chinese  manufactural  equipment  in  any  of  its  critical  information  infra-\\nstructures,  a  majority  of  hard-  and  software  components  in  the  telecommu-\\nnications  and  power  structures  have  reportedly  remained  dependent  on \\nChinese products.47\\n\\nIn addition, India’s conflict with its enduring rival Pakistan has also increas-\\ningly  involved  the  use  of  ICT.  While  more  incidents  occurred  in  the  Indo- \\nPakistani  cyber  conflict  than  in  the  cyber  conflict  with  China,  the  risk  of \\n\\n\\x0cINDIA REVIEW\\n\\n383\\n\\nescalation and the level of severity were significantly lower, as both adversaries \\nhave demonstrated restraint and incidents have been limited to low-level tit- \\nfor-tat stealing  of  targeted  critical  information and  mutual harassment,  pro-\\npaganda and nuisance disruption.48 Pakistan does not have a long tradition of \\nmath training and encryption expertise as is the case, for example, in several \\nCentral Asian republics, and the Pakistani IT industry is relatively nascent. As \\na result, both the military and civilian cyber security expertise is suspected to \\nbe  relatively  limited,  and  the  Pakistani  state  has  only  recently  begun  to  add \\ncyber  warfare  to  its  toolkit  of  asymmetric  conflict  behavior,  allegedly  with \\nassistance from China.49  Attacks directed at Indian  networks have primarily \\nbeen conducted by private hacker groups such as the “Pakistan Cyber Army”, \\nthe “Pak Cyber Pyrates” and the “Muslim Liberation Front”, who have been \\nbased in Pakistan but also in Saudi Arabia, the US and Europe.50\\n\\nYet, these actors should not be discounted. For instance, the Pakistan Cyber \\nArmy allegedly hacked, defaced and erased data from India’s Central Bureau \\nof  Investigation  (CBI)  website,  previously  considered  highly  secure.51 \\nSimilarly, mostly Pakistan-based hackers defaced and compromised 112 gov-\\nernment websites between December 2011 and February 2012. In the run-up \\nto the militant attack on the Pathankot airbase and army brigade headquarters \\nin  Uri  in  January  2016,  the  spyware  “Smeshapp”  targeted  the  computer  and \\nsmart  phone  devices  of  around  2,000  Indian  Border  Security  Force  and \\nCentral  Industrial  Security  Force  officers  to  gain  tactical  information  on \\ncounter  terrorism  operations  and  troop  movements.52  Following  the  Indian \\narmy’s  retaliatory  “surgical  strikes”  in  Pakistan-administered  Kashmir, \\n“patriotic hackers” from both sides engaged in a tit-for-tat series of low-level \\nattacks.53  In  February  2017,  Pakistani \\nintelligence  allegedly  mounted \\na  phishing  campaign  against  the  CBI  and  Indian  Army  officers.  After  the \\nIndian  government  revoked  the  special  status  granted  to  Jammu  and \\nKashmir on 5 August 2019, cyber security firm Kaspersky noted an increase \\nof (non-attributed) cyber attacks against Indian institutions.54  In turn, India- \\nbased  groups  reportedly  launched  numerous  low-level  cyber  attacks  against \\nPakistani  networks  in  the  past  two  decades,  often  in  retaliation  to  incidents \\nsuch as the Mumbai terror attacks of 2008 or upsurges in hostilities in Jammu \\nand Kashmir, including a sophisticated three-year APT operation nicknamed \\n“Operation  Hangover”  against  Pakistani  government  and  military \\ninstitutions.55  In  the  future,  Pakistan-based  groups  are  expected  to  further \\ndevelop  cyber  capabilities  as  means  to  mitigate  the  conventional  military \\nasymmetry and also engage in “influence operations” to subvert India’s demo-\\ncratic processes.56\\n\\nFinally,  India’s  networks  have  also  been  compromised  by  a  diffuse  set  of \\nstates or state-sponsored threat groups. First, India had to upgrade its systems \\nafter the “Stuxnet” worm – a malware against Iran’s nuclear program identi-\\nfied in 2010 and allegedly built with US involvement – unintendedly affected \\n\\n\\x0c384\\n\\nH. EBERT\\n\\neight per cent of computers in India, including critical information infrastruc-\\ntures such as  the Gujarat and Haryana electricity boards and an offshore oil \\nrig.57 Second, in 2013, top-secret documents leaked by former US intelligence \\ncontractor Edward Snowden disclosed that India was the fifth most-targeted \\nstate  by  the  National  Security  Agency’s  data  mining  tool  “Boundless \\nInformant” and “PRISM” program intercepting and collecting network con-\\ntent  (only  behind  Iran,  Pakistan,  Jordan  and  Egypt),  and  served  as  a  special \\ncollection  site  for  targeting  third-countries.58  Similar  vulnerabilities  were \\nexposed  in  leaked  US  State  Department  classified  cables,  published  by \\nWikiLeaks in 2010.\\n\\nTogether, these state-sponsored cyber attacks demonstrate the broad range \\nof existing or potential strategic threats to India’s national security, from novel \\nforms of Chinese influence and asymmetric warfare by weaker rivals to unin-\\ntended consequences of great power cyber conflict, and expose the extensive \\nand  growing  vulnerabilities  of  India’s  information  systems.  The  absence  of \\neffective  cyber  security  norms  and  institutions  and  the  uncertainty  about \\nattribution  and  states’  motives  –  whether  growing  capabilities  are  driven  by \\nself-defense or military expansion remains difficult to determine – has created \\nwhat  one  observer framed as  a “cyber  security dilemma”.59  While  India  was \\nstill not at peril to plunge into full-fledged “cyber war” in 2018, this dilemma \\ncarries a latent risk of miscalculation and escalation from cyber conflict into \\nthe kinetic realm of future militarized interstate disputes.\\n\\nCyber terrorism and extremism: from Lashkar-e-Cyber to hyper-nationalist \\nidentity politics\\n\\nSecurity Studies scholars have recently sounded alarm bells over the increasing \\nuse  of  modern  ICT  by  non-state  groups,  including  terrorist  organizations, \\nhighlighting the vulnerability of air control systems, hospitals, nuclear power \\nplants or stock markets.60 Driven by a combination of economic, political and \\npsychological forces, these fears were however often exaggerated and remained \\nhypothetical.  To  date,  there  is  no  publicly  recorded  evidence  of  a  single \\ncasualty  caused  by  a  terrorist  attack  on  information  systems  or  of  state- \\nsupported  or  sponsored  groups  utilizing  cyber  terrorism.61  According  to \\nintelligence experts, nightmare scenarios often overestimated terrorist organi-\\nzations’  ability  to  acquire  the  resources  and  expertise  required  for  effective \\ncyber  attacks.62  Therefore,  policy  and  scholarship  focused  on  how  terrorist \\ngroups use ICT to enhance their propaganda (incitement, radicalization and \\nrecruitment), financing, training, planning (through open-source information \\nand secret communication) and execution to achieve ideological, political or \\nreligious goals and international legal mechanisms to address the issue.63\\n\\nThese  debates  pertain  to  India’s  security  landscape  as  the  various  terrorist \\ngroups targeting India have increasingly used ICT to propagate, finance, train, \\n\\n\\x0cINDIA REVIEW\\n\\n385\\n\\nplan and execute their activities.64  The first major incident of a terrorist group \\ntargeting  India  through  the  use  of  ICT  occurred  in  2006,  when  the  militant \\noutfit  Indian  Mujahedeen  (IM)  carried  out  a  series  of  bomb  attacks  in  Delhi, \\nMumbai  and  across  several  other  Indian  cities.  In  its  investigation  of  the \\nincident,  India’s  National  Intelligence  Agency  (NIA)  revealed  that  before  and \\nafter  the  attack  IM  members  had  used  complex  communication  code  and \\nencrypted  e-mail  accounts  as  well  as  proxy  servers  to  disguise  their \\nlocations.65  In a series of attacks in Varanasi in March 2006, in Hyderabad in \\nAugust 2007 and Ahmedabad and Bangalore in August 2008, terrorist groups \\nalso hacked wireless internet connections to camouflage their locations.66\\n\\nWhile  these  ICT-enabled  incidents  remained  under  the  central  govern-\\nment’s  radar,  Indian  authorities  started  paying  more  attention  to  cyber \\nterrorism  when  to  their  surprise  the  Pakistan-based  armed  Jihadi  group \\nLashkar-e-Taiba  (LeT)  used  sophisticated  modern  technologies,  including \\nself-produced  ICT  devices,  in  preparing,  launching  and  propagating  their \\nattacks  against  sites  in  Mumbai  in  November  2008.67  Having  recruited  IT \\nengineers,  executives  and  technicians  since  the  early  2000s,  LeT  had \\nbecome  one  of  the  world’s  most  technologically  sophisticated  terrorist \\norganizations.  Its  charity  arm,  Jamaat-ud-Dawa,  has  invested  in  social \\nmedia  for  propaganda  and  recruitment  purposes,  in  particular  among \\nJammu  and  Kashmir’s  youth.68\\n\\nSince  the  Mumbai  attacks,  terrorist  groups  targeting  India  have  made \\nhabitual  use  of  ICT  for  propaganda  purpose.  Terrorist  organizations \\nhave  also  used  ICT  to  more  effectively  exploit  internal  political  instabil-\\nities  in  India,  as  was  the  case  in  August  2012  when  Pakistan-  and \\nand \\nBangladesh-based  groups \\nJamiat-e-Islami  allegedly  used  social  media  to  disseminate  incendiary \\ndisinformation  to  escalate  a  communal  conflict  between  Muslim  settlers \\nand  indigenous  Bodo  tribe  members  in  Assam,  leading  to  mass  mobili-\\nzation  against  and  a  subsequent  mass  exodus  of  North-Easterners  from \\nIndian  cities.69\\n\\nincluding  Harkat-ul-Jihad-al-Islami \\n\\nAt the  same time, extremist right-wing groups located inside India have \\nincreasingly  used  electronic  platforms,  most  commonly  the  popular  mes-\\nsaging app “WhatsApp”, to mobilize Hindu nationalist sentiments, exacer-\\nbate  religious  and  caste  tensions,  and  fuel  communal  discrimination  and \\nviolence.70  In  November  2017,  for  instance,  fabricated  rumors  about \\nattacks  against  Hindus  by  “Rohingya  Islamic  terrorists”  in  Burma  circu-\\nlated  quickly  and  triggered  further  anger  against  Rohingya  refugees  in \\nIndia.71  Evidently,  the  proliferation  of  ICT  has  thus  facilitated  and  ampli-\\nfied  the  effects  of  using  nationalist  identities  as  a  vehicle  for  mobilization \\nand  incitement.  Beyond  the  sensationalist  threat  inflation  of  cyber  terror-\\nism,  this  broad  set  of  emergent  capabilities  will  likely  pose  a  growing \\nthreat  to  India’s  national  security.\\n\\n\\x0c386\\n\\nH. EBERT\\n\\nCyber crime: hackers’ paradise\\n\\nFinally, India’s cyber security has also been compromised by incidents of cyber \\ncrime,  understood  as  the  criminal  use  of  a  cyber  attack  or  cyber  espionage \\nentailing activities such as fraud, identity theft and internet scams.72 Reported \\ncyber crime incidents in India have risen from only 142 in 2006 to 12,317 in \\n2016  (see  Table  2),  at  which  point  India  ranked  among  the  five  states  most \\naffected  by  this  globally  proliferating  problem.73  Moves  toward  demonetiza-\\ntion  and  the  use  of  mobile  web-  and  wallet-based  transactions  are  likely  to \\nproduce  new  vulnerabilities.74  Already  in  2015,  cyber  crime  caused  an  esti-\\nmated loss of 28 USD billion for the Indian economy.75\\n\\nMost  of  these  cyber  crimes  have  originated  abroad,  including  from \\nBangladesh,  China  and  Pakistan.76  For  cyber  criminals,  India  has  developed \\ninto an attractive and easy target given its position as an outsourcing hub, the \\nrapid growth of internet access and relatively open networks on the one hand, \\nand  the  prevalence  of  pirated  software  and  inexpensive  devices  and  low \\nconviction  rates  on  the  other.  India’s  finance  and  banking  sector  has  been \\nidentified  as  the  most  vulnerable.77  In  October  2016,  3.2  million  debit  cards \\nwere compromised in a financial breach of several Indian banks, at that point \\nthe  largest  cyber  crime  incident.78  More  recently,  India  after  Russia  and \\nUkraine  was  the  third  worst-affected  state  by  the  infamous  “WannaCry”, \\na complex malware stolen from the US National Security Agency and which \\nin May 2017 was the largest ransomware attack, later attributed to a hacking \\ngroup  allegedly  controlled  by  the  North  Korean  government  (“Guardians  of \\nPeace”,  also  known  as  the  Lazarus  group,  HIDDEN  COBRA  or  ZINC).79 \\nAmong various other entities, the ransomware affected the networks of four \\nstate governments and the Andhra Pradesh Police. Additionally, according to \\nan expert report submitted to the UN Security Council, India was the second \\nmost  affected  country  by  North  Korean  cyber  attacks  against  financial \\n\\nTable 2. Cyber crime in India, 2006–2016.\\nYear\\n2006\\n2007\\n2008\\n2009\\n2010\\n2011\\n2012\\n2013\\n2014\\n2015\\n2016\\n\\nNumber cyber-related crime\\n142\\n217\\n288\\n420\\n966\\n1,791\\n2,876\\n5,963\\n9,622\\n11,592\\n12,317\\n\\nAnnual growth factor\\n-\\n1.53\\n1.33\\n1.46\\n2.30\\n1.85\\n1.61\\n2.07\\n1.61\\n1.2\\n1.06\\n\\nSource:  Author’s  compilation  based  on  NCRB  “Annual  Reports  Crime  in  India, \\n1953–2014,” National  Crime Records Bureau, 2016,  http://ncrb.gov.in/; “Crime \\nin India. 2016” (New Delhi: National Crime Records Bureau, 2017) and  Statista \\n“India:  Number  of  Cyber  Crimes  2015,”  Statista,  2017,  https://www.statista. \\ncom/statistics/309435/india-cyber-crime-it-act/.\\n\\n\\x0cINDIA REVIEW\\n\\n387\\n\\ninstitutions,  cryptocurrency  exchanges  and  mining  activity  designed  to  earn \\nforeign currency between 2015 and 2019.80\\n\\nAnother sector strongly targeted by cyber criminals is India’s health sector. \\nAs India’s health institutions have quickly become digitized, they have become \\na vulnerable and lucrative target. In August 2019, for example, the US cyber \\nsecurity company FireEye disclosed that 6.8 million health records had been \\nstolen  from  an  unnamed,  India-based  healthcare  website  by  China-based \\ncriminals and offered for sale or relayed to Chinese pharmaceutical companies \\nto  gain  a  market  advantage.81  Beyond  financial  losses,  advanced  attacks  like \\nransomware also carry risks for patients’ health when hospitals’ operation is \\ndisrupted as criminals hold critical data to ransom.\\n\\nYet,  politically,  the  most  relevant  cyber  crime  attacks  were  the  regular \\nbreaches  of  databases  and  software  associated  with  the  UIDAI  and  its \\nAadhaar system. In January 2018, for example, an alleged hack by unknown \\nintruders  made  personal  data  of  1  billion  people  publicly  available  for  pur-\\nchase,  then  the  largest  breach  of  personal  data.82  Reports  on  such  breaches \\nfurther buttressed data security and privacy concerns and undermined public \\ntrust in India’s digital transformation and public institutions more generally.\\nFinally, after the US government reinforced controls domestically, India has \\nbecome one of the largest exporters of cyber crime, with criminals based across \\nthe world exploiting poorly secured Indian networks.83  According to assess-\\nments  by  the  Manohar  Parrikar  Institute  for  Defence  Studies  and  Analyses, \\nIndia  by  2012  hosted  most  of  the  world’s  computers  connected  to  bot  net-\\nworks  and  was  the  third-largest  generator  of  spam  zombies.84  While  cyber \\ncrime has been foremost commercially driven, its dramatic proliferation and \\nthe disproportionate targeting of government institutions resulted in increas-\\ning political ramifications and pressures on the Indian state to become more \\nactive  both  nationally  and  internationally  to  protect  India’s  digitized  society \\nand cashless economy.\\n\\nSecuring the info-nation’s open networks\\n\\nOver  the  past  two  decades,  the  Indian  state  has  started  to  adjust  to  the \\nchallenges of cyber conflict, terrorism and crime. The following sections will \\ntrace  the  development  of  India’s  national  and  international  cyber  security \\npolicies in that time period.\\n\\nNational cyber security policies\\n\\nDrivers and gains of national legislative, institutional and strategic milestones\\nSince  the  late  1990s,  federal  Indian  governments  and  bureaucracies  took \\ndomestic-level  legislative,  institutional  and  strategic  steps  to  adapt  to  the \\nnascent  proliferation  of  ICT  and  concomitant  cyber  security  threats. \\n\\n\\x0c388\\n\\nH. EBERT\\n\\nLegislators  were  the  first  to  adjust.  In  June  2000,  14  years  after  the  internet \\n(ERNET) was introduced and five years after it became publicly accessible in \\nIndia, the Indian parliament passed the Information Technology Act, the first \\nlaw  in  the  Union  to  secure  commercial  IT  industry  interests.85  At  the  time, \\nIndia was the twelfth state in the world to pass cyber law. While the 2000 IT \\nAct focused on regulating the evolving e-commerce and related cyber crime, it \\ncame to constitute the key reference for ensuing cyber legislation. It did not \\nyet,  however,  incorporate  broader  cyber  security  risks  as  a  national  security \\nconcern for the executive, whose agenda still prioritized conventional militant, \\nsectarian and separatist threats.86\\n\\nIt took eight years and a series of external and internal shocks to broaden \\nIndia’s  cyber  legislation.  In  Eurasia,  sophisticated  DDoS  attacks  against \\nEstonian institutions in 2007 and cyber attacks against Georgia in 2008 illu-\\nstrated the threats of cyber conflict and the failure of conventional deterrence. \\nAgainst this backdrop, the cyber-enabled Mumbai attacks in November 2008 \\ngalvanized  revisions  to  India’s  domestic  cyber  jurisdiction.  Only  one  month \\nafter  the  Mumbai  attacks,  in  December  2008,  the  Indian  parliament  passed \\na major amendment to the IT Act with provisions related to cyber terrorism, \\nfor the first time officially mentioning cyber security and acknowledging the \\nrise of cyber threats to India.87 The amended Act enhanced cyber law enforce-\\nment, such as obliging internet providers to retain data, and punishments for \\ncyber terrorism and cyber crime, including death penalty for the former.88  It \\nalso designated CERT-In as the “national nodal agency” for the protection of \\nCII  and  proposed  a  novel  institution  for  CII  protection.  As  such,  it  marked \\na  significant  transition  of  India’s  cyber  security  legislation  from  a  focus  on \\ncommerce to one on national security objectives, particularly terrorism.89\\n\\nlater \\n\\nWhile  India’s  novel  cyber  security  legislation  did  not  yet  cause  strategic \\nadjustments to the state’s cyber security policies, it did lay the foundation for \\ncyber security institutions.90 As a reaction to intelligence failures in the Kargil \\nwar  of  1999,  the  Indian  government  established  the  National  Technical \\nFacilities  Organization, \\ncalled  National  Technical  Research \\nOrganization  (NTRO),  in  2004.  Reporting  directly  to  India’s  NSA  in  the \\nPMO,  the  NTRO  was  modeled  after  the  US  National  Security  Agency  as \\na  specialized  technical  agency  mandated  to  strategically  gather  intelligence \\nthrough  satellite  and  terrestrial  internet  communications  monitoring  and  to \\nimprove  intelligence  coordination  by  creating  secure  digital  networks  for \\ninteragency  information  sharing  on  emerging  threats.91  Nevertheless,  turf \\nwars  erupted  between,  in  particular,  the  Ministry  of  External  Affairs  (MEA) \\nand the NTRO on the one side and the Department of Telecommunications \\nand IT on the other.92  The 2008 designation of CERT-In as the nodal agency \\nfor  cyber  security  incident  responses  and  crisis  management  activities  was \\ninsufficient to resolve the rivalry.\\n\\n\\x0cINDIA REVIEW\\n\\n389\\n\\nTo  address  these  disputes,  but  also  driven  by  significant  frustrations  with \\nthe WikiLeaks and Snowden revelations as well as by mounting national and \\ninternational  pressures  to  address  the  exponential  growth  of  cyber  security \\nincidents, the Indian government undertook significant institutional reforms. \\nThen-NSA Shivshankar Menon tasked then Deputy-NSA Latha Reddy in late \\n2011 to revise the Indian government’s cyber security organizational structure. \\nReddy  coordinated  the  reform  with  her  counterparts  at  the  Department  of \\nElectronics and IT (DeiITY), now the Ministry of Electronics and Information \\nTechnology  (MeitY),  R.  Chandrashekhar  and  then-director  of  CERT-In, \\nGulshan  Rai,  and  consulted  then-Principal  Scientific  Advisor,  Rajagopalan \\nChidambram,  and  other  relevant  institutions.  Based  on  an  analysis  of  other \\nstates’ cyber security architectures and after arduous negotiations, the group \\nreached an agreement on a list of roles and responsibilities for each ministry, \\nwith  the  Defense  Ministry  mandated  with  leading  cyber  defense,  the  Home \\nMinistry with cyber crime, the MEA with cyber security diplomacy, and the \\nPMO  with  coordinating  the  multiple  activities.  As  a  result,  a  three-layered \\ncyber  regime  gradually  evolved  whose  composition  marked  a  shift  from \\na  focus  on  economic  aspects  and  cyber  crime  to  a  focus  on  broader  aspects \\nof  national  security  and  defense.  The  first  layer  consists  of  institutions \\nentrusted  with  cyber  security  management,  such  as  the  National  Security \\nCouncil  Secretariat  (NSCS)  and  the  NTRO;  the  second  layer  consists  of \\ninstitutions  fulfilling  governance  functions  and  includes  the  Ministries  of \\nCommunications,  Electronics  and  IT,  Defense,  External  Affairs,  and  Home \\nAffairs; and the third layer consists of non-governmental stakeholders such as \\nacademia, critical infrastructure providers and businesses.93\\n\\nSimultaneous to the NSCS’s institutional reforms, Gulshan Rai at the DeiTY \\nled  the  development  of  a  strategic  national  policy  framework  that  acknowl-\\nedged the growing level of cyber threats and the need for a high-level govern-\\nment  response  that  linked  the  different  institutional  layers.94  In  June  2013, \\nunder increased pressure to prove autonomous agency following the Snowden \\nrevelations,  the  MeitY  promulgated  the  National  Cyber  Security  Policy \\n(NCSP), previously approved by the cabinet. India was only the third country \\nin  the  world  to  announce  a  cyber  security  policy.95  The  NCSP  outlined  an \\nintegrated  vision  “to  build  a  secure  and  resilient  cyberspace  for  citizens, \\nbusinesses  and  government”  and  identified  key  instruments  to  implement \\nthis  vision.96  Top  priorities  included  increasing  capacity  to  prevent  and \\nrespond  to  cyber  threats  by  helping  to  create  a  workforce  of  500,000  cyber \\nsecurity  professionals  for  the  private  sector  within  five  years,  enhancing \\ncoordination  between  the  different  cyber  security  layers  as  well  as  cyber \\nsecurity  awareness,  establishing  early  warning  systems,  and  strengthening \\nthe indigenous cyber security industry.\\n\\nThese institutional and strategic adjustments yielded meaningful results. In \\nJanuary 2014, more than five years after the recommendation in the 2008 IT \\n\\n\\x0c390\\n\\nH. EBERT\\n\\nAct  amendment,  the  DeiTY  also  published  a  notification  to  establish  the \\nNCIIPC. The NCIIPC was placed under the NTRO and mandated to design \\nmeasures to protect critical information infrastructures against cyber warfare \\nand terrorism in cooperation with private sector and other security agencies, \\nidentifying crucial sub-sectors, tracing and analyzing malware and botnets and \\nenhancing  cyber  security  awareness  and  training.97  As  a  response  to  the \\nincreasing  number  of  large-scale  attacks  against  the  financial  sector,  Union \\nMinister Arun Jaitley announced the formation of a sectoral CERT for finance \\n(CERT-Fin)  in  February  2017.98  Moreover,  the  Indian  state  also  increased \\ncyber security awareness in the police and judiciary by promoting large-scale \\ntraining programs and prohibiting  the use  of private mail servers from gov-\\nernment  networks  previously  exploited  by  US  intelligence.  This  provision \\nbecame codified in the E-Mail Policy of the Government of India in July 2015.\\nFinally,  the  government  took  preliminary  steps  to  improve  coordination. \\nFirst,  the  PMO  created  the  new  position  of  National  Cyber  Security \\nCoordinator  (NCSC)  in  March  2015,  and  assigned  Gulshan  Rai  to  take  up \\nthis position. In addition, the government announced the establishment of the \\nmulti-stakeholder  body  National  Cyber  Coordination  Center  (NCCC)  in \\nsummer  2016.  Implemented  by  CERT-In  and  involving  the  NSCS,  the \\nIntelligence  Bureau  (IB),  the  Research  and  Analysis  Wing  (RAW),  the \\nNTRO, the Department of Telecommunications, and the three armed forces, \\nthe NCCC was tasked with centrally scanning web traffic entering the country \\nto detect threats at meta-data level and sharing alerts with and coordinating \\nresponses by affected agencies in real-time.99  Lastly, the government increas-\\ningly  engaged  with  non-governmental  third-layer  actors  through  multi- \\nstakeholder institutions and public private partnerships. In 2012, it established \\na  Joint  Working  Group  on  the  Engagement  with  Private  Sector  on  Cyber \\nSecurity. Initially chaired by Deputy NSA Reddy and later by NCSC Rai, the \\nworking  group  served  as  a  platform  for  information  sharing  and  drafted \\nrecommendations  for  enhancing  concrete  collaboration  between  the  public \\nand private sector.100\\n\\nIn  addition  to  these  adjustments  at  the  government  level,  India’s  military \\ninstitutions  have  responded  to  cyber  threats,  often  earlier  than  their  civilian \\ncounterparts.101  While  information  on  cyber  security  capacity  building  in \\nmilitary  institutions  is  usually  not  publicly  available,  selective  evidence  sug-\\ngests that all three military branches have incorporated cyber defense and to \\na lesser degree offense into their doctrines and began developing the respective \\ncapabilities.  In  its  2004  doctrine,  the  Indian  army  defined  seven  forms  of \\ninformation warfare, yet without detailing its own operational capacity.102  It \\nstood  up  the  Army  Cyber  Security  Establishment  in  2005  and  formed  the \\nCyber  Security  Laboratory  at  the  Military  College  of  Telecommunication \\nEngineering  in  April  2010.  The  Indian  navy  identified  electronic  warfare  as \\na key task in its 2009 doctrine and, after its Eastern Command headquarters at \\n\\n\\x0cINDIA REVIEW\\n\\n391\\n\\nVisakhapatnam had been targeted by a cyber attack in 2012, became the only \\nbranch  to  establish  a  cyber  security  unit.103  The  Indian  air  force’s  2012 \\ndoctrine  similarly  acknowledged  that  the  navy  had  been  affected  by  cyber \\nthreats,  and  outlined  a  roadmap  of  how  to  adapt.104  Overall,  the  Indian \\nmilitary  branches’  adjustments  reflected  a  broader  shift  in  India’s  domestic- \\nlevel  cyber  security  policies,  from  a  focus  on  commerce  and  trade-driven \\nconcerns linked  to  cyber  crime to one  on  defense-driven  concerns linked  to \\ncyber conflict and terrorism.\\n\\nLimitations of and impediments to  India’s cyber security policy\\nDespite  these  reforms,  a  persistent  gap  exists  between  the  ideation  and  the \\nimplementation of the above initiatives, undermining the effectiveness of the \\nIndian state’s response to cyber threats.105  Implementation of the NCSP and \\nits broader strategic ambitions has been lacking and inconsistent both at the \\ncentral and state levels largely due to three impediments.\\n\\nFirst, a lack of adequate cyber security capacity has impeded India’s ability \\nto protect its networks. According to a classified note by India’s NSCS leaked \\nin  June  2013,  India  deployed  556  cyber  security  experts  across  government, \\na  number  it  decried  as  “grossly  inadequate”  when  compared  to  its  peers.106 \\nPlans had already been announced, prior to the publication of the NCSP, to \\nrecruit over 4,446 cyber security experts for six government agencies in charge \\nof India’s cyber security infrastructure. Yet, despite efforts to institutionalize \\ncapacity-building  and  training  such  as  MeitY’s  Information  Security \\nEducation  and  Awareness  (ISEA)  project,  the  development  of  standardized \\ncyber security curricula by the NASSCOM-DSCI Cyber Security Task Force, \\nand  the  opening  of  a  series  of  cyber  labs  and  training  centers  at  federal  and \\nstate levels following the promulgation of the NCSP, recruitment both for the \\npublic  and  private  sectors  has  noticeably  lagged  behind  initial  ambitions.  In \\n2015, 87% of respondents to a survey by the Information Systems Audit and \\nControl Association admitted that India is facing a severe cyber security skills \\ngap.107  By  early  2017,  only  around  200,000  of  the  500,000  cyber  security \\nexperts promised in the NCSP had been recruited, leading some observers to \\ncall for recruiting experts from abroad.108 Though India’s IT but also its cyber \\nsecurity  talent  pools  were  larger  than  those  of  most  other  major  digital \\neconomies  in  absolute  terms  in  2018,  the  sub  sector  with  the  largest  gap \\nbetween  demand  and  supply  was  the  cyber  security  sector.109  For  example, \\ncyber attacks against India’s largest nuclear power plant in 2019 attributed to \\nNorth Korea alarmingly revealed India’s reliance on outdated doctrines such \\nas the “air gap strategy”.110\\n\\nIndia failed to harness its IT talent pool to recruit adequate expertise largely \\ndue to insufficient cyber security education and awareness as well as targeted \\nresources.  India’s  higher  education  was  late  in  offering  formal  training  for \\nhighly specialized skills such as cryptography, forensic science and intrusion \\n\\n\\x0c392\\n\\nH. EBERT\\n\\ndetection, and the government was overwhelmed with the task of increasing \\npublic awareness at the pace of digitization.111\\n\\nRelatedly,  law  enforcement  in  India’s  cyber  security  policy  has  lagged \\nbehind jurisdiction. The rate of conviction of cyber crime remained abysmally \\nlow,  as  enforcement  agencies  lacked  basic  forensic  capabilities,  access  to \\nelectronic  evidence  for  criminal  investigations  remained  limited,  and  the \\ntime  to  obtain  such  evidence  from  abroad  was  too  lengthy  due  to  a  lack  of \\nsufficient expertise among Indian officials filing such requests.112 Partly due to \\ninsufficient investments and a lack of recruitment guidelines as well as aware-\\nness about careers in cyber security, most qualified Indian IT specialists prefer \\nworking  abroad  or  in  multinational  software  development  companies.  As \\na  result,  India  has  remained  largely  dependent  on  importing  IT  hardware \\nand cyber security software solutions such as encryption software.\\n\\nThe lack of capacity-building also persisted in India’s military and intelli-\\ngence  institutions.  Successive  governments  have  been  reluctant  to  commit \\nfully to developing military cyber capabilities. The publicly available evidence \\nsuggests that despite the Ministry of Defense’s longstanding public warnings \\nabout  growing  cyber  threats  to  India’s  national  security  and  Prime  Minister \\nModi’s  call  to  develop  a  “Digital  Armed  Force”  in  October  2014,  DIA  and \\nNTRO  have  only  recently  been  mandated  to  develop  India’s  offensive  cap-\\nabilities, a subject that has not been discussed proactively in public.113 Already \\nin 2012, the military announced plans to establish a tripartite Cyber Command \\nto enhance its exploitative, interceptive and intrusive capabilities, but due to \\nunsettled questions on recruitment and the desired degree of jointness, over-\\nlapping  mandates  and  general  bureaucratic  lethargy,  it  took  India’s  Defense \\nMinister  until  July  2017  to  approve  the  plans  and  the  cabinet  until \\nOctober  2018  to  approve  the  establishment  of  the  Cyber  Defense  Agency \\n(CDA).114 Headquartered in New Delhi, the tri-service agency is led by a two- \\nstar  general,  Rear  Admiral  Mohit  Gupta,  to  coordinate  the  military’s  cyber \\nwarfare planning and conduct – yet, by mid-2019, the agency still needed to be \\ntransformed into a full-fledged cyber command led by a three-star general as \\noriginally outlined. In addition, the agency struggled with a lack of legislative \\nclarity on its responsibilities and difficulties to recruit the projected 1,000 cyber \\nsecurity experts.115  As a result, operations,  such as espionage attacks against \\nstates  including  China  and  Pakistan  between  2010  and  2013,  codenamed \\n“Operation  Hangover”,  remained  relatively  unsophisticated.116  Moreover, \\nthe Indian state’s less ambitious goal of protecting the Indian defense informa-\\ntion networks’ integrity was only partially achieved. By 2018, these networks \\nwere still largely dependent on Chinese and US hard and software despite the \\navailability of Indian competitor products. The Air Force Network (AFNET) \\nand the army’s Network for Spectrum (NFS) are both dependent on hardware \\nfrom  the  US  company  Cisco,  and  the  Indian  army’s  official  computers  are \\nmostly using Windows as operating system.117\\n\\n\\x0cINDIA REVIEW\\n\\n393\\n\\nSimilarly, evidence suggests that initiatives to build cyber security capabil-\\nities  in intelligence  agencies such  as  RAW, IB, and  the  National Intelligence \\nAgency  (NIA)  remained  stalled  due  to  red  tape.  As  Major  General \\nP.  K.  Mallick  points  out,  the  NCSC  lacks  executive  power  and  his  office  is \\nheavily understaffed. Indian intelligence agencies lack credible code breaking \\ncapability  acquired  by  agencies  in  the  US,  the  UK,  and  likely  in  China  and \\nRussia.118  Moreover, the full implementation of projects such as the National \\nIntelligence  Grid  (NATGRID),  handled  by  MHA’s  cyber  division,  and  the \\nCentral  Monitoring  System  (CMS)  have  been  repeatedly  delayed.  Finally,  it \\ntook until July 2019 for the Indian parliament to pass an amendment to the \\nNIA Act 2008 providing the NIA with the power to investigate cyber terror-\\nism. India’s reluctance to build military cyber security capabilities was rooted \\nin  a  general  skepticism  of  militarizing  cyberspace  and  lacking  high-level \\npolitical attention before the Mumbai attacks in 2013.\\n\\nWhile these impediments are not unique to India, India has lagged behind \\nregional  and  global  players  in  most  measures  of  cyber  security  capacity.  As \\nTable  A1  in  the  appendix  shows,  it  ranked  17  out  of  19  among  the  G20 \\nmember  states  (excluding  the  European  Union)  and  the  weakest  among  the \\nBRICS  member  states  in  “cyber  power”  measured  by  the  Economist \\nIntelligence Unit119; showed relatively low “networked readiness” as measured \\nby the World Economic Forum120; zero “cyber readiness” as documented by \\nthe Potomac Institute for Policy Studies121; and a relatively low and declining \\n“cyber  commitment”  according  to  the  International  Telecommunication \\nUnion.122  The  high  pace  and  scale  of  its  digitization  and  the  volume  and \\nsophistication of cyber threats require India to invest in cyber security capacity \\nfar beyond efforts undertaken thus far.\\n\\nSecond, a lack of coordination among multiple stakeholders, due largely to \\ngovernment  agencies’  overlapping  mandates  and  the  concomitant  turf  wars, \\nresulted  in  persistent  institutional  gridlock.  While  disruptive  events  such  as \\nthe Kargil conflict, Mumbai attacks and WikiLeaks and Snowden revelations \\ntriggered  punctuated  initiatives,  the  NCSP  still  remained  largely  detached \\nfrom  Prime  Minister  Modi’s  other  digital  initiatives  or  the  state’s  broader \\nnational  security  doctrines.  Turf  wars  between  ministries  such  as  MoD  and \\nMHA and civilian agencies such as NTRO, IB and RAW persisted despite the \\nNSCS-led  organizational  reform.  The  NCSC  remained  detached  from  cyber \\noperations  by  intelligence  agencies.123  Progress  to  enhance  coordination \\nbetween  provincial  government  agencies,  responsible  for  law  enforcement, \\nand  federal  agencies  has  been  equally  sluggish.124  The  NCCC,  approved  in \\nMay 2013 to enhance coordination, was still only partially operational by late \\n2019  as  a  majority  of  relevant  stakeholders  were  insufficiently  aware  of  its \\nexistence.125 MeitY was unable to maintain its lead agency role in formulating \\ncyber security policy against more powerful institutions such as MoD, MHA \\nand  NTRO.  The  lack  of  inter-ministerial  coordination  effectively  torpedoed \\n\\n\\x0c394\\n\\nH. EBERT\\n\\nthe intended establishment of a CERT-Fin mentioned in February 2017, which \\nfound no reference in the 2018 budget announced by the Union government \\none year later.126\\n\\nSimilarly,  coordination  and  cooperation  between  the  public  and  private \\nsector, deemed crucially important for protecting information networks, has \\nbeen  beset  by  mutual  distrust.  While  the  Indian  state  traditionally  relied \\nheavily  on  self-regulation by  the  private sector  in cyberspace,127  the  govern-\\nment became increasingly skeptical as various industry associations competed \\nover  stakeholder  representation  instead  of  coordinating  cyber  security  mea-\\nsures, and companies often invested in joint ventures rather than in research \\nand  development.  In  turn,  the  private  sector  was  suspicious  of  the  state’s \\nability to  provide  the public  goods  necessary  to secure  cyberspace.128  A lack \\nof  trust,  however,  significantly  undermined  the  NCCC’s  mandate  to  share \\ngathered intelligence with the private sector.129  As a result, the joint working \\ngroup established in 2012 has failed to produce substantial outcomes.130\\n\\nA  lack  of  coordination  also  prevailed  among  military  institutions.  The \\nplethora  of  institutions  within  the  military  dealing  with  cyber  security  and \\nthe lack of harmonization among their independent cyber security capability- \\nbuilding projects undermined even the relatively modest goal of protecting the \\nmilitary’s defense information networks, never mind the concomitant adjust-\\nments to force structure and strategy.131  The Defense Information Assurance \\nand Research Agency (DIARA) was tasked to manage cyber security incidents \\nfor  the  armed  forces  and  the  Indian  Joint  Armed  Forces  Doctrine  issued  in \\n2017  observed  an  “emerging  triad”  of  space,  cyber  and  special  operations \\ncapabilities  that  complement  the  conventional  capabilities  at  land,  sea  and \\nair.  However,  the  Ministry  of  Defense  cyber  security  units  have  pursued \\noverlapping cyber security mandates, and all military branches have developed \\ntheir own CERT teams and cyber security policies.132\\n\\nCivil-military  coordination  has  also  been  limited,  and  the  role  of  the \\nmilitary  in  the  state’s  broader  cyber  security  policy  has  remained  poorly \\ndefined.  In  the  process  of  designing  a  new  organizational  chart  for  India’s \\ncyber  security,  the  Defense  Ministry  successfully  insisted  on  maintaining \\nautonomous  cyber  security  authority.  Projects  such  as  NATGRID  remained \\ndelinked from the armed forces. As a result, the military’s response to increas-\\ning cyber threats has inhibited “clarity of communications between India and \\nits  allies,  not  to  mention  potential  adversaries  like  Pakistan”,133  and \\na consolidated policy for how the civilian and the defense institutions would \\nrespond in case of an emergency is still wanting.134\\n\\nFinally,  effective  implementation  has  been  impeded  by  India’s  status  as \\na rising digital democracy and related intricacies of balancing the imperatives \\nof  openness,  privacy  and  security.  India  shares  the  challenge  of  securing \\na  quickly  growing  cyber  ecosystem  without  compromising  individual  rights \\nand  the  potential  for  innovation  with  other  rising  democracies,  whose  open \\n\\n\\x0cINDIA REVIEW\\n\\n395\\n\\nsocieties  and  electoral  systems  have  inherent  vulnerabilities  and  whose  poli-\\ntical processes take more time to adapt to emerging technologies than those in \\nauthoritarian  states.  Yet,  the  Indian  state  has  faced  extraordinary  pressures \\ngiven  the  scale  of  its  digitization  and  the  growing  challenges  to  its  liberal \\ndemocracy,  and  its  attempts  to  control  cyberspace  have  been  contested.  For \\ninstance, the government had to withdraw its first draft of a national encryp-\\ntion  policy  as  provided  in  the  NCSP  in  2015  after  massive  civil  society \\nopposition  to  perceived  civil  liberty  infringements.  Similar  opposition  chal-\\nlenged  the  implementation  of  the  Aadhaar  system.  Rooted  in  the  urge  to \\ndevelop  a  registry  of  citizens  after  the  Kargil  conflict  of  1999,  during  which \\nPakistan-based militants exploited the lack of identification to cross the border \\ninto India and establish “sleeper cells”, Aadhaar sought to maximize security \\nthrough identification rather than through anonymity. While India’s Supreme \\nCourt  validated  Aadhaar’s  constitutionality  in  September  2018,  its  gradual \\nexpansion has triggered widespread privacy and security concerns, including \\nin the form of a petition filed by academic and activist late Shamnad Basheer \\npending  at  the  time  of  writing  in  the  Delhi  Supreme  Court.135  Equally,  the \\nrelatively sophisticated cyber crime regulation has been widely criticized for an \\nexcessive surveillance and censorship.136 Achieving a coherent, balanced cyber \\nsecurity  policy  has  proved  beyond  the  capacity  of  the  Indian  government, \\ngiven the competing demands of privacy, openness and national security. In its \\nattempt to replicate its IT “miracle” to cyber security, the Indian state under-\\nestimated the degree to which cyber security has posed a more complex and \\ndemanding policy challenge to India’s democratic polity. Given these impedi-\\nments  to  implementation,  legislative,  institutional  and  strategic  government \\nefforts to address cyber security threats have often been confined to statements \\nof principles and intentions.\\n\\nIndia’s international cyber security policy\\n\\nDrivers and gains of bilateral and multilateral cyber diplomacy\\nUnable  to  shore  up  its  domestic  defenses  to  match  the  pace  of  emerging \\ntransnational threats, and pressured by the resulting relative disadvantage in \\ncapabilities, the Indian state felt increasingly compelled to engage in bilateral \\nand  multilateral  cyber  diplomacy  to  foster  technology  transfer  and  shape \\nevolving  norms  in  cyber  security-related  negotiations  in  its  favor.137  The \\nMEA, MeitY, MHA, MoD, NSCS, CERT-In, and other law enforcement and \\ndefense  agencies  and  forces  have  adjusted  their  structures  and  boosted  their \\nresources for international engagement on cyber security, cyber crime, digital \\ntrade and internet governance, respectively.\\n\\nIndia  engaged  extensively  in  bilateral  cyber  interactions  that  primarily \\nserved  to  exchange  information  on  threats,  best  practices  and  joint  policy \\ngoals  and  instruments,  and  to  prepare  and  evaluate  joint  capacity  building. \\n\\n\\x0c396\\n\\nH. EBERT\\n\\nBetween 2000 and mid-2017, India entered 103 international bilateral arrange-\\nments  that  were  either centered  on  cyber  security or outlined cyber  security \\nefforts  as  part  of  other  policy  area  engagements,  including  39  MLAT  agree-\\nments, 54 Memoranda of Understanding (MoUs) and Joint Statements and 10 \\nCyber Frameworks, around 90% of which were concluded since 2014.138 These \\nagreements  most  prominently  entailed  provisions  on  information  sharing, \\nresearch and development and capacity building, and involved over 60 states \\nincluding  established  cyber  powers  such  as  the  US  and  Russia  and  evolving \\ncyber powers such as Israel, Japan and South Korea. In fact, by 2016 India was \\nthe only major power that had entered formal arrangements on cyber security \\nwith  the  US  and  Russia,  underlining  its  attempt  to  protect  its  networks \\nthrough  cyber  partnerships,  avoid  disproportionate  dependence  on  any  one \\nstate,  and  position  itself  as  a  potential  interlocutor  on  cyber  security \\nnegotiations.139\\n\\nIndia’s  bilateral  engagement  with  the  US  yielded  the  most  significant \\nresults.  Embedded  within  the  broader  bilateral  rapprochement  since  the \\nearly  2000s,  cooperation  on  cyber  security  was  driven  by  growing  Indo-US \\nICT  market  interdependencies,  a  shared  concern  about  increasing  Chinese \\nespionage,  and  India’s  endorsement  of  the  US-favored  multistakeholder \\napproach  to  global  internet  governance  in  June  2015.  Already  in  2001,  both \\nsides formed the India-US Cyber Security Forum that was later developed into \\na  whole-of-government  cyber  dialogue  as  well  as  the  ICT  Working  Group \\nestablished in 2005 and led to the signing of the comprehensive Framework for \\nthe India-US Cyber Relationship in June 2016.140 Facilitated by these delibera-\\ntions, the CERT-In, modeled on the US-CERT, as well as the National Skills \\nRegistry (NSR), an information repository for sectoral expertise, were estab-\\nlished  in  2004  and  2005,  respectively.  Both  governments  signed  a  MoU  that \\ninstitutionalized  information  and  expertise  sharing  between  their  CERTs  in \\nJuly 2011, which was renewed in January 2017.141\\n\\nOnly four months after the India-US framework agreement and at a time \\nwhen Washington formally accused Moscow of conducting cyber operations \\nto influence US elections, India concluded a “comprehensive” cyber security \\nagreement with Russia at the BRICS summit in Goa. While a previous agree-\\nment of September 2015 narrowly focused on cyber terrorism, the 2016 India- \\nRussia agreement, which was not made public, reportedly focused heavily on \\ndefense,  including  advancing  military-to-military  cooperation  on  cyber \\ndefense  and  interagency  measures  against  cyber  terrorism  and  crime.142  In \\nFebruary  2018,  both  renewed  their  commitment  to  deepen  cooperation \\nbetween  specialized  agencies,  information  sharing  and  capacity  building  to \\nprevent the use of ICT in cyber conflicts, terrorism and crime.143 While India \\nreportedly  hoped  to  benefit  from  Russia’s  experience  with  building  cyber \\nsecurity  capabilities  and  its  leading  cyber  security  companies,  Russia  sought \\nto further expand its position as India’s largest weapons supplier. Both sides \\n\\n\\x0cINDIA REVIEW\\n\\n397\\n\\nrecognized cyber security as a field that might resuscitate an otherwise dwind-\\nling bilateral relationship.\\n\\nAt the multilateral level, India engaged in regional and global institutions to \\nadvance  its  cyber  security  interests.  Regional  organizations  (ROs)  in  which \\nIndia  is  a  member  or  partner  and  which  seek  to  construct  regional  cyber \\nsecurity regimes include the Association of Southeast Asian Nations (ASEAN) \\nand its Regional Forum (ARF), the Bay of Bengal Initiative for Multi-Sectoral \\nTechnical and Economic Cooperation (BIMSTEC), the Asia-Pacific Economic \\nCooperation  (APEC)  forum  and  the  Shanghai  Cooperation  Organization \\n(SCO). Among these, ASEAN and ARF have gone the furthest in facilitating \\nregional  cyber  cooperation,  in  particular  through  confidence  building  mea-\\nsures to reduce the risk of misperception and escalation of cyber conflicts.144 \\nTo enhance technical cooperation, CERT- \\nIn joined annual Asia Pacific CERT (APCERT) drills since 2010. In addition, \\nthe  SCO,  which  has  focused  on  joint  efforts  to  address  cyber  terrorism,  has \\nbecome  an  increasingly  important  RO  in  India’s  cyber  diplomacy.  Since \\nbecoming a full member in June 2017, India has joined an anti-cyber terrorism \\njoint drill in December 2017 designed to enhance coordination and informa-\\ntion  sharing  among  member  states  and  hosted  a  workshop  on  developing \\nstandard  operating  procedures  for  addressing  cyber  crime  in  Hyderabad  in \\nMay 2019.\\n\\nIndia’s  cyber  diplomacy  in  global  multilateral  institutions  has  focused  on \\ninitiatives to build norms for responsible state behavior, through which India \\nsought to help raise the costs for malicious cyber activities while building more \\neffective cyber defense capabilities.145 New Delhi recurrently claimed a greater \\nrole for the United Nations (UN) in global cyber security policy-making and \\nbecame  a  member  of  five  of  the  six  UN  Groups  of  Governmental  Experts \\n(UNGGE)  established  in  2004,  which  produced  three  reports  in  2010,  2013 \\nand  2015  stipulating  a  long-awaited  consensus  that  and  how  international \\npublic law, including the UN Charter, applies to cyberspace.146  In an attempt \\nto delegitimize  the alleged use of  non-state cyber proxies and potential  state \\ncyber attacks by China and Pakistan, Indian delegations emphasized the need \\nto  reach  international  consensus  on  how  to  attribute  and  address  cyber \\nterrorism and supported the establishment of an explicit right to self-defense \\nagainst state-sponsored cyber attacks.\\n\\nIndia also engaged in non-governmental cyber norms building efforts such \\nas  the  Global  Conference  on  Cyberspace,  which  it  hosted  in  New  Delhi  in \\nNovember  2017, the  Global  Commission  on  the  Stability  of  Cyberspace  and \\nthe UN High-Level Panel on Digital Cooperation, and endorsed two reference \\nreports  on  international  law  in  cyberspace  by  non-governmental  experts \\npublished in 2013 and 2017 (Tallinn Manuals). In December 2017, by entering \\nthe  Wassenaar  Arrangement,  a  non-binding  export  control  regime  on  con-\\nventional  arms  and  dual-use  goods  and  technologies,  India  sought  to  gain \\n\\n\\x0c398\\n\\nH. EBERT\\n\\neasier access to cyber security technologies such as IP surveillance and intru-\\nsion software and greater influence on regulating technology transfer.147  The \\nIndian  government  also  used  its  membership  in  the  Group  of  20  (G20)  to \\nincrease awareness on cyber terrorism.148  Finally, the Indian government has \\ncalled for a new UN “framework” to address cyber crime that would replace \\nthe Council of Europe’s Convention on Cybercrime (“Budapest Convention”), \\nwhich  New  Delhi  has  for  various  tactical  and  practical  reasons  criticized  as \\nbeing  discriminatory,  ineffective  and  detrimental  to  state  sovereignty.149 \\nOverall, building on  its historically  active involvement in  international arms \\ncontrol  and  disarmament  institutions,  India  managed  to  position  itself  as \\na  leading  voice  for  developing  countries’  interests  in  global  cyber  security \\nnegotiations.\\n\\nLimitations of and Impediments to India’s Cyber Security  Diplomacy\\nWhile India’s cyber diplomacy is widely perceived as more advanced than national \\nefforts  to  build  capacities,  actual  implementation  is  often  limited.150  Bilateral \\ndialogues rarely went beyond the exchange of expertise to focus on more robust \\njoint training or law enforcement cooperation or yield more concrete outcomes, \\na  limitation  that  can  also  be  observed,  though  to  lesser  degrees,  in  bilateral \\ninteractions  on  other  policy  issues.  Meaningful  discussion  on  cyber  security \\nremained  perfunctory  in  South  Asia  and  were  concentrated  in  East  Asia.151 \\nFinally, the Indian state was even more reluctant to empower multilateral global \\ninstitutions  in  which  state  control  is  more  limited.152  As  at  the  domestic  level, \\nconstraints  to  capacity  and  coordination  as  well  as  ambiguity  in  its  strategic \\nculture also impeded India’s ability to boost its cyber security through diplomacy.\\nFirst, despite institutional reforms in various ministries, India commanded \\nhighly limited cyber diplomacy capacities. This impediment is linked to gen-\\neral  constraints  of  India’s  organizational  foreign  policy  capacity.  Despite \\nhaving  a  diplomatic  workforce  with  comparably  high  analytical,  managerial \\nand leadership skills, the Indian foreign service lacks a critical mass of officers \\nand  the  infrastructure  for  effectively  collecting  and  processing  information \\nand  is  insufficiently  engaged  with  the  public.153  In  the  MEA,  one  director \\nmanaged  all the  above-mentioned  bilateral  and  multilateral  engagements  on \\nher own, leaving the ministry overwhelmed with implementing the intentions \\noutlined in the quickly proliferating arrangements. Similarly, India hosted the \\nfifth  Global  Conference  on  Cyber  Stability  in  November  2017  in  New  Delhi \\nbut was unable to ensure tangible outcomes.\\n\\nSecond, relatively poor coordination between the MEA and other bodies in \\nand out of government resulted in diverging priorities and a fragmentation of \\nIndia’s international engagement.154  MEA’s “imperial and exclusivist view of \\nforeign policy” and the civil society and private sector’s view of the MEA as \\n“heavy-footed  and  old-fashioned  as  well  as  ill-informed  in  their  areas  of \\n\\n\\x0cINDIA REVIEW\\n\\n399\\n\\noperation” was particularly pronounced and problematic in the area of cyber \\nsecurity.155\\n\\nFinally, the intricacies of securing cyberspace without compromising priv-\\nacy and openness also contributed to a lack of strategic coherence in India’s \\ncyber  security  diplomacy.  The  Indian  foreign  policy  establishment’s  tradi-\\ntional emphasis on strategic autonomy and related concerns about solutions \\ndeemed too “Western” conflicted with the national security community’s urge \\nto  address  cyber  security  concerns  quickly  and  expediently.156  For  example, \\ndeepening  cyber  security  cooperation  with  the  US  promised  to  allow  India \\naccess to critical cyber security technologies, but the bilateral cyber dialogue \\nfailed to yield results as substantial as in other areas, most notably in nuclear \\nenergy. It was derailed by the leakage of information on incidents of US cyber \\nespionage  and  US  concerns  about  technology  leakages  by  others,  fueling \\na preexisting distrust.\\n\\nIndia has therefore aligned with Russia and China instead and pursued an \\ninherently ambivalent policy of multi-alignment in cyber diplomacy.157 India \\nalong  with  Russia  continuously  criticized  the  Wassenaar  Arrangement  as \\ndiscriminatory,  favoring  states  already  possessing  the  most  advanced  tech-\\nnologies and denying access to specific (dual use) technologies to others; the \\nTallinn Manuals as lacking inclusivity as the group was exclusively composed \\nof European and North American experts; and the Budapest Convention as \\ndiscriminatory  (as  it  was  not  part  of  the  convention’s  drafting  process), \\nineffective  (in  particular  its  MLA  regime,  but  also  given  that  states  from \\nwhich  the  majority  of  attacks  against  Indian  networks  originate  are  non- \\nsignatories), and impinging on states’ sovereignty (in particular its article 32. \\nb,  which  provides  law  enforcement  agencies  transborder  access  to  data, \\na  concern  that  has  been  widely  described  as  a  deliberate  Russian \\nmisinterpretation).158  In  the  future,  the  strategic  coherence  of  India’s  cyber \\ndiplomacy  will  further  depend  on  how  it  manages  the  tension  of  seeking \\ncloser cyber cooperation with the US while being a full member in the SCO, \\nwhich  has  evolved  as  a  significant  vehicle  for  the  Chinese  and  Russian \\ngovernment  to  internationally  promote  norms  for  greater  state  control  in \\ncyberspace.\\n\\nRisks and opportunities for India’s cyber security\\n\\nThis study found that the growing chasm between India’s national and inter-\\nnational aspirations and advances in ICT and its ability to secure its networks \\nin cyberspace is driven by a lack of capacity-building and coordination and the \\nsticky  processes  inherent  in  balancing  security,  privacy  and  openness  in \\na  quickly  digitizing  democracy.  This  finding  has  generalizable  implications \\nfor  the  scholarship  on  how  states  handle  cyber  threats,  in  particular  quickly \\ndigitizing  emerging  economies  with  democratic  polities.  First,  possessing \\n\\n\\x0c400\\n\\nH. EBERT\\n\\na  strategic  edge  in  ICT  is  an  insufficient  condition  for  protecting  a  state’s \\nquickly digitizing networks. If even a state with a tradition of using technology \\nas a principal vehicle for economic and political development, a highly skilled \\nIT workforce and well-developed cyber security regulatory system is unable to \\nharness  its  established  human  and  technological  resource  potential,  imple-\\nmenting and enforcing cyber security policies requires a strategic effort coor-\\ndinated  not  only  among  involved  state  agencies  but  among  the  multiple \\nstakeholders.\\n\\nMoreover,  capacity-building  and  its  various  manifestations,  from  cyber \\nsecurity  skills  and  knowledge  to  awareness  and  military  defense  capabilities, \\nare critical for effective implementation. Harnessing a comparative advantage \\nin  ICT  to  secure  information  networks  requires  fundamental  reforms  of \\neducation  and  training  at  different  educational  and  vocational  levels  as  well \\nas a competitive hiring scheme for the most qualified specialists. Transforming \\nfrom an IT power to a cyber power – a state that is more effective than others \\nin  maximizing  the  benefits  of  advanced  digitization  while  minimizing  the \\nconcomitant risks – further requires a single high-level framework that spells \\nout the roles of and partnerships between the various stakeholders, including \\nthe military, in both national- and global-level policy-making. Future scholar-\\nship should further examine the sources of persistent implementation failure \\nin  democratic  polities,  including  the  sources  of  insufficient  cyber  security \\ncapacity-building in a state with formidable ICT resources. More fundamen-\\ntally,  India’s  experience  in  trying  to  secure  the  ICT  domain  has  followed \\npatterns by which it governed other technologies such as energy, health and \\nnuclear. Arguably, the case revealed that the effects of emerging technologies \\nsignificantly depend on the structure of the society and state in which they are \\ndeployed. To test this assumption, future scholarship should study how rising \\ndigital democracies govern ICTs in comparison to emerging technologies.\\n\\nThe  extent  to  and  means  by  which  India  will  be  able  to  more  effectively \\nexploit its talent pool to secure its information networks will also have political \\nconsequences  for  the  evolving  international  cyber  security  policy  landscape \\nand  broader  political  climate.  First,  India’s  shortcomings  could  significantly \\naffect the cyber security of other countries. Already a major source of global \\nspam  and  future  waves  of  DDoS  attacks,  growing  insecurity  in  Indian  net-\\nworks  could  further  destabilize  global  cyberspace.  Second,  the  way  in  which \\nNew  Delhi  balances  the  imperatives  of  privacy,  openness  and  security  when \\naddressing its extensive digital divide will influence the appeal of democratic \\ngovernance  in  other  digital  democracies,  and  could  counter  or  amplify  the \\nnotion that cyber security governance is per se more effective in authoritarian \\nstates. India has the world’s second largest population of connected as well as \\nthe  largest  population  of  unconnected  people.  As  the  fastest  growing  large \\neconomy, India has used its resources to bridge this divide and exhibited by far \\nthe fastest growing internet user base of any large economy, expected to reach \\n\\n\\x0cINDIA REVIEW\\n\\n401\\n\\none billion by 2030. Being the world’s largest democracy, it will be a bellwether \\ncountry for how to bridge this digital divide in a democratic context.\\n\\nFinally,  and  relatedly,  finding  a  balance  suitable  to  its  needs  could  also \\nincrease  India’s  leverage  in  global  cyber  security  governance.  India  could \\nserve  as  a  model  for  emerging  digital  democracies  and  rightfully  claim \\na  leadership  role  for  representing  primary  concerns  by  the  Global  South \\nsuch as affordable access and local content generation as well as for champion-\\ning  a  free  and  open  internet  and  a  more  decentralized  multistakeholderism \\nsensitive  to  the  growing  number  of  governments,  internet  corporations  and \\nusers  with  increasing  stakes  in  cyberspace.  With  Prime  Minister  Modi’s \\ndecision  to  tie  India’s  economic,  political  and  social  development  closely  to \\nthe success of its ICT-enabled transformation, India’s engagement in bilateral, \\nmultilateral and multistakeholder negotiations to shape global cyber security \\nnorms and regimes is likely to increase. Given US retreat from various inter-\\nnational fora and Chinese digital protectionism, India has a unique opportu-\\nnity  to  tip  the  scale  in  future  cyber  negotiations  and  to  pioneer  its  own \\ncompetitive paradigm of how to navigate digital globalization.\\n', 'Privacy Impact Assessment \\nEINSTEIN Program \\n\\nCollecting, Analyzing, and Sharing \\nComputer Security Information Across the \\nFederal Civilian Government  \\n\\nDepartment of Homeland Security \\nNational Cyber Security Division \\nUnited States  \\nComputer Emergency Readiness Team \\n(US-CERT) \\n\\nSeptember 2004 \\n\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n\\x0cPRIVACY IMPACT ASSESSMENT \\n\\nExecutive Summary \\n\\nThe Einstein Program \\n\\nIntroduction \\nThe Role of DHS and US-CERT \\nThe Einstein Program \\n\\nReasons for Information Collection \\n\\nWhat Information is to be collected? \\nThe Intended Use of the Information \\nWith Whom Will the Information Be Shared? \\nNotice and Consent \\nEnsuring the Security of the Information \\nCreation of a Privacy Act System of Records \\nConclusion \\n\\n1\\n\\n2\\n2\\n2\\n3\\n\\n5\\n6\\n8\\n8\\n9\\n9\\n9\\n9\\n\\n− ii −  \\n\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n\\x0cEXECUTIVE SUMMARY  \\n\\n•  This Privacy Impact Assessment (PIA) examines the privacy implications of the United \\nStates Computer Emergency Readiness Team’s (US-CERT’s) EINSTEIN Program in \\naccordance with Section 208 of the E-Government Act and the guidance for PIAs issued \\nby the Office of Management and Budget (OMB).  This PIA addresses for the EINSTEIN \\nProgram:  \\n\\no  What and why the information is being collected;  \\no  The intended use of the agency information;  \\no  With whom the information will be shared;  \\no  What notice or opportunities for consent would be provided to individuals \\n\\nregarding information collected; \\n\\no  How that information is shared and secured; and  \\no  Whether a system of records is being created under section 552a of title 5, United \\n\\nStates Code (the “Privacy Act”). \\n\\n•  The EINSTEIN Program is an automated process for collecting, correlating, analyzing, \\nand sharing computer security information across the Federal civilian government.  By \\ncollecting information from participating Federal government agencies, the US-CERT \\nbuilds and enhances our nation’s cyber-related situational awareness.  Awareness will \\nfacilitate identifying and responding to cyber threats and attacks, improve network \\nsecurity, increase the resiliency of critical, electronically delivered government services, \\nand enhance the survivability of the Internet.  \\n\\n•  The US-CERT has prepared the EINSTEIN Program to implement statutory and \\n\\nadministrative responsibilities in two distinct, but related areas.  \\n\\no  First, in accordance with the mandate of the Homeland Security Act, as well as of \\n\\nHomeland Security Presidential Directive 7, the Department of Homeland \\nSecurity (DHS) through the US-CERT will deploy the EINSTEIN Program to \\nhelp protect cyberspace.   \\n\\no  Second, in accordance with the Federal Information Security Management Act \\n\\n(“FISMA”), the EINSTEIN Program supports Federal agencies in their efforts to \\ncomply with Congressional requirements for information security, including \\ncompliance with information assurance guidelines prepared by OMB.  The \\nEINSTEIN Program provides an essential layer of protection for the Federal \\nEnterprise Architecture (“FEA”) and the IT infrastructure used to deliver essential \\ncitizen services.  There are no other cross-agency, automated processes that \\nsupport FISMA compliance, protect the FEA, and focus on delivery of essential \\ngovernment services.   \\n\\n• \\n\\nIn this manner, the EINSTEIN Program supports Federal agencies’ efforts to protect their \\ncomputer networks.  System and network administrators within each agency are \\nresponsible for guarding access to sensitive information and computing infrastructure.  \\nDuring the past several years, network attacks and disruptions have become increasingly \\ncommon and occur at rates that prevent government officials from managing risks \\neffectively without a collective and collaborative information-sharing program.  Both \\n\\n− 1 −  \\n\\n\\x0cstatutory provisions and the Office of Management and Budget require agencies to share \\nincident and risk data with the US-CERT to accomplish these goals.     \\n\\n•  Federal agency partners are the core of the EINSTEIN Program’s capability.  Each \\nFederal agency administrator retains complete control of network data in strict \\naccordance with Federal laws and polices.  Agencies gather and subsequently share \\nsecurity data directly with the US-CERT, based on reporting requirements established by \\nOMB.  In turn, the US-CERT prepares a strategic, cross-agency assessment, which is \\nthen shared back with all Federal civilian agencies.  Federal civilian agencies are -- in \\nreturn for sharing anomaly and security data -- better positioned to protect their systems, \\nsave scarce resources, and provide essential services.  \\n\\nTHE EINSTEIN PROGRAM  \\n\\nIntroduction \\n\\nBecause we live in a world dominated by computers and the Internet, protection of \\ncyberspace is of critical importance to this nation’s national security, economic well-being, \\npublic safety, and the protection of personal information maintained in electronic databases.  \\nThis is especially true at the Federal agency level where relationships between citizens and their \\nGovernment have been and will continue to be transformed by technology.1  These advances \\nhave allowed agencies to enhance their functions and services, achieve efficiencies, and increase \\ntransparency and access.  \\n\\nWith the clear benefits from technology, however, has come an increased awareness of \\nthe potential vulnerabilities of the Federal information infrastructure.  It is critical to assess and \\nmanage cyber risks at the federal agency level in order to ensure the delivery of government \\nservices, whether in times of calm or under national alert.  Experience has demonstrated, \\nmoreover, that protecting federal cyberspace requires a cross-government awareness of issues \\nand collaborative management.  \\n\\nThe Role of DHS and US-CERT \\n\\nFederal policy recognizes the importance of an enterprise solution for cybersecurity.  \\nAppropriately, the Director of the Office of Management and Budget (OMB) is required by \\nFISMA to oversee Federal agency information security policies and practices and to coordinate a \\ncomprehensive, government-wide, risk-based approach for managing information security \\nissues.  FISMA additionally requires OMB to oversee the operation of a central Federal \\ninformation security incident center, the function of which is now housed in NCSD’s US-CERT.  \\nOMB provides guidance to Federal agencies on incident identification and reporting.2\\n\\n1 \\n\\nIn fact, the E-Government Act of 2002 was enacted to promote federal use of technology as a \\n\\nprimary means to access high quality Government information and services across multiple channels and to make \\nthe Federal Government more transparent and accountable.  Section 208 of that statute requires the preparation of \\nprivacy impact assessments for information technology that collects, maintains or disseminates information that is in \\nan identifiable form. \\n\\n2 \\n\\nThe US-CERT function is the central activity for the collection and analysis of reports detailing \\n\\ncyber events impacting Federal information technology (IT) resources.  The US-CERT mission is, inter alia, to assist \\n\\n− 2 −  \\n\\n                                                 \\n\\x0cFISMA places responsibility on multiple levels of each agency to support government-\\nwide incident identification and reporting.  The creation and maintenance of incident reporting \\nprocesses raise managerial as well as technical issues.  Agency heads, senior program officials, \\nagency CIO’s, Inspectors General, and other security professionals are each part of an \\noverarching and integrated process to define, maintain, continuously improve, and certify \\nincident reporting requirements.  Inherent in this responsibility are requirements to develop \\nincident identification and reporting processes that reflect an understanding of both agency-\\nspecific risks as well as risks that are generated by shared infrastructures and systems.  \\n\\nSignificantly, the Homeland Security Act establishes a primary role for the Department of \\n\\nHomeland Security in coordinating this enterprise solution through crisis management for \\ncyberspace security.  Within DHS, the National Cyber Security Division (NCSD) serves as the \\nFederal government’s cornerstone for cyber security coordination and preparedness.  The \\noperational arm of the NCSD is the United States Computer Emergency Readiness Team (US-\\nCERT), a partnership between NCSD and the public and private sectors that has the \\nresponsibility to: \\n\\n•  Compile and analyze information security incident information; \\n• \\n•  Consult with national security agencies and operators of national security systems to \\n\\nInform agencies about information security threats and vulnerabilities; and \\n\\npromote cyber security best practices and preparedness. \\n\\nAs a central repository of incident information, the US-CERT has a responsibility to \\n\\npresent a single, government-wide focus for monitoring and evaluating risk management and \\nassessment activities based on identified government priorities, functions, and services.  Only \\nthrough an active information exchange on incidents and activities can the government \\nimplement the information security objectives in FISMA.  In summary, US-CERT carries out \\nthese responsibilities by obtaining and analyzing information and data from Federal agencies, \\nand disseminating timely, actionable information based on that analysis.   \\n\\nThe EINSTEIN Program \\n\\nMost of the Federal government’s Internet-based services are provided separately by each \\n\\nagency within individual agency jurisdictional boundaries and in the context of individual \\nagency cultures and unique information systems.  Proper management of cyber risks, however, \\nrequires that Federal civilian agencies work collaboratively on information security issues and \\nchallenges in order to foster situational awareness.  Situational awareness involves the ability to \\nidentify, process, and comprehend the critical elements of information related to an area of \\ninterest -- in this case, cybersecurity.  Building situational awareness to help protect federal \\ninformation systems (and help them protect themselves) and cyberspace, generally, requires \\ninput in the form of information and data from federal agencies.  \\n\\nCurrently, information sharing from Federal agencies to the US-CERT about cyber \\nvulnerabilities and incidents occurs manually and inconsistently.  There are no established \\nprocesses for automating information sharing about cyber incidents; instead, the information \\nexchange that does occur happens primarily after the fact, when multiple systems in the Federal \\n\\nFederal agencies and departments in securing their cyberspace. \\n\\n− 3 −  \\n\\n                                                                                                                                                             \\n\\x0cinfrastructure already may have been affected.  Experience with recent cyber attacks has \\ndemonstrated that effective defenses require accelerated information sharing, analysis, and \\nenhanced response preparation.  \\n\\nThe lack of any meaningful system to test or monitor system activity across all Federal \\nagencies in real-time places individual agency systems and operations at risk.  Because of our \\ncyber interdependence, IT weaknesses associated with any single Federal agency can affect the \\nsecurity of the entire Federal government.  Put another way, our interconnected network of \\ninformation systems has made each agency only as secure as the security of our weakest link.  \\nThis underscores the importance of cross-governmental information security collaboration.  \\nEffective implementation of FISMA requires robust incident identification and reporting across \\nall of the government agencies. \\n\\nUS-CERT has therefore created the EINSTEIN Program to help agencies more \\n\\neffectively protect their systems and networks.  The EINSTEIN Program is an automated process \\nfor collecting, correlating, analyzing, and sharing computer security information across the \\nFederal civilian government so that Federal agencies will be aware, in near real-time, of the \\nthreats to their infrastructure and can act swiftly to take corrective measures.  \\n\\nThe cornerstone of the EINSTEIN Program is the ability to generate and report necessary \\nIT-related information from the Federal agencies in a timely and appropriate manner. Given the \\nrecord of inconsistent and incomplete agency reporting to date, it is essential that agencies \\nrespond to OMB requirements to report to the US-CERT.  Although the incident and security \\ninformation that is currently collected by Federal agencies can provide some value, to truly \\nenhance the security of Federal information systems consistent with FISMA and OMB \\nexpectations, agencies must contribute to a common pool of useful, actionable, situational \\nawareness.  \\n\\nAgency and network administrators will also benefit from services provided by cross-\\nagency and collaborative benefits generated from the EINSTEIN Program.  Ultimately, each \\nagency must undertake responsibility for developing an appropriate risk management and \\nsecurity program at the department or agency level.  Of OMB’s Six Common Security \\nWeaknesses, agency administrators are responsible – at a minimum – for detecting, reporting, \\nand sharing information on vulnerabilities.3     \\n\\nOMB: Six Common Security Weaknesses \\n\\n1.   \\n2.   \\n3.   \\n4.   \\n\\nSenior Management Attention \\nMeasuring Performance \\nSecurity Education & Awareness \\nFunding and Integrating Security into Capital Planning and Investment Control \\n\\n3  \\n\\nThe EINSTEIN Program is structured to support resolution of the six common IT security \\n\\nweaknesses identified by the OMB in multiple ways. This is true of the sixth weakness – detecting, reporting, and \\nsharing network vulnerabilities -- but also other weaknesses.  For example, the automated incident and reporting \\ncapability can also secure contractor operations.  Most importantly, however, the EINSTEIN Program offers, for the \\nfirst time, an ability to measure performance with regard to complex IT security issues.  In the area of privacy \\nprotection, for example, the capability can measure whether and the extent to which sensitive data is being \\nimproperly accessed, secured, or at risk because of other reasons.  \\n\\n− 4 −  \\n\\n                                                 \\n\\x0c5.   \\n6.   \\n\\nEnsuring that Contractor Services are Adequately Secure \\nDetecting, Reporting, and Sharing, Information on Vulnerabilities \\n\\nHowever, the capability provides several additional benefits for system and network \\nadministrators to help address common security weaknesses and promote the cyber security of \\ngovernment systems.  These include each of the following:  \\n\\n•  Worm Detection:  Sharing and collaborating on IT incidents, threat, and vulnerabilities \\nproduces a sophisticated picture of attacks across the Federal .gov domain.  The US-\\nCERT provides this information directly to network administrators for the benefit of \\ndepartment and agency systems protection.    \\n\\n•  Anomalous Activity – In- and out-bound:  Similarly, in culling out certain cross-agency \\nindicia – such as known criminal behavior or traffic that is highly suggestive of criminal \\nbehavior – the capability offers directly to the department and agency administrators an \\neasy to understand picture on priority emergencies and needs.  In the absence of such \\ninformation, administrators must continue to rely on insufficient information to leverage \\nscarce resources and to protect their systems.  \\n\\n•  Configuration Management:  The US-CERT will be able to provide counsel on \\n\\nconfiguration management options.  Configuration challenges are fast becoming one of \\nthe most difficult problems for agency administrators.  The EINSTEIN Program offers \\ninformation and options – based on a collective and collaborative approach.  \\n•  Trends Analysis:  The US-CERT uses the information collected and analyzed to \\n\\ngenerate a cross-governmental trends analysis.  The analysis offers to departments and \\nagencies an accurate and aggregate picture on the health of the Federal.gov domain.  The \\ninformation is offered in real-time, and may include an assessment of anomalous amounts \\nof network traffic across the .gov domain – or, in some cases, within a single agency.  \\nThe data can also offer an aggregate comparison on the health of the Federal .gov domain \\nas compared to the Internet or even portions of the national network.  \\n\\nREASONS FOR INFORMATION COLLECTION \\n\\nOMB requires that Federal civilian agencies report cyber incidents to the US-CERT.  The \\n\\nEINSTEIN Program provides an efficient and cost-effective way to comply with legal \\nrequirements and protect critical systems.  In operating the EINSTEIN Program, the US-CERT \\nwill significantly strengthen the security posture of the federal government.  US-CERT will \\nprovide both technical support and program management. \\n\\nUS-CERT analysis will provide agencies with a better understanding of their current \\nsecurity status as it relates to the overall government security status and the status of Internet \\nsecurity generally.  In addition, agencies will be able to perform analyses that will help to \\nincrease the security and understanding of potential security problems on their networks.  The \\nEINSTEIN Program will help agencies identify baseline network traffic patterns, configuration \\nproblems, unauthorized network traffic, network backdoors, routing anomalies, and network \\nscanning activities.  \\n\\nThe EINSTEIN Program will provide the US-CERT and Federal agencies with a \\n\\ncapability to detect behavioral anomalies within their networks.  By analyzing the data and \\ndetecting these anomalies, the ability to detect new exploits and attacks in cyberspace will be \\n\\n− 5 −  \\n\\n \\n\\x0cgreatly increased.  Enhancing the ability to act swiftly in today’s rapidly changing electronic \\nenvironment is essential to protect government systems.   \\n\\nThe following are examples of the various analytic processes and products that the \\n\\nEINSTEIN Program will produce to protect the participating Federal agencies: \\n\\n•  Determine the scope and impact of any specific worm across the Federal government and \\n\\nhow it relates to the Internet community at large; \\n\\n•  Detect anomalous network behavior or activities against the Federal government and \\ndetermine whether it’s a focused attack or part of a larger Internet-related activity; \\n•  Determine the level of impact and any damage associated with cyber attacks against the \\n\\nFederal government; \\n\\n•  Diagnose specific Federal agency Internet traffic problems as they relate to the much \\n\\nlarger Internet backbone infrastructure; \\n\\n•  Pinpoint the apparent source responsible for any cyber-related attacks; \\n•  Determine the cyber state of the Federal government in near real-time and its interaction \\n\\nwith the global Internet community; \\n\\n•  Compile an overall situational awareness of trends and traffic patterns for all participating \\n\\nFederal agencies; \\n\\n•  Detect early warning and indications of emerging attacks and malicious reconnaissance \\n\\nactivities and adverse impact on Federal government agencies; and \\n\\n•  Correlate system compromises within the Federal government.   \\n\\nWhat Information is to be Collected \\n\\nWhen an individual uses the Internet to browse, read pages, download information or \\n\\notherwise communicate with a Federal “.gov” website, pursuant to Federal law and policy, \\nFederal agencies collect security and network information about these transactions.  In order to \\ncollect this information legally, agencies must post security and privacy policies, which include \\nnotice about: use of cookies; collection of security and automated data; collection of email traffic \\nand information from web forms; and collection of personal identifiers for service delivery \\npurposes.  Additionally, when personally identifiable information is collected, agencies are \\nrequired to conduct privacy impact assessments (“PIA”) analyzing the privacy implications of \\nthe collection.   \\n\\nThe information associated with the collection of security and network information is \\n\\ncreated at the agency level and allows agencies to monitor their own network activity.  The \\nEINSTEIN Program will obtain certain portions of this data -- the portion needed to conduct \\nanalysis of the status of Internet traffic -- in near real time, in order to perform analysis and \\nprovide situational awareness for Federal agencies concerning the state of Internet traffic across \\nthe Federal .gov domain.  The collection will be passive, that is, obtaining the data needed for \\nanalysis will not interfere with the communications to and from agencies.  \\n\\nThe particular data to be collected are strictly limited, and are selected based on criteria \\n\\nfor anomaly detection and other information technology risks.  The data may include: \\n\\n•  Autonomous System Numbers (ASN).  An autonomous system is a group of Internet \\nProtocol (IP) networks that adhere to a single routing policy. An Autonomous System \\n\\n− 6 −  \\n\\n\\x0cNumber (ASN) identifies the autonomous system -- networks using the same, specified \\nrouting policy -- and enables the autonomous system to exchange information with other \\nautonomous systems. \\n\\n• \\n\\nICMP Type/Code.  ICMP (Internet Control Message Protocol) is used to communicate \\ncontrol messages on the Internet between hosts/routers.  ICMP packets can contain \\ndiagnostic (ping, traceroute), error (network/host/port unreachable), information \\n(timestamp, address mask request, etc.), or control (source quench, redirect, etc.) \\nmessages.  Although these messages are generally harmless, there are nevertheless some \\nmessage types that should be dropped. Some ICMP messages can be used to redirect \\ntraffic from a web site.  Other messages can leak information about a host that could be \\nhelpful to an attacker.  ICMP messages are also sometimes used as part of DOS attacks \\n(e.g., flood ping, ping of death). \\n\\n•  Packet Length.  A packet is specially formatted group of bits containing data, IP address, \\nand control information that is transmitted over a network as a collective unit. Messages \\nare usually broken down into a sequence of several transmitted packets that are \\nreconstructed for completeness at their destination. Different systems use packets of \\nvarying sizes, and abnormal or spikes in packet length, especially in light of the protocol \\nbeing used, could be indicia of malicious activity. \\n\\n•  Protocol.  A protocol is a standardized means of communication among machines across \\na network.  Protocols allow data to be taken apart for faster transmission, transmitted, and \\nthen reassembled at the destination in the correct order. The protocol used determines the \\nway errors are checked, the type of compression, the way the sender indicates the end of \\nthe transmission, and the way the receiver indicates that the message has been received. \\nProtocols can describe low-level details of machine-to-machine interfaces (e.g., the order \\nin which bits and bytes are sent across a wire) or high-level exchanges between allocation \\nprograms (e.g., the way in which two programs transfer a file across the Internet).  \\n\\n•  Sensor identification and connection status.  Sensor identification is the description of \\n\\nwhere the sensor is located so it is clear which network/system/agency the data is coming \\nfrom.  Connection status is simply whether or not the system is receiving information \\n\\n•  Source and Destination IP Address.  Internet Protocol (IP) addresses are four octet (32-bit) \\n\\nsource or destination addresses that uniquely identify computers either on a given \\nnetwork or on the Internet.  Source identifies the device sending the packet; destination \\nidentifies the intended recipient. \\n\\n•  Source and Destination Port.  In the networking world, the term ‘port’ is a number that \\nidentifies the beginning or endpoint of a logical connection.  This number that is part of \\nthe URL (Internet address) right after the domain name.  Every Internet protocol has a \\ndedicated port -- for instance, file transfer protocol services channel information on port \\n21, HTTP services use port 80 and POP (or POP3) services use port 110.  Internet \\nprotocols appearing on an unusual port number may be indicia of malicious activity. \\n\\n•  TCP flag information.  Simply stated, a TCP flag is a piece of information that is added \\nto packets traveling between computers that describes the status of the connection \\n\\n− 7 −  \\n\\n\\x0cbetween the computers.  These ‘flags’ are very specific information, and any abnormality \\nin the way they appear or are paired could be indicia of malicious activity.4   \\n\\n•  Timestamp and duration information.  A time that is printed to a file (such as email) or \\nother location to help keep track of when data is added, removed, sent, received, etc. \\n\\nThe Intended Use of the Information \\n\\nThe information to be collected by the EINSTEIN Program will be used to provide the \\n\\nUS-CERT and Federal agencies with the capability to detect and correlate anomalies across \\nagency networks.  These anomalies include configuration problems, unauthorized network \\ntraffic, network backdoors, routing anomalies, network scanning activities, and baseline network \\ntraffic patterns.   \\n\\nThe process is as follows: \\n\\nFirst, Federal civilian agencies will collect subject data.  Each agency will transmit to a \\n\\nsecure US-CERT facility only that data that meet the criteria for anomaly detection and other IT \\nrisks.  The US-CERT has structured the program to limit the amount of data collected.   \\n\\nSecond, the US-CERT will then analyze data submissions.  Analysts are trained to \\n\\nidentify anomalous activity and will strictly focus only on such activities.  \\n\\nThird, where there are suspicious anomalies or other aberrations, the US-CERT analysts \\n\\nwill collaborate with agency partners to examine more carefully additional network activity \\nassociated directly with such activities.   \\n\\nFourth, in addition to providing information about potential anomalies and other \\naberrations, EINSTEIN will also be able to offer agencies counsel on configuration management \\noptions.  The EINSTEIN Program will offer information and options based on a collective and \\ncollaborative approach.  \\n\\nSituational information generated as a result of EINSTEIN will also allow the US-CERT \\n\\nto generate a cross-governmental trends analysis.  The analysis will provide departments and \\nagencies with an accurate and aggregate picture of the health of the Federal .gov domain in real-\\ntime, and an aggregate comparison of the health of the Federal .gov domain as compared to the \\nInternet.  \\n\\nWith Whom Will the Information Be Shared \\n\\nThe data generated by, and required to operate the EINSTEIN Program, will be shared \\n\\nbetween US-CERT and participating Federal agencies.  The program is structured so that data is \\nshared in increments.  Certain categories of data, as explained above, will be collected.  If \\nanomalous activities are uncovered by the EINSTEIN Program, US-CERT will ask for additional \\ninformation in order to ascertain the cause of the anomaly.  Upon US-CERT’s completion of an \\nanalysis of the necessary data, the results will be shared with a particular Federal agency or \\n\\n4  \\n\\nTransmission Control Protocol is a set of rules that govern how computers ‘communicate’ with \\n\\none another and how information is organize and sent between computers over the Internet.   \\n\\n− 8 −  \\n\\n                                                 \\n\\x0cagencies.  Upon receipt of these anomaly reports, it will be up to each agency, consistent with its \\nown information sharing practices, to decide if and how to act on the information.  US-CERT \\nwill not share information obtained through the EINSTEIN Program beyond its agency partners, \\nexcept to the extent that such information can be generalized as part of the alerts and warnings \\nthat are central to the US-CERT mission. \\n\\nNotice and Consent \\n\\nWhen personally identifiable information is collected by a Federal agency, that agency \\n\\nmust comply with all relevant statutory and regulatory requirements relating to privacy \\nprotections.   As an example, Federal agencies must post notices on their websites as well as at \\nother major points of entry that computer security information is being collected.  Such notices \\ncover automated data collection, security and intrusion detection, and information collected from \\ne-mails.  Additionally, each Federal agency must publish PIAs covering personally identifiable \\ndata that may be collected.   \\n\\nThe EINSTEIN Program does not in any way supersede or replace the privacy \\nrequirements in place for participating Federal agencies, based on information collected in the \\nnormal course of conducting operations.  Although OMB enforces these privacy requirements, \\nthe US-CERT will be available to assist participating agencies in ensuring compliance.   \\n\\nEnsuring the Security of the Information  \\n\\nThe US-CERT has structured the EINSTEIN Program to allow for an increase in the \\n\\nspeed and quality of alerts and reports about the health of, and threats to, the Federal .gov \\ndomain to facilitate compliance with security requirements.  The limited information sent to the \\nUS-CERT will be sent using a secured protocol (e.g., secure socket shell).   \\n\\nAccess to the data is strictly limited to users on a need-to-know basis.  The records will \\n\\nbe maintained in an area subject to general building security, including physical and \\nadministrative safeguards.  Any paper records and electronic records on CD-ROMS and floppy \\ndiscs are stored in lockable metal cabinets in rooms locked during non-duty hours.  The records \\nstored in electronic media (electronic databases or CD-ROMS and floppy discs) are password \\nprotected.  A schedule regarding the types of records to be stored, as well as the length that such \\nrecords will be retained, is currently being prepared.   \\n\\nCreation of a Privacy Act System of Records \\n\\nUS-CERT has not prepared a system of records notice for the EINSTEIN Program \\n\\nbecause the program is not intended to collect information that will be retrieved by name or \\npersonal identifier.  The primary focus of the program is at the network level.  Accordingly, a \\nsystem of records is not being created.  \\n\\nConclusion \\n\\nOne of the main goals of the EINSTEIN Program is to improve the quality, quantity, and \\nspeed of sharing information.  By participating in the EINSTEIN Program, Federal agencies will \\nbenefit by raising the cyber situational awareness for their individual agency, help meet their \\nstatutory requirements concerning information security, and contribute to the overall effort to \\n\\n− 9 −  \\n\\n\\x0cbuild the government cyber situational awareness.  In addition, agency participation assists US-\\nCERT in determining the best ways to help agencies protect themselves, and contributes to the \\nability of US-CERT to provide timely alert and warning information to government and the \\nprivate sector. \\n\\nFederal agency participation is paramount to the overarching situational awareness \\n\\ncapabilities the EINSTEIN Program can offer and its collaborative benefits.  The use of this \\nautomated analysis capability by the Federal civilian agencies represents one way that the US-\\nCERT is leveraging current operational technology to significantly increase the overall \\nsituational awareness of our Nation’s Cyberspace, as well as the Internet community at large.   \\n\\n* \\n\\n* \\n\\n* \\n\\nContact information:  Questions or comments about this PIA should be directed to Thomas \\nDukes, Office of the General Counsel, DHS, Thomas.Dukes@dhs.gov, Nuala O’Connor Kelly, \\nChief Privacy Officer, Department of Homeland Security, nuala.kelly@dhs.gov. or Andy Purdy, \\nPrivacy Officer, NCSD, andy.purdy@dhs.gov. \\n\\n− 10 −  \\n\\n \\n \\n \\n \\n \\n \\n \\n\\x0c', '5/2/22, 11:27 PM Health Care Cybersecurity Challenges and Solutions Under the Climate of COVID-19: Scoping Review - PMC\\nhttps://www-ncbi-nlm-nih-gov.ezproxy.lib.ryerson.ca/pmc/articles/PMC8059789/?report=printable 1/28\\nJ Med Internet Res. 2021 Apr; 23(4): e21747.\\nPublished online 2021 Apr 20. doi: 10.2196/21747: 10.2196/21747\\nHealth Care Cybersecurity Challenges and Solutions Under the Climate of COVID-19: Scoping Review\\nMonitoring Editor: Corey Basch\\nReviewed by Clemens Kruse and Andelka Phillips\\nYing He, PhD, Aliyu Aliyu, MSc, Mark Evans, PhD, and Cunjin Luo, PhD\\nSchool of Computer Science, University of Nottingham, Nottingham, United Kingdom,\\nSchool of Computer Science and Informatics, De Montfort University, Leicester, United Kingdom,\\nSchool of Computer Science and Electronic Engineering, University of Essex, Colchester, United Kingdom,\\nKey Lab of Medical Electrophysiology, Ministry of Education, Institute of Cardiovascular Research, Southwest Medical University, Luzhou, China,\\nCunjin Luo, School of Computer Science and Electronic Engineering, University of Essex, Wivenhoe Park, Colchester, CO4 3SQ, United Kingdom, Phone: 44 7493622995,\\nEmail: cunjin.luo@essex.ac.uk.\\nCorresponding author.\\nCorresponding Author: Cunjin Luo cunjin.luo@essex.ac.uk\\nReceived 2020 Jun 23; Revisions requested 2020 Nov 17; Revised 2020 Dec 8; Accepted 2021 Feb 21.\\nCopyright ©Ying He, Aliyu Aliyu, Mark Evans, Cunjin Luo. Originally published in the Journal of Medical Internet Research (https://www.jmir.org), 20.04.2021.\\nThis is an open-access article distributed under the terms of the Creative Commons Attribution License (https://creativecommons.org/licenses/by/4.0/), which permits unrestricted\\nuse, distribution, and reproduction in any medium, provided the original work, first published in the Journal of Medical Internet Research, is properly cited. The complete\\nbibliographic information, a link to the original publication on http://www.jmir.org/, as well as this copyright and license information must be included.\\nAbstract\\nBackground\\n1 2 2 3,4\\n1\\n2\\n3\\n4\\n5/2/22, 11:27 PM Health Care Cybersecurity Challenges and Solutions Under the Climate of COVID-19: Scoping Review - PMC\\nhttps://www-ncbi-nlm-nih-gov.ezproxy.lib.ryerson.ca/pmc/articles/PMC8059789/?report=printable 2/28\\nCOVID-19 has challenged the resilience of the health care information system, which has affected our ability to achieve the global goal of health and\\nwell-being. The pandemic has resulted in a number of recent cyberattacks on hospitals, pharmaceutical companies, the US Department of Health\\nand Human Services, the World Health Organization and its partners, and others.\\nObjective\\nThe aim of this review was to identify key cybersecurity challenges, solutions adapted by the health sector, and areas of improvement needed to\\ncounteract the recent increases in cyberattacks (eg, phishing campaigns and ransomware attacks), which have been used by attackers to exploit\\nvulnerabilities in technology and people introduced through changes to working practices in response to the COVID-19 pandemic.\\nMethods\\nA scoping review was conducted by searching two major scientific databases (PubMed and Scopus) using the search formula “(covid OR healthcare)\\nAND cybersecurity.” Reports, news articles, and industry white papers were also included if they were related directly to previously published\\nworks, or if they were the only available sources at the time of writing. Only articles in English published in the last decade were included (ie, 2011-\\n2020) in order to focus on current issues, challenges, and solutions.\\nResults\\nWe identified 9 main challenges in cybersecurity, 11 key solutions that health care organizations adapted to address these challenges, and 4 key ar‐\\neas that need to be strengthened in terms of cybersecurity capacity in the health sector. We also found that the most prominent and significant\\nmethods of cyberattacks that occurred during the pandemic were related to phishing, ransomware, distributed denial-of-service attacks, and\\nmalware.\\nConclusions\\nThis scoping review identified the most impactful methods of cyberattacks that targeted the health sector during the COVID-19 pandemic, as well\\nas the challenges in cybersecurity, solutions, and areas in need of improvement. We provided useful insights to the health sector on cybersecurity\\nissues during the COVID-19 pandemic as well as other epidemics or pandemics that may materialize in the future.\\nKeywords: health care, security incidents, root causes, cybersecurity challenges, cybersecurity solutions, COVID-19, pandemics\\nIntroduction\\n5/2/22, 11:27 PM Health Care Cybersecurity Challenges and Solutions Under the Climate of COVID-19: Scoping Review - PMC\\nhttps://www-ncbi-nlm-nih-gov.ezproxy.lib.ryerson.ca/pmc/articles/PMC8059789/?report=printable 3/28\\nBackground\\nCOVID-19 has been an unprecedented challenge for the global health care system. It has further challenged the resilience of the health information\\nsystem, which has affected our ability to achieve the global goal of health and well-being. The sector has become a primary target of adapted cyber‐\\nsecurity attacks [1,2]. To manage the pandemic and this extraordinary situation, the health sector has shifted its focus from the security of their sys‐\\ntems and practices to their primary duty of delivering health care in order to save lives, placing themselves in a vulnerable situation. Attackers are\\ntaking advantage of the COVID-19 pandemic and have launched a number of cyberattacks against health care organizations [3-8]. Recent cyberat‐\\ntacks have impacted health care organizations such as Brno University Hospital [3], the US Department of Health and Human Services [4], the\\nWorld Health Organization (WHO) [5], Gilead Sciences, Inc [6], hospitals in Romania [7], as well as the general supply chain of the health sector [8].\\nThe health sector must be prepared to counteract cyberattacks in order to protect the availability of essential health care services as well as the\\nconfidentiality and integrity of health care information.\\nCybercrime adapts to changes in the world situation very quickly. At the beginning of an escalation in the COVID-19 pandemic, malware cyberat‐\\ntackers identified common vulnerabilities and adapted their attacks to exploit these vulnerabilities. The current situation in the United Kingdom\\nand worldwide provides a fertile breeding ground for various cyberattacks [9]. Cyberattackers are leveraging the increased reliance on remote\\nworking, decreased mobility, and the closure of borders between different countries, and the heightened demand for personal protective equipment\\n(PPE) such as masks and gloves. The complex health care supply chain is also a target [10]. As a result, greater fear, uncertainty, and doubt is being\\nexperienced by the general population.\\nRationale\\nThere is some research reviewing the literature on cybersecurity in the health sector. Jalali et al [11] performed a systematic review of the literature\\non cybersecurity response plans in health care. Coventry et al [12] conducted a narrative review on trends in cyber threats and ways forward in the\\nhealth sector. Kruse et al [13] systematically reviewed health care–related cyber threats and trends. Offner et al [14] reviewed cyber threats and\\nmitigation strategies among Australian health care organizations. Sardi et al [15] performed a systematic review of cyber risk in health facilities.\\nHowever, there is limited research on an in-depth review and analysis of key cybersecurity challenges and solutions, specifically in the health sector,\\nin the context of a pandemic situation such as COVID-19.\\nObjective\\nThrough a scoping review, this paper aims to identify the most prominent and significant methods of attack and threats that have affected the\\nhealth sector during the COVID-19 pandemic, cybersecurity challenges, solutions, and areas that require further improvement. This research covers\\nnot only security-related matters as a result of the COVID-19 pandemic but also discusses inherent security challenges in health information sys‐\\ntems that can be potentially exploited by attackers during the COVID-19 pandemic. It has implications for the whole spectrum of the health sector\\nas a result of the increase in cybersecurity risks such as phishing, ransomware, and distributed denial-of-service (DDoS) attacks during the coron‐\\navirus crisis and in the long term.\\n5/2/22, 11:27 PM Health Care Cybersecurity Challenges and Solutions Under the Climate of COVID-19: Scoping Review - PMC\\nhttps://www-ncbi-nlm-nih-gov.ezproxy.lib.ryerson.ca/pmc/articles/PMC8059789/?report=printable 4/28\\nMethods\\nProtocol andRegistration\\nThe review was performed according to the PRISMA-ScR (Preferred Reporting Items for Systematic Reviews and Meta-Analyses Extension for\\nScoping Reviews) checklist, proposed by the Joanna Briggs Institute [16]. The aim of this review is to identify health sector cyberattacks, security\\nchallenges, and solutions. Before undertaking this review, a protocol was created detailing sources of information, search strategies, eligibility crite‐\\nria, source selection, and data charting processes. The PRISMA-ScR checklist is presented in Multimedia Appendix 1.\\nInformationSources\\nA search of two major scientific databases (PubMed and Scopus) was performed to identify relevant articles. These include both original research\\narticles and review articles.\\nSearch\\nThe search formula “(covid OR healthcare) AND cybersecurity” was used to search for articles. The articles identified should have either a COVID\\x02cybersecurity core or a healthcare–cybersecurity core.\\nEligibility Criteria\\nOnly articles in English published in the last decade were included (ie, 2011-2020) in order to focus on current issues, challenges, and solutions.\\nReports, news articles, or websites were also included only when they are related directly to previously published work, or they were the only cur‐\\nrently available information source at the time of manuscript preparation. Inclusion criteria were as follows: (1) relevance to health care cybersecu‐\\nrity and (2) coverage of well-discussed cybersecurity issues, challenges, and solutions.\\nSelectionof Sources of Evidence\\nThe selection process is illustrated in Figure 1. The results of the search were exported to the EndNote library. The title and abstract of each paper\\nwere analyzed by 2 of the authors to assess eligibility. In cases in which this was not obvious, all 4 authors examined the paper and, when necessary,\\nread it to assess relevance. A total of 307 identified papers were screened and 53 duplicates were removed. An additional 57 papers were excluded\\nfor not focusing on the healthcare–cybersecurity core or the COVID-cybersecurity core in the abstract. Another 197 papers were excluded for lack‐\\ning these cores in the full text. In total, 56 papers were included in the review.\\n5/2/22, 11:27 PM Health Care Cybersecurity Challenges and Solutions Under the Climate of COVID-19: Scoping Review - PMC\\nhttps://www-ncbi-nlm-nih-gov.ezproxy.lib.ryerson.ca/pmc/articles/PMC8059789/?report=printable 5/28\\nDataChartingProcess\\nThe data were extracted and stored in a standardized Microsoft Excel (Microsoft Corp) form. This was an iterative process whereby the charting ta‐\\nble is continually updated. Data charting was carried out both independently and collectively by at least two authors to ensure the quality of the ex‐\\ntracted key findings from the literature before being used in the analysis.\\nData Items\\nKey data items, including title, abstract, authorship, aims, key findings related to the review objectives, evidence document, document type, year of\\npublication, and location, were extracted.\\nCritical Appraisal WithinSources of Evidence\\nAlthough the Joanna Briggs Institute suggests that the critical appraisal is usually not needed for a scoping review, we had at least 2 authors check\\nthe quality of the source of evidence to ensure they were relevant, up to date, and from reputable sources. In cases in which this was not obvious, all\\n4 authors assessed the sources.\\nSynthesis of Results\\nBy aggregating information from the selected literature, the results were analyzed and qualitatively presented in both tabular and descriptive for‐\\nmats (grouped into themes), which aligned with the objective and scope of the review.\\nResults\\nFour themes were observed across the selected literature: (1) health sector condition changes due to COVID-19, (2) health care cyberattacks during\\nthe COVID-19 pandemic, (3) health care cybersecurity challenges, and (4) health care cybersecurity controls.\\nHealth Sector ConditionChangesDue to COVID-19\\nThe findings pertaining to changes in conditions in the health sector as a result of COVID-19 are summarized in Table 1. The main changes to health\\nservices caused by the COVID-19 pandemic include decreased mobility, border closures, and the increasing reliance on remote work, often carried\\nout with little previous experience and planning. These conditions have made the health sector more vulnerable to potential cyberattacks [1,2,17].\\n5/2/22, 11:27 PM Health Care Cybersecurity Challenges and Solutions Under the Climate of COVID-19: Scoping Review - PMC\\nhttps://www-ncbi-nlm-nih-gov.ezproxy.lib.ryerson.ca/pmc/articles/PMC8059789/?report=printable 6/28\\nAs health staff and patients are restricted in terms of movement due to the lockdown, the decrease in mobility and border closures make individu‐\\nals and organizations turn to technology to provide essential health services such as appointments, diagnosis, and even operations. Examples are\\nthe use of eConsultation (electronic consultation) services for patients and electronic multidisciplinary teams. Although these technologies have\\ntheir advantages, they leave users and receivers of these technologies open to a variety of attacks such as phishing campaigns and ransomware at‐\\ntacks [18].\\nFurthermore, health services staff often have limited previous experience with remote working and with planning for this change, which leaves the\\nsector vulnerable to cyberattacks [9,14,19]. As health services make use of a variety of medical devices, interconnectivity and interoperability cre‐\\nate issues as they are now being accessed from outside health services’ internal network perimeter. The medium and mode of access creates prob‐\\nlems as access to the sensitive parts of health services can be reached via unsecured network connections or unpatched systems by staff working\\nremotely [19]. In addition, some medical devices use off-the-shelf software, such as commercial operating systems (eg, older versions of Windows).\\nThese systems are vulnerable to a large variety of threats such as malware, ransomware, etc [20,21]. Overall, the health care industry significantly\\nlags behind other industries in terms of cybersecurity and coupled with a lack of digital literacy among staff mostly working from home, makes it a\\nprominent target [15,22].\\nAdditionally, the increase in demand for certain goods such as PPE and other protective merchandise such as masks, gloves, etc, are exposing health\\nservices and even governments to digital scams, especially in the form of phishing attacks. As health services are in need of these essential items,\\nthey can be targeted by adversaries via luring emails with the intention of stealing sensitive information [17].\\nHealth Care CyberAttacksDuring the COVID-19Pandemic\\nMultiple cyberattacks occurred at the beginning of the global COVID-19 pandemic (early 2020) in the health sector. We selected well-documented\\ncyberattacks with detailed information available, including root causes and consequences. The main findings are summarized in Table 2.\\nBrno University Hospital in the Czech Republic, which is one of the country’s main COVID-19 testing centers, was struck by ransomware, resulting\\nin the postponement of surgeries. The ransomware infection was confirmed in the early hours of the day when the hospital decided to disconnect\\nall computer networks. It was noticed that the ransomware infection was gradually replicating, and all the individual systems were failing. As a re‐\\nsult, all computers had to be shut down. The hospital is reported to be still recovering capabilities, as it is not yet fully operational due to the attack\\n[3]. The attack had an impact on the activities of the hospital as there was no database systems, that is, means of storing data; hence, staff have had\\nto write and transfer their notes manually. This leads to slow processes and can potentially endanger lives in these trying times.\\nThe US Department of Health and Human Services experienced a DDoS attack intended to disrupt the organization’s responses to the COVID-19\\npandemic. This attack targeted its servers by overloading it with millions of hits over several hours [4]. It was reported as a campaign of disruption\\naimed at hindering the response to the coronavirus pandemic as the targeted agency was tasked with protecting the health of citizens and deliver‐\\ning essential human services. Although the agency claimed the attack was not successful, and that the attackers did not infiltrate the internal net‐\\nwork nor steal any data, this demonstrates that attacks like these can cause damage not just to the services of health agencies but also to the lives\\nthat depend on it, especially in times of emergencies.\\n5/2/22, 11:27 PM Health Care Cybersecurity Challenges and Solutions Under the Climate of COVID-19: Scoping Review - PMC\\nhttps://www-ncbi-nlm-nih-gov.ezproxy.lib.ryerson.ca/pmc/articles/PMC8059789/?report=printable 7/28\\nIncreased phishing website hacking attempts on the WHO and its partners led to the WHO putting out a warning to the general public to be more\\ncareful [5], as it has been reported that over 4000 coronavirus-related domains (ie, domains that contain words like “corona” or “covid”) have been\\nregistered since the beginning of 2020. These registered domains were used by adversaries for phishing-related activities. Thus, the WHO incident\\nwas orchestrated by hackers in order to steal passwords. It was reported that a group of hackers created a malicious website posing as an email lo‐\\ngin portal for WHO employees in an attempt to steal their passwords. Although the WHO claims the attack was not successful, it still shows that\\nphishing attacks can be leveraged to target health organizations.\\nCoronavirus vaccine manufacturer Gilead Sciences, Inc, was also targeted by hackers [6]. Staff at this pharmaceutical company were targeted via a\\nfake email login page that was designed to steal passwords. It was reported that the attack was an attempt to compromise the email accounts of\\nstaff at the company using messages that impersonated journalists.\\nHospitals in Romania experienced ransomware attacks by hackers as well [7]. The hackers were planning to use COVID-19–themed emails to infect\\nthese hospitals with ransomware. Their motivation was the protest against the COVID-19 quarantine measures of the country. The hackers owned\\nmalwares (eg, remote access trojans, ransomware, website defacements, and SQL injection tools) that can be used to bring down servers and steal\\ninformation. It was reported that they intended to send emails about COVID-19 to hospitals to infect computers, encrypt files, and disrupt hospital\\nactivities. However, the attack was not as successful as the hackers were tracked down and arrested by Romanian law enforcement.\\nIt has been reported that Interpol has cautioned agencies around the world about a significant rise in the global number of ransomware attacks ex‐\\nplicitly targeting hospitals and health institutions [8]. It discovered that there was an increase in the number of attempted ransomware attacks on\\norganizations in the 194 member countries. Additionally, a cyber warning was issued for key health care organizations involved in the coronavirus\\nresponse both in the United Kingdom and the United States. A joint statement by the United Kingdom’s National Cyber Security Centre (NCSC) and\\nUS Cybersecurity and Infrastructure Security Agency revealed that malicious cyber campaigns had been uncovered, with large-scale “password\\nspraying” campaigns directed at health care bodies and medical research organizations in both nations [23].\\nHealth care supply chains have not been omitted from these attacks; the US Federal Bureau of Investigation (FBI) issued a warning about a malware\\ntargeting this sector. The malware is called Kwampirs, a remote access Trojan that exploits network vulnerabilities of targeted organizations across\\nthe United States, Europe, Asia, and the Middle East [24]. The infected supply chain components included cyber-physical systems assets in health\\ncare organizations. The FBI alerted the health care sector against future cyberattacks, as Kwampirs have been historically targeting health care\\norganizations.\\nThe analysis of the above-mentioned incidents indicate that the health sector has become a primary target of cybersecurity attacks. Attackers are\\ntaking advantage of the COVID-19 pandemic and launching attacks, which are mainly ransomware, DDoS, phishing, and other type of malwares. The\\nhealth care supply chain can be more vulnerable to cyberattacks especially during pandemics. The cyberattacks have resulted in negative impacts\\non the availability of essential health care services and challenged health care organizations in the protection of the confidentiality and integrity of\\nhealth care information.\\nHealth Care Cybersecurity Challenges\\n5/2/22, 11:27 PM Health Care Cybersecurity Challenges and Solutions Under the Climate of COVID-19: Scoping Review - PMC\\nhttps://www-ncbi-nlm-nih-gov.ezproxy.lib.ryerson.ca/pmc/articles/PMC8059789/?report=printable 8/28\\nSelected papers discussing the main challenges of cybersecurity in the health sector were reviewed, and the main findings are summarized in\\nTable 3.\\nThe analysis shows that the main cybersecurity challenges of the health sector are remote work security assurance, endpoint device management,\\nhuman errors, the lack of security awareness, inadequate senior-level security risk assessment, inadequate business continuity plans, the lack of\\ncoordinated incident response, constrains on budget and resources, and vulnerability of medical systems. These challenges cover not only the secu‐\\nrity-related matters as a result of the COVID-19 pandemic but also the inherent security challenges in the health sector that can be potentially ex‐\\nploited by attackers during the COVID-19 pandemic. It is imperative for the health care organizations to identify these challenges and take actions\\nfor prevention.\\nRemote Working Security Assurance As remote working is now an integral element of health care service delivery, health staff are relying on enter‐\\nprise remote desktop protocols and virtual private networks (VPN) to access internal networks. However, these come with certain risks that adver‐\\nsaries are looking to exploit. For example, the remote desktop protocol has a history of security issues and generally should not be publicly accessi‐\\nble without additional protections such as firewall, whitelist, and multifactor authentication [10]. Likewise, VPNs also have some known and un‐\\nknown vulnerabilities, both on the client and server side, which have been exploited for years by cybercriminals [19]. The DDoS attacks on health\\ncare systems [14] and the innumerable wireless connected devices [9] have created further challenges to a remote work environment.\\nEndpoint Device Management A number of endpoint devices, which comprises various patient-monitoring equipment that either connects to the\\ninternet or legacy-dispersed networks, are often unpatched [12]. This risk further increased during the pandemic as a result of organizations com‐\\npeting to procure internet of things (IoT) devices during the COVID-19 pandemic for their staff, which resulted in more employees than before us‐\\ning personal devices to perform work from home. From an enterprise architecture perspective, having tighter integration across the information\\ntechnology (IT) environment is positive in terms of the organization being more agile; however, it makes the network vulnerable to cyberattacks\\nsuch as email phishing, ransomware, DDoS, and network data breaches [13]. The integration of new endpoint devices with outdated legacy systems\\ncan increase vulnerabilities [13,25]. However, organizations overly rely on perimeter defense (antivirus, firewalls) and other forms of basic protec‐\\ntion against cyberattacks [26]. By interviewing 19 C-Suite cybersecurity professionals, Jalali et al [27] also confirmed the factor that most influences\\ncybersecurity in a hospital setting is endpoint complexity.\\nHuman Factors in Cybersecurity Existing research has shown that the majority of information security incidents are related to human error [28].\\nThere is a tendency for human error when staff are busy focusing on saving lives and adjusting to new work environments and technologies. With\\nsudden changes in working practices, being under stress for an extended period of time makes employees vulnerable to falling into malicious trick‐\\nery and making mistakes [28]. According to Jalali at al [19], there is a statistically significant positive correlation between workload and the proba‐\\nbility of a health care staff opening a phishing email. Naidoo et al [25] developed a multilevel influence model to explore how cybercriminals ex‐\\nploited the COVID-19 pandemic using social engineering techniques. However, the health sector lacks root cause analysis [28] to prevent human er‐\\nror related security incidents, especially those through unintentional human error [29]. Although some efforts have been made in applying the hu‐\\nman reliability analysis technique in the context of information security (eg, Information Security Core Human Error Causes [IS-CHEC] [30]) to ana‐\\nlyze human error, such approaches have not been widely adopted.\\n5/2/22, 11:27 PM Health Care Cybersecurity Challenges and Solutions Under the Climate of COVID-19: Scoping Review - PMC\\nhttps://www-ncbi-nlm-nih-gov.ezproxy.lib.ryerson.ca/pmc/articles/PMC8059789/?report=printable 9/28\\nLack of Security Awareness Cybercriminals are exploiting people’s anxieties during the COVID-19 pandemic. Gordon et al [31] identified that there\\nis low awareness in the health sector of risks. Furnell et al [32] identified that the most common action taken in response to the most disruptive\\nbreaches or attacks is additional staff training or communication. Coventry et al [33] reported that health staff had poor awareness of the conse‐\\nquences of certain behaviors, and there is a lack of policies and reinforcement of secure behavior. However, increased cybersecurity awareness is\\nrequired for the health sector to protect themselves and their patients from potential cyber threats such as phishing and ransomware. Due to the\\nlack of prior planning and training to work under pandemic situations, health care staff require more training and support, such as pandemic-spe‐\\ncific cybersecurity training campaigns, documented procedures, and guidance on revised procedures and technologies [34]. For example, health\\nsector staff should be made aware of and able to flag phishing emails containing buzzwords during a pandemic, such as “WHO” or “donation.” They\\nshould also be advised on how to validate trustworthy information sources in order to avoid ransomware attacks [1].\\nInadequate Board-Level Risk Assessment Communication There is a lack of understanding of security risks and its impact on organization-wide risk\\nmanagement, such as impacts on patient care and clinical outcomes [36]. The health sector lacks a matrix that can translate the strategic improve‐\\nment needs of a health care system into prioritized information/cyber improvement needs [35]. Schwartz et al [37] identified that there is a lack of\\nappreciation among health care executive management staff of the business risk impacts of cyber breaches.\\nInadequate Business Continuity Plans The health sector does not have enough data protection mechanisms; Walker-Roberts et al [42] confirmed\\nthat the health sector lacks sophisticated data security tools compared to other industries. Security is not built into its supply-chain and third-party\\nvendors. Existing research shows that the key security risks challenging business continuity are vendor dependence, inappropriate encryption con‐\\nfigurations, and the inability to handle health information sharing and exchange with third-party and cross-border partners [38-41]. Risks will con‐\\ntinue to grow if cybersecurity is not integrated into the project life cycle from the beginning [12]. Cybersecurity capability is a strategic asset that\\nevery health organization must adopt, along with the concepts of building organizational resilience and the capacity to recover from incidents and\\nlearn from mistakes in order to maintain business continuity [11].\\nLack of Coordinated Incident Response Involving Different Parties As highlighted by Coventry and Branley [12], the health care sector has a exhib‐\\nited a trend of having a time lag between the occurrence of an attack and its detection. In fact, this aids attackers by giving them more time to ex‐\\nplore the network and conduct lateral movement, which increases the damage inflicted by security breaches. Current health care cyber defense re‐\\nsponse is often reactive and undertaken after malicious attacks [43], lacking a coordinated incident response capacity to counteract constantly\\nemerging and evolving malware threats [44]. The failure of health care organizations in having a successful and secure backup mechanism in place\\nmakes it frail in terms of incident response and recovery [12]. Pullin et al [45] also confirmed that cybersecurity should be a team effort, with ev‐\\neryone from board members to front-line employees being held accountable for cybersecurity.\\nLimited Budget and the Need to Deliver Health Care Services Without Disruption Although health care services are spending funds to become more\\nintegrated to deliver health care services without disruption [9], the necessary emphasis is not given to the security aspect in terms of upkeep (eg,\\nkeeping software updated and systems secure). However, this is reported to be due to a shortage in experienced cybersecurity experts within health\\ncare organizations with the required skills and experience to enable health care organizations to change their business operations at significant\\npace without undertaking the “usual” levels of cybersecurity assurance [46]. Boddy et al [9] identified the needs of a value-based system to weigh\\nand balance the benefits and risks in aspects of security, privacy, and adoption of technology.\\n5/2/22, 11:27 PM Health Care Cybersecurity Challenges and Solutions Under the Climate of COVID-19: Scoping Review - PMC\\nhttps://www-ncbi-nlm-nih-gov.ezproxy.lib.ryerson.ca/pmc/articles/PMC8059789/?report=printable 10/28\\nVulnerable Medical Cyber-Physical Systems Cybersecurity measures such as vulnerability scans or patch management are often not available or\\nonly possible by manufacturers [49]. Their basic limited capability makes them vulnerable to compromise [47]. Cybersecurity measures such as\\nvulnerability scans or patch management are often not available or only accessible for manufacturers. Moreover, their connection and reliance upon\\nthe health care network significantly increase the cybersecurity risk to the entire health care system [48]. With the widespread use of IoT medical\\ndevices, cyber threats can be introduced to medical cyber-physical systems though vulnerable IoT devices [44].\\nHealth Care Cybersecurity Controls\\nSelected papers discussing cybersecurity solutions present within the health sector were reviewed, and the main findings are summarized in\\nTable 4.\\nApply Endpoint Device Protection During the COVID-19 pandemic, health staff working from home may adopt telehealth technologies or IoT de‐\\nvices. This increases cybersecurity risks, as it expands the footprint for cyberattack to the use of new devices outside of the service providers’ net‐\\nwork [50]. Health staff are advised to restrict the technologies and devices they used to remain compliant with security regulations such as Health\\nInsurance Portability and Accountability Act during the pandemics [20]. However, health care organizations mainly reply on perimeter defense (eg,\\nantivirus, firewalls) for protection against the potential cyberattacks [26]. The National Institute of Standards and Technology (NIST) has recently\\nreleased a draft security guide and recommendations for managing the security IoT devices, but it is unclear whether it will be enforced across the\\nhealth sector [50].\\nSecure Remote Work Environment Existing solutions include the use of multifactor authentication and the monitoring of the log activity of user ac‐\\ncounts and revoking account access if no longer needed [10]. Deebak et al [51] proposed a chaotic map–based authenticated security framework\\nfor remote point of care. Health organizations such as those in the United Kingdom have started using services to monitor their remote access infra‐\\nstructure constantly and to investigate anomalies. For example, the National Health Service (NHS) has employed attack surface reduction rules (eg,\\nblock macros, executable content, process creation) [52]. Furthermore, a more recent NHS Digital service, Secure Boundary, was introduced as a\\nperimeter security solution to enable secure access for NHS staff and to provide security monitoring [53].\\nRaise Security Awareness Health care organizations already have cybersecurity programs in place to increase levels of security awareness [45,55].\\nExisting solutions include the use of cybersecurity training programs and cybersecurity awareness campaigns [56]. In a cybersecurity campaign,\\nthe IT department sends out fake phishing emails to their staff and provides further training to those who fail to identify these emails [56]. In the\\nUnited Kingdom, more than 100 NHS boards have completed cybersecurity training accredited by the Government Communications Headquarters\\nsince the WannaCry attack. Furthermore, the NCSC’s Board Toolkit for the NHS provides additional information on ransomware and backups. NHS\\nDigital also runs a cyber awareness campaign called the Keep I.T. Confidential campaign. Over 340 organizations have downloaded the materials\\nsince its launch in September 2019 [57]. However, there is not enough work on training programs tailored to the pandemic such as COVID-19–\\nthemed social engineering, although the world is realizing the importance of raising the awareness of COVID-19–related cyberattacks [58]. Existing\\nresearch shows that positive organizational climate can influence people’s behavior [59].\\n5/2/22, 11:27 PM Health Care Cybersecurity Challenges and Solutions Under the Climate of COVID-19: Scoping Review - PMC\\nhttps://www-ncbi-nlm-nih-gov.ezproxy.lib.ryerson.ca/pmc/articles/PMC8059789/?report=printable 11/28\\nEnsure Business Continuity Health care leadership must embrace cybersecurity and develop strong cultures of cybervigilance [61]. The health sec‐\\ntor already has business continuity solutions in place such as data backups and intrusion detection and prevention systems [54]. NHS trusts have\\nbeen asked to follow and meet the Cyber Essentials and government standards. NHS Digital has launched a Data Security and Protection Toolkit\\n[60], a self-assessment tool for organizations that need to access NHS patient information and systems. The toolkit must be applied to ensure that\\norganizations practice good cyber hygiene. Security risk assessment is essential to ensure business continuity. Kim et al [22] systematically as‐\\nsessed the impacts of cybersecurity threats on remote health care. Cybersecurity insurance in health care [62] should also be considered as a solu‐\\ntion to ensure business continuity management, but it has not been widely adopted.\\nApply Technical Controls General technical controls applied by the health sector include encryption, authentication, and authorization to protect\\ndata from cyber threats [63]. Cryptographic security is used to address data sharing and storage of patient information across network systems\\n[66]. Homomorphic encryption is applied to ensure robust security and privacy guarantees while enabling analysis of encrypted data and sensitive\\nmedical information [64]. Blockchain is also applied to facilitate health care interoperability due to its immutability, transparency, and decentraliza‐\\ntion [65]. Network segmentation and isolation also need to be considered by the health sector [1]. With network segmentation, network traffic can\\nbe isolated and/or filtered to limit and/or prevent access between network zones. For example, in case of systems compromise, one should freeze\\nany activity in the system, disconnect the infected machines from any external drive or medical device, and go offline from the network.\\nPolicy and Legislation The health sector already has security policies and legislation in place for cybersecurity management. Laws and regulations\\nare available to protect medical cyber-physical systems [64]. Security controls need to be tailored according to regulation [67]. Manufacturers are\\nalso required to consider these regulations to design medical devices [68]. However, policymakers may need to alter policies to allow new techno‐\\nlogical innovations to be applied to health care [69]. The US Congress passed the 21st Century Cures Act to promote the interoperability of elec‐\\ntronic health records and promote more patient control over one’s own health information while protecting privacy and cybersecurity [20].\\nHowever, more efforts are needed on security policies or legislations in handling cybersecurity-related matters during pandemics like COVID-19.\\nIncident Reporting and Cyber Threat Intelligence Support The health sector is required to report cybersecurity incidents to a supervisory authority,\\nsuch as the national Computer Security Incident Response Team in the European Union. In the United Kingdom, there is government-approved sup‐\\nport from the NCSC. NHS Digital has issued two high-severity CareCERT alerts in 2019 (BlueKeep and DejaBlue). After developing a high-severity\\nalert process handbook, remediation went from 18 weeks for BlueKeep down to 3 weeks for DejaBlue [68]. He and Johnson [70,71] proposed a\\ngeneric security template, which is an evidence-based argumentation approach to facilitate incident reporting and exchange. This approach was ap‐\\nplied to a health care organization but has not been widely adopted. Hakak et al [1] identified the needs of establishing an international workforce\\nto facilitate threat reporting and cyber threat intelligence (eg, attack vectors and countermeasures) exchange to combat pandemic-themed cyber\\nthreats. The health sector will benefit from such practices during pandemics in order to avoid similar incidents.\\nCybersecurity Guidance Specific to COVID-19 Some health care organizations have started providing security guidance specific to COVID-19 for\\ntheir staff. For example, NHS Digital has added guidance on working from home security, ramping up its on-site support for trusts on risk mitiga‐\\ntions, data backup, and threat response. They also offer the NHS the NCSC’s Protective Domain Name Service free of charge [72]. Furthermore, gov‐\\n5/2/22, 11:27 PM Health Care Cybersecurity Challenges and Solutions Under the Climate of COVID-19: Scoping Review - PMC\\nhttps://www-ncbi-nlm-nih-gov.ezproxy.lib.ryerson.ca/pmc/articles/PMC8059789/?report=printable 12/28\\nernments also provide cybersecurity guidance to both individuals and organizations. For example, the United Kingdom’s Information\\nCommissioner’s Office created an information hub in order to assist individuals and organizations to protect data during the COVID-19 pandemic\\n[73].\\nDiscussion\\nSummary of Evidence\\nThrough a scoping review, this research identified key cybersecurity challenges, solutions adapted by the health sector, and areas to be improved in\\norder to counteract the cyberattacks introduced through changes to working practices in the face of the COVID-19 pandemic. This review identified\\n9 main challenges in cybersecurity and 11 key solutions that health care organizations adapted to address these challenges. Based on our findings\\nand analysis, we can conclude that the main challenges that the health sector faces due to the COVID-19 pandemic include increased reliance on re‐\\nmote working by staff, high demand for PPE by staff on the first line of defense, and decreased mobility due to the lockdown. Indeed, these changes\\nhave made the health sector vulnerable to potential cyberattacks. For example, remote work was taken up by users with little previous experience,\\nand there was also no planning and cybersecurity-associated assurance prior to the shift. Furthermore, evidence can be seen from the security inci‐\\ndents that took place during the lockdown period such as those of Brno University Hospital, hospitals in Romania, etc. The health sector continues\\nto face security challenges [1,17]. Challenges such as remote working security assurance, endpoint device management, inadequate business conti‐\\nnuity plans, lack of security awareness, etc, are apparent in the health sector. There are some existing solutions employed by health care organiza‐\\ntions, especially in the United Kingdom, such as remote access monitoring. Figure 2 summarizes the main findings from the literature review and\\nhighlights the gaps and vulnerabilities that were exploited during the cyberattacks that took place during the COVID-19 pandemic. However, there\\nare still challenges and gaps to be addressed, as discussed below.\\nImplications for FutureResearch\\nAlthough the health sector has made some efforts to address these challenges, more research is required in some domains.\\nTechnical Controls The health sector has applied some technical solutions to tackle cybersecurity challenges in order to secure the remote work en‐\\nvironment and monitor endpoint applications. These include but are not limited to network security (eg, network segmentation), multifactor au‐\\nthentication, password protection, patching systems, and the use of intrusion detection and prevention systems. There are also innovative security\\nsolutions such as the zero-trust principle (ie, to treat all devices as untrustworthy before access or authorization can be considered). The use of\\nVPNs is a popular technique in the remote work environment but is not always required. Health care organizations should avoid the abuse of VPNs\\nand ensure it is applied to specific tasks, such as for system admin use and medical diagnosis purposes through access to legacy systems (eg, patient\\nrecords management systems) stored on private data servers. Future research should explore innovative solutions such as blockchain as it can facil‐\\nitate health care interoperability due to its immutability, transparency, and decentralization. In general, the health sector significantly lags behind\\nother sectors in terms of cybersecurity. Future research should borrow experience from general cybersecurity practices (eg, NIST guidelines) and\\nadapt them according to the needs of the health sector, especially in the context of pandemics.\\n5/2/22, 11:27 PM Health Care Cybersecurity Challenges and Solutions Under the Climate of COVID-19: Scoping Review - PMC\\nhttps://www-ncbi-nlm-nih-gov.ezproxy.lib.ryerson.ca/pmc/articles/PMC8059789/?report=printable 13/28\\nCyber Resilience In order to improve system resilience, health organizations have some business continuity planning in place for data protection\\nand recovery but lack a systematic way to maintain cyber resilience [18]. The vulnerabilities in the cyber supply chain makes it difficult to recover\\nfrom an incident caused by third parties [38-41]. In the case of impact on medical devices or clinical information systems, incident response should\\nbe coordinated with device manufacturers and vendors. Health care organizations have realized the importance of having a comprehensive view of\\ncybersecurity management in order to prevent cyberattacks [18] but have not built this coordinated capacity. There is a lack of a cyber resilience\\nprogram to evaluate vendors’ capabilities around threat protection, particularly across email servers (phishing and ransomware), breadth of port‐\\nfolio coverage in addressing cloud architecture, and endpoint security. Future research should focus on building a coordinated cybersecurity capac‐\\nity in order to systematically assess vulnerabilities and respond to cyber threats.\\nHuman Factors in Cybersecurity People are likely to make mistakes, especially in the context of changes in their traditional way of working. Health\\ncare organizations are required to adopt a nonblaming culture in reporting incidents. The health sector should focus on root cause analysis [28] and\\nprevent incidents from happening especially through unintentional human error. Published research has shown that the majority of information se‐\\ncurity incidents relate to human error [28,29], which is a vulnerability that attackers will look to exploit. A human error analytical approach such as\\nIS-CHEC could be deployed both reactively, through integration within incident management practices [29,30], and proactively, through simple in‐\\nteraction with operational personnel [29], to detect current human error areas of weaknesses and apply associated remedial and preventative mea‐\\nsures. Moreover, health care staff in the organization need to be educated and build awareness of the ongoing security situation during the COVID\\x0219 pandemic. For example, in the case of infection, staff are required to disconnect from the network to contain the spread. Organizations should\\ncontinuously raise awareness internally by launching campaigns even during a time of crisis (ie, to inform health staff not to open suspicious\\nemails). Future research should focus on creating pandemic-themed security awareness campaigns. Moreover, a positive and empowering culture is\\nalso required (eg, by sharing the rate of people who did not click on phishing-negative emails during a training campaign). Experience can be bor‐\\nrowed from the organizational climate literature to positively influence people’s behavior [59].\\nStrategic Cybersecurity Management Although health care organizations have invested in cybersecurity to counteraction security attacks, further\\nefforts are needed to reprioritize cybersecurity risk assessment during the COVID-19 pandemic, reallocate security investment, and optimize re‐\\nsource utilization to obtain adequate assurances. According to Argwa et al [46], health care organizations are advised to allocate more resources\\nand funding to cybersecurity. Strategic cybersecurity investment is still an immature research area in health care largely due to boards’ inability to\\nfully understand and anticipate the direct and indirect impact on their health services. Further, there are language barriers between the technical\\nteam and the board [27]. Another reason is that the board finds it difficult to estimate the costs of investing and balancing these against potential\\nbenefits procured or impacts mitigated [8] as cybersecurity investments prevent potential losses but may not generate business benefits directly.\\nMoreover, organizations should not only create security guidelines specific to the COVID-19 pandemic but also plan for the long term for remote\\nworking and spend efforts on strengthening their security mechanisms and cybersecurity crisis management capabilities. More research efforts are\\nneeded to support the top management teams of the health sector to understand the threat landscape and make better-informed decisions to allo‐\\ncate resources not just to provide services to staff and patients but also for protection and resilience, in order to continuously serve even in times of\\nemergency such as the current pandemic and beyond.\\nLimitations\\n5/2/22, 11:27 PM Health Care Cybersecurity Challenges and Solutions Under the Climate of COVID-19: Scoping Review - PMC\\nhttps://www-ncbi-nlm-nih-gov.ezproxy.lib.ryerson.ca/pmc/articles/PMC8059789/?report=printable 14/28\\nContrary to systematic reviews, scoping reviews are used to identify knowledge gaps, scope a body of literature, and clarify concepts. However,\\nsome limitations should be considered. Scoping reviews usually provide descriptive information in order to address the objectives of the review,\\nwhich often leads to less defined searches. This review mitigated this limitation by clearly defining the search terms and search formula. Scoping\\nreviews are also at risk of bias from different sources. All 4 authors were involved in the article identification, selection, and analysis processes in\\norder to reduce the risks of bias. Because of variability when conducting a scoping review, there is a need for methodological standardization to en‐\\nsure the strength of evidence. This review followed the PRISMA-ScR to standardize the process and improve the strength of evidence. Another limi‐\\ntation is that this review included exact terms used to search the titles or abstracts of existing publications. Any articles that used different terms,\\n(eg, “computer security”) would not have been included. In addition, publications that were not written in English were excluded. Moreover, al‐\\nthough this scoping review focused on health care, the solutions identified could be applied to other industries.\\nConclusions\\nThe COVID-19 pandemic has challenged the resilience of the health care information system. This research was motivated by the urgency of coun‐\\nteracting the cyberattacks that have recently happened to hospitals, pharmaceutical companies, the US Department of Health and Human Services,\\nand the WHO and its partners, etc. We performed a review on security challenges of the health sector and the solutions employed during COVID-19.\\nWe identified the root causes of the security incidents that have impacted the health sector during the COVID-19 pandemic, cybersecurity chal‐\\nlenges, solutions, and areas in need of improvement. The results show that the main root causes of the security incidents that happened during the\\nCOVID-19 pandemic are mainly from phishing, ransomware, DDoS attacks, and malware. The main challenges faced by health care organizations are\\ninadequate endpoint device management, lack of security awareness, insecure remote work environment, inadequate business continuity plans,\\nlack of coordinated incident response, and difficulty in trading off security investment and service delivery quality. Needless to say, another major\\nchallenge is human error, both from the perspective of the health care worker at the frontline and those working from home. As the COVID-19 pan‐\\ndemic has shifted our priorities, there is a greater tendency for human error to occur when staff are preoccupied with saving lives, working in a\\nstrange or different environment, and using new or various technologies. With little or no experience and a lack of prior planning and training to\\nwork in such situations, health care workers require more than training and support, such as adequate time, documented procedures, and guidance\\non revised procedures and technology.\\nAlthough the health sector has made some efforts to address these challenges by applying technical measures, raising security awareness, enforcing\\npolicies, and developing COVID-19–specific guidelines, more research efforts are still required in some domains. Future research should focus on\\nexploring enhanced technical controls through the adaption of general cybersecurity practices (eg, NIST guidelines); improving cyber resilience by\\nbuilding a coordinated cybersecurity capacity to systematically assess vulnerabilities of the complex health care supply chain and respond to cyber\\nthreats; reducing human-related security incidents by exploring human error reduction approaches and pandemic-themed awareness campaigns;\\nand enhancing strategic cybersecurity management by exploring crisis management planning, security risks reprioritization, and the optimization\\nof cybersecurity budget and resource reallocation.\\nMany health care organizations are applying a temporary solution to counteract cyber threats during the COVID-19 pandemic. These organizations\\nshould plan for the long term, provide adequate levels of cybersecurity resources to deal with fast-changing situations, and offer the required assur‐\\nance within these changes. This paper provides useful insights for the health sector on their cybersecurity issues during the COVID-19 pandemic or\\n5/2/22, 11:27 PM Health Care Cybersecurity Challenges and Solutions Under the Climate of COVID-19: Scoping Review - PMC\\nhttps://www-ncbi-nlm-nih-gov.ezproxy.lib.ryerson.ca/pmc/articles/PMC8059789/?report=printable 15/28\\nother epidemic or pandemic situations in the future. Moreover, cybersecurity experience in other sectors can be borrowed and applied in the health\\nsector.\\nAcknowledgments\\nThis work was supported by the National Natural Science Foundation of China (grant 61803318).\\nAbbreviations\\nDDoS distributed denial of service\\nFBI Federal Bureau of Investigation\\nIoT internet of things\\nIT information technology\\nNCSC National Cyber Security Centre\\nNHS National Health Service\\nNIST National Institute of Standards and Technology\\nPPE personal protective equipment\\nPRISMA-ScR Preferred Reporting Items for Systematic Reviews and Meta-Analyses Extension for Scoping Reviews\\nVPN virtual private network\\nWHO World Health Organization\\n5/2/22, 11:27 PM Health Care Cybersecurity Challenges and Solutions Under the Climate of COVID-19: Scoping Review - PMC\\nhttps://www-ncbi-nlm-nih-gov.ezproxy.lib.ryerson.ca/pmc/articles/PMC8059789/?report=printable 16/28\\nAppendix\\nMultimedia Appendix 1\\nPRISMA-ScR checklist.\\nFootnotes\\nConflicts of Interest: None declared.\\n', \"SafeConfig’16 – Testing and Evaluation for Active and \\nResilient Cyber Systems \\n\\nNicholas J. Multari1, Anoop Singhal2, David Manz1 \\n1Pacific Northwest National Lab      2National Institute for Standards and Technology \\nnick.multari@pnnl.gov, anoop.singhal@nist.gov, david.manz@pnnl.gov \\n\\nABSTRACT \\nThe premise of this year’s SafeConfig Workshop is existing tools \\nand  methods  for  security  assessments  are  necessary  but \\ninsufficient  for  scientifically  rigorous  testing  and  evaluation  of \\nresilient  and  active  cyber  systems.  The  objective  for  this \\nworkshop is the exploration and discussion of scientifically sound \\ntesting  regimen(s)  that  will  continuously  and  dynamically  probe, \\nattack,  and  “test”  the  various  resilient  and  active  technologies. \\nThis adaptation and change in focus necessitates at the very least \\nmodification,  and  potentially,  wholesale  new  developments  to \\nensure that resilient- and agile-aware security testing is available \\ntesting,  validation  and \\nto \\nexperimentation must also be repeatable, reproducible, subject to \\nscientific scrutiny, measurable and meaningful to both researchers \\nand practitioners. \\n\\nthe  research  community. \\n\\n  All \\n\\nKeywords \\nSafeConfig;  Testing;  Validation;  Security;  Resilience;  cyber; \\ntestbeds; metrics; cyber experimentation; science of cybersecurity \\n\\n  Using  existing \\n\\n1.  SCOPE AND OBJECTIVES \\nThe  premise  of this year’s  SafeConfig  Workshop  is  that  existing \\ntools  and  methods  for  security  assessments  are  necessary  but \\ninsufficient  for  scientifically  rigorous  testing  and  evaluation  of \\nresilient and active cyber systems. For example, we contend that \\nexisting penetration testing tools, red team processes, and security \\ntesting are not able to cope with inherent nature of continuous and \\nresilient  systems. \\ntechniques  and \\nprocedures (TTP) by adversarial groups and penetration teams are \\noften  adequate  to  accomplish  the  job  needed  for  cybersecurity \\ntesting. However, to increase the scientific validity, the validation \\nof resilient systems must not be a static test or one consisting only \\nof breach of perimeter or exfiltration of data. Rather the objectives \\nfor \\nthe  exploration  and  discussion  of \\nscientifically  sound  testing  regimen(s)  that  will  continuously and \\ndynamically  probe,  attack,  and  “test”  the  various  resilient  and \\nactive  technologies.  This  adaptation,  and  change  in  focus \\nnecessitates  at  the  very  least  modification,  and  at  the  most, \\nwholesale  new  developments  to  ensure  that  resilient  and  agile \\n\\nthis  workshop  are \\n\\ntactics, \\n\\nPermission  to  make  digital or  hard  copies of  part  or  all  of this work  for  personal  or \\nclassroom use is granted without fee provided that copies are not made or distributed \\nfor profit or commercial advantage and that copies bear this notice and the full citation \\non the first page. Copyrights for third-party components of this work must be honored. \\nFor  all  other  uses,  contact  the  Owner/Author(s).  Copyright  is  held  by  the \\nowner/author(s). \\nCCS’16, October 24–28, 2016, Vienna, Austria. \\nACM ISBN 978-1-4503-4139-4/16/10. \\nDOI: http://dx.doi.org/10.1145/2976749.2990485 \\n\\naware  security  testing  is  available  to  the  research  community. \\nThese  impediments  will  also  include  natural  faults  such  as \\nflooding,  fire,  or  hardware  failure,  or  even  staff  member \\nnegligence. They must also be repeatable, reproducible, subject to \\nscientific scrutiny, measurable and meaningful to both researchers \\nand  practitioners.  The  following  topics  are  of  interest  of  this \\nworkshop: \\n\\n• Configuration testing, forensics, debugging and evaluation. \\n• Continuous monitoring and response. \\n• Cyber agility and moving target defense. \\n• Cyber resiliency. \\n• Cost effectiveness. \\n• Resilience/ agility effectiveness. \\n• Risk measurement. \\n• Testbeds. \\n• Research Infrastructure. \\n• Verification techniques. \\n• Validation techniques. \\n• Testing & evaluation methods. \\n• Cyber-physical systems security. \\n• Security configuration verification and economics. \\n• Security metrics - Adversarial and user Measures \\n• Mission metrics - Mission assurance, Mission measures, \\nConflicting mission management  \\n• Security policy management  \\n• Theory of defense-of-depth \\n\\n2.  PROGRAM COMMITTEE \\nSteering Committee \\nEhab Al-Shaer, UNC Charlotte, USA \\nChris Oehmen, Pacific Northwest National Lab, USA \\nKrishna Kant, Temple University, USA \\n\\nTechnical Program Committee \\nGail-Joon Ahn, Arizona State University, USA \\nSteve Borbash, US Department of Defense, USA \\nRichard Colbaugh, Periander, UK \\nSeraphin Calo, IBM Research, USA \\nTom Carroll, Pacific Northwest National Laboratory, USA \\nAndrea Ceccarelli, Universita degli Studi di Firenze, IT Yung Ryn \\nChoe, Sandia National Lab, USA \\nNora Cuppens, Telecom Bretagne, FR \\nHerve Debar, Telecom SudParis, FR \\nSabrina De Capitani di Vimercati, Universita degli Studi di   \\n     Milano, IT \\nQi Duan, University of North Carolina, USA \\nThomas Edgar, Pacific Northwest National Lab, USA \\nErrin Fulp, Wake Forrest University, USA \\n\\n1871 \\n\\xa0\\xa0\\n \\n \\n \\n \\n\\xa0\\n\\x0cYong Guan, Iowa State University, USA \\nArlette Hart, FBI, USA \\nMichael Huth, Imperial College London,UK \\nDoug Jacobson, Iowa State University, USA \\nDong-Seong Kim, University of Canterbury, New Zealand \\nRick Kuhn, NIST, USA \\nPeng Liu, Pennsylvania State University, USA \\nLuigi Mancini, Universita di Roma La Sapienza, IT \\nNuno Neves, University of Lisbon, PT \\nHamed Okhravi, MIT Lincoln Labs, USA \\nMohammed Rahman, Tennessee Tech, USA \\nHarigovind Ramasamy, IBM Research, USA \\nIndrajit Ray, Colorado State University, USA \\nWalid Saad, University of Miami, USA                          \\nMohamed Shehab, Univ of North Carolina Charlotte, USA \\nNeeraj Suri,  Technishe Universitat Darmstadt, GE \\nPaulo Verissimo, University of Luxembourg, LU  \\nCarlos Becker Westphall, Federal University of Santa Catarina,  \\n     Brazil \\nGeoffrey Xie, Naval Postgraduate School, USA \\nQuanyan Zhu, New York University \\n\\n3.  WORKSHOP CO-CHAIRS \\nNicholas  J.  Multari  provides  programmatic  and \\ntechnical \\nguidance  to  cybersecurity  research  programs  at  the  Pacific \\nNorthwest National Lab (PNNL).   Prior to joining PNNL, he led \\nthe trusted cyber  technology  research  at  Boeing  Research  and \\nTechnology  in  Seattle,  Washington. In  2008,  he  served  as  a \\nconsultant  to  the  USAF  Scientific  Advisory  Board  (SAB) \\ninvestigating the effects of the contested cyber environment on the \\nUSAF mission. Other positions held include five years as a Senior \\nSecurity  Engineer  with  Scitor  Corporation  in  Northern  Virginia, \\n\\nand 20 years as a computer scientist in the Air Force retiring as a \\nLt. Col. He is a member of external advisory boards at University \\nof Washington and Iowa State University.  He received his PhD in \\ncomputer science from the University of Texas at Austin. \\n\\nAnoop  Singhal,  is  currently  a  Senior  Computer  Scientist  in  the \\nComputer Security Division at the National Institute of Standards \\nand  Technology  (NIST)  in  Gaithersburg,  MD.   He  received  his \\nPh.D. \\nin  Computer  Science  from  Ohio  State  University, \\nColumbus,  Ohio.  His  research  interests  are  in  network  security, \\nnetwork  forensics,  cloud  computing  security  and  data  mining \\nsystems.  He  is  a  member  of  ACM,  senior  member  of  the  IEEE \\nand  he  has  co-authored  over  50  technical  papers  in  leading \\nconferences and journals.  He has two patents in the area of attack \\ngraphs  and  he  has  also  co-edited  a  book  on  Secure  Cloud \\nComputing. \\n\\nDavid  Manz  is  a  Senior  Cyber  Security  Scientist  at  the  Pacific \\nNorthwest National Laboratory. He holds a B.S. in Computer and \\nInformation Science from the Robert D. Clark Honors College at \\nthe University of Oregon and a Ph.D. in Computer Science from \\nthe  University  of  Idaho.  David's  work  at  PNNL  includes \\nenterprise  resilience  and  cyber  security,  secure  control  system \\ncommunication,  and  critical  infrastructure  security.  Prior  to  his \\nwork  at  PNNL, David  spent  five years  as  a  researcher  on  Group \\nKey  Management  Protocols  for  the  Center  for  Secure  and \\nDependable  Systems  at  the  University  of  Idaho  (U  of  I).  David \\nalso  has  experience \\nteaching  undergraduate  and  graduate \\ncomputer  science  courses  at  U  of  I,  and  as  an  adjunct  faculty  at \\nWashington  State  University.  David  has  co-authored  numerous \\npapers  and  presentations  on  cyber  security,  control  system \\nsecurity, and cryptographic key management. \\n\\n1872 \\n\\x0c\", 'Connections: The Quarterly Journal \\nISSN 1812-1098, e-ISSN 1812-2973 \\n\\nPh. Fluri & T. Tagarev, Connections QJ 19, no. 3 (2020): 5-12 \\nhttps://doi.org/10.11610/Connections.19.3.00  \\n\\nEditorial \\n\\nThe Concept of Resilience: Security Implications \\nand Implementation Challenges \\n\\nPhilipp Fluri 1 and Todor Tagarev 2 \\n\\nAbstract:  Aiming  for  a  more  effective  and  efficient  response  to  diverse \\nand multidimensional threats, an increasing number of defense and secu-\\nrity  organizations,  the  United  Nations,  NATO,  and  the  EU  embrace  the \\nconcept  of resilience in their security strategies and policies. This article \\nprovides a brief overview of the concept, a sample of definitions used in \\npolicy documents, and the types of problems they seek to resolve. Then \\nwe introduce the reader to the 15 articles published in the  Summer and \\nFall 2020 issues of Connections that present the evolution of the concept \\nof resilience and its implementation by and within political, defense, and \\nlaw enforcement organizations, as well as its anticipated contribution to \\ncybersecurity,  disaster  preparedness,  peacebuilding,  post-conflict  resto-\\nration and countering hybrid threats. \\n\\nKeywords:  resilience,  theory,  concept,  institutions,  police  force,  crisis \\nmanagement,  disaster  risk,  Sendai  framework,  critical  infrastructure,  cy-\\nbersecurity,  maturity,  hybrid  threats,  peacebuilding,  stabilization,  post-\\nconflict reconstruction, NATO, European Union. \\n\\nIn recent years, the notion of resilience has experienced an astonishing expan-\\nsion  away  from  the  area  of  its  original  application  and  transformation  of  its \\nmeaning. Originally it denoted the aptitude of material (objects and substanc-\\nes)  bent,  stretched,  twisted,  or  compressed  to  spring  back  into  the  original \\nform – in mechanics, the work required to strain an elastic body to the elastic \\n\\nPartnership for Peace Consortium of Defense \\nAcademies and Security Studies Institutes \\n\\nCreative Commons \\nBY-NC-SA 4.0 \\n\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n\\x0cPh. Fluri & T. Tagarev, Connections QJ 19, no.3 (2020): 5-12 \\n\\nlimit and “the work performed by the body in recovering from such strain.”1 In \\npsychological and medical contexts, it was then used metaphorically in cases of \\nillness and setbacks to describe the psychological quality that allows people to \\nbe “knocked down by the adversities of life and come back at least as strong as \\nbefore.”2  \\n\\nIts  adoption  by  a  variety  of  sciences  and ‘discourses’  has  both  augmented \\nand arguably inflated its meaning. In the latter (medical) field, the questions of \\ndescribing  resilience  and what  creates  resilience,  how  to  build resilience,  and \\nhow  to  use  it  in  a recovery  process  after  traumatic  events  became  important \\nfoci of research and debate. Resilience, thus understood, is more than ‘coping’ \\nwith a situation. It entails the (potential) ability to surpass and grow beyond a \\ngiven state. It is also understood to be a quality that could be strengthened by \\ninvesting into it adequately. In this sense, ‘resilience’ is now also used in busi-\\nness and environmental studies and defense and security, including human se-\\ncurity. \\n\\nThis special two-volume issue (Summer &Fall 2020) of Connections focuses \\non the concept(s) of resilience in the spheres of defense and security (including \\nhuman  security).  If  usage  of  the term  ‘resilience’  abounds  in  the  non-security \\nfield, so it does inside the defense and security field – a situation that for mere-\\nly pragmatic reasons necessitates a closer investigation of what different inter-\\nest groups actually mean by the term. Its gross over-use may lead us to believe \\nwe understand it in all its implications which, in fact, we may not yet. \\n\\nIn the past decade, the concept of resilience evolved from a purely academ-\\nic and engineering interest to dedicated incorporation in national and interna-\\ntional security policies. One example of the former is Bulgaria’s 2016 cyberse-\\ncurity strategy “Resilient Bulgaria 2020.”3 The resilience-based approach to cy-\\nbersecurity, where resiliency is defined as “the ability to anticipate, withstand, \\nrecover  from,  and  adapt  to  adverse  conditions,  stresses,  attacks,  or  compro-\\nmises on systems that use or are enabled by cyber resources,”4 is turning into a \\nde-facto  standard  guiding  both  systems  engineering  and  the  search  for  ade-\\nquate organizational arrangements.  \\n\\nThe United Nations embraced the concept at the beginning of this century. \\nIn  2005,  the  World  Conference  on  Disaster  Reduction  adopted  the  “Hyogo \\nFramework  for  Action  2005-2015,”  which  placed  the  focus  on  strengthening \\n\\n\\n \\n \\n \\n\\x0cThe Concept of Resilience: Security Implications and Implementation Challenges \\n\\nthe resilience of nations and communities to disasters.5 The United Nations Of-\\nfice defined resilience for Disaster Risk Reduction as “the capacity of a system, \\ncommunity  or  society  potentially  exposed to hazards to adapt, by resisting or \\nchanging in order to reach and maintain an acceptable level of functioning and \\nstructure,” where this capacity “is determined by the degree to which the so-\\ncial system is capable of organising itself to increase this capacity for learning \\nfrom past disasters for better future protection and to improve risk reduction \\nmeasures.”6 Respectively, the Hyogo Framework for Action emphasized efforts \\nto build resilience through enhanced national and local capabilities to manage \\nand  reduce  risk  and  the  use  of  knowledge,  innovation,  and  education  to  pro-\\nmote  a  culture  of  resilience  at  all levels.  The  follow-up Sendai  Framework  for \\nAction, adopted in 2015 7 with a “renewed sense of urgency,” called for the in-\\ntegration of “both disaster risk reduction and the building of resilience into pol-\\nicies, plans, programmes and budgets at all levels.”8 \\n\\nThe  uncertainty  and  the  unpredictability  of  the  security  environment  are \\nanother  reason  to  embrace  the  concept  of  resilience.  Given  the  broad  spec-\\ntrum  of  threats  and  security  challenges, the  proliferation  of  conventional  and \\nunconventional  conflicts,  the  fuzzy  boundaries  between  military,  asymmetric \\nand  hybrid  threats,  and  the  challenges  brought  by  the  COVID-19  pandemics, \\nNATO turned to the need to enhance the resilience of each member state and \\nthe alliance as a whole.9  \\n\\n \\n \\n\\x0cPh. Fluri & T. Tagarev, Connections QJ 19, no.3 (2020): 5-12 \\n\\nResilience is also the central pillar of the European Union’s strategy to deal \\nwith  multidimensional  hybrid  threats  that  combine  coercive  and  subversive \\nmeasures, including CBRN hazards and disinformation.10 Again, member states \\nare mainly responsible for strengthening resilience and enhancing response ca-\\npabilities, while EU institutions reinforce national efforts.  \\n\\nFurthermore, the 2020 EU Security Union Strategy 11 and Counter-Terrorism \\nAgenda 12 stress the importance of resilience and, in particular, the resilience of \\ncritical infrastructures. Hence, taking into account new policies and the lessons \\nfrom  the  implementation  of  the  2008  European  Critical  Infrastructure  Di-\\nrective,13 the European Commission proposed replacing it with a new directive \\naimed at enhancing the resilience of critical entities providing essential services \\nin the EU.14 \\n\\nResilience has in the meantime been addressed and discussed by scientists, \\npolicymakers, and military planners seeking novel ways to increase the safety \\nand  security  of  organizations,  communities,  industrial  sectors,  critical  infra-\\nstructures, armed and security forces and services, and societies in the face of \\nnew and unforeseen threats and challenges.  \\n\\nTo reflect on conceptual and practical developments and outline options for \\n\\nshaping security and defense policies, we invited authors to comment on: \\n\\nthe evolution of the concept of resilience \\ninvesting in resilience vs. investing in prevention and preparedness \\n\\n• \\n• \\n•  measures of effectiveness and measures of performance \\n\\ntential vulnerabilities  – military forces again depend on the civilian and commercial \\nsectors for transport, communications, and basic supplies such as food and water). \\nSee  “Resilience  and  Article  3,”  NATO  Topics,  Last  updated:  16  November  2020, \\nwww.nato.int/cps/en/natohq/topics_132722.htm. \\n\\n \\n \\n\\x0cThe Concept of Resilience: Security Implications and Implementation Challenges \\n\\n• \\n\\nlessons learned and good practices in the implementation of the con-\\ncept of resilience. \\n\\nAs a result, the Summer and Fall 2020 issues of Connections include 15 orig-\\ninal articles presenting the evolution of the concept of resilience in the defense \\nand  security  sector,  its  implementation  by  and  within  political,  defense,  and \\nlaw enforcement organizations, as well as its contribution to cybersecurity, dis-\\naster  preparedness,  peacebuilding,  post-conflict  restoration  and  countering \\nhybrid threats. \\n\\nIn  his  foundational  article,  Peter  Rogers  proposes  to  look  into  the  diverse \\nand many origins of the concept of resilience, which make the pursuit of a uni-\\nfied  theory  both  attractive  and  challenging.  However,  such  difficulty  has  not \\ndeterred  politicians  and  theoreticians  alike  from  claiming  to  understand  and \\napply the resilience concept to deal with uncertainty.15 Dr. Rogers argues that \\nthis desire to both reduce and totalize leads to a misunderstanding of the dif-\\nferent points of emergence and the dynamics of the resilience concept. \\n\\nDrs. Carmit Padan and Reuven Gal propose to map the multitude of defini-\\ntions of resilience in a two-dimensional matrix, divided into four content cate-\\ngories: social, economic, political, and military.16 This matrix generates twelve \\nsub-types of resilience and can subsequently be used for a comprehensive def-\\ninition of resilience and its sub-aspects, as well as for the possible assessment \\nof resilience in its various apparitions. \\n\\nResilience was also the dominant issue in discussions during the 2020 Trans-\\natlantic Security Jam.17 Dr. Dinos Kerrigan-Kyrou reports on the Jam’s findings, \\nwith  particular  reference  to  the  expectable  Post-Covid  future.  The  author \\nstates that whereas the pandemic has not created new global power conflicts, \\nit has not resulted in enhanced cooperation needed to enhance resilience and \\nlimit human and economic losses. Its spread has exacerbated processes threat-\\nening international order, rules-based trade, international cooperation and co-\\nordination.  \\n\\nDr. Nadja Milanova shows how the concept of resilience in defense and se-\\ncurity is evolving towards the inclusion of a wide-ranging and multidimensional \\nset  of  vulnerabilities  and  across  the  spectrum  of  associated  military  and  non-\\nmilitary  mitigation  strategies.  She  argues  that while  corruption and poor  gov-\\nernance are now recognized as security threats, the strengthening of defense \\nand related security institutions in both Allied and Partners nations remains to \\n\\n \\n \\n \\n\\x0cPh. Fluri & T. Tagarev, Connections QJ 19, no.3 (2020): 5-12 \\n\\nin the NATO Warsaw Summit Declaration). Institutional resilience based on in-\\ntegrity,  transparency,  and  accountability  is  critical  for  ensuring  the  fulfillment \\nof NATO’s resilience commitment and its baseline requirements. These include \\ncontinuity  of  government  with  the  ability  to  make  decisions  and  provide  ser-\\nvices to the population. \\n\\nDr. Marleen Easton and Vanessa Laureys present a case study on the effects \\nof  the  terrorist  attack  at  Brussels  Airport  on  March  22,  2016,  which  explores \\npolice officers’ experiences concerning their coping strategies after the terror-\\nist attack and the (in)formal workplace social support that affected their resili-\\nence.  The  study  provides  an  in-depth  analysis  into  the  coping  strategies  and \\nprocesses  of  workplace  social  support  that  may  contribute  to  police  officers’ \\nresilience following a traumatic event. Besides, it offers insights into the police \\norganization’s best practices to foster its employees’ resilience and job perfor-\\nmance. \\n\\nMikio Ishiwatari, in “Evolving Concept of Resilience: Soft Measures of Flood \\nRisk  Management  in  Japan,”  shows  how  the  concept  of  resilience  has  been \\nevolving in light of and answer to changes in climate, the socioeconomic envi-\\nronment, technology adaptations, etc. Ishiwatari analyzes areas that affect re-\\nsilience by reviewing the policy change of flood risk management,  particularly \\nsoft measures, in Japan. Based on lessons from the evolving concept of resili-\\nence, he recommends that developing countries should not only invest in infra-\\nstructure but also consider soft measures regarding changes in socioeconomic \\nand natural conditions. \\n\\nThis follow-on Fall 2020 issue of Connections includes contributions on re-\\n\\nsilience in cybersecurity, post-conflict peacebuilding, and human security.  \\n\\nThe concept of resilience finds increasing application in the provision of cy-\\nbersecurity, including attempts at measuring the level of resilience and organi-\\nzational maturity. In the opening article, Dr. George Sharkov provides an over-\\nview  of  organizational  and  community  cybersecurity  and  resilience  maturity \\nmodels  and  cybersecurity  indexes  and  suggests  that  maturity  needs  to  be \\nplaced  in  the  focus  of  the  second-generation  national  cybersecurity  strate-\\ngies.18 \\n\\nThe contribution by Andras Hugyik is dedicated to the development of hy-\\nbrid  warfare  and  cybersecurity  capabilities  in  the  Hungarian  Defense  Forces. \\nHugyik tracks the application of the concept of resilience in Hungary, presents \\nan  elaborate  scenario  of  a  hybrid  attack  against  the  country,  including  a \\ncyberattack, and, on that basis, outlines the key measures to strengthen the re-\\nsilience at the national level and in the armed forces. \\n\\nThe  theme  of  resilience  to  hybrid  influence  is  then  pursued  by  a  team  of \\nGeorgian  authors  led  by  Dr.  Shalva  Dzebisashvili.  In  the  article  “Russian  Eco-\\nnomic Footprint and the Impact on Democratic Institutions in Georgia,” the au-\\n\\n\\n \\n \\n \\n\\x0cThe Concept of Resilience: Security Implications and Implementation Challenges \\n\\nthors provide sound statistical evidence on the Russian influence on Georgia’s \\neconomy. On the example of media freedom, they claim that above a certain \\nthreshold, stronger Russian economic influence is positively correlated with the \\nweakening  of  Georgian  democratic  institutes.  The  authors  conclude  that  Rus-\\nsia’s  economic  footprint  has  reached  the  ‘redline’  of  9  percent  of  Georgia’s \\nGDP,  and significant effort  is  needed to  reverse the trend  and  increase Geor-\\ngia’s resilience in its economic and political dimensions. \\n\\nThe following three articles address the resilience of stabilization and peace \\noperations,  and  peacebuilding  efforts.  First,  Dr.  Philipp  Fluri  critically  reviews \\nthe stabilization and reconstruction mission in Afghanistan and concludes that, \\nnotwithstanding numerous positive outcomes, it has been unnecessarily ambi-\\ntious, not tailored to the environment, and aiming to build peace for Afghans \\nrather  than  with  them.  In  contrast,  peacebuilding  missions  augmented  with \\nmeasures  to  enhance  resilience,  such  as  those  in  Guatemala,  Liberia,  and  Ti-\\nmor-Leste, focus on local ownership and dialogue and may thus achieve long-\\nlasting sustainable effects.  \\n\\nIn her contribution, Veronica Waeni Nzioki reviews the evolution of interna-\\ntional  peace  operations  and  how  technologies  are  contributing  to  their  resili-\\nence.  Advanced  technologies,  such  as  drone-mounted  sensors,  sensor  net-\\nworks,  and  advanced  communications,  and  innovative  ways  of  their  applica-\\ntion,  can  increase  the  organizational  agility  and  capacity  for  anticipation  and \\nforesight and thus contribute to operational success and peacekeepers’ safety.  \\nThe contribution by María Julia Moreyra reminds us that women play a cru-\\ncial role in family, community, and societal resilience. Hence, particularly with \\nthe  account  of  the  COVID-19  pandemics,  the UN  Women,  Peace  and  Security \\nAgenda provides a focus on governmental and international efforts to strength-\\nen resilience and increase safety and security.  \\n\\nIn the article “After the Crisis: The Role of Resilience in Coming Back Strong-\\ner,” Giulia Ferraro examines the role of resilience in the disaster management \\ncycle, on par with the prevention, preparedness, and response to crises of vari-\\nous origin. She then looks into the Sendai Framework for Disaster Risk Reduc-\\ntion  as  a  good  starting  point  for  elaborating  resilience  measures  and  bench-\\nmarking within an overarching approach to crises. \\n\\nDr. Borislava Manojlovic provides the final contribution to this two-volume \\nspecial issue of Connections. Through a series of problem-solving workshops in-\\nvolving South Koreans and representatives of North Korean communities living \\nin  South Korea,  she  explores  the  micro-level  factors  contributing  to the  resili-\\nence to conflict between the South and the North. Dr. Manojlovic finds out that \\nthe key to enhancing the resilience to conflict is the quality interaction among \\ncommunity  members  and  promoting  understanding,  tolerance,  and  respect \\nthrough education. \\n\\nThe editors would like to thank the authors for inspiring contributions and \\nthe Editorial Board of Connections for making these two volumes possible. The \\n\\n11 \\n\\n \\n \\n \\n\\x0cPh. Fluri & T. Tagarev, Connections QJ 19, no.3 (2020): 5-12 \\n\\ncombined  contributions  allowed  us  to  document  the  evolution—and  the  ex-\\npanding application in security policies—of a concept that may not have come \\nto its end yet. Inevitably, therefore, this examination is preliminary and descrip-\\ntive. It is certainly worth revisiting the topic in the future to examine what fur-\\nther developments the concept of resilience will experience, the evidence of its \\ncontribution to enhancing security, examples of good practice, and innovative \\nways of strengthening resilience. \\n\\nDisclaimer \\nThe views expressed are solely those of the author and do not represent official \\nviews of the PfP Consortium of Defense Academies and Security Studies Insti-\\ntutes, participating organizations, or the Consortium’s editors. \\n\\nAbout the Authors \\n\\nPhilipp H. Fluri, DDr., is a co-founder and former deputy director of the Geneva \\nCentre  for  the  Democratic  Control  of  Armed  Forces  (DCAF)  and  executive-in-\\nresidence of the Geneva Centre for Security Policy. After many years of working \\nas  a  political  advisor  and  educator  on  all  continents,  he  is  currently  Sergio  de \\nMello  Chair,  School  of  Diplomacy  and  International  Relations,  Seton  Hall  Uni-\\nversity, New Jersey. E-mail: drphilippfluri@gmail.com. \\n\\nTodor Tagarev is a professor in the Institute of Information and Communication \\nTechnologies of the Bulgarian Academy of Sciences and Head of its Center for \\nSecurity  and  Defense  Management.  An  engineer  by  education,  Prof.  Tagarev \\ncombines  governmental  experience  with  sound  theoretical  knowledge  and \\nbackground in cybernetics, complexity, and security studies – a capacity effec-\\ntively  implemented  in  numerous  national  and  international  multidisciplinary \\nstudies, including ongoing Horizon 2020 projects in the fields of crisis manage-\\nment and cybersecurity. https://orcid.org/0000-0003-4424-0201 \\n\\n12 \\n\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n\\x0cReproduced with permission of copyright owner.\\n\\nFurther reproduction prohibited without permission.\\n\\n\\x0c', 'DOI:10.1145/3349276 \\n\\nPeter J. Denning\\n\\nThe Profession of IT \\nAn Interview with  \\nAndrew Odlyzko  \\non Cyber Security \\n\\nIs a “Cyber Pearl Harbor” any greater a risk than a natural disaster?  \\nHow shall we prioritize our preparations for a cyber disaster?\\n\\nT HE  CYBER  INSECURITIES  of  the \\n\\nInternet  are  widely  touted \\nas  precursors  of  a  “Cyber \\nPearl Harbor,” that could by \\nsome  reckonings  mark  the \\nend of civilization. What if this is not \\na grave risk at all? What if the systems \\naspects we point at most frequently as \\nthe sources of vulnerabilities are actu-\\nally assets in tamping down the risk? \\nWhat if we spent more time develop-\\ning  our  ability  to  be  resilient  rather \\nthan to provide absolute security?\\n\\nAndrew  Odlyzko—mathematician, \\ncryptographer,  author,  and  informa-\\ntion  technology  analyst—has  been \\nasking these questions and has provid-\\ned a thorough analysis. His contrarian \\nideas have provoked controversy.\\nI talked to him about this.\\n\\nQ:  Military  tensions  among  major \\npowers  have  been  escalating  in  the \\npast  few  years.  Government  leaders \\nare  openly  worried  that  a  military-\\ngrade  preemptive  cyber  attack  could \\ndevastate a nation. What do you think \\nof this?\\n\\nA:  As  we  increase  our  reliance  on \\ndigital  technologies,  attackers  will \\nfind  networks  of  computers  increas-\\ningly  attractive  targets.  So  yes,  there \\nwill surely be a “Cyber Pearl Harbor.” \\nWe know not the day nor the hour. \\n\\nWhat we have to remember is that a \\n\\ndevastating  cyber  event  can  result  not \\nonly from hostile attacks but also from \\nnatural  events  such  as  solar  coronal \\nejections that fry electronics on Earth. \\nWe  are  also  subject  to  devastations \\nfrom other events such as convention-\\nal  wars,  terror  attacks,  earthquakes, \\ntsunamis,  or  superstorms.  Some  di-\\nsasters are caused by innocent human \\nmistakes, too, simple coding or opera-\\ntional errors, or unanticipated interac-\\ntions of complex systems. Any of these \\nevents  can  lay  waste  to  a  region  or \\ncountry. It is impossible to prevent all \\nthese  disasters.  So  the  question  must \\nbe: How do we prepare with maximum \\nresiliency to recover rapidly? And how \\nmuch of that effort should be devoted \\nto security in the cyber realm?\\n\\nQ: Given the range of possible devas-\\ntating  cyber  disasters,  what  security \\nmeasures would you recommend?\\n\\nA: It depends very much on the na-\\nture  of  the  organization.  A  business \\nshould  focus  on  protecting  the  busi-\\nness; a government agency should fo-\\ncus on protecting the country.\\n\\nMassive  cyber  attacks  are  certainly \\na threat. But it seems fairly well estab-\\nlished  that  they  can  only  be  launched \\nby sophisticated, well-resourced adver-\\nsaries who have ample time to prepare. \\nThat basically means nation-states and \\npossibly  terrorist  and  criminal  organi-\\nzations. Such adversaries must be dealt \\nwith  by  national  military  and  intelli-\\ngence  agencies  and  by  international \\ncollaborative  efforts.  Just  as  we  never \\nexpected most citizens to build person-\\nal fallout shelters, we should not expect \\nthem to acquire and manage informa-\\ntion  systems  that  would  resist  attacks \\nby a determined large agency.\\n\\nGovernments  rely  also  on  strate-\\ngic doctrines such as the balance be-\\ntween  offense  and  defense  and  their \\nability to deter aggressive acts. Those \\nactions obviously influence the prob-\\nabilities of massive attacks.\\n\\nMore  than  anything,  government \\nagencies  must  concentrate  on  gen-\\neral resilience. Note that resilience is \\ndesirable  in  general,  not  just  against \\nhostile  attacks.  Protection  against \\n\\nU\\nD\\nE\\n\\n.\\n\\nN\\nM\\nU\\n/\\nO\\nK\\nZ\\nY\\nL\\nD\\nO\\n\\nW\\nE\\nR\\nD\\nN\\nA\\n\\nF\\nO\\n\\nY\\nS\\nE\\nT\\nR\\nU\\nO\\nC\\n\\nO\\nT\\nO\\nH\\nP\\n\\n28    CO M MUNICATIONS OF THE   ACM   |   SEPTEMBER 2019  |   VOL. 62  |   NO. 9\\n\\nVviewpoints \\n \\n \\n \\n\\x0cviewpoints\\n\\nbioterrorism  does  not  differ  much \\nfrom  protection  against  natural  pan-\\ndemics. Similarly, restoration of com-\\nputer  networks  is  similar  whether \\nthey  are  brought  down  by  a  geomag-\\nnetic  storm,  an  electro-magnetic \\npulse  from  a  nuclear  explosion  in \\nspace, or a cyber attack.\\n\\nQ:  But  what  about  non-government \\norganizations? What should they do?\\nA: A business or educational insti-\\ntution  should  worry  primarily  about \\nthe  mundane  attacks  that  affect  its \\noperations.  This  effort  is  of  general \\nvalue  because  protection  against  the \\nmundane  also  reduces  exposure  to \\nmassive attacks in the Internet.\\n\\nStandard  measures  such  as  anti-\\nvirus  software,  firewalls,  two-factor \\nauthentication,  security  training,  and \\nbasic security practices are what regu-\\nlar enterprises should concentrate on.\\nAll organizations should make it a \\npriority  to  protect  their  data  through \\nregular, hard-to-corrupt backups. The \\nability  to  restore  data  is  an  essential \\npart of resilience and recovery.\\nEnterprises  can  further \\n\\nincrease \\ntheir resiliency by participating in back-\\nup communication networks, including \\neven amateur (ham) radio. And I could \\ngo  on  to  list  more  steps  of  similar  na-\\nture, all helpful in securing cyberspace.\\n\\nQ:  All  the  measures  you  have  cited \\nare  standard  ones.  They  have  been \\nadvocated by security experts for de-\\ncades.  Why  has  your  ACM  Ubiquity \\nessay \\n(see  https://bit.ly/2G5b76S) \\ncaused controversy?\\n\\nA:  The  utter  familiarity  of  this  ad-\\nvice  is  a  key  part  of  my  argument. \\nWe  have  known  for  decades  of  these \\nmethods for improving cybersecurity. \\nThey are taught widely in courses and \\ndiscussed  in  books.  They  are  not  se-\\ncret.  Yet  most  of  the  damaging  cyber \\nattacks  we  have  suffered  could  have \\nimplementing \\nbeen  prevented  by \\nthose measures.\\n\\nSo the big questions are: Why were \\nthose  steps  not  taken,  and  what  has \\nbeen  the  result?  My  (controversial) \\nanswer is that cybersecurity has sim-\\nply not been very important. The “Cy-\\nber Pearl Harbor” scenarios are seen \\nas  far  removed  from  day-to-day  op-\\nerations of civilian enterprises. What \\nthey have to deal with is regular crime \\n\\nMore than anything, \\ngovernment agencies \\nmust concentrate on \\ngeneral resilience.\\n\\nand regular mistakes, similar to what \\nthey have always faced in the physical \\nrealm.  There  have  been  a  few  head-\\nline-grabbing  cyber  attacks  involv-\\ning  theft  of  personal  identification \\ninformation  from  firms  with  large \\ndatabases. These are a small percent-\\nage of all cyber attacks. These events \\nillustrate  my  point.  The  companies \\ninvolved  did  not  consider  the  risk  of \\nmassive theft to be important enough \\nto invest in strong security measures. \\nThey now see that they were wrong.\\n\\nWe  have  an  online  ecosystem  in \\nwhich  crime  is  being  kept  within \\nbounds by countermeasures by enter-\\nprises and law enforcement agencies. \\nIn  almost  all  cases,  criminals  aim  to \\nsteal data or money without divulging \\ntheir identities or destroying systems.\\nAs the economy and society at large \\nincrease  their  dependence  on  infor-\\nmation  technologies,  crime  is  mi-\\ngrating  into  cyberspace.  As  a  result, \\nmore  resources  are  being  put  into \\ncybersecurity.  This  is  happening  at  a \\nmeasured  pace  without  drastic  reen-\\ngineering of our systems.\\n\\nQ:  Security  experts  have  said  that \\nmuch  software  code  is  a  mess  of \\n“spaghetti” that cannot be verified as \\ncorrect.  There  is  a  dark  industry  that \\npainstakingly  searches  through  the \\ntangled  codes  and  sells  its  findings \\nas  “zero  day  exploits”  on  the  black \\nmarket.  Purchasers  of  these  exploits \\nare  able  to  launch  surprise  attacks \\nand inflict serious damage before the \\nvictims are able to defend themselves \\nwith new patches. On what basis have \\nyou  concluded  that  “spaghetti  code” \\nis not a great risk?\\n\\nA: I have not concluded that at all. \\n“Spaghetti  code”  is  a  risk,  and  is  in-\\ndeed  continually  being  exploited  by \\nattackers.  What  I  point  out  is  that \\n“spaghetti  code”  also  has  positive \\n\\nfeatures.  Attackers  are  seldom  able \\nto make clean penetrations that leave \\nno traces, and when they insert their \\nown malware, they often mess up.\\n\\nStuxnet—a  virus  that  damaged  Ira-\\nnian nuclear centrifuges—is a famous \\nexample.  Although  attribution  has \\nbeen  difficult,  security  experts  have \\nplaced a strong likelihood that Stuxnet \\nwas  a  collaboration  between  the  U.S. \\nand Israel, based on the style of coding, \\nsimilarity  to  other  programs,  and  the \\nvariable  names  used.  And,  of  course, \\nthe creators of Stuxnet did slip up fairly \\nsubstantially in that it escaped into the \\nwild from the Iranian facilities.\\n\\nQ: When I grew up, operating systems \\nwere much smaller and more cleanly \\norganized.  Some  early  operating  sys-\\ntems  were  under  50-thousand  lines \\nof  code.  Today’s  major  operating \\nsystems  are  closing  in  on  100-mil-\\nlion lines, and one of the open source \\nLinux  distributions  is  near  500  mil-\\nlion. None of those systems has been \\nformally  verified.  They  are  cited  as \\npremier  examples  of  spaghetti  code. \\nAnd  yet  today’s  major  operating  sys-\\ntems  are  amazingly  reliable  com-\\npared to the old. How do you explain \\nthe  rise  of  reliability  along  with  the \\nrise of complexity?\\n\\nA: Much of the progress is due to the \\nsuperabundance of storage space and \\ncycles.  This  enables  us  to  tolerate  the \\nbloat induced by patches and repairs, \\nmost of which are to the mass of soft-\\nware outside the operating system ker-\\nnel. The accumulation of patches does \\ngenerally make systems more reliable. \\nFurther, designers now devote a lot of \\nresources  to  programs  that  monitor \\nother programs and they test far more \\nexhaustively than before. Even though \\nthere  are  strange  states  you  can  push \\nsystems  into—which  is  what  many \\nhostile  exploits  do—those  states  tend \\nnot to occur in the situations that mat-\\nter to regular users most of the time.\\n\\nMany  of  the  prescriptions  of  soft-\\nware  engineering  are  violated  rou-\\ntinely.  For  example,  we  know  how  to \\neliminate  the  continuing  vulnerabil-\\nity  to  buffer  overruns—but  we  have \\nnot  done  so.  Still,  progress  has  been \\nsubstantial.  Disciplined  coding  prac-\\ntices and isolation techniques such as \\nsandboxing  have  been  major  factors \\nimproving reliability.\\n\\nSE PT EMBER 2019  |   VOL.  62  |   NO. 9  |   COMMUNICATIONS OF THE  ACM     29\\n\\nV\\x0cviewpoints\\n\\nAdvertise with ACM!\\n\\nReach the innovators \\nand thought leaders \\nworking at the \\ncutting edge \\nof computing \\nand information \\ntechnology through \\nACM’s magazines, \\nwebsites \\nand newsletters.\\n\\n◊◆◊◆◊\\n\\nRequest a media kit \\nwith specifications \\nand pricing:\\n\\nIlia Rodriguez\\n+1 212-626-0686\\nacmmediasales@acm.org\\n\\nAs the economy  \\nand society  \\nat large increase \\ntheir dependence \\non information \\ntechnologies,  \\ncrime is migrating  \\nto cyberspace.\\n\\nAs  you  mentioned,  we  are  unable \\nto  formally  verify  the  giant  operating \\nsystems  we  most  rely  on.  But  we  can \\nformally verify small systems, such as \\nthose  needed  to  run  reliable  backup \\nsystems.  Those  are  key  to  recovery, \\nand thus to resilience.\\n\\nQ: You have said that some of the still-\\npopular  older  technologies  for  secu-\\nrity  such  as  firewalls  are  less  secure. \\nCan you say more?\\n\\nA:  Firewalls  have  been  getting  less \\neffective.  One  reason  is  that  more  and \\nmore  of  the  traffic  is  encrypted,  and \\nthus  increasingly  difficult  for  firewalls \\nto  classify.  Another  is  that  the  entire \\ndigital  environment  of  the  enterprise \\nhas changed. Originally, firewalls were \\na  good  way  to  protect  trusted  internal \\nsystems  from  hostile  penetration.  To-\\nday the architecture of enterprises has \\nchanged  considerably.  Their  systems \\nare intertwined with those of suppliers, \\npartners, and customers, as well as with \\ndevices  owned  by  employees.  Much \\ncomputation happens in the cloud, not \\nthe local network. In this environment, \\nsecurity  professionals  have  less  ability \\nto  see  and  control  what  is  happening. \\nThere is no well-defined security perim-\\neter for a firewall to protect.\\n\\nIn addition, far more of the attacks \\nrely  on  human  engineering—for  ex-\\nample,  phishing,  whaling,  ransom-\\nware, frauds, deceptions, social engi-\\nneering. Firewalls cannot stop them.\\nOn  the  other  hand,  firewalls  con-\\ntinue  to  improve.  They  are  far  more \\nsophisticated  than  their  early  incar-\\nnations  of  two  decades  ago.  They  are \\nnot about to disappear.\\n\\nQ:  You  have  a  reputation  for  taking \\ncontrarian  stands  on  issues.  This \\nseems  to  result  from  your  desire  to \\nunderstand  whether  popular  claims \\nstand on solid ground—and frequent-\\nly they do not. A few years ago you chal-\\nlenged  Metcalfe’s  Law  that  the  value \\nof a network grows with the square of \\nthe  number  of  nodes.  What  was  your \\nchallenge and what came of that?\\n\\nA:  The  argument  (developed  in  a \\npaper with Briscoe and Tilly) was that \\nMetcalfe’s  Law  overestimated  the \\nvalue of a network. We proposed that \\nusually a more accurate measure was \\ngiven by the product of the number of \\nnodes and the logarithm of that. This \\nproposal has held up quite well. This \\nleads  to  a  more  realistic  view  of  the \\nsize  of  network  effects  for  new  tech-\\nnologies,  and  therefore  of  the  pros-\\npects of new ventures.\\n\\nMore  generally,  contrary  opinions \\ndo help broaden people’s horizons and \\nprepare them for the inevitable surpris-\\nes.  In  some  cases,  the  dominant  con-\\nsensus  is  not  just  wrong,  but  leads  to \\nsubstantial waste of time and resourc-\\nes. That is the case with the apocalyp-\\ntic  claims  about  cybersecurity.  There \\nis  much  talk  about  need  for  drastic \\naction  and  reengineering  our  systems \\nfrom  the  ground  up.  But  this  talk  is \\nnot matched by actions. Technologists \\noverestimate  their  chances  of  making \\nbig  impacts  with  their  radical  propos-\\nals. There is a need for improved secu-\\nrity technologies, but when we look at \\ndecisions  that  are  being  made,  we  see \\nthey  implicitly  assume  that  security  is \\nimportant but not urgent. This is likely \\nto continue. I expect us to continue to \\nmake good progress in staying ahead of \\ncriminals and attackers without radical \\nchanges in Internet and operating sys-\\ntem architectures. \\n\\nAndrew Odlyzko is a mathematician and a former head \\nof the University of Minnesota’s Digital Technology \\nCenter and of the Minnesota Supercomputing Institute, \\nUSA. He was previously a researcher and research \\nmanager at Bell Labs and AT&T Labs, USA. His recent \\nworks are available at his home page http://www.dtc.\\numn.edu/~odlyzko.\\n\\nPeter J. Denning (pjd@nps.edu) is Distinguished \\nProfessor of Computer Science and Director of the \\nCebrowski Institute for information innovation at the \\nNaval Postgraduate School in Monterey, CA, USA, is \\nEditor of ACM Ubiquity, and is a past president of ACM. \\nThe author’s views expressed here are not necessarily \\nthose of his employer or the U.S. federal government.\\n\\nCopyright held by author. \\n\\n30    CO MMUNIC ATIONS OF THE  AC M   |   SEPTEMBER 2019  |   VOL. 62  |   NO. 9\\n\\n\\x0c', '5/8/22, 3:19 PM Chapter 10: Implementation Experiences from Smart Grid Security Applications and Outlook on Future Research | Smart Grid Security\\nhttps://learning.oreilly.com/library/view/smart-grid-security/9780128023549/B9780128021224000109/B9780128021224000109.xhtml#st0050 1/35\\nC H A P T E R 1 0\\nImplementation Experiences from\\nSmart Grid Security Applications and\\nOutlook on Future Research\\nStylianos Basagiannis\\nRohan Chabukswar\\nYi Yang\\nKieran McLaughlin\\nMenouer Boubekeur\\nUnited Technologies Research Centre, 4th floor Penrose Wharf, Cork, Ireland\\nCentre for Secure Information Technologies (CSIT), Queen’s University Belfast, UK\\nAbstract\\nExperiences from smart grid cyber-security incidents in the past decade\\nhave raised questions on the applicability and effectiveness of security\\nmeasures and protection mechanisms applied to the grid. In this chapter\\nwe focus on the security measures applied under real circumstances in\\ntoday’s smart grid systems. Beginning from real world example imple\\x02mentations, we first review cyber-security facts that affected the electri\\x02cal grid, from US blackout incidents, to the Dragonfly cyber-espionage\\ncampaign currently focusing on US and European energy firms. Provided\\na real world setting, we give information related to energy management\\nof a smart grid looking also in the optimization techniques that power\\ncontrol engineers perform into the grid components. We examine the ap-\\n*\\n*\\n†\\n†\\n*\\n*\\n†\\n5/8/22, 3:19 PM Chapter 10: Implementation Experiences from Smart Grid Security Applications and Outlook on Future Research | Smart Grid Security\\nhttps://learning.oreilly.com/library/view/smart-grid-security/9780128023549/B9780128021224000109/B9780128021224000109.xhtml#st0050 2/35\\nplication of various security tools in smart grid systems, such as intrusion\\ndetection systems, smart meter authentication and key management us\\x02ing Physical Unclonable Functions, security analytics and resilient control\\nalgorithms. Furthermore we present evaluation use cases of security tools\\napplied on smart grid infrastructure test-beds that could be proved im\\x02portant prior to their application in the real grid, describing a smart grid\\nintrusion detection system application and security analytics results.\\nAnticipated experimental results from the use-cases and conclusions\\nabout the successful transitions of security measures to real world smart\\ngrid operations will be presented at the end of this chapter.\\nKeywords\\nSmart grid security incidents\\ndefence mechanisms\\nsecurity measures\\napplication use-cases\\n10.1. Smart Grid Evolution\\nThe evolution of smart grids nowadays has raised important security concerns around the globe.\\nAutomation and control for optimized power distribution on building or district levels opens up\\nnew attack vectors to control and manipulate critical infrastructures. Evidence that the smart grid\\ntends to surround us all can be found in the rapid deployment of electrical smart meters,\\nconsidering that only in the US, approximately 36 million meters are already in use from 2007\\n(Institute of Electric Efficiency, 2012). In the same line across the European domain, smart grid\\ndeployment has been in the front lines of electrical architectural plans. To this end, grid\\nmodernization by utilizing ICT tools and interconnectivity services can offer a variety of benefits\\nfrom accurate monitoring to remote supervision, enabling a more intelligent, resilient and\\ninteractive electrical network. Its successful operation though does not depend only on the energy\\nsavings; it is considered to be a prerequisite that strong security mechanisms and defences will be\\n5/8/22, 3:19 PM Chapter 10: Implementation Experiences from Smart Grid Security Applications and Outlook on Future Research | Smart Grid Security\\nhttps://learning.oreilly.com/library/view/smart-grid-security/9780128023549/B9780128021224000109/B9780128021224000109.xhtml#st0050 3/35\\nengaged while communication grid services and control is enabled. But how can we be certain that\\nevolving smart grids will be secure?\\n10.1.1. Documented Incidents\\nReal world experiences and reports (Kroposki et al., 2008; Institute of Electric Efficiency, 2012;\\nTweed, 2011) on documented cyber-security incidents in the grid, show that smart grids\\ncontrolling sensitive assets and components are an attractive target for attackers. One of the best\\nknown security incidents with a massive impact on industrial control systems is Stuxnet\\n(Karnouskos, 2011). The Stuxnet worm, detected in June 2010, was a highly sophisticated malware\\ntargeting specific control software developed by Siemens Corporation. Its core functionality\\nenabled attackers to infect Siemens Programmable Logic Controller units (PLCs) modifying the\\ndecision of the control executed by the device while erasing any trace created in the log files. Using\\na valid digital certificate and exploiting zero-day vulnerabilities, Stuxnet manages to fully control\\nthe well-known Siemens WinCC SCADA software, which on its side, allows to manipulate process\\nautomation of industrial controllers and even allow access control and user authorization on the\\ncontrolled components. Until its discovery, Stuxnet was a powerful cyber-weapon that allowed the\\nremote control of safety critical industrial systems for years without being detected. According to\\nSymantec’s report approximately 45,000 networks have been infected with Stuxnet, 60% of them\\nbeing hosted in Iran.\\nClose to the Stuxnet case, cyber-security incidents have been discovered in September 2011,\\nreported as the Duqu (Duqu, 2011) virus. Believed to be originated from Stuxnet authors, its\\npurpose was to collect information from end-users of industrial control systems and use them for\\nfuture attacks. Although traces from Duqu executables have been found in a limited number of\\norganizations, it is confirmed that it was targeting industrial control manufacturing companies. As\\nimposed by its nature, Duqu is considered to be an attack preparation malicious tool that aims to\\naid future industrial cyber-attacks, such as the Stuxnet case.\\nAnother serious cyber-attack that could have catastrophic impact is the one reported back in 2008\\n(Krebs, 2008) related to a nuclear plant in Georgia, USA. The Edwin I nuclear plant (U.S. Energy\\nInformation Administration, 2012) was forced to make an emergency shutdown that was a result\\nof some software updates from the control manufacturer. It is crucial to note with this example,\\nthat (malicious) maintenance activities is one among the most common causes for incidents, as\\ncompromised or manipulated equipment can interrupt critical systems’ operations. For example,\\nconsider updating the firmware of a control device; the specific operation either involve a physical\\naccess to the device and installing the firmware through a dedicated laptop or – more recently –\\nupdate remotely the firmware of the device via IP networks. Both cases raise cyber-security\\nconcerns as media being involved in the update can carry non-certified software, as well as\\nfirmware packages can be already wrapped with malicious code and located still on the firmware’s\\n5/8/22, 3:19 PM Chapter 10: Implementation Experiences from Smart Grid Security Applications and Outlook on Future Research | Smart Grid Security\\nhttps://learning.oreilly.com/library/view/smart-grid-security/9780128023549/B9780128021224000109/B9780128021224000109.xhtml#st0050 4/35\\ncompany servers. In the Georgia case, the specific maintenance activity although driven by the\\nsoftware control manufacturer, resulted in a 48 hour disruption of the nuclear plant operation\\nraising certain alarms and major concerns about the reliability of the operations, being applied to a\\ncritical infrastructure (U.S. Energy Information Administration, 2012).\\nMcAfee’s report in (McAfee, 2011) raises huge concerns related to the Night Dragon malware\\n(Dragonfly, 2014). Focusing primarily on industrial control systems, its main objective was to\\nlaunch attacks depending on a combination of techniques including social engineering and spear\\x02phishing. Known software vulnerabilities found in end-user operating systems such as Windows,\\nallowed the Night Dragon to obtain valuable information that spanned from financial reports to\\nbusiness deals and sensitive intellectual property data.\\nOne of the incidents worth mentioning is the attack launched against the US electrical grid in\\n2009 (Zhang, 2013) which affected power distribution and transmission. After a huge number of\\ninvestigations from both electrical and ICT experts, the final outcome of the analysis of the incident\\nwas that hidden malicious software has infiltrated the facility. It was confirmed that attackers could\\nuse software backdoors to cut electricity at will.\\nConcerning AMI, at the US Black Hat conference 2009, Mike Davis, an IOActive security\\nconsultant, proved the weaknesses of the whole metering architecture and in particular of smart\\nmeters that were being deployed in those days (Cordova, 2010). By means of a proof of concept, he\\ndemonstrated that a cyber attack could be used to get remote control of about 15,000 out of 22,000\\nhomes within 24 hours. To show that Mike Davis and his team created a simulator as well as a real\\npiece of malicious software (i.e. a worm) capable of self-replicating and self-distributing across an\\narea where all houses are equipped with the same brand of meter.\\nIn August, 2012, Justin Clarke reported a security flaw in the operating system of RuggedCom’s\\nRugged Operating System (ROS) (August, 2012). RuggedCom products provide ruggedized\\nnetwork timing and communications infrastructure for electricity transmission and distribution, as\\nwell as other industrial applications. Clarke’s report asserted that a single key could be used to\\npenetrate the inner workings of the ROS. Once inside, an attacker could easily view communication\\ntraffic without additional security barriers.\\nIn July 2012, the top U.S. military official responsible for defense against cyber attacks, General\\nKeith B. Alexander, reported a 17-fold increase in cyber attacks against American infrastructure\\nfrom 2009 to 2011 (Gjelten, 2013). GlobalData reported in September 2012 that the cyber security\\nmarket in China will increase from $1.8 billion in 2011 to $50 billion in 2020. Symantec observed\\nspear phishing attempts in the form of emails with PDF attachments from February 2013 to June\\n2013. The email topics were related to office administration issues such as dealing with an account\\nor problems with a delivery. Identified targets of this campaign were mainly US and UK\\norganizations within the energy sector. In May 2013, the attackers began to use the Lightsout\\nexploit kit (InfoSecurity Website, 2014) for attacks, redirecting targets from various websites. The\\nexploit kit has been upgraded over time with obfuscation techniques. The updated version of\\n5/8/22, 3:19 PM Chapter 10: Implementation Experiences from Smart Grid Security Applications and Outlook on Future Research | Smart Grid Security\\nhttps://learning.oreilly.com/library/view/smart-grid-security/9780128023549/B9780128021224000109/B9780128021224000109.xhtml#st0050 5/35\\nLightsout became known as the Hello exploit kit. A newer approach used by attackers involves\\ncompromising the update site for several industrial control system (ICS) software producers. They\\nthen bundle Backdoor.Oldrea with a legitimate update of the affected software.\\nTo date, three ICS software producers are known to have been compromised. The Dragonfly\\nattackers used hacked websites to host command-and-control (C&C) software (Symantec Security\\nresponse, 2014). Compromised websites appear to consistently use some form of content\\nmanagement system. The current targets of the Dragonfly group, based on compromised websites\\nand hijacked software updates, are the energy sector and industrial control systems, particularly\\nthose based in Europe. While the majority of victims are located in the US, these appear to mostly\\nbe collateral damage. That is, many of these computers were likely infected either through watering\\nhole attacks or update hijacks and are of no interest to the attacker. By examining victims with\\nactive infections – where additional malicious activity has been detected – it is possible to gather a\\nmore accurate picture of ‘true’ victims. Dragonfly uses two main pieces of malware in its attacks.\\nBoth are Remote Access Tool (RAT) type malware which provide the attackers with access and\\ncontrol of compromised computers. Dragonfly’s favored malware tool is Backdoor.Oldrea, which is\\nalso known as Havex or the Energetic Bear RAT. Oldrea acts as a back door for the attackers on the\\nvictim’s computer, allowing them to extract data and install further malware. Oldrea appears to be\\ncustom malware, either written by the group itself or created for it. This provides some indication\\nof the capabilities and resources behind the Dragonfly group. The second main tool used by\\nDragonfly is Trojan.Karagany. Unlike Oldrea, Karagany was available on the underground market.\\nThe source code for version 1 of Karagany was leaked in 2010. Symantec believes that Dragonfly\\nmay have taken this source code and modified for its own use. Symantec found that the majority of\\ncomputers compromised by the attackers were infected with Oldrea. Karagany was only used in\\naround 5 percent of infections. The two pieces of malware are similar in functionality and what\\nprompts the attackers to choose one tool over other remains unknown.\\n10.1.2. Evolving Security Standards\\nThe smart grid becomes the major litmus test for future Internet of things, proving ground for a\\nnetwork of millions of smart meters. In this way equipment and meter manufacturers must\\nconsider security as a critical, system-level requirement when developing smart grid devices. There\\nis no doubt that multilayered, life-cycle hardware and software security is the best solution for\\nkeeping smart grids operational. For this reason, new security standards in an international\\nmanner have to be in place as living, upgradable documentation in order to secure grid operation\\nand controllability from recent attack bursts.\\nCurrently, a smart grid environment relies heavily on standards, mainly to guarantee\\ninteroperability among systems. Standards also play a key role in smart grid cyber security.\\n5/8/22, 3:19 PM Chapter 10: Implementation Experiences from Smart Grid Security Applications and Outlook on Future Research | Smart Grid Security\\nhttps://learning.oreilly.com/library/view/smart-grid-security/9780128023549/B9780128021224000109/B9780128021224000109.xhtml#st0050 6/35\\nStandards to develop smart grid cyber security are available today, although some enhancements\\nand new materials will be required to reflect the evolution of the smart grid, its technologies, and\\nthreats. Some will also need to be specifically profiled for the smart grid environment. The\\nchallenge is to maintain these standards over time at an appropriate pace. This will require\\nsubstantial effort, but the benefit of supporting the deployment of smart grid infrastructures that\\nare secure by design will make it worthwhile (ECETS, 2012). The CEN-CENELEC-ETSI SG\\x02CG/SGIS working group (ECETS, 2012) chose a European electrical grid stability scenario as\\nreference to define security levels. These security level definitions help to create a bridge between\\nelectrical grid operations and cyber security. They provide guidance in helping to identify critical\\nareas where security matters, mostly from a global electrical grid stability point of view, starting\\nfrom pan-European supergrids down to microgrids in city neighborhoods.\\nFIGURE 10.1 M/490 SG-CG/SGIS Security Levels\\nThe last few years have seen an exponential growth of threats. In its fourth quarter 2012 threats\\nreports executive summary document, McAfee says, “For the year, new malware sample\\ndiscoveries increased 50 percent with more than 120 million samples now in the McAfee Labs\\n‘zoo’”. Cyber threats are also evolving and becoming highly sophisticated. Advanced persistent\\nthreats (APT) are good illustrations of this mutation. Also, attackers are no longer amateurs, but\\nhighly skilled and organized professionals able to launch complex and coordinated attacks using\\nsophisticated tools. Information systems have always been targeted by cyber attackers. What is\\nrelatively new is the realization that industrial control systems are also vulnerable. This was\\ndemonstrated in 2010 with Stuxnet, the first discovered malware targeting industrial control\\nsystems. Electrical grids are valuable and critical targets that need to be protected from cyber\\nthreats. Smart grid layers require a system of systems approach with differentiated security needs.\\nThe smart grid includes different domains:\\n5/8/22, 3:19 PM Chapter 10: Implementation Experiences from Smart Grid Security Applications and Outlook on Future Research | Smart Grid Security\\nhttps://learning.oreilly.com/library/view/smart-grid-security/9780128023549/B9780128021224000109/B9780128021224000109.xhtml#st0050 7/35\\n• Power generation\\n• Transmission\\n• Distribution\\n• Distributed energy resources\\n• Smart cities\\n• End consumers\\nIt relies on a multitude of stakeholders, each with its own specific role and activity within a given\\ndomain. A smart grid architecture is a system of systems: a large and complex system made of\\nsmaller and simpler systems distributed and interconnected. Each smaller system has a different\\nsystemic impact on the global system stability and each must be assessed. Each smart grid\\nsubsystem and its associated assets require specific security functions and solutions. For example,\\nthe solution to secure a substation is not the same as the solution to secure demand response and\\nhome energy management systems. However, this does not mean that subsystems with “lower”\\ncriticality should not be secured. The security measures for each level must be sufficient to mitigate\\nthe risks. All subsystems would not necessarily need to align to the subsystem having the highest\\nsecurity requirements to effectively protect the whole system, since they have their own role to play\\nin the global smart grid ecosystem. Smart grid stakeholders need to analyse security levels from the\\nperspective of a global risk assessment of each smart grid use case and subsystem considered in the\\nend-to-end architecture.\\n10.2. Sustainable Building Integrated Energy Test\\x02Beds\\nDistributed generation with a high penetration of renewable energy sources and low-carbon\\ntechnologies is accepted as an alternative for traditional centralized power plants (Kroposki et al.,\\n2008). The microgrid concept has emerged as the local-level integration and coordination of\\ndistribution energy resources, and enables the reduction of running cost and green house gas\\nemissions, as well as guarantee availability of power supply, among other benefits (WBCSD, 2007).\\nThe microgrid concept can be extended to commercial and residential buildings, where there are\\ngrowing opportunities for reduction of energy consumption and new market opportunities for\\nstakeholders. Those sectors consume around 40% of total energy use in industrial societies\\n(Scenarios for a clean energy future, 2000), and account for nearly one-third of greenhouse gas\\nemissions. On the other hand, the security of microgrids increasingly comes as second priority.\\nEspecially when the integration of heterogeneous systems inside a building is rising, weak security\\nimplementations of the individual components cause critical vulnerabilities. To this end, different\\ncontrol strategies residing either in local embedded controllers of the components, or high level\\n5/8/22, 3:19 PM Chapter 10: Implementation Experiences from Smart Grid Security Applications and Outlook on Future Research | Smart Grid Security\\nhttps://learning.oreilly.com/library/view/smart-grid-security/9780128023549/B9780128021224000109/B9780128021224000109.xhtml#st0050 8/35\\ncontrol up to the SCADA system can cause system instability, which can easily result in major grid\\nfaults.\\nWe are going to describe common control strategies that are often implemented in smart grids. We\\nselect to focus on the test-bed microgrid (Valdivia et al., 2014) which is composed of different\\ncomponents all controlled through a SCADA system. Although it is a small-case system only,\\nhierarchical control strategies assure the optimal operation of all of the sub-systems, and it applis a\\nmultidisciplinary approach consisting of information and communication technologies (ICT),\\npower systems, power electronics, controls and optimization, and diagnostics. The electrical\\nmicrogrid incorporates a 10 kW wind Turbine (Bergey Excelsys), a 35 kWh (85 kW peak) Li-Ion\\nbattery (Saft), a 50 kW electrical/82 kW thermal combined heat and power unit (CHP) by\\nSokratherm, a feeder management relay at the point of coupling between the microgrid and the rest\\nof the building, and a set of local loads. Both the battery and the wind turbine are interfaced with\\nthe microgrid through power electronics converters (Triphase and Aurora, respectively), while the\\nCHP is interconnected through a synchronous machine. This structure incorporates all of the major\\ncomponents in microgrids, such as renewable generation, Internal Combustion (IC) based\\ngeneration, storage and different kind of interfaces. Thus, different control strategies on different\\nhierarchical layers, stability issues (such as those resulting from synchronous machines interfacing\\ncontrolled power electronics converters) and seamless transition from island to grid-connected\\nmode, among others, can be evaluated. For further information the reader can refer to (Valdivia et\\nal., 2014).\\nOriginally an integrated test-bed like the one described in (Valdivia et al., 2014) is controlled by\\nfollowing the hierarchical three-layer architecture illustrated in Figure 10.2. Similar approaches\\nhave been reported in (Lopes et al., 2006; Vasquez et al., 2010).\\nFIGURE 10.2 Hierarchical control of the building-level electrical microgrid and thermal system\\n10.2.1. Tertiary (Supervisory) Control Layer\\nTertiary control is performed by an integrated energy management system based on model\\npredictive control. Recent efforts have focused on the application of predictive control to heating,\\n5/8/22, 3:19 PM Chapter 10: Implementation Experiences from Smart Grid Security Applications and Outlook on Future Research | Smart Grid Security\\nhttps://learning.oreilly.com/library/view/smart-grid-security/9780128023549/B9780128021224000109/B9780128021224000109.xhtml#st0050 9/35\\nventilation, and air conditioning (HVAC) systems in energy efficient buildings (Ma et al., 2012;\\nSamad & Kiliccote, 2012) thereby not including electrical local generation and storage. Here, the\\nsupervisory control considers the electrical microgrid components as well as heating system\\n(including boiler, CHP, storage components), and computes the optimal set-points of them such\\nthat the running energy cost is minimized (Xiaohong et al., 2010). Electrical and thermal load\\nforecasts as well as gas/electricity pricing and weather forecasts are exploited to achieve this goal.\\nThe problem is cast as mixed integer linear programming provided that all the equipment models\\nare conveniently linearized.\\n10.2.2. Secondary (Coordination) Control Layer\\nThe secondary control is used to perform coordination tasks and is implemented by two dedicated\\ncontrol units:\\n1. Programmable Logic Controller (PLC) and a Supervisory Control and Data Acquisition (SCADA)\\nsystem: This system performs central control of the electrical microgrid. It performs tasks such as\\ndetection, seamless islanding transition and reconnection via a Feeder Management Relay (FMR),\\nas well as load balancing under islanding conditions. This also receives set points from tertiary\\ncontrol for the different subsystems and sends them as inputs to the primary controllers via\\nstandard communications (Modbus) and analog/digital signals. This layer can also include\\nprovision of ancillary services to the utility grid. An overview of the SCADA Human Machine\\nInterface is shown in Figure 10.3. under operation in islanded conditions.\\n2. Building Management System (BMS): Figure 10.3 shows also the BMS for the building heating\\nsystem that implements the local controller algorithms for thermal system components. The two\\nboilers that provide hot water to the main heater are controlled using an On/Off algorithm to\\nregulate the flow temperature to its set-point. A PI algorithm is used to regulate the flow\\ntemperature for each mixing valve. The radiators are modulated by on-off thermostats to maintain\\nzone temperatures close to the user-selected set-points. Figure 10.3 shows the BMS HMI for boiler\\nmanagement and experimental temperature profiles over one week. This is a simple operation\\nexample where the boiler and mixing valve are scheduled to be active at 7am and off at 9pm and\\nduring the weekend (3/23/2013 and 3/24/2013).\\n5/8/22, 3:19 PM Chapter 10: Implementation Experiences from Smart Grid Security Applications and Outlook on Future Research | Smart Grid Security\\nhttps://learning.oreilly.com/library/view/smart-grid-security/9780128023549/B9780128021224000109/B9780128021224000109.xhtml#st0050 10/35\\nFIGURE 10.3 Overview of BMS HMI and system operation\\n10.2.3. Primary (Local) Control Layer\\nThe primary control layer is embedded in the generators and is responsible for assuring the\\nstability of the electrical system and the correct dynamics and power quality. Thermal system local\\ncontrollers are PI for mixing valve control, and On/Off for radiators and boiler control.\\nFigure 10.4 illustrates a detail of the power electronics converter for the battery. A multi-stage\\nDC-DC converter boosts the battery voltage (360-480 V approx.) to 650 V approx. This converter\\nalso controls the DC link voltage using a multi-loop strategy. The three-phase DC-AC converter\\ncontrols the AC-side current in d-q frame using a PI control plus resonators for harmonic\\ncompensation. This control structure for the DC-AC stage (herein shown for grid-follower\\noperation) can be easily completed with an external voltage control for grid-forming operation. The\\nset points for the grid-current are managed by the secondary control layer (the SCADA system),\\nwhich receives inputs such as state of charge and maximum power available from the battery\\nmanagement system.\\n5/8/22, 3:19 PM Chapter 10: Implementation Experiences from Smart Grid Security Applications and Outlook on Future Research | Smart Grid Security\\nhttps://learning.oreilly.com/library/view/smart-grid-security/9780128023549/B9780128021224000109/B9780128021224000109.xhtml#st0050 11/35\\nFIGURE 10.4 Battery inverter local controller (grid-follower strategy)\\nA critical issue related to system stability comes from the fact that the grid impedance in island\\nconditions is significantly larger than that under grid-connected conditions. This can influence\\nsignificantly the current control loop dynamics, so that a controller stable under grid-connected\\nmode can be unstable in island mode. Figure 10.5 illustrates the plan of the current loop for\\ndifferent grid inductances (having feed-forward of grid voltage and considering digital delays). A\\nsubstantial phase and magnitude drop is observed above 400 Hz with large inductance.\\nFIGURE 10.5 Influence of grid-impedance on inner plant dynamics (current-loop) in power converters\\nFigure 10.6 shows results corresponding to an islanding transition. At the time of islanding, the\\nmicrogrid was exporting 18 kW at the point of common coupling. As can be seen, the microgrid\\nremains stable with similar total harmonic distortion (THD) less than 2%. Load balancing\\nalgorithms are applied to compensate the instantaneous power unbalance at the time of islanding,\\nleading to only 3% overvoltage compared to the final steady-state value.\\n5/8/22, 3:19 PM Chapter 10: Implementation Experiences from Smart Grid Security Applications and Outlook on Future Research | Smart Grid Security\\nhttps://learning.oreilly.com/library/view/smart-grid-security/9780128023549/B9780128021224000109/B9780128021224000109.xhtml#st0050 12/35\\nFIGURE 10.6 Experimental Transition from grid-connected (parallel) mode to islanded mode\\nAfter describing low and high level control strategies, it should be also noted that security is\\ntightly connected to a common secure flow of information that is centrally inspected but locally\\ngenerated from the components of the grid. Even in case of a small-scale power plant that requires\\na hierarchical control strategy to assure the optimal operation of all the sub-systems. This involves\\na multidisciplinary approach which includes information and communication technologies (ICT),\\nthat malicious users can exploit. Cyber security attempts can be sourced due to small alert\\ndeactivation that an intruder can perform. Notifications and fake true-positives (on the SCADA\\nlevel) can be easily set up if an intruder will have access to the communication medium and deflect\\nalert messages from its intended recipient. For example, if a smart meter is hacked, not issuing\\nmessages when the battery component of the grid is charging, the SCADA centralized decision\\nalgorithms can go ahead with legitimate but not authorized operations, bringing the battery\\ncomponent to danger, and thus the grid at risk.\\n10.3. Security Measures and Protection\\nMechanisms\\nWith rising levels of automation in European electric power systems, the number of sensors and\\nactuators in SCADA systems is increasing, making field-level control systems more and more\\npowerful, while the smart-metering infrastructure seeks to converge with grid automation systems.\\nCurrently, there are several critical shortcomings in smart grid security technologies. For example,\\nthe resilience of systems for Supervisory Control and Data Acquisition (SCADA) to attacks is one\\nsuch concern, along with cost-effective smart meter authentication and intrusion detection. While\\nmeasures are in place for restoration of physical components of a grid in the event of an attack\\n(CIGRE, 2007, 2008), fast restoration of the smart aspects of the grid remains overlooked. These\\n5/8/22, 3:19 PM Chapter 10: Implementation Experiences from Smart Grid Security Applications and Outlook on Future Research | Smart Grid Security\\nhttps://learning.oreilly.com/library/view/smart-grid-security/9780128023549/B9780128021224000109/B9780128021224000109.xhtml#st0050 13/35\\ndeficiencies in smart grid security need to be addressed by the development of concerned\\ntechnology. As the smart grid concept today depends heavily on increased use of Information and\\nCommunication Technologies (ICT) systems and pervasive interconnectivity to realize its services\\nobjectives, security measures and protection mechanisms have to be always activated, maintained\\nand ready-to-react in case of suspicious events. However, we have to take into account that cyber\\nsecurity risks associated with smart grids are not well understood, and the most effective tools and\\ntechnologies for monitoring and mitigating vulnerabilities are in their infancy. Such a premise can\\nalso be a ‘point’ of breach as security tools and mechanisms have to be utilized by educated\\nSCADA administrators in order to fully exploit their advantages. We review in this section some of\\nthe most common security mechanisms and protection techniques that real smart grids are using in\\norder to prevent proactively cyber security attempts.\\n10.3.1. Intrusion Detection Systems\\nThe operation of electrical utilities relies heavily on SCADA systems. Due to the demand for state\\x02of-the-art means of communication in smart grids, the complexity of SCADA systems and their\\ninterconnections has increased, leaving them vulnerable to a wider range of cyber-security attacks.\\nEven as the legacy components in the grid lack inherent countermeasures against cyber-attacks, the\\nsophistication of attacks in this domain is increasing continuously, with declining need for\\nresources to execute them. With the code for Stuxnet – arguably the most influential malware in the\\ncontext of industrial control systems – in the public domain, its attack vectors and exploits can be\\nadapted towards new targeted attacks.\\nThe contemporary defences against such threats either rely on delayed or overdue security\\npatches, leading to SCADA systems being forced to operate with known vulnerabilities, or the use\\nof existing IT security methodologies that are not fully compatible with SCADA operations, so that\\neven the most mature technology in the IT domain leaves gaping vulnerabilities specific to the\\nsmart grid environment. Intrusion detection and prevention tools specialized for SCADA systems\\nare mostly unripe for implementation (Verba & Milvich, 2008; Coutinho et al., 2009; Carcano et\\nal., 2011). While fiscal, legal and practical issues hinder retrofitting of smart grid SCADA\\nnetworks, an alternative route which correlates temporal and physical status information with\\ntraffic and packet content could add robustness to smart grid communications, along with boosting\\ncapabilities for real-time monitoring of the network and connected devices and generating forensic\\nlogging data.\\nThe Industrial Control Systems Cyber Emergency Response Team (ICS-CERT) has identified\\nseveral design actions for intrusion detection and mitigation in control systems (ICS-CERT, 2012),\\nsuch as SCADA application whitelisting to prevent intruders migrating within networks,\\nimplementing security zones for communications to slow down lateral movement through the rest\\n5/8/22, 3:19 PM Chapter 10: Implementation Experiences from Smart Grid Security Applications and Outlook on Future Research | Smart Grid Security\\nhttps://learning.oreilly.com/library/view/smart-grid-security/9780128023549/B9780128021224000109/B9780128021224000109.xhtml#st0050 14/35\\nof the network (Grimes, 2010), and firewalls/data-diodes to enforce one-way communication\\nbetween network segments.\\nIn summary, a novel mechanism that blends physical knowledge of SCADA and power systems\\nwith emerging network security skills is called for, one that unifies currently disparate approaches\\nfor IT security, such as stateful firewalls, data-diodes, application whitelists and behavioural\\nanalysis, to enable discovery of zero-day vulnerabilities through analysing behaviour and\\nsymptoms.\\n10.3.2. Physical Unclonable Functions- PUFs\\nA physical Unclonable Function (PUF) is a cryptographic function that generates a unique identity\\nfor a device based on the physical attributes of the device that cannot be cloned or mimicked by\\nanother device. A PUF embedded inside a smart meter can be exploited as a natural source of\\ncryptographic keys used to protect the confidentiality of the meter data. While the concept of PUFs\\nis well established, there exist only early proposal to apply it to smart meters.\\nThe original PUFs were based on random optical reflection patterns, now classified as non\\x02electronic PUFs (Tolk, 1992; Pappu et al., 2002). They gave rise to analogue-PUFs which\\nmeasured various electronic attributes like threshold voltages, coating, power distribution and LC\\nvalues. These were followed by intrinsic PUFs, which did not require special fabrication steps and\\ncould be integrated into the same chip as other functions. These measure either random delay\\ndeviations due to silicon process variability, or use the stable settling states of digital memory, but\\npre- and post-processing steps like error correction codes are necessary to ensure resilience and\\nuniqueness of PUF-based keys, which still demand huge administrative effort and human\\nintervention for generation and management in large-scale networks. Cutting-edge PUF classes\\ninclude asynchronous or self-timed logic allowing fastest possible execution of complex functional\\nblocks while increasing the robustness and entropy of PUF-based cryptography, without using\\ncomplex blocks like error correction, reducing the cost of implementation on a device.\\nFundamental strong authentication employing PUFs to generate cryptographic keys securely\\nand automatically inside smart meters could reduce the attack points existing in the Advanced\\nMetering Infrastructure (AMI). Authentication protocols using error correction services and new\\nPUF designs could improve the stability of PUFs and economise on on-chip resources, making\\nPUF-based authentication economically viable for hardware implementation.\\n10.3.3. Advanced Security Analytics\\n5/8/22, 3:19 PM Chapter 10: Implementation Experiences from Smart Grid Security Applications and Outlook on Future Research | Smart Grid Security\\nhttps://learning.oreilly.com/library/view/smart-grid-security/9780128023549/B9780128021224000109/B9780128021224000109.xhtml#st0050 15/35\\nThe primary objective of cyber-security risk assessment is to identify vulnerabilities and threats,\\nand determine their impact. Risk assessment provides a structured process that identifies risks in\\nterms of consequences, their probabilities and their effect on objectives, either qualitatively using\\nthreat graphs and game-theoretic models, or quantitatively by using metrics representing threat\\nprobabilities. There are many conflicting risk assessment methodologies, standards and tools\\n(SISRAM, 2012). A repository is maintained by the European Network and Information Security\\nAgency (ENISA), but none of those have a standard common framework to ensure a minimum\\nlevel of harmonization, which prevents automation of security analysis methodologies. Current\\nrisk assessment frameworks are based on those designed for IT and traditional power grid systems\\nsuch as those described by National Institute of Standards and Technology (NIST) (NIST, 2014),\\nNorth-American Electric Reliability Corporation (NERC) (NERC, 2002), International Society of\\nAutomation (ISA) standards (ISA, 2007), thus not catering to the idiosyncrasies of a smart grid.\\nThis makes it an arduous task to apply one or more of these methods and techniques for any\\nrealistic risk assessment.\\nIt is necessary to merge both cyber and power systems security approaches for risk assessment of\\na smart grid. The existing standards and best practices should be evolved to employ tools that\\nprovide significant insights into threats and security strategies, such as attack graphs and game\\x02theoretic models, in tandem with enhanced algorithms for security analytics using machine\\x02learning techniques to identify previously unknown patterns in the data.\\n10.3.4. Resilient Control Algorithms\\nWith an increasing connectivity, control systems to the Internet and proprietary IT solutions\\nbecoming integral parts of such systems, the security and resilience of critical control systems to IT\\nthreats is a concern that is not completely addressed by incorporating traditional IT security in\\ncontrol design. Control systems utilizing closed-loop schemes, malicious data and actions can enter\\nat any point inside the cyber-physical system and culminate in adverse physical effects on the\\ninfrastructure, even in the case of encrypted communications. Thus, while providing the necessary\\ntools, conventional IT security cannot guarantee comprehensive security of a cyber-physical\\nsystem. The fresh domain of resilient control systems attempts to develop a theory for control\\nsystems with performance that degrades gracefully under unexpected and malicious attacks.\\nAutomatic fault detection systems in control loops can allow dynamic reconfiguration and\\ndisconnection of attacked control loops to restrain the physical system within a safe operating state,\\nbut require detailed dynamic models, something that is not readily available for large-scale power\\ngrids. Even in case of exceptions, these tools are initiated from non-dynamic estimates of state, and\\nare not designed to detect cyber-threats in real time. Bad Data Detection (BDD), which is commonly\\nused by SCADA and Energy Management Systems (EMS), can be circumvented by an attacker with\\n5/8/22, 3:19 PM Chapter 10: Implementation Experiences from Smart Grid Security Applications and Outlook on Future Research | Smart Grid Security\\nhttps://learning.oreilly.com/library/view/smart-grid-security/9780128023549/B9780128021224000109/B9780128021224000109.xhtml#st0050 16/35\\nsome knowledge of power systems, but the key idea of using data measurement redundancy can\\nbe applied to future smart grids making dynamic models and real-time fault detection an\\ninteresting avenue for control system resilience. To achieve this, the possibility of employing\\ndynamic models of power grids to isolate cyber-attacks should be investigated for small- and large\\x02scale and distributed implementation, along with developing methodologies and simulation tools\\nthat can be used to assess the sensitivity and relevance of various components in control loops in\\nsmart grids. Controller hierarchies and overlapping control authority can be exploited for defence\\nagainst unexpected threats.\\n10.4. Anticipated Results: Smart Grid Test-Bed Use\\x02Cases\\nIn this section we review two use-case studies coming from the smart grid infrastructure. We\\ndescribe network vulnerabilities in IEC 61850, which may be discovered by performing fuzz testing\\nof system operations, and secondly perform security analytics in SCADA system data.\\n10.4.1. Network Vulnerabilities in IEC 61850 Smart\\nSubstations\\nIEC 61850 (IEC, 2003) based smart substations have played a significant role in power system\\noperation, becoming increasingly complex and interconnected as state-of-the-art information and\\ncommunication technologies (ICT) are adopted. Although the IEC 62351 standard (International\\nElectrotechnical Commission – IEC, 2007) has provided a framework for the cybersecurity\\ndesign of the IEC 61850 protocol, problems remain and major manufacturers often do not\\nimplement adequate security in their intelligent electronic devices (IEDs) (Hoyos et al., 2012). In\\nrecent years, during the construction of smart substations, utilities and manufacturers have tended\\nto pay more attention on the interoperation of devices and implementation of functions. As a result\\nthere has often been a lack of attention on cyber-security considerations and testing. Research on\\neffective cyber-security for IEC 61850 based smart substations is still at an early stage, and the\\nanalysis of specific vulnerabilities and cyber-attacks is still ongoing.\\n10.4.2. IEC 61850 Based Smart Substation\\n5/8/22, 3:19 PM Chapter 10: Implementation Experiences from Smart Grid Security Applications and Outlook on Future Research | Smart Grid Security\\nhttps://learning.oreilly.com/library/view/smart-grid-security/9780128023549/B9780128021224000109/B9780128021224000109.xhtml#st0050 17/35\\nIn order to realise the essential requirements of smart substation automation systems, i.e. control,\\nmonitoring, and relay protection, IEC 61850 divides the whole system into three logical levels\\n(substation level, bay level, and process level) and ten logical interfaces, as shown in Figure 10.7.\\nFIGURE 10.7 The logical architecture of SCADA systems in smart substations\\nIn Figure 10.7, the meanings of the interfaces (from ① to ⑩) are as follows:\\n1. Protection-information exchange between station and bay level, such as protective action events.\\n5/8/22, 3:19 PM Chapter 10: Implementation Experiences from Smart Grid Security Applications and Outlook on Future Research | Smart Grid Security\\nhttps://learning.oreilly.com/library/view/smart-grid-security/9780128023549/B9780128021224000109/B9780128021224000109.xhtml#st0050 18/35\\n2. Protection-information exchange between bay level and remote protection, for example, data\\nexchange between fibre channels for differential line protection.\\n3. Data exchange within bay level.\\n4. Current transformer (CT) and voltage transformer (VT) instantaneous data exchange (especially\\nsample values) between process and bay level.\\n5. Control-data exchange between process and bay level, for example, generic object oriented\\nsubstation event (GOOSE) trip signals sent from intelligent electronic devices (IEDs) to intelligent\\nterminals.\\n6. Control-data exchange between bay and station level, such as control commands sent from the\\nmonitoring system to IEDs.\\n7. Data exchange between substation (level) and a remote engineer’s workplace.\\n8. Direct data exchange between the bays especially for fast functions such as interlocking.\\n9. Data exchange within station level.\\n10. Control-data exchange between substation (devices) and a remote control centre.\\nA typical network architecture of IEC 61850 based SCADA systems is shown in Figure 10.8. The\\narchitecture consists of the physical level, process level, bay level and substation level.\\n• The physical level includes electronic current transformers (ECT), electronic voltage transformers\\n(EVT), and switchgear.\\n• On the process level, merging units (MUs) are connected in the SV/IEEE1588 network, and\\nintelligent terminal (ITs) are connected in the GOOSE/IEEE1588 network. The process level\\nnetworks are Ethernet switch-based fibre-optic networks.\\n• The bay level IEDs include relays, measure-control devices, fault recorder, network analyser, and\\ntime synchronization IED. The bay level IEDs are connected in the process level networks and the\\nsubstation level network.\\n• The substation level consists of the monitoring system, engineering workstation, SCADA database,\\nand remote terminal unit (RTU). The substation level network, a switch-based cable network,\\nsupports MMS, GOOSE and simple network time protocol (SNTP). The control centre\\ncommunicates with the smart substation using IEC 60870-5-104.\\n5/8/22, 3:19 PM Chapter 10: Implementation Experiences from Smart Grid Security Applications and Outlook on Future Research | Smart Grid Security\\nhttps://learning.oreilly.com/library/view/smart-grid-security/9780128023549/B9780128021224000109/B9780128021224000109.xhtml#st0050 19/35\\nFIGURE 10.8 A typical network architecture of IEC 61850 based SCADA system\\nIn conventional IT security, fuzz testing is regarded as one of the most useful techniques in\\nfinding vulnerabilities of software and protocol implementations (Kim et al., 2011). In protocol\\nfuzzing, a fuzzer can send virtually unlimited test cases using invalid or falsely manipulated data,\\nwithin the framework defined by a given protocol specification, to a protocol implementation. The\\neffective test cases as input information can find security vulnerabilities of the application, which\\nwere not anticipated by the protocol designers or software developers. Therefore, fuzz testing is an\\neffective approach to test and improve the security and reliability of protocol implementations (Sui\\net al., 2011).\\nInjected packets, including abnormal remote commands and set points, may bring a normal\\nprocess into unintended states and/or cause an IEC 61850 server to freeze or other unexpected\\nbehaviours (Reaves & Morris, 2012). Malformed packets transmitted to IEDs may lead to denial of\\nservice by crashing an IEC 61850 protocol stack (Morris et al., 2011). One of the mitigation\\nmeasures for the malformed packet attack is to test the robustness of IEDs using the fuzzing\\ntechnology to identify potential vulnerable points.\\nIEC 61850, based on an object-oriented modelling approach, adopts state machines to define and\\ndelineate complex protocol service and functional behavior of IEDs. In terms of security and\\nreliability testing for the IEC 61850 communication stack, the IEC 61850 protocol is more difficult to\\ntest than those without state machines. In addition, the IEC 61850 based IEDs to be tested in smart\\n5/8/22, 3:19 PM Chapter 10: Implementation Experiences from Smart Grid Security Applications and Outlook on Future Research | Smart Grid Security\\nhttps://learning.oreilly.com/library/view/smart-grid-security/9780128023549/B9780128021224000109/B9780128021224000109.xhtml#st0050 20/35\\nsubstations have complicated logical models, including numerous logical nodes, data, and data\\nattributes. Current testing approaches for protocol security and reliability are based on capturing,\\nmutating, and then replaying messages between the tester and the IED. However, due to the\\ncomplexity of IEC 61850, conventional testing methods may be inefficient when replaying too\\nmany redundant packets. An additional issue is that when an IED freezes and does not respond to\\nthe client, due to a malformed packet sent by the tester, the test process has to stop.\\nIn this case study an automatic fuzz testing approach is used to test the security and reliability of\\nthe IEC 61850 protocol stack, as well as the robustness of IEC 61850 based IEDs. The core idea of\\nthe IED robustness testing is to send test cases with malformed messages to the IED, and then\\ncheck the communication status of the IED. The robustness of the IED depends on its response to\\nthe malformed messages. For test cases with the same malformed message, the more unhandled\\nexceptions and unexpected behaviours there are, the worse the robustness of the IED. The\\nproposed fuzzing approach used is a black box testing method, which only needs to know the IEC\\n61850 protocol, rather than the specific implementation of communication module inside the IED\\n(Jiang et al., 2014).\\nIn order to implement the above fuzz testing method, a test platform, such as shown in Figure\\n10.9, can be tailored for security testing of IEC 61850, using a fuzzing simulator, IEDs, a remote\\x02controlled power strip, and a switch.\\n5/8/22, 3:19 PM Chapter 10: Implementation Experiences from Smart Grid Security Applications and Outlook on Future Research | Smart Grid Security\\nhttps://learning.oreilly.com/library/view/smart-grid-security/9780128023549/B9780128021224000109/B9780128021224000109.xhtml#st0050 21/35\\nFIGURE 10.9 A test-bed for fuzz testing of IEC 61850\\nThe fuzzing simulator runs the fuzz testing method as an IEC 61850 client. The IEDs are IEC\\n61850 based servers, such as real protection relays, as well as measurement and control devices.\\nThe Ethernet switch connects the fuzzing simulator and the IEDs. The power strip in Figure 10.9\\ncan be remotely controlled by the simulator in order to turn on or off the IEDs. The fuzz testing\\nsteps may be executed as follows:\\n1. As an IEC 61850 client, the fuzzing simulator accesses the IED as an IEC 61850 server. In this case,\\nthe normal communication is built between the IEC 61850 client and the server in the test-bed, and\\nnormal communication packets are captured, e.g. via Wireshark.\\n2. In the fuzzing simulator, the collected messages are pre-processed by removing useless and\\nredundant data, in order to generate a set of initial sample messages. A number of test cases with\\n5/8/22, 3:19 PM Chapter 10: Implementation Experiences from Smart Grid Security Applications and Outlook on Future Research | Smart Grid Security\\nhttps://learning.oreilly.com/library/view/smart-grid-security/9780128023549/B9780128021224000109/B9780128021224000109.xhtml#st0050 22/35\\nmalformed messages are constructed from the sample messages, using mutation-based fuzzing\\nmethods.\\n3. During the fuzz testing process, the malformed messages are automatically sent to the IEDs one by\\none, and the malformed messages which cause the IED communication failure or status exception\\nare recorded into a log file.\\n4. The fuzzing simulator should automatically detect the status of the IED tested. If the IED is crashed\\ndue to the test, the fuzzing simulator will send a control command to the remote-controlled power\\nstrip to restart the crashed IED, so that the fuzz testing can continue to test the next malformed\\npacket after the IED restarted.\\n5. After the fuzz testing, the robustness reports of the tested IEDs are generated according to the\\nability of IEDs to addressing malformed packets.\\nIn general the results at the time of publishing typically show that most IEDs exist with cyber\\nvulnerabilities with varying associated levels of risk. The common issues encountered for IEDs\\ninclude:\\n• The human machine interface (HMI) of the IED tested has no response\\n• The communication programming of the IED is overflowed\\n• The IED cannot connect normally to the monitoring system\\n• The IED cannot communicate with the RTU\\n• The dispatcher in the control centre cannot remotely control the IEDs in smart substations\\nThe clear consequence for control systems that use IEDs with the above vulnerabilities is that an\\nattacker can severely disrupt the management and control of the underlying physical systems via a\\nrange of malformed packets. For mitigation, several steps should be taken. The first obvious step is\\nthe robust testing and patching of devices by manufacturers. For users, as has been covered in\\nprevious chapters, there is a requirement for protection and monitoring of the network\\nenvironments in which the IED devices are used. Particular cyber-security mechanisms should\\ninclude clear segregation of functionally different network domains, protected by firewalls, with\\ndevices such as IEDs contained in security zones with strict cyber-security policy enforcement.\\nZones containing with the most functionally critical assets, such as the IEDs, should also be\\ncarefully monitored with intrusion detection systems, tailored to the network and devices\\ncharacteristics and security policies of that security zone.\\n10.4.3. Security Analytics in SCADA Systems\\nSecurity analytics, at its heart, checks for consistency among the different variables accrued from a\\nSCADA system. The key idea behind such a consistency check is that if only a subset of the sensors\\nare manipulated by an attacker, the values that they communicate will not conform to the values\\nmeasured by the unattacked sensors. When it comes to smart grids, smart meters form an\\n5/8/22, 3:19 PM Chapter 10: Implementation Experiences from Smart Grid Security Applications and Outlook on Future Research | Smart Grid Security\\nhttps://learning.oreilly.com/library/view/smart-grid-security/9780128023549/B9780128021224000109/B9780128021224000109.xhtml#st0050 23/35\\naxiomatic component of the grid. These smart meters communicate back values of dozens of\\nvariables at every time step. However, not all of these variables are measured — the meter\\nmeasures a few values, and all other variables are calculated by using physical formulae involving\\nthese few measurements.\\nMost typically, the meter will measure the RMS values of the phase-to-neutral voltages (V , V ,\\nV ), the RMS currents through each phase and neutral (I , I , I , I ), and the average active power\\nthrough each phase (P , P , P ). From these ten measured values, Kirchhoff’s Voltage and Current\\nLaws, Ohm’s Law, and other physical and geometrical formulae will allow the meter to calculate\\nthe remaining variables: The phase-to-phase voltages (V , V , V ), the reactive (Q , Q , Q )\\nand apparent (S , S , S ) powers through each phase, the total active (P), reactive (Q) and apparent\\n(S) powers, and the total positive and negative active, reactive and apparent energies. Some meters\\nalso provide the aggregate power factor, albeit there being no uniform agreement over its\\ndefinition. Some meters could even be designed to measure a few of the values which can be either\\ncalculated or measured (like the phase-to-phase voltages).\\nAll this data, from all the meters can be collected and physical equations can be used to cross\\x02check the reconciliation of their outputs (within a certain allowable error). Such verification can\\nprove invaluable in the cases where one or more of the meters have been manipulated to measure\\nincorrect values. There is room, however, for a simpler verification on a smaller scale.\\nIn October 2014, cyber-security researchers managed to remotely shut down power supplies to\\nhouseholds, tamper with meter readings, and insert malicious worms into the meters by hacking\\nthe reprogrammable chips inside smart meters in Spain (Illera & Vasquez-Vidal, 2014). In such an\\nattack, the attacker has to modify the readings communicated by the meter to the utility. If the\\nutility implements cross-checking equations for intra-meter values, the number of variables that the\\nattacker needs to modify to maintain consistency multiplies.\\nAs an example, consider just the voltages in the grid. The meter measures the phase-to-neutral\\nvoltages (V , V , V ), and either measures or calculates the phase-to-phase voltages (V , V ,\\nV ). However, as shown in Figure 10.10, it is clear that these six values are not independent. In\\nthe phasor notation, they form four triangles. Geometrically, if each of these angles subtended by\\nthe three smaller triangles at the origin is calculated using the cosine formula, they should add up\\nto 360° (or 2π radians). Thus, one of the consistency checks can use the equation:\\nA B\\nC A B C N\\nA B C\\nAB BC CA A B C\\nA B C\\nA B C AB BC\\nCA\\n5/8/22, 3:19 PM Chapter 10: Implementation Experiences from Smart Grid Security Applications and Outlook on Future Research | Smart Grid Security\\nhttps://learning.oreilly.com/library/view/smart-grid-security/9780128023549/B9780128021224000109/B9780128021224000109.xhtml#st0050 24/35\\nFIGURE 10.10 Phasor Diagram of Grid Voltages\\nHowever, it is unreasonable to expect the formulae to yield perfect agreement in nominal\\nconditions, due to many factors such as synchronicity of measurements, accuracy, etc., which\\nmakes it necessary to allow for a certain error while cross-validation. The intra-meter equations are,\\nmore often as not, of an implicit form. In addition, several variables, such as currents and powers,\\n5/8/22, 3:19 PM Chapter 10: Implementation Experiences from Smart Grid Security Applications and Outlook on Future Research | Smart Grid Security\\nhttps://learning.oreilly.com/library/view/smart-grid-security/9780128023549/B9780128021224000109/B9780128021224000109.xhtml#st0050 25/35\\ncould very well be zero at any time, and might cause divide-by-zero errors in some formulae. Thus,\\nit is advisable to consider the distribution of the deviations of the actual values from the calculated\\nvalues.\\nOne method is to construct a histogram of historical data (when the system is known to have\\nbeen in an unattacked state), and calculate the probability of the deviation experienced by the real\\x02time measurements during cross-validation. If too many cross-validations yield discrepancies that\\nhave a low probability, it would be fair to assume that something is wrong in the meter firmware,\\nmost probably an attack. A security analytics display that checks this could look similar to Figure\\n10.11, where 19 cross-checking equations are calculated at each time, and coloured grey\\n(probability > 68.63%), light grey (4.55% < probability < 68.63%), dark grey (4.55% < probability <\\n0.3%), or faded grey (probability < 0.3%), the values being chosen to match 1σ, 2σ, and 3σ normal\\nvariations even for other distributions for consistency reason.\\nFIGURE 10.11 Intra-Meter Security Analytics\\nThis methodology also provides a way for multiple levels of security analysis. For example, at\\nthe end of the day, a comparison could be made between the day’s distributions of errors with the\\nhistorical histograms, using a measure of distance such as the Bhattacharyya distance. If the\\ndistance is higher than expected, there could be a problem with the meter. In Figure 10.11, this\\n5/8/22, 3:19 PM Chapter 10: Implementation Experiences from Smart Grid Security Applications and Outlook on Future Research | Smart Grid Security\\nhttps://learning.oreilly.com/library/view/smart-grid-security/9780128023549/B9780128021224000109/B9780128021224000109.xhtml#st0050 26/35\\nwould correspond to checking whether 68.63% of the area is coloured grey, 26.82% is coloured light\\ngrey, 4.25% is dark grey, and 0.3% is faded grey.\\n10.5. Conclusion and Look Ahead\\nIt is a clear fact that in the smart grid concept energy and security systems have been designed\\nseparately for both demand and supply. Industry today on the other hand, focuses on the\\ndevelopment of next-generation integrated security and energy management solutions. The\\nprimary focus is controlling power on district level (buildings interconnections), where\\nrequirements are more specific, generally aiming to provide security, comfort, and secure and\\nefficient energy supply, particularly for critical loads. According to real world implementation\\nexperiences, a known problem occurs in the grid when the demand side requires more energy than\\nthe maximum provided by the smart grid. This can, in the worst case, lead to a shutdown of all the\\ndemand loads and supply devices, including the critical demand systems. Such a premise can for\\nsure raise security awareness of ICT people while smart grid control engineers on the same line,\\ndesign resilient control algorithms for the individual grid components.\\nNowadays smart grid control engineers face a new challenge when managing distributed energy\\nsystems; they have to minimize the total energy consumption without confining performance or\\nsecurity standards, while maintaining a certain level of functionality of the grid for safety purposes.\\nMeanwhile, as ICT attacks and cyber-physical hacking is rapidly expanding composing a regular\\n“top news” label in the security community blogs, newly introduced security mechanisms have to\\nbe validated with respect to realistic smart grid operating conditions, such as in test-beds with a\\nfocus on protecting communication infrastructures and, above all, human lives. First experiences\\non smart grid demonstrations reveal that new architectures emerge from the requirements of new\\nuse cases and actors, being expanded on top of existing grid infrastructures. This leads to\\ninterconnecting existing subsystems with new ones, which inherently implies an enlargement of\\nthe grid’s attack surface, and so requires considering new risk mitigation measures. This must be\\ndone by taking into consideration the potential impact of an attack to the end-to-end electrical\\nsystem stability for each use case. New approaches to manage cyber contingencies in a consistent\\nway can be found in the domains of advanced intrusion detection systems, security analytics based\\non data mining and clever clustering techniques as well as physical unclonable functions for smart\\nmeter protection.\\nAcronyms\\n5/8/22, 3:19 PM Chapter 10: Implementation Experiences from Smart Grid Security Applications and Outlook on Future Research | Smart Grid Security\\nhttps://learning.oreilly.com/library/view/smart-grid-security/9780128023549/B9780128021224000109/B9780128021224000109.xhtml#st0050 27/35\\nAMI\\nAdvanced Metering Infrastructure\\nAPT\\nAdvanced Persistent Threat\\nBDD\\nBad Data Detection\\nBMS\\nBuilding Management System\\nCHP\\nCombined Heat and Power (Unit)\\nCT\\nCurrent Transformer\\nECT\\nElectronic Current Transformer\\nEVT\\nElectronic Voltage Transformer\\nEMS\\nEnergy Management System\\nFMR\\nFeeder Management Relay\\nGOOSE\\nGeneric Object-oriented Substation Event\\nHVAC\\nHeating, Ventilation, and Air Condition\\nIED\\nIntelligent Electronic Device\\nIC\\nInternal Combustion\\nICS\\nIndustrial Control System\\nISA\\nInternational Society of Automation\\nIT\\nIntelligent Terminal\\nMU\\nMerging Unit\\nNERC\\nNorth-American Electric Reliability Corporation\\nNIST\\nNational Institute of Standards and Technology\\nPLC\\nProgrammable Logic Controller\\nPLL\\nPhase-Locked Loop\\nPWM\\nPulse Width Modulation\\nRAT\\nRemote Access Control\\nRMS\\n5/8/22, 3:19 PM Chapter 10: Implementation Experiences from Smart Grid Security Applications and Outlook on Future Research | Smart Grid Security\\nhttps://learning.oreilly.com/library/view/smart-grid-security/9780128023549/B9780128021224000109/B9780128021224000109.xhtml#st0050 28/35\\nRoot Mean Square\\nROS\\nRugged Operating System\\nRTU\\nRemote Terminal Unit\\nSCADA\\nSupervisory Control and Data Acquisition\\nSNTP\\nSimple Network Time Protocol\\nTHD\\nTotal Harmonic Distortion\\nVT\\nVoltage Transformer', 'MIPRO 2016, May 30 - June 3, 2016, Opatija, Croatia\\n\\nGoing White Hat: Security Check by Hacking \\nEmployees Using Social Engineering Techniques \\n\\nZrinka Lovrić Švehla, Ivan Sedinić and Luka Pauk\\nHrvatski Telekom d.d./ Data and Cyber Security Section, Zagreb, Hrvatska \\nzrinka.lovric@t.ht.hr; ivan.sedinic@t.ht.hr; luka.pauk@t.ht.hr  \\n\\nAbstract – Information security is built on top of three basic \\nbuilding  blocks:  people,  processes  and  technology.  Even \\nwhen  organization  has  very  refined  processes  and  state  of \\nthe  art  technology,  people  usually  remain  the  weakest  link \\nin  the  security  chain.  Social  engineering  is  the  practice  of \\nobtaining  confidential  information  or  valuable  assets  by \\nmanipulation  of \\nlegitimate  users  or  owners.  Large \\ntelecommunication  companies,  having  large  customer  base \\nand  a  broad  collection  of  sensitive  data,  present  a  very \\ninteresting target for social engineering attacks. In order to \\nidentify the risks for the business, penetration testing can be \\nused  as  a  method  for  determining  organizational  resilience \\nagainst  malicious  attack  attempts.  Usually  these  tests  are \\ndone  using  technical  methods,  but  non  technical  methods \\nlike  social  engineering  can  also  be  employed.  In  this  paper \\nwe  present  a  case  study  of  a  penetration  test  using  social \\nengineering techniques targeting a large telecommunication \\nin Croatia. We describe the preparation process, techniques \\nused for testing, results and lessons learned. \\n\\nI.\\n\\nINTRODUCTION\\n\\nThe  need  for  protection  of  assets  is  present  in  every \\nbusiness.  Companies  create  security  policies  and  other \\ndocumentation to set the rules that should help in building \\nthe  level  of  security  awareness  and  to  help  protect \\ncompany\\'s  valuable  assets.  Numerous  security  processes \\nare  being  defined  to  prevent  and  to  minimize  the  risk \\nrelated to both internal and external misuse and fraud, as \\nwell  as  to  minimize  the  damage  when  misuse  or  fraud \\noccurs.  State  of  the  art  security  solutions  are  being \\nimplemented  to  assure  protection  and  security  of  assets \\nlong term. If people who work for and in the company are \\nnot aware of security threats and importance of company\\'s \\nassets  and  if  they  are  easily  susceptible  to  manipulation \\n[4], there is no security tool or document that will prevent \\nleakage of information, misuse of assets or fraud. One of \\nthe hardest threats to handle is social engineering. The art \\nof manipulation put in practice, with the goal of obtaining \\nconfidential  information can  easily  cause  serious damage \\nto  the  company  that  is  vulnerable  to  social  engineering. \\nSocial  engineering  is  a  blend  of  science,  technology  and \\nart [5]. It is not always negative and there is no person in \\nthe world that did not use it at least once, in order to get \\nwhat he or she wants. When put in business perspective, it \\nis  among  the  highest risks  for  the company,  especially  if \\nthe target is being hacked live – by other person. \\n\\nIn  this  article  we  present  a  short  overview  of  what \\nsocial  engineering  is,  how  penetration  testing  by  using \\nsocial  engineering  techniques  was  performed,  what  was \\nthe outcome of it and lessons learned. \\n\\nII.\\n\\nSOCIAL ENGINEERING\\n\\ninformation  or  performing  actions \\n\\nSocial  engineering  is  combination  of  techniques  used \\nby  malicious  attackers  to  divulge  victims  in  enclosing \\nconfidential \\nto \\ncompromise information security, by exploiting the flaws \\nin  human  logic  [2].  It  is  categorized  into  two  categories: \\nhuman  based  and  technology  based.  Three  main  forms \\nare: \\n\\n(cid:2) Phishing  -  The  practice  of  sending  emails \\nappearing  to  be  from  reputable  sources  with \\nthe  goal  of  influencing  or  gaining  personal \\ninformation. \\n\\n(cid:2) Vishing: The practice of eliciting information \\nor  attempting \\ninfluence  action  via  \\ntelephone,  may  include  such  tools  as  “phone \\nspoofing“\\n\\nto \\n\\n(cid:2) Impersonation:  The  practice  of pretexting  as \\nanother  person  with  the  goal  of  obtaining \\ninformation  or  access  to  a  person,  company, \\nor computer system. [5] \\n\\nThe  behavioral  component  is  very  important  for \\n\\nsuccess of performing social engineering activities [1]. \\n\\nThere  are  different  categories  of  people  who  perform \\nsocial  engineering  activities:  hackers,  penetration  testers, \\nspies,  identity  thieves,  evil  employees,  recruiters,  sales \\npeople, governments, and ordinary people [5].\\n\\nCommon  social  engineering  vector  attacks  are: \\nimpersonation,  dumpster  diving,  shoulder  surfing,  false \\ntrust, and web sites [5]. Each of them has its upsides  and \\ndownsides and that is the reason why the common case is \\nthe combination of those.  \\n\\nIn order to achieve their goals, the attackers are using \\ndifferent  tools:  applications,  burner  phones,  caller  ID \\nspoofing,  cameras,  GPS  trackers,  recording  devices  and \\nsimilar [5].\\n\\nVictims  will  be  more  susceptible  to  successful  social \\nengineering  attack \\nis  psychology  driven \\nthere \\npersonality trait like diffusion of responsibility, chance for \\nintegration, guilt or trust relationship [3]. \\n\\nif \\n\\nTypical  social  engineering  attack  consists  of  four \\n\\nsteps: \\n\\n1. Information gathering \\n\\n2. Relationship development \\n\\nAuthorized licensed use limited to: Ryerson University Library. Downloaded on May 01,2022 at 01:35:21 UTC from IEEE Xplore.  Restrictions apply. \\n\\n1419\\n\\n\\x0c3. Exploitation \\n\\n4. Execution \\n\\nIII.\\n\\nRESEARCH PROBLEM\\n\\nto \\n\\nthe  organization \\n\\nBeing one of the largest telecommunication companies \\nin  Croatia, \\nis  continuously  facing \\nnumerous threats to its security. Significant part of threats \\nis targeted towards obtaining customer data. Organization \\nhas  more  than  one  thousand  employees  who,  based  on \\ntheir job description, need to have access to personal data \\nof  customers  or  employees,  via  databases,  self-care \\nportals, social networks or interactive voice response tools \\n(IVR).  These  people  are  trained  to  be  helpful  and  to  put\\nthe  customer  (internal  or  external, \\nthe  service \\ndepending on the position) as a first priority. The level of \\ntheir  security  awareness  is being  constantly built  through \\nvarious  educations,  e-learning  sessions,  posters  and \\nworkshops. The data that these employees have access to \\nis a very valuable asset to the company and therefore any \\nmisuse  could  cause  serious  reputation  and  financial \\ndamage. Since many employees have access to one of the \\nmost  sensitive  category  of  data  that  company  has, \\ninformation  security  department  decided  to  conduct  a \\nthe \\npenetration \\norganizational  security  posture  against  social  engineering \\nattacks. \\n\\nspecifically  asses \\n\\nthat  will \\n\\ntest \\n\\nIV.\\n\\nTEST PREPARATIONS\\n\\nPenetration \\n\\ntest  was  planned  and  managed  by \\ndepartment  responsible  for  information  security.  The \\norganization  has  established \\ninternal  procedure  for \\nplanning  and  conducting  penetration  tests,  which  defines \\nthat  following  needs  to  be  defined  in  the  preparation \\nphase: \\n\\n(cid:2)\\n\\n(cid:2)\\n\\n(cid:2)\\n\\n(cid:2)\\n\\n(cid:2)\\n\\nscope of the testing, \\n\\ntester\\'s initial level of access, \\n\\ntesting methodology, \\n\\nprimary goals of the test, \\n\\nnext steps. \\n\\nMost critical part of the preparation phase is defining \\nthe scope of the test. Improperly defined scope can cause \\nserious  problems,  because  testers  could  unexpectedly  go\\n\"out of scope\" and perform potentially damaging tests on \\nproduction  systems  and  other  critical  organizational \\nassets.  When  defining \\ntechnical \\npenetration test, this is usually done by listing systems and \\ntheir  location  (IP  addresses,  URLs,  etc.).  With  social \\nengineering  this  is  much  more  challenging,  because \\nboundaries are not so well defined. In our particular case, \\nthe  scope  was  defined  by  listing  contacts  (email,  phone, \\nsocial networks) testers can use, which were also publicly \\navailable on company\\'s portal. \\n\\nthe  scope  of \\n\\nthe \\n\\nDefining \\n\\nlevel  of  access \\ninfluences \\n\\nis  also \\ninitial \\ntester\\'s \\nimportant,  because \\ntesting \\nit  drastically \\nscenarios. For example,  we  could  give  testers the role of \\nto  nothing), \\nthe  complete  outsider  (having  access \\nemployee  (having  access  to  internal  resources),  vendor \\n(having  limited  maintenance  access  to  some  resources), \\netc.  In  our  case,  it  was  decided  that  testers  will  have \\n\\ncustomer\\'s role. This means that they already use some of \\nthe company\\'s services and have access to a customer self-\\ncare portal.  \\n\\nTesting  methodology  was,  of \\n\\nsocial \\nengineering, with the primary goal of unauthorized access \\nto customer\\'s data.  \\n\\ncourse, \\n\\nBefore the test begins, it is crucial to have appropriate \\nauthorizations. \\n  In  our  case,  the  authorization  was \\nrequested from the director of the department in the scope \\nof the test, and from responsible board member. However, \\nthe  decision  still  remains  if  personnel  “targeted”  with  a \\ntest  should  be  informed.  When  testing  using  technical \\nmethods,  it  is  usually  advisable  to  inform  the  system \\noperators  and  other  personnel,  so  they  can  properly \\nmonitor  the  system  and  report  any  potential  problems. \\nHowever,  one  could  argue  if  this  approach  is  better, \\nbecause  it  could  skew  the  testing  results.  When  testing \\nusing  social  engineering,  this  argument  is  even  more \\nconvincing. Employees with the knowledge they are being \\n“tested”  could  became  more  distrusting  and  significantly \\nalter  their  behavior.  In  our  case,  it  was  decided  that \\nemployees will not be informed, but we believe this isn\\'t \\nnecessary  the  recommended  approach  and  that  decision \\nshould be done on a case by case basis. \\n\\nPartner company specialized in providing information \\nsecurity  services  was  hired \\ntest. \\nAppropriate  written  authorization  with  clearly  defined \\nscope  was  issued  to  them,  in  order  to  minimize  the \\nchances of misunderstandings and legal issues. \\n\\nto  conduct \\n\\nthe \\n\\nIt was decided that no special accounts will be opened \\nfor the purpose of the testing. Partner company themselves \\nensured  they  have  appropriate  customer  accounts  which \\nwere belonging to real persons. These persons authorized \\nthe testing using their data and it was decided that all test \\nwill be done using or targeting their data.  \\n\\nV.\\n\\nMETHODOLOGY\\n\\nPenetration  testing  was  done  in  the  real  environment \\n\\nand on the real data.  \\n\\nThe goals of the testing were: \\n\\n(cid:2)\\n\\n(cid:2)\\n\\n(cid:2)\\n\\ncheck  the  possibility  of  access  to  data  that \\nshould  not  be  available  without  clear \\nverification \\nthe \\ncustomer, \\n\\nauthentication  of \\n\\nand \\n\\ncheck the possibility of customer\\'s data \\nmanipulation or change by avoiding to \\nprovide the data needed for verification and \\nauthentication, \\n\\nbased on the penetration testing results, \\nprovide the guidelines for improvement of \\nprocesses. \\n\\nThe testing  lasted  6 days  with  the  schedule presented \\nin  Table  1.  Penetration  testing  started  by  gathering \\ninformation  via  phone  calls,  social  networks  and  e-mail. \\nDuring  all  four  phases  (information  gathering,  building \\nrelationship,  exploit  and  execution),  different  social \\nengineering  methods  were  used,  as  described  in  Table  2.\\nThese  methods  were  selected  in  order  to  assure  that \\n\\nAuthorized licensed use limited to: Ryerson University Library. Downloaded on May 01,2022 at 01:35:21 UTC from IEEE Xplore.  Restrictions apply. \\n\\n1420\\n\\n\\x0ccollected information is true and independent. No special \\ntools were used, just the land line, mobile phone with SIM \\ncards from different telecom operators, laptop and Internet \\nservices.  \\n\\nExamples of attacks include: \\n\\n(cid:2)\\n\\n(cid:2)\\n\\n(cid:2)\\n\\nattempting to reset  customer’s password without \\nappropriate authorization,  \\n\\nordering  /  buying  services    without  appropriate \\nauthorization, \\n\\nchanging tariffs, changing options, etc. \\n\\nUsually the tester would try to convince the employee he \\nneeds to do this while claiming he doesn’t have access to \\ndata  or  resources  needed  for  authorization  (lost  ID  card, \\nlost phone, etc.).  \\n\\nDay 1 \\n\\nDay 2\\n\\nDay 3\\n\\nDay 4\\n\\nDay 5\\nDay 6\\n\\nMethod\\nTrust\\n\\nHelp\\nAccess to easily \\naccessible \\ninformation\\nKnowing internal \\nprocesses\\n\\nClout\\n\\n(cid:2) Information gathering \\n(cid:2) Initial (test) calls and calls related to \\nidentification of protection process \\n\\n(cid:2) Emails sending planning \\n(cid:2) Start of communication with social \\n\\nnetworks services \\n(cid:2) Phone calls (daily)\\n(cid:2) Emails\\n(cid:2) Planning of escalations and new calling \\nmodels, selection of key methods for \\nadditional testing\\n\\n(cid:2) Emails analysis\\n(cid:2) Phone calls\\n(cid:2) Phone calls (daily and nightly)\\n\\n(cid:2) Phone calls (daily and nightly)\\n(cid:2) Making report\\nTable 1: Testing schedule \\n\\nCharacteristics\\nCreation of trust with the person that tester \\nis speaking to in order to get confidential \\ninformation\\nReverse engineering\\nAccess to information that seem easily \\naccessible\\n\\nAccess to information pretending to be \\ninternal employee\\nUsage of information that point to \\nknowledge about internal processes\\nAccess to information pretending that \\nhigher instance/manager is included in \\ncommunication\\n\\nTable 2: Testing methods \\n\\nVI.\\n\\nRESULTS\\n\\nin \\n\\nsix \\n\\ntesting \\n\\nresulted \\n\\nPenetration \\n\\nidentified \\nvulnerabilities: one high, three medium and two low risk. \\nRisk  methodology  was  provided  by  the  partner  company   \\nand \\nit  used  a  qualitative  approach.  The  standard \\nquantitative vulnerability risk scoring (like CVSS, usually \\nrequested  for  technical  tests)  wasn\\'t  used,  because  it  was \\ndifficult  to apply it to non-technical findings   Risk level \\ndescription  is  given  in Table 3.  For each  one of  findings \\nthe  recommendation  in  sense  of  a  countermeasure  was \\ngiven. \\n\\nSomewhat  unexpected \\n\\nthat  most \\nsuccessful  exploits  were  not  based  on  persuasion \\ntechniques, but on employees’ mistakes and lack of proper \\n\\nfinding  was \\n\\nknowledge  of  the  process.  In  some  cases,  documented \\ninstructions were not clear enough and it was apparent that \\nemployees  are  overwhelmed  with  information \\nin  a \\nrelatively  complex  environment.  These  problems  cannot \\nbe addressed with security awareness trainings, since lack \\nof awareness is not the primary cause, but more analytical \\napproach is required with the primary goal of making the \\nemployee’s work more simple and straightforward.\\n\\nRisk level \\nCritical\\n\\nHigh\\n\\nMedium\\n\\nLow\\n\\nInformative\\n\\nDescription \\n\\nBy exploiting critical risk level \\nvulnerability, privileged access to data or \\nsystems can be gained.\\nBy exploiting high risk level vulnerability, \\nnon privileged access to data or systems can \\nbe gained, with customers\\' privileges, as \\nwell as access to customers\\' sensitive data.\\nBy exploiting medium risk level \\nvulnerability limited access with customer \\nprivileges can be gained or the attacker can \\naccess as a customer.\\nBy exploiting low level risk vulnerability, \\nthe attacker can obtain the information about \\nsystems, about customers or other \\ninformation that can be useful in future \\nattacks.\\nBy exploiting informative risk \\nvulnerabilities, no damage can be made and \\nthose are just for your information.\\n\\nTable 3: Risk levels \\n\\nOperational  recommendations  (OR),  as  well  as \\n\\nstrategic ones (SR) were also given: \\n(cid:2) OR1:  define  and \\n\\nimplement  unambiguous \\n\\ncustomer identification process \\n\\n(cid:2) OR2: make security checklist for every process: \\nif  the  customer  wants  to  change  something \\nregarding  his  personal  data  or  subscription  to \\nservices,  the  employee  has  to  fulfill  the  check \\nlist – to control if all the needed security checks \\nhave been done \\nSR1: educate all personnel on security and social \\nengineering \\nSR2:  monitor  the  implementation  of  security \\ncheck lists from OR2 \\nSR3:  continuous  penetration  testing  on  broader \\nscope \\n\\n(cid:2)\\n\\n(cid:2)\\n\\n(cid:2)\\n\\nIn  the  follow-up  meeting,  these  recommendations \\nwere  used  to  create  action  points  with  appropriate \\nresponsible  persons  and  deadlines.  Customer\\'s  accounts \\nused  for  the  testing  were  reversed  to  original  state. \\nPartner  company  was  asked  to  destroy  all  confidential \\ndata gathered during the test. \\n\\nVII.\\n\\nCONCLUSION\\n\\nThere  is  no  company  that  is  immune  to  social \\nengineering. Penetration testing done in one of the biggest \\ntelecommunication  companies \\nit. \\nDespite  continuous  educations  and  building  up  security \\nawareness  of  all  employees,  especially  ones  who  have \\naccess  to  customer  data,  the  company  is  vulnerable. \\nPeople are leaving the company, the new ones are coming. \\nEveryone  can  have  a  bad  day  or  just  want  to  be  as \\n\\nin  Croatia  proved \\n\\nAuthorized licensed use limited to: Ryerson University Library. Downloaded on May 01,2022 at 01:35:21 UTC from IEEE Xplore.  Restrictions apply. \\n\\n1421\\n\\n \\n\\x0cefficient as possible in reaching his daily targets or simply \\nthe  internal  process  is  too  complicated.  All  of  this \\nincreases  chances  for  successful  social  engineering \\nin  everyday \\nattacks.  Besides  security  checkpoints \\nprocesses  and  powerful \\nthe  continuous \\neducation  is  the  key  to  minimizing  the  risk  related  to \\nsocial engineering. \\n\\ntechnology, \\n', 'How secure is your cache against side-channel a!acks?\\nZecheng He\\nPrinceton University\\nPrinceton, NJ\\nzechengh@princeton.edu\\nRuby B. Lee\\nPrinceton University\\nPrinceton, NJ\\nrblee@princeton.edu\\nABSTRACT\\nSecurity-critical data can leak through very unexpected side chan\\x02nels, making side-channel attacks very dangerous threats to informa\\x02tion security. Of these, cache-based side-channel attacks are some\\nof the most problematic. This is because caches are essential for\\nthe performance of modern computers, but an intrinsic property of\\nall caches – the different access times for cache hits and misses –\\nis the property exploited to leak information in time-based cache\\nside-channel attacks. Recently, different secure cache architectures\\nhave been proposed to defend against these attacks. However, we do\\nnot have a reliable method for evaluating a cache’s resilience against\\ndifferent classes of cache side-channel attacks, which is the goal of\\nthis paper.\\nWe first propose a novel probabilistic information flow graph\\n(PIFG) to model the interaction between the victim program, the\\nattacker program and the cache architecture. From this model, we\\nderive a new metric, the Probability of Attack Success (PAS), which\\ngives a quantitative measure for evaluating a cache’s resilience\\nagainst a given class of cache side-channel attacks. We show the\\ngenerality of our model and metric by applying them to evaluate\\nnine different cache architectures against all four classes of cache\\nside-channel attacks. Our new methodology, model and metric can\\nhelp verify the security provided by different proposed secure cache\\narchitectures, and compare them in terms of their resilience to cache\\nside-channel attacks, without the need for simulation or taping out a\\nchip.\\nCCS CONCEPTS\\n• Security and privacy → Side-channel analysis and counter\\x02measures; • General and reference → Evaluation; • Computer\\nsystems organization → Processors and memory architectures;\\nKEYWORDS\\nCache, side-channel attack, security modeling, quantification\\nACM Reference Format:\\nZecheng He and Ruby B. Lee. 2017. How secure is your cache against\\nside-channel attacks?. In Proceedings of MICRO-50, Cambridge, MA, USA,\\nOctober 14–18, 2017, 13 pages.\\nhttps://doi.org/10.1145/3123939.3124546\\nPermission to make digital or hard copies of all or part of this work for personal or\\nclassroom use is granted without fee provided that copies are not made or distributed\\nfor profit or commercial advantage and that copies bear this notice and the full citation\\non the first page. Copyrights for components of this work owned by others than ACM\\nmust be honored. Abstracting with credit is permitted. To copy otherwise, or republish,\\nto post on servers or to redistribute to lists, requires prior specific permission and/or a\\nfee. Request permissions from permissions@acm.org.\\nMICRO-50, October 14–18, 2017, Cambridge, MA, USA\\n© 2017 Association for Computing Machinery.\\nACM ISBN 978-1-4503-4952-9/17/10. . . $15.00\\nhttps://doi.org/10.1145/3123939.3124546\\n1 INTRODUCTION\\nConfidentiality, integrity and availability are the key components of\\ninformation security. Among them, loss of confidentiality cannot\\nbe reversed once the information has leaked. Encryption is very\\nfrequently used to protect data confidentiality. Various encryption\\nalgorithms have been proposed, as have attacks on these algorithms.\\nSome of these attacks focus on intrinsic algorithm vulnerabilities\\nand try to break the algorithms themselves. Other attacks target\\nimplementations of the algorithms, even though the algorithms are\\nshown to be secure. Side channel attacks fall in the latter class, and\\nthey target implementation characteristics, such as execution time\\n[8], power consumption [21], resource sharing [9], sounds [1] and\\nradiation [10] of real implementations of crypto algorithms.\\nSide channel attacks are serious threats to information security\\nfor many reasons. First, side-channel attacks are hard to detect. Most\\nside-channel attacks do not require special privileges or equipment,\\nand their behavior may not be overtly harmful. For example, a\\nsimple program running in user mode measuring execution time,\\nor a smartphone near a laptop with its microphone on, can both be\\nside-channel attacks. Second, side channels are not easy to eliminate\\nwithout affecting performance. Removing potential side channels\\nfrom physical or software implementations of crypto algorithms\\noften significantly degrades efficiency, e.g., disabling a cache or\\ndisabling sharing of bus wires. Third, side-channel attacks can break\\nvarious systems. This is because side-channel attacks target the\\nphysical features of implementations of algorithms, rather than a\\nspecific algorithm. Therefore, different crypto algorithms can be the\\ntargets of one type of side-channel attack, as long as they have some\\nsimilarity in their hardware or software implementations. Fourth,\\nside-channel attacks destroy the entire confidentiality of data or\\nprograms, once they succeed, because they recover cryptographic\\nkeys, instead of decrypting specific data. No matter what plaintext is\\nencrypted, as long as the secret keys are leaked, the encrypted data\\ncan be easily recovered by attackers because encryption/decryption\\nalgorithms are publicly known.\\nCache based side-channel attacks exploit the difference in the\\naccess times of cache hits and misses. This makes cache side-channel\\nattacks hard to eliminate, because this time difference is an inherent\\nfeature of all caches. Also, disabling the cache is not a practical\\nsolution to these attacks, because caches are the most important\\nperformance component in modern computers, and disabling the\\ncache causes unacceptable performance degradation.\\n1.1 Past Work\\nThese cache attacks are realizable in the real world, for example [3],\\n[8], [2], [25] successfully attack the L1 cache, and recovered the\\nsecret keys of AES. [20] shows cache side-channel attacks are prac\\x02tical on the last level cache (LLC) as well. [33] shows that L2 cache\\n341\\nMICRO-50, October 14–18, 2017, Cambridge, MA, USA Zecheng He and Ruby B. Lee\\nside-channel attacks in virtualized environments are practical. [37]\\nsuccessfully launched cache side-channel attacks in cloud settings.\\nMany approaches have been proposed to defeat these attacks, and\\nthey can be categorized into two classes: software based approaches\\n[4], [11] and hardware based approaches. Software approaches of\\x02ten mitigate only specific applications. For example, [23] discusses\\ncompact S-box tables and frequently randomized tables for AES\\nencryption. Special instructions are proposed for AES in [22] and\\n[28]. System level mitigation [12] may cause impact on performance.\\nUncachable tables and inaccessible high-resolution timers are ap\\x02proaches to defend against side-channel attacks [29], [30]. However,\\nuncacheable tables increase the total execution time of encryption\\nand inaccessibility of timers cause other benign applications to not\\nwork properly. [34] and [16] claim prefetching (and locking) can be\\nused as a mitigation technique, without significantly influencing per\\x02formance, however, only a specific type of attack can be prevented.\\n[16] proposes a defense of LLC (Last Level Cache) side-channel at\\x02tacks based on CAT (Cache Allocation Technology). This approach\\nnot only prefetches secure critical data, but also pins them in the\\nLLC, thus all secure critical accesses are hits. However, pinning the\\ndata in the cache causes cache fragmentation and needs support by\\nspecial hardware.\\nHardware based approaches provide a different way of defending\\nagainst cache side-channel attacks. Many new cache architectures\\nhave been proposed. In general, there are two categories of defenses:\\npartitioning based approaches and randomization based approaches.\\nThe first category includes the Static Partitioned (SP) cache [24],\\nthe Partition Locked (PL) cache [31] and the Non-monopolizable\\n(Nomo) cache [7]. Randomization based cache architectures include\\nRandom Permutation (RP) [31] cache, Newcache [32], [19], Random\\nFill (RF) [18] cache and Random Eviction (RE) cache [5]. We will\\ndescribe these secure cache proposals in greater detail in Section 2,\\nand will evaluate their resilience to cache side-channel attacks in\\nSection 4.\\nSome work has been proposed on evaluating cache security. [27],\\n[15], [14], [35] use mutual information to evaluate cache security. [5]\\nintroduces the side-channel vulnerability factor (SVF) and pattern\\ncorrelation to evaluate caches. [36] suggests the Cache Side-channel\\nVulnerability metric (CSV) as an improvement to SVF for the access\\x02based attacks considered in [5]. [27], [26] and [6] used success\\nprobability to calculate an attacker’s chances of success.\\nHowever, very limited work has been proposed on systematically\\nmodeling and comparing between different caches against different\\nkinds of attacks. In this paper, we will answer two questions: (1) How\\ncan we systematically model and evaluate a cache’s resilience to\\nside-channel attacks? (2) Among all proposed secure cache designs,\\nwhich one is more resilient to a class (or classes) of cache side\\x02channel attacks?\\nOur contributions are:\\n• We propose the Probabilistic Information Flow Graph (PIFG),\\na new model based on an information flow graph (IFG) and\\nconditional probabilities, and a new metric, Probability of\\nAttacker’s Success (PAS) to evaluate and quantify a cache\\narchitecture’s resilience to cache side-channel attacks. We\\nshow how PIFG models the relevant features of attackers,\\nvictims and cache architectures. We also show the impact of\\nan attacker preparing for a cache attack (pre-PAS).\\n• We apply PIFG and PAS on nine cache designs and four\\npractical attacks, which cover all the known time-based cache\\nside-channel attacks and hardware secure cache defenses.\\n2 BACKGROUND\\n2.1 Cache Side Channel Attacks\\nTable 1 shows a classification of all cache side-channel attacks,\\nusing timing differences (due to cache hits or misses) as the channel\\nmedium to leak secret meta-data.\\nThe intrinsic characteristic of most cache attacks is the timing\\ndifference between cache hits and misses. An ideal attacker is able\\nto observe whether each of the victim’s memory accesses is a cache\\nhit or cache miss. He is also able to infer the memory address or\\naddresses used by the victim from his observations of the cache\\nshared with the victim. This memory address (or addresses) is the\\nmetadata leaked to the attacker through such cache timing side\\nchannel attacks, from which he can derive, for example, the secret\\nkey of encryption algorithms.\\nHowever, in general, attackers do not have the ability to observe\\neach of the victim’s cache accesses. Therefore, indirect observations\\nare used. In some of these attacks, attackers measure the access\\ntime of each of his own individual memory accesses (column 2 of\\nTable 1), after some interferences with the victim. In other attacks,\\nattackers observe the total execution time of the victim’s security\\x02critical operation (column 1 of Table 1), instead of the access time\\nof each memory access. In Table 1, we use the historical names,\\n\"access-based\" versus \"timing-based\" cache side-channel attacks\\nto distinguish these two types of attacks, although both are based\\non measuring time differences, but at different scales of a single\\nmemory access or the time for an entire security-critical operation\\n(e.g., encryption of a whole block of memory), respectively.\\nCache side-channel attacks can also be classified into \"miss\\nbased\" attacks versus \"hit based\" attacks. In the former, attackers are\\ninterested in observing whether there is a longer average time (ac\\x02cess time or operation execution time, over many trials) due to cache\\nmisses. The cache misses are due to either the victim (column 1) or\\nthe attacker process (column 2).In the latter, denoted hit-based at\\x02tacks, attackers are interested in observing whether there is a shorter\\naverage time due to cache hits.\\nSince hit/miss based attacks and timing/access based attacks are\\northogonal, we have four categories of cache side-channel attacks,\\nwhich cover the space of all known cache side-channel attacks. Our\\nproposed model covers all these 4 categories, and thus all cache\\nside-channel attacks based on the timing channel. We give a repre\\x02sentative example of each category in Table 1, and describe each of\\nthese below. In the names of the representative attacks, the attacker\\nperforms the 2 actions, e.g., \"evict\" and \"time\", with the \"-and-\"\\nindicating the attacker waits in-between these actions for the victim\\nto perform the security-critical operation (e.g., crypto) between these\\ntwo actions, except for the Collision attack, where the attacker does\\nnot perform any cache actions.\\nType 1, e.g., Evict-and-time Attack: The attacker wants to ob\\x02serve whether the victim has a longer average execution time due\\n342\\nHow secure is your cache against side-channel a!acks? MICRO-50, October 14–18, 2017, Cambridge, MA, USA\\nTable 1: Types of cache side-channel attacks. This table covers\\nall known cache side-channel attacks due to time differences.\\nTiming Based Attacks Access Based Attacks\\nType 1: Type 2:\\nMiss Based\\nAttacks\\nObserve if victim uses\\nthe attacker-evicted\\ncache line(s), caus\\x02ing victim’s longer\\nexecution time for an\\nentire security-critical\\noperation.\\nObserve if victim evicts\\nthe attacker’s cache\\nline(s), causing the\\nattacker to later miss\\non these cache line(s)\\nresulting in longer\\nmemory access time.\\nE.g., Evict-and-time at\\x02tack\\nE.g. Prime-and-probe\\nattack\\nType 3: Type 4:\\nHit Based\\nAttacks\\nObserve if victim reuses\\nmemory lines fetched\\nby his previous mem\\x02ory accesses, causing\\nvictim’s shorter execu\\x02tion time for an entire\\nsecurity-critical opera\\x02tion.\\nObserve if attacker\\nuses the victim-fetched\\ncache line(s), which\\ncauses the attacker’s\\nshorter memory access\\ntime.\\nE.g. Cache Collision\\nattack\\nE.g. Flush-and-reload\\nattack\\nto the victim’s cache miss(es), over a large number of trials. In\\nthis attack, the attacker first evicts one (or some) cache set (sets)\\nwhich contain the victim’s security-critical data. If the victim uses\\nthe evicted data, a cache miss occurs. This cache miss increases the\\nvictim’s execution time for the security-critical operation (e.g., a\\nblock encryption in AES), which can be observed by the attacker.\\nType 2, e.g., Prime-and-probe Attack: The attacker wants to ob\\x02serve whether he gets a longer access time due to a cache miss for his\\nown memory access. In this attack, the attacker first \"primes\" some\\ncache lines by loading his own memory lines into the cache. Then,\\nthe victim executes the secure operation. If the victim’s security\\x02critical data maps to a primed cache line, the attacker’s cache line is\\nevicted. Then, when the attacker \"probes\" the same memory line(s)\\nby loading it (them) again, he can measure his own access time to\\nsee whether he gets a cache miss or not. If the victim did not fetch\\nhis own data line into a primed cache slot, the attacker should get a\\ncache hit.\\nType 3, e.g., Cache Collision Attack: The attacker wants to ob\\x02serve whether the victim has a shorter execution time due to cache\\nhits of the victim’s own memory accesses. This attack is very spe\\x02cial because the attacker does not need to interfere with the victim.\\nWhen the victim accesses the same memory line M again, the second\\nmemory access is a hit because the first memory access has fetched\\nM into the cache. This hit causes the victim’s execution time to be\\nshorter. The hits because of previous memory accesses are called\\n\"cache collisions\".\\nType 4, e.g., Flush-and-reload Attack: The attacker wants to\\nobserve if he gets a cache hit for his own memory access. In this\\nattack, the attacker shares a library or data with the victim. The\\nattacker first flushes the shared memory line(s) out of the cache,\\nthen waits for the victim to execute. If the victim uses the shared\\nlibrary or data, these shared memory lines will be fetched into the\\ncache. After the victim finishes his security-critical operations, the\\nattacker reloads the shared memory lines. A hit in the attacker’s\\nreloads indicates that the corresponding memory line has been used\\nby the victim.\\n2.2 Secure Cache Architectures\\nSecure cache architectures have been proposed to defend against\\ncache side-channel attacks. In general, they can be classified into\\ntwo categories: partitioning based architectures and randomization\\nbased architectures. We briefly introduce these secure cache designs\\nbelow.\\n2.2.1 Partitioning based architectures. Intuitively, partitioning\\nbased secure cache architectures separate the victim’s cache partition\\nand the attacker’s cache partition. These architectures significantly\\nreduce interference between the attacker’s and the victim’s memory\\naccesses, however, they often degrade the cache’s performance.\\nStatic Partitioning (SP) Cache: This is the basic design of parti\\x02tioning based caches. A static partitioning cache statically separates\\nthe cache for the victim and the attacker. No sharing of the cache\\nis allowed in this architecture. This cache architecture prevents all\\ninterferences of victim’s and attacker’s memory accesses. However,\\nthe security protection is at the cost of degrading cache performance.\\nIt is only deployed in extremely security-sensitive applications.\\nPartition Locked (PL) Cache: Partition locked cache [31] lever\\x02ages cache line based partitioning, which is much finer in granularity\\n(better) than SP cache. Every cache line in the PL cache can have\\nits Protection bit set or cleared. A protected cache line cannot be\\nreplaced by non-protected lines, e.g. by the attacker’s data. On an\\nattacker’s cache miss to evict a protected cache line, the attacker’s\\ndata is directly transferred from memory to the processor, without\\nbeing brought into the cache. The line based granularity makes cache\\nsharing still possible. The correct way to use PL cache is prefetching\\n(and lock) all security-critical data into the cache before starting\\nsecurity-critical operations.\\nNon-monopolizable (Nomo) Cache: Non-monopolizable (Nomo)\\nCache [7] uses way-based partitioning, rather than set-based (for SP)\\nor line-based (for PL) partitioning. Each security-sensitive process\\nis assigned some reserved ways in each cache set. All the remain\\x02ing cache ways can be shared by all processes. This modification\\nprohibits the attacker occupying a whole cache set. However, if the\\nvictim’s data exceed the reserved ways, the victim has to interfere\\nwith the attacker. In this situation, it is possible that the victim still\\nleaks some information through cache sharing.\\n2.2.2 Randomization based architectures. Randomization based\\ncache architectures mess up the information obtained by the attacker.\\nWe briefly discuss some randomization based cache architectures\\n343\\nMICRO-50, October 14–18, 2017, Cambridge, MA, USA Zecheng He and Ruby B. Lee\\nbelow. In general, randomization based architectures are more effi\\x02cient, performance wise, than partitioning based approaches.\\nConventional Fully Associative (FA) Cache with Random re\\x02placement policy: A fully associative cache with a random replace\\x02ment policy is the most basic version of a randomization based cache.\\nAny memory line can be mapped to any cache line, and a random\\ncache line is evicted on a cache miss. However, FA caches are slow\\nand power-hungry.\\nRandom Permutation (RP) Cache: A Random permutation\\ncache [31] uses dynamic permutation tables to map memory ad\\x02dresses to cache sets. In a conventional set-associative cache, the\\nindex bits in the memory addresses determine the cache set index\\nnumber. In RP cache, each (secure) process has a distinct permuta\\x02tion table. Index bits are first translated to the real cache set index\\nnumber using the table. If the victim’s memory access M is mapped\\nto a cache set S that belongs to another process (possibly the attacker),\\na random cache set S0 will be evicted and the index mappings of S\\nand S0 are swapped.\\nNewcache: Newcache [32] [19] randomizes memory-to-cache\\nmappings. This randomization is achieved by using an ephemeral\\nlogical cache between memory addresses and real physical cache\\nlines. The mapping between memory addresses and the logical cache\\nis like a direct mapped cache. The mapping between the logical\\ncache and the physical cache is fully associative. Newcache is a\\npower-efficient version of a fully-associative cache with random re\\x02placement because fewer tag bits need to be compared associatively.\\nThis reduces the width of the CAM (Content Addressable Memory)\\nused to inversely map each physical cache line to a memory line [19].\\nRandom Fill (RF) Cache: Random fill cache [18] modifies the\\nfetch policy on a cache miss. On a cache miss, instead of bringing\\nthe accessed memory line M into the cache, RF cache randomly\\nselects a memory line M0 within a neighborhood window of M (from\\nmemory line M \\n', '• F E AT U R E\\n\\n48   JOURNAL AWWA • JUNE 2020\\n\\n\\x0c• F E AT U R E\\n\\nIndustrial \\nControl \\nSystems: \\nCyber \\nPolicies and \\nStrategies\\n\\nAnil Gosine\\n\\nKey Takeaways\\n\\nA collaborative, all-hazards approach to preparing for threats to critical \\ninfrastructure has enhanced security and resilience in the United States \\nand Canada.\\n\\nIt’s up to individual organizations—including water utilities—to have all the \\nelements of an effective security plan in place.\\n\\nCybersecurity around industrial control systems needs to keep pace with \\nthe sophistication and evolution of attacks on technology environments.\\n\\nPolicies, procedures, risk assessments, and the right technique platforms—\\nall held together by staff knowledge and expertise—create a strong defense.\\n\\nLayout imagery by Gorodenkoff/Shutterstock.com\\n\\nJOURNAL AWWA • JUNE 2020   49\\n\\n\\x0c• F E AT U R E  \\n\\nI C S  C y b e r s e c ur i t y \\n\\nR esilience in North America’s water sector has \\n\\nimproved because security practices have \\nevolved from focusing only on natural haz-\\nards to taking an all-hazards approach. The \\nwater sector is developing capacities and capabilities in \\nresponse to broad classifications of emergencies. The  \\nUS Environmental Protection Agency, US Department \\nof Homeland Security, and Public Safety Canada use \\nstrategies and guidance in the United States and \\nCanada to make critical infrastructure resilient, and \\nwater is a significant sector in this paradigm. Still, \\ngreater alignment of standards between the Canadian \\nand US governments at the federal and state/provincial \\nlevels is necessary.\\n\\nIt’s widely agreed that critical sectors should have \\nrecovery plans for cyber incidents, and there is renewed \\nsupport for advanced research of digital innovations \\nand improved cyber skills and knowledge across the \\nwater sector. A joint vision statement and action plan \\nwere announced by the United States and Canada in \\n2011 through their declaration, “Beyond the Border: \\nA Shared Vision for Perimeter Security and Economic \\nCompetitiveness”; much can be done to build on these \\ngovernmental efforts. \\n\\nIn the United States, America’s Water Infrastructure \\nAct of 2018 mandates that drinking water systems serv-\\ning more than 3,300 people conduct risk assessments \\nand update emergency response plans, including for \\nthe resilience and security of electronic, computer, and \\nother automated systems. In Canada, responsibility for \\nwater management is shared by the federal, provincial, \\nand municipal governments, an approach that calls for \\nclose cooperation among all levels of government. Public \\nSafety Canada, in partnership with Defence Research and \\nDevelopment Canada, manages the Canadian Safety and \\nSecurity Program to strengthen the country’s ability to \\nanticipate, prepare for, respond to, and recover from var-\\nious malevolent acts by providing guidance to utilities, \\nassociations, and provincial governments.\\n\\nUnifying Operational and Information \\nTechnology\\nDifferences between operational technology (OT) and \\ninformation technology (IT) are evident in their security \\nobjectives, network segmentation, topology, functional \\npartitioning, user accounts, untested software, and miti-\\ngation strategies. Despite these differences, harmonizing \\nOT and IT similarities—policies, procedures, and \\nresponses—can make them each more effective. OT  \\nsystems—specifically industrial control systems (ICS)—\\nand IT systems can function together efficiently while \\nproviding necessary cybersecurity measures.\\n\\n50   JOURNAL AWWA • JUNE 2020\\n\\nHowever, the current separation of OT and IT domains \\n\\nwithin many organizations supports both disciplines, \\nleading to separate structures and processes. These are \\nsome of the solutions to overcoming this division:\\n\\n • Developing joint bodies and governance structures to \\n\\nalign IT and OT missions\\n\\n • Jointly managing and executing cross-technology \\n\\nprojects\\n\\n • Harmonizing duplicate and/or overlapping processes\\n • Developing interdisciplinary skills within both \\n\\ndomains that acknowledge the requirements of both \\ngroups\\n\\n • Abolishing split responsibilities between IT and OT, \\n\\nespecially concerning security\\n\\n • Jointly managing the currently separate infrastructures\\n • Promoting effective communication between team \\n\\nmembers and leadership\\n\\nA cyberattack within the OT environment can have \\nserious and wide-ranging consequences of prolonged \\noutages beyond financial losses; these include angry cus-\\ntomers and community leaders, sickness, loss of revenue, \\nloss of life, and damage to the environment. For example, \\nin December 2017, new “trojan” malware, called Triton, \\ntargeted ICS in a Saudi Arabian petrochemical plant. It \\nwas designed to communicate with safety instrumented \\nsystems (i.e., sets of hardware and software controls) and \\ndeploy alternative logic to these devices, meaning they \\nwould not function correctly. In February 2018, a water \\nutility in Europe was compromised by a cryptocurrency \\nmalware mining attack; this was the first public report of \\nan authorized cryptocurrency miner affecting ICS. \\n\\nCritical data that used to be in a secured data cen-\\nter now move across an increasingly complex system of \\nnetworked environments, including Internet of Things, \\nindustrial Internet of Things, cloud servers, virtualized \\nenvironments, and mobile devices. But today’s cyber \\nthreats can no longer be viewed simply as network issues; \\ninstead, they must include control system devices such as \\nsensors, drives, actuators, smart power supplies, and in-\\nstrumentation. Because these devices include alarms and \\nmanagement functionality, they are often mischaracter-\\nized as “trusted”; in truth, these devices are most often \\nunmanaged, meaning the risks are overlooked.\\n\\nEstablishing a Security Overview\\nA security overview defines the mission, objectives, and \\nscope of the security management program for any ICS \\nwithin a utility. Its purpose is to design, implement, oper-\\nate, and maintain a secure network that enables all process \\ncontrol systems to be securely managed to support the util-\\nity’s water and wastewater operations and its customers, \\nand to be in compliance with regulatory requirements. \\n\\n\\x0c• F E AT U R E  \\n\\nI C S  C y b e r s e c ur i t y \\n\\n“ICS” is a general term that encompasses several types \\n\\nof control systems used to automate industrial process-\\nes, including supervisory control and data acquisition \\nsystems, distributed control systems, and smaller control \\nsystem configurations such as programmable logic con-\\ntrollers. An ICS needs to be secure, effective, and resil-\\nient, and protected at a level commensurate with realistic \\nrisks. Working across the utility, managers should devel-\\nop a consensus-based strategy that enforces a compre-\\nhensive plan and promotes continuous improvements in \\nsecurity. By encouraging stakeholder participation, there \\nis greater adherence to compliance. Having more sets of \\neyes on maintaining security makes it easier to iden-\\ntify areas for improvement and potential cross-sector \\ninitiatives. An ICS security management program should \\nconsist of elements such as policies and procedures, con-\\ntrol mechanisms, compliance management, and incident \\nresponse; these and others are \\noutlined in Figure 1.\\n\\n • Engage design projects \\n • Establish ongoing governance \\nFormal governance for managing OT systems \\nsecurity ensures that a consistent and appropriate \\napproach is followed across the organization. Failure \\nto establish proper process security governance \\nleads to poor risk management, with potentially \\ndire consequences for the organization’s operations. \\nAn effective governance framework provides clear \\nroles and responsibilities, an up-to-date policy and \\nstandards for managing process control security risk, \\nand assurance that all policies and procedures are \\nfollowed. The governance plan ideally is approved \\nby an executive-level sponsor; this ensures account-\\nability in the cybersecurity management program \\n(specifically OT security policies) and an OT security \\narchitecture with controls to support the policies.\\n\\nICS Governance\\nCybersecurity has evolved. It can \\nrespond to more sophisticated \\nthreats that target industrial \\nautomation and control systems \\nfor water and wastewater supply, \\nutility feeds, collection and dis-\\ntribution stations, treatment \\nfacilities, and regulatory dis-\\ncharge points. Critical- \\ninfrastructure facility leaders \\nneed to understand their sys-\\ntems’ risks so that they can man-\\nage them appropriately.\\n\\nTo achieve a utility’s security \\ngoals, the operational technolo-\\ngy group (or whoever is assigned \\nresponsibility) should develop \\na framework based on security \\nindustry best practices; these can \\nthen be tailored to the utility’s \\nspecific needs, its process control \\nenvironment, and its security pos-\\nture. Several actions go into creat-\\ning a cybersecurity framework: \\n\\n • Understand the risk \\n • Implement a secure architec-\\n\\nture \\n\\n • Establish response capabil-\\n\\nities \\n\\n • Improve awareness and skills \\n • Manage third-party risks \\n\\nElements of an Industrial Control System\\n\\nPolicies,\\nprocedures,\\nand (industry)\\nstandards\\n\\nAdministrative\\nand technical\\ncontrols \\n\\nIntegration\\nstandards for\\nhardware\\nand software\\n\\nAsset\\ninventory and\\nassociated risk\\nand compliance\\nmanagement\\n\\nElements of\\nan Industrial\\nControl System\\n\\nCybersecurity\\nawareness\\nand training\\n\\nRegulatory\\ncompliance \\n\\nIncident\\nmanagement\\nand response\\n\\nFigure 1\\n\\nJOURNAL AWWA • JUNE 2020   51\\n\\n\\x0c• F E AT U R E  \\n\\nI C S  C y b e r s e c ur i t y \\n\\nSecuring Utility Systems\\nMaintaining ICS integrity requires a thorough under-\\nstanding of the communications standards among the \\nICS components. In this cyberphysical layer, it can be dif-\\nficult to spot communications errors, cybersecurity \\nthreats, and network health problems. However, the \\nsymptoms are usually obvious and can include sluggish \\nhuman–machine interface updates, unexplained shut-\\ndowns, and precarious failures of ICS components. An \\neffective and healthy process-controls network prevents \\nthese failures. \\n\\nUtilities can understand risk by \\nconducting periodic, rigorous  \\nrisk assessments that cover all \\nsystem aspects.\\n\\nTo find and isolate issues in OT networks before they \\ncause problems or are found by those wishing to do the \\nutility harm, cybersecurity tools and techniques must in-\\nclude network security monitoring and intrusion detection \\nsystems for ongoing analysis. Continuous-threat-detection \\nplatforms are being used more because they provide ex-\\ntreme visibility into ICS networks, comprehensive threat \\ndetection and vulnerability insights, and passive monitor-\\ning techniques—ensuring there are no impacts on under-\\nlying operational processes. \\n\\nOne difference between ICS and plant IT security \\nis their main cybersecurity objectives. IT systems are \\nbusiness systems whose primary security objective is to \\nprotect data (i.e., confidentiality). In contrast, the main \\nsecurity objective of an ICS is to maintain the integrity of \\nits production process and the availability of its compo-\\nnents. Protecting information is still important, but loss \\nof production can mean an immediate loss of income, \\nloss of view and control capability, damaged production \\nequipment, and possible safety issues. \\n\\nICS security uses a comprehensive set of defense-in- \\ndepth layers to isolate the control system and the physi-\\ncal process from the plant IT system. Utilities should im-\\nplement a defense-in-depth strategy that continuously re-\\nviews and establishes its current risk, which for an ICS is \\nbest understood by knowing the utility’s threats and vul-\\nnerabilities. Utilities can understand risk by conducting \\nperiodic, rigorous risk assessments that cover all system \\naspects. Risk assessments are a cornerstone in defining, \\n\\n52   JOURNAL AWWA • JUNE 2020\\n\\nunderstanding, and planning remediation efforts; they \\nare constantly updated in timely intervals, supported  \\nby all areas and levels of the organization.\\n\\nA cross-functional team can create a culture for  \\nprotecting ICS. The team should include at least one  \\nexecutive-level manager for leadership and guidance,  \\nsecurity and operations management at the corporate \\nlevel, and full participation from control system  \\nengineers and managers. The team should be trained  \\non the essential aspects of ICS cybersecurity. It should \\nalso be fully aware of the utility’s ICS infrastructure  \\nsecurity challenges and risks that need to be addressed.\\n\\nCybersecurity Architecture Document\\nOrganizations are advised to develop a cybersecurity \\narchitecture document that identifies and describes all \\ndevices required to protect utility operations and the \\nways they interact with each other. The document should \\ncategorize all critical devices and group them to apply \\ncybersecurity requirements based on the potential \\nimpact that compromise, loss, and misuse of those assets \\nwould have on reliable operation. This architecture docu-\\nment is a strategic planning guide that defines the antici-\\npated state of the organization’s ICS infrastructure. It \\nsets the context for planning, design, and implementa-\\ntion that also facilitates budgeting for security solutions \\nand personnel. \\n\\nThe primary purpose of creating a cybersecurity archi-\\ntecture document is to ensure that the business strategy \\nand ICS security principles are aligned, and that there \\nis accountability and shared responsibility. As such, the \\ncybersecurity architecture should provide traceability \\nfrom the business strategy down to the technology and \\npolicies that are implemented. A formal security gover-\\nnance plan is critical as the cybersecurity threats become \\nmore sophisticated. It is imperative that critical infra-\\nstructure facilities appropriately manage this risk within \\ntheir environments—overly complex solutions not only \\nlead to insecurity and potential human error but also to \\nincreased operational costs.\\n\\nMany executive teams struggle with cybersecurity \\nexpenditures because it is difficult to see any return on \\ninvestment. Documenting the existing security archi-\\ntecture and potential risks makes it easier to justify \\nthese costs and communicate what is being done and \\nwhy. Connecting business objectives with security in the \\narchitecture and governance documents also helps man-\\nagers understand the need for cybersecurity measures in \\nthe realm of ICS. \\n\\nDecision makers must understand the high-priority \\nareas in which security improvements are likely to yield \\nthe greatest benefit. This can be achieved by mapping \\n\\n\\x0c• F E AT U R E  \\n\\nI C S  C y b e r s e c ur i t y \\n\\nall networked assets and digital communication links, \\nthe physical network audit, and electronic host discovery \\nto identify network connections. Where a visual media \\ntrace is not possible, loss assessment can be used to iden-\\ntify these elements:\\n\\n•\\t Actions that could be performed by an attacker \\n\\n•\\t\\n\\nvia unauthorized electronic access\\nElectronic services available on device interfaces \\nover network links\\n\\n•\\t Consequences of unauthorized access and as-\\nsignment of a loss metric (low, moderate, high)\\n\\n•\\t Threat assessment—both motivation and oppor-\\n\\ntunity \\n\\n•\\t Roles and privileges of authorized users (to prior-\\n\\nitize defense efforts)\\n\\nThreat Intelligence \\nCyber adversaries use increasingly sophisticated tools, \\ntechniques, and procedures that can evade stand-alone \\nsecurity solutions with multiyear campaigns that tar-\\nget valuable and sensitive information. Organizations \\nneed an evidence-based, holistic view of the threat \\nlandscape with a proactive security approach, moving \\nbeyond security information management to what’s \\nknown as threat intelligence. Threat intelligence pro-\\nvides context, indicators, increased awareness, and \\nactionable responses to current or emerging threats \\nthat aid in decision-making at an operational, tactical, \\nor strategic level. \\n\\nThe goal of threat intelligence feed services is to help \\n\\norganizations become aware of, recognize, and act on \\nindicators of cyber attacks and to compromise such sce-\\nnarios in a timely manner. Security teams worldwide are \\nconstantly challenged to discover, analyze, and interpret \\nthe vast number of daily events that indicate attacks. \\nSecurity consortiums lead efforts to automatically \\ndetect, contextualize, and prioritize threats; perform fo-\\nrensic analysis; and automate responses. As part of their \\noverall strategy, utilities should define what they expect \\nto achieve from threat intelligence:\\n • Establishing an analysis process\\n • Learning how threat intelligence is used\\n • Defining what types of alerts are needed\\n • Determining how intelligence is collected, reported, \\n\\nand communicated to relevant stakeholders\\n • Gathering vendor news, such as vulnerability in-\\n\\nformation, incidents, integrations, CVE (common \\nvulnerabilities and exposures) alert advisories,  \\ncorporate news  \\n\\nResponding to security challenges by simply adding \\n“innovative” products is not the best approach; instead, \\na threat intelligence platform is a better way to prepare a \\n\\nutility’s defense. Combining threat intelligence capabil-\\nities within an organization’s software, hardware, and \\npolicy defense strategy enhances staff’s ability to search \\nfor advanced attacks, profile atypical malware, and de-\\ntect adversaries. Internal threat intelligence teams are \\nhardly common because of the associated high costs, la-\\nbor, and time, as well as lack of alignment with a typical \\nutility’s security approach. \\n\\nAn important function of threat intelligence feeds is to \\norganize threats according to their potential to harm an \\norganization. Many utilities have time to see only what \\nrelates to their environment, but the best systems prior-\\nitize threats automatically, allowing human analysts to \\nfirst focus their efforts on the most important threat data \\nor information. Having a tool that can prioritize threats \\nis essential.\\n\\nThreat intelligence is no longer exclusive to large, \\n\\nwell-funded organizations; it’s becoming a required com-\\nponent of mitigation strategies for utilities and other orga-\\nnizations of all sizes. Economies of scale now allow small \\nbusinesses to access credible threat intelligence sources \\nbased on an organization’s profile and supply chain.\\n\\nCyber adversaries use increasingly \\nsophisticated tools, techniques, \\nand procedures that can evade \\nstand-alone security solutions with \\nmultiyear campaigns that target \\nvaluable and sensitive information.\\n\\nRisk Compliance\\nWater and wastewater providers seek to improve their \\noperational excellence and risk management across the \\nenterprise. Complex, manual data compilation and \\nanalysis have led to inefficient reporting practices. The \\nchallenge of universally tracking compliance adherence \\nand risk management can be improved in various ways, \\nsuch as using a software-as-a-service platform built  \\nspecifically for OT.\\n\\nAny platform that automates security risk and compli-\\nance management should also automate assessment of the \\ncurrent cybersecurity defense; this can shorten the time to \\ncompliance for the end user. By automating security risk \\nassessment, a security risk and compliance management \\n\\nJOURNAL AWWA • JUNE 2020   53\\n\\n\\x0c• F E AT U R E  \\n\\nI C S  C y b e r s e c ur i t y \\n\\nAdvantages of Automating \\nSecurity Risk Assessment\\n\\nIdentify information security\\nrisks quickly\\n\\nThe platform dashboard provides at-a-\\nglance, real-time views for team members \\nto see intelligent risk-scoring, missing \\ncontrols, and potential impacts of a \\ncybersecurity threat.\\n\\nReduce complexity through automation\\n\\nThe platform reports on the completion \\nof each step in the process, including \\nuploading regulatory and client-driven \\nrequirements, risk assessment, planning \\ncorrective activities, and success in meeting \\nrequirements.\\n\\nProvide a collaborative platform  \\n\\nThe environment allows assigned \\nstakeholders to log in and monitor \\ncompliance management across \\nmultiple data sources, internal assets, \\nand vendors.\\n\\nContinuously monitor risk posture\\n\\nIn their cyber risk assessment of critical \\ninfrastructure ecosystems, utilities need \\nthe capability to receive dynamic data \\nto provide real-time visibility into threat \\nintelligence and mitigation efforts.\\n\\nFigure 2\\n\\nplatform enhances a utility’s security efforts, such as \\nthrough speedy risk identification, reduced complexity, \\nenhanced collaboration, and continuous monitoring. The \\ntasks that can be accomplished are described in Figure 2.\\n\\nBuilding a Cybersecurity Arsenal\\nThese are challenging times for security manag-\\ners, with corporate boards demanding heightened \\n\\n54   JOURNAL AWWA • JUNE 2020\\n\\nawareness of cyber risks, faster processing of pro-\\ngressively complex data, and efficiently managed \\nservices for more intelligent devices. The following \\ncritical infrastructure protection (CIP) policies \\nand procedures established by the North \\nAmerican Electric Reliability Corporation align \\nwith AWWA’s 2019 Cybersecurity Risk & \\nResponsibility in the Water Sector report and \\nCybersecurity Guidance & Tool webpage:\\n\\n • Cybersecurity Policy (overarching policy)\\n • CIP 002 Regional Water System (RWS) Cyber \\n\\nSystem Categorization\\n\\n • CIP 003 Security Management Control\\n • CIP 004 Personnel and Training\\n • CIP 005 Electronic Security Perimeters\\n • CIP 006 Physical Security of RWS Cyber Systems\\n • CIP 007 System Security Management\\n • CIP 008 Incident Reporting and Response \\n\\nPlanning\\n\\n • CIP 009 Recovery Plans for RWS Cyber Systems\\n • CIP 010 Configuration Change Management \\n\\nand Vulnerability Assessments\\n • CIP 011 Information Protection\\nSecurity teams are in a better position to defend \\n\\ntheir organizations against threats if they know \\nwhat to expect. With that understanding, it’s im-\\nportant to note that appropriate tools and staff are \\nvital, and they should be augmented with addition-\\nal intelligence and capabilities. \\n\\nAbout the Author\\n\\nAnil Gosine is executive director of \\nStrategic Efficiency Consortium (www.\\nstrategicefficiency.org) in Detroit, Mich.; \\nagosine@strategicefficiency.org.\\n\\nhttps://doi.org/10.1002/awwa.1518\\n', 'Modeling Structure and Resilience of the Dark Network\\n\\nManlio De Domenico1, ∗ and Alex Arenas1\\n1Departament d’Enginyeria Inform`atica i Matem`atiques,\\nUniversitat Rovira i Virgili, 43007 Tarragona, Spain\\n\\nWhile the statistical and resilience properties of the Internet are no more changing signiﬁcantly\\nacross time, the Darknet, a network devoted to keep anonymous its traﬃc, still experiences rapid\\nchanges to improve the security of its users. Here, we study the structure of the Darknet and we\\nﬁnd that its topology is rather peculiar, being characterized by non-homogenous distribution of\\nconnections – typical of scale-free networks –, very short path lengths and high clustering – typical\\nof small-world networks – and lack of a core of highly connected nodes.\\n\\nWe propose a model to reproduce such features, demonstrating that the mechanisms used to\\nimprove cyber-security are responsible for the observed topology. Unexpectedly, we reveal that its\\npeculiar structure makes the Darknet much more resilient than the Internet – used as a benchmark\\nfor comparison at a descriptive level – to random failures, targeted attacks and cascade failures, as\\na result of adaptive changes in response to the attempts of dismantling the network across time.\\n\\nI.\\n\\nINTRODUCTION\\n\\nSince when Internet became a publicly accessible in-\\nfrastructure and communication network, its resilience\\nto random failures – caused, for instance, by unexpected\\ncrashes due to nodes’ malfunction or protocol’s errors – or\\nattack – actions devoted to isolate nodes that play a vital\\nrole in the network – has been widely investigated[1–5].\\nIn fact, the Internet exhibits highly nontrivial structural\\nand dynamical properties, from heavy-tail distribution\\nof connections – known as scale-free property[6] – to a\\nmoderate amount of clustering – proportional to the frac-\\ntion of nodes that form closed triangles –, whose model-\\ning has been the subject of intense research activity[7–\\n11]. In fact, several years after the Internet ﬁrst proper\\ncrash, in 1980, the focus of many studies has been, and\\nstill is, to improve its resilience[10, 12–17]. In late 90s,\\nabout 30 years after the ﬁrst Internet prototype, the US\\nDefense Advanced Research Projects Agency (DARPA)\\nand the Oﬃce of Naval Research started to develop a\\ncommunication network, at the application layer, based\\non anonymous connections and, in principle, resistant to\\nboth eavesdropping and traﬃc analysis[18]. This net-\\nwork was based on onion routing, a special infrastructure\\nfor private communications over a public network that is\\nable to hide the content of a message and the identity of\\npeers who are exchanging it[19]. Nowadays, this infras-\\ntructure is better known as Tor network and represents\\nthe backbone of the Darknet, an Web of hidden services\\nthat are not reachable from within the Internet. The\\nDarknet turned out to be the most suitable communica-\\ntion network to exchange sensitive information, both licit\\nand illicit, becoming soon the target of governments try-\\ning to identify dissidents or of intelligence agencies, such\\nas CIA and GCHQ[20], to contain unauthorized news\\nleaks, distribution of illegal contents or trade of illegal\\nsubstances.\\n\\n∗ To whom correspondence should be addressed; E-mail: man-\\n\\nlio.dedomenico@urv.cat.\\n\\nHere, we characterize the structural properties of the\\nDarknet across time, from 2013 to 2015, and we compare\\nthem against the Internet topology. It is worth remark-\\ning that throughout the manuscript we model and char-\\nacterize the Darknet from a complex system perspective,\\nmeaning that we attach to the representation of both the\\nInternet and the Darknet from available data, while fo-\\ncusing the study on the particular networks structures\\nthey provide. Note that this comparison is performed at\\na descriptive level, using the structure of the Internet as a\\nbenchmark to highlight the salient features of the Dark-\\nnet. The Autonomous Systems data capture connections\\nat the Internet layer (IP packages), while Tor works on\\nthe application layer, which means that is built on top of\\nthe Internet and transport layers. We propose a model,\\nbased on how Tor functions, to reproduce with high ac-\\ncuracy the most salient characteristics of the Darknet.\\nFinally, we perform a thorough analysis, based on simula-\\ntions, of the resilience of both networks to three diﬀerent\\ntypes of failures, static – due to random disruptions or\\ntargeted attacks[1] – and dynamical – due to the cascade\\nfailures induces by attacking a single speciﬁc node of the\\nnetwork[21, 22], and show that the Darknet is much more\\nrobust than the Internet under any perspective.\\n\\nII. OVERVIEW OF THE DATA SETS\\n\\nFor our analysis, we use publicly available data sets for\\nboth the Internet and the Darknet. The Internet topol-\\nogy, at the level of autonomous systems (AS), is sampled\\nfrom historical AS-level topology data derived from Bor-\\nder Gateway Protocol (BGP) monthly snapshots, con-\\nsisting of IPv4 and IPv6 links appearing between diﬀer-\\nent endpoints during that month. The data are hosted\\nby the UCLA Computer Science Department’s Internet\\nResearch Lab[23].\\n\\nThe Darknet topology is sampled from the data ob-\\ntained by probing the Tor network to improve its\\nperformance[24]. The links between endpoints are ex-\\ntracted from the chain of circuits built by Tor clients to\\n\\n6\\n1\\n0\\n2\\n\\nc\\ne\\nD\\n5\\n\\n]\\nh\\np\\n-\\nc\\no\\ns\\n.\\ns\\nc\\ni\\ns\\ny\\nh\\np\\n[\\n\\n1\\nv\\n4\\n8\\n2\\n1\\n0\\n.\\n2\\n1\\n6\\n1\\n:\\nv\\ni\\nX\\nr\\na\\n\\n \\n \\n \\n \\n \\n \\n\\x0cprobe the network. The network is directed, but we will\\ntreat it as undirected, in the following. The full raw data\\nare available upon request and a partial release can be\\ndownloaded from a public repository[25]. Although such\\ndata were obtained to study the performance of the Tor\\nnetwork and not its topology, they provide the best ap-\\nproximation to the underlying topology of the Darknet\\nto date.\\n\\nIn both cases, we have been able to build three tem-\\nporal snapshots, corresponding to the networks in De-\\ncember 2013, May 2014 and January 2015. The Internet\\nnetwork snapshots have 46,462, 47,626 and 49,635 nodes\\nwith 195,446, 204,254 and 221,470 connections, in the\\nthree periods, respectively. The Darknet network snap-\\nshots have 5,921, 4,953 and 5,535 nodes with 2,017,542,\\n536,287 and 274,831 connections, in the three periods, re-\\nspectively. The structure of both networks for the 2015\\nperiod is shown in Fig.1A.\\n\\nIII. THE STRUCTURE OF THE DARKNET\\n\\nA. Characterizing the Darknet topology\\n\\nLet us indicate with A[ξ]\\n\\nij (t) the entries of the adjacency\\nmatrix of each network (ξ = Internet and Darknet) at\\ntime t (t = 2013, 2014 and 2015), with value equal to\\none if i and j are connected, and zero otherwise (here\\ni, j = 1, 2, ..., N [ξ](t), where N indicates the number of\\nnodes in the network and E the number of edges).\\n\\nFor any node i in each network, we calculate the de-\\nij (t) – characterizing the number of\\n\\ni (t) = (cid:80)\\n\\nA[ξ]\\n\\ngree k[ξ]\\n\\nj\\n\\n2 k[ξ]\\n\\nconnections of each node – and the local clustering co-\\neﬃcient c[ξ]\\ni (t) – characterizing the tendency of nodes to\\nform triangles –, deﬁned by the ratio between the num-\\nber of closed triangles involving node i and the maximum\\ni (t)[k[ξ]\\nnumber of triangles 1\\ni (t) − 1] node i might be\\npart of. The mean degree is deﬁned by ¯k[ξ](t) = (cid:104)k[ξ]\\ni (t)(cid:105),\\nwhereas the average local clustering coeﬃcient if given\\nby ¯c[ξ](t) = (cid:104)c[ξ]\\ni (t)(cid:105). Another macroscopic structural\\ndescriptor of interest is the global clustering coeﬃcient\\nC [ξ](t), deﬁned by the ratio between the total number\\nof closed triplets and the total number of connected\\ntriplets of nodes in the network. In general, the values of\\n¯c[ξ](t) and C [ξ](t) are diﬀerent for networks with a non-\\nhomogeneous connectivity. Throughout the analysis no\\npower-law ﬁtting is performed, the power laws indicated\\nin the plots are a simple eye-guide.\\n\\nThe degree distribution is shown in Fig. 1 and exhibits\\nhighly inhomogeneity, with evident heavy tails that re-\\nsemble two diﬀerent truncated power laws with cut-oﬀ.\\nThe distribution of the local clustering coeﬃcient is also\\ndiﬀerent in the two cases, with much more unclustered\\nnodes in the Internet than the Darknet.\\nIn the Inter-\\nnet, a signiﬁcant fraction of nodes has local clustering\\nequal to 1 and few nodes have intermediate values, at\\n\\n2\\n\\nvariance with the Darknet where the local clustering is\\nmore uniformly distributed and peaked around 0.3. On\\naverage, Darknet nodes have mean degree close to 100\\nand are more clustered than Internet nodes, which have\\nmean degree close to 10.\\n\\nTo quantify how easy is to transmit information be-\\ntween any two nodes of each network, we calculate the\\naverage path length (cid:96)[ξ](t), obtained by averaging the\\nlength of all shortest path connecting any pairs of nodes,\\nand the diameter D[ξ](t), deﬁned as the length of the\\nlongest shortest path. The Internet has average path\\nlength close to 3.5, with diameter between 10 and 12,\\nwhereas the average path length in the Darknet ranges\\nbetween 2 and 2.5, with diameter between 4 and 5 (see\\nSupplementary Figure 1). Therefore, assuming no time\\nconstraints in the propagation of the information for both\\nnetworks, communication in the Darknet is, in princi-\\nple, much faster than the Internet, with the two most\\nextremal nodes separated by no more than 5 hops, less\\nthan half of the Internet. Given that the traﬃc in the\\nDarknet is encrypted and the routing is decentralized, at\\nvariance with the Internet, the shortest paths for commu-\\nnicating compensate the higher latency and throughput\\nof the channels.\\n\\nIn Fig. 1C is shown the relationship between the size\\nof the networks, their average path length and their\\nglobal clustering for the three snapshots under consider-\\nation. The presence of high clustering and short average\\npath lengths are strong indicators that the two networks\\nhave nontrivial topology and formation mechanisms. In\\nfact, both networks exhibit the property known as small-\\nworldness[26]. Small-world networks are characterized by\\nhigh clustering, with respect to random expectation, and\\ncharacteristic length scaling as (cid:96) ∼ log N . The average\\nlocal clustering of the Internet is more than 1000 times\\nhigher than its uniformly random expectation, whereas\\nthe clustering of the Darknet is between 7 and 32 times\\nlarger than its uniformly random expectation, suggesting\\nnontrivial triadic closure mechanisms underlying both\\nnetworks. The characteristic length of the Darknet is\\nlarger than its uniformly random expectations, whereas\\nthis is not the case for the Internet. Although small-\\nworldness is better understood as a tendency, rather than\\nbeing quantiﬁed by a single number, it is worth remark-\\ning that (cid:96)(t) ≈ log N (t) – as in small worlds – for the\\nInternet snapshots and (cid:96)(t) ≈ log log N (t) – as in ultra-\\nsmall worlds[27] – for the Darknet ones.\\n\\nThe Internet and the Darknet also exhibit diﬀerent\\ntypes of higher-order correlations, as shown in Fig. 1D,\\nwhere the average nearest-neighbors’ degree and the av-\\nerage local clustering coeﬃcient are scattered against the\\ndegree. This kind of analysis is generally used to shade\\nlight on the degree-degree correlations of the network:\\nif the degree or the clustering of each node are inde-\\npendent on the nodes in the neighborhood, no trends\\nare expected.\\nInstead, the two systems present highly\\nanti-correlations, with hubs (i.e. nodes with largest de-\\ngree) tending to be connected, on average, to nodes with\\n\\n\\x0c3\\n\\nFIG. 1. Structural analysis of Internet and Darknet topologies. Force-directed visualization of the (A) Internet and\\nthe Darknet in 2015, with nodes colored to put in evidence the underlying mesoscale structure. (B) Density of the degree (solid\\nlines are for guidance only) and local cluster coeﬃcient for the two networks in 2015. (C) Scatter plot of network sizes, average\\npath length and global clustering coeﬃcient for the three temporal snapshots considered in this study. (D) Average nearest-\\nneighbors’ degree (left) and average local clustering coeﬃcient (right) against degree, to characterize higher-order correlations\\n(see Supplementary Figure 1 for other structural descriptors and their evolution between 2013 and 2015).\\n\\nmuch smaller degree and local clustering coeﬃcient. This\\ntendency is conﬁrmed by the negative assortative mix-\\ning measured in both networks (see Supplementary Fig-\\nure 1), deﬁned by the Pearson’s correlation coeﬃcient of\\nthe degree of linked pairs of nodes[28, 29].\\n\\nFrom this structural analysis we ﬁnd that while struc-\\ntural descriptors of the Internet do not change over time,\\nthis is not the case for the Darknet, that is still evolv-\\ning (see Supplementary Figure 1 for other structural de-\\nscriptors and their evolution between 2013 and 2015).\\nNevertheless, while the Internet has been widely investi-\\ngated and several models have been proposed to explain\\nits structure, the peculiar properties of the Darknet and\\nthe previous unavailability of data about its structure\\ncall for a model that is able to reproduce its most salient\\ncharacteristics.\\n\\nB. Modeling the Darknet structure\\n\\nTo model the Darknet,\\n\\nit is crucial to understand\\nhow the Tor network functions. Any Tor client initially\\nqueries the Directory Authorities to get the consensus,\\na table providing information about all active nodes in\\n\\nthe network and their metadata. The metadata is then\\nevaluated to build a circuit, a chain of three nodes used\\nto connect the client to the server where the (possibly\\nhidden) service is located. The choice of the nodes of\\nthe circuit is subjected to severe constraints, by default.\\nFor instance, the same node can not be chosen twice and\\nnodes run by the same operator are usually avoided. The\\nchoice of the ﬁrst node is not performed uniformly ran-\\ndom: instead, nodes with largest bandwidth are favored,\\nwith priority to long-lived nodes called “guard”.\\n\\nWe model the above procedure with the following sim-\\nple growing model. At time τ = 0 a small random net-\\nwork with n0 (cid:28) N nodes and e0 edges is created ﬁrst. We\\nassign a timestamp T (n) to such nodes (n = 1, 2, ..., n0),\\nthat will allow to calculate their age A(n, τ ) later at\\nany time τ , and a property B(n), not varying on time,\\nwhose value is sampled from a heavy-tailed distribution,\\nto mimic the empirical bandwidth distribution.\\nIn the\\nfollowing, we will use a log-normal distribution.\\n\\nAt each time step τ = 1, 2, ..., N −n0, a new node n and\\nM links enter the network. The timestamp T (n) = τ and\\na bandwidth are assigned to n, as previously described.\\nIt is crucial to remark that the M links do not involve\\nnode n necessarily, at variance with processes based on\\n\\nINTERNETDARKNETABCD\\x0c4\\n\\nalthough the main ﬁnding here is that the degree dis-\\ntribution of simulated networks reproduce with excellent\\naccuracy the empirical one, as shown in Fig. 2.\\n\\nThis result is of particular interest because, in general,\\nnetworks with degree distribution scaling as power laws\\nwith exponent smaller than -2 (and especially close to\\n-1) and cutoﬀ are very diﬃcult to model. Mechanisms\\ninvolving degree-based preferential attachment and the\\ninﬂuence of some exogenous properties, like aging and\\ncost, have been proposed[30] although they are able to re-\\nproduce power-law scaling with exponent equal or larger\\nthan -2 with cutoﬀ.\\n\\nThe ensemble of random realizations of our model is\\nsuﬃcient to reproduce the main topological properties\\nof the Darknet, including its structural resilience as we\\nwill see later. Figure 3 shows the comparison between\\nobserved values and their expectation according to our\\nmodel.\\n\\nC. Lack of “rich club” eﬀect in the Darknet\\n\\nIt has been shown that in many complex networks,\\nespecially the Internet, nodes that are very central tend\\nto interconnect more each other. This eﬀect, called rich\\nclub, produces a core of nodes that is really important for\\nthe stability and the robustness of the network and can be\\nquantiﬁed[31, 32]. Let us denote by E[ξ]\\n>k(t) the number of\\nconnections among the N [ξ]\\n>k(t) nodes with degree larger\\nthan the threshold k. The rich-club coeﬃcient is deﬁned\\nby\\n\\n.\\n\\n(2)\\n\\nN [ξ]\\n\\nφ[ξ]\\nk (t) =\\n\\n>k(t)\\n>k(t) − 1]\\n\\n2E[ξ]\\n>k(t)[N [ξ]\\nHowever, to understand to which extent the observed\\nrich-club eﬀect is not due to chance, we generate an en-\\nsemble of 1000 random networks preserving the empirical\\ndegree distribution and calculate the expected coeﬃcient\\n˜φ[ξ]\\nk (t). Therefore we study how the ratio φ[ξ]\\nk (t)\\nchanges as a function of k: when this ratio is close to 1\\nthe observed rich-club is compatible with random ﬂuc-\\ntuations, whereas when it is larger (smaller) than 1 it\\nindicates the existence (absence) of a rich core of nodes.\\nWe show in Fig. 4 the calculated value of the ratio for\\nthe Internet and the Darknet in 2015. The Internet ex-\\nhibits a clear rich-club eﬀect for nodes with intermediate\\ndegree, around k = 50, with largest hubs tending to be\\nnot interconnected each other. Conversely, the Darknet\\ndoes not exhibit a rich core, with slight tendency of the\\nlargest hubs to be not interconnected each other, eﬀect\\nthat in is magnitude signiﬁcantly smaller than the case\\nof the Internet.\\n\\nk (t)/ ˜φ[ξ]\\n\\nSumming up, the Internet consists of a backbone of\\nhigh-centrality nodes, whereas the Darknet does not.\\nThis result is compatible with the fact that nowadays\\nInternet is a very centralized network providing an easier\\nway to manage and search for online services, whereas\\n\\nFIG. 2. Modeling the Darknet structure in 2015. De-\\ngree distribution obtained from an ensemble of 50 random\\nrealizations of our model compared against the empirical dis-\\ntribution (the dashed line is for guidance only, to show the\\ndeviation of the degree distribution from a pure power-law\\nwith scaling exponent equal to -1.\\n\\nthe traditional preferential attachment. In fact, in a trust\\nnetwork like the Darknet, new nodes have to increase\\ntheir reputation before being trusted and this is more\\nlikely to happen with aging. Nevertheless, links have to\\nbe created between trusted nodes at time τ , therefore\\n2M nodes are randomly chosen with probability\\n\\npn(cid:48)(τ ) =\\n\\nAβ(n(cid:48), τ )Bγ(n(cid:48))\\nn\\n(cid:80)\\ni=1\\n\\nAβ(i, τ )Bγ(i)\\n\\n,\\n\\n(1)\\n\\nwhere A(n(cid:48), τ ) = τ − T (n(cid:48)) is the age of node n(cid:48) at time\\nτ . The nodes are then randomly linked into M pairs.\\nCrucially, the degree of each node at each time step does\\nnot play any role in the growing process, that is com-\\npletely driven by exogenous node’s properties such aging\\nand bandwidth. The ﬁnal step is to rewire nodes ran-\\ndomly, while preserving the degree distribution: this last\\nstage destroys possible structural correlations due to the\\nprevious stages of the model and it is crucial to introduce\\na higher level of randomness in connectivity.\\n\\nThis Darknet stochastic model is very general and,\\nvarying the exponents β and γ, it is possible to explore\\ndiﬀerent scenarios, e.g. where probability is inversely\\nproportional to age (β < 0) and proportional to band-\\nwidth (γ > 0). In practice, the value of M is ﬁxed by the\\ndata as M = (E − e0)/(N − n0) and therefore, the only\\nfree parameters of the model are, in general, β and γ. In\\nthe following, we do not ﬁt the parameters and we just\\nconsider the simplest scenario with linear proportionality\\n(β = γ = 1).\\n\\nOur simulations revealed that this model generates\\nnetworks that are remarkably close to the observed one\\nfrom diﬀerent perspectives. The high clustering and\\nsmall characteristic length are satisfactorily reproduced,\\n\\n\\x0c5\\n\\nFIG. 3. Reproducing the Darknet (2015) structural descriptors. Diﬀerent structural descriptors obtained from an\\nensemble of 400 random realizations of our model compared against the observed values. In the last panel, we report the mean\\nrelative diﬀerence between the value calculated from the data and the values calculated from the model (“D” is for diameter,\\n“APL” is for average path length and “GC” is for global clustering).\\n\\nthe Darknet is very decentralized (as the Usenet, the an-\\ncestor of the Internet) but it is more diﬃcult to manage\\nand search for hidden online services.\\n\\nIV. RESILIENCE OF THE DARKNET\\n\\nA. Resilience to static failures\\n\\nHere we investigate how the structural properties of the\\nDarknet and the Internet are reﬂected in their resilience\\nto perturbations. We consider three diﬀerent types of\\ndisturbances based on topological and dynamical pertur-\\nbations. Topological perturbations are static removals\\nof nodes that might mimic either random disruptions or\\ntargeted attacks[1]. Dynamical perturbations start with\\nthe disruption of a single node, generally the one with\\nhighest degree, that triggers a cascade of failures[21, 22].\\nIn random disruptions, a fraction pf ail of nodes is cho-\\nsen uniformly random in the network and removed. In\\ntargeted disruptions, the fraction pf ail of nodes is chosen\\naccordingly to their ranking with respect to a measure\\nof centrality. Usually, the degree is used, but also the\\nbetweenness[33] – quantifying centrality with respect to\\nthe communication ﬂow – and k-coreness[34] – based on\\nthe core decomposition of a network and characterizing\\nto which nested shell a node belongs to. It is common\\nto quantify the resilience of a network to such pertur-\\nbations by observing how the relative size of the largest\\nconnected component changes as a function of 1 − pf ail,\\ni.e. the fraction of survived nodes. This method allows to\\nquantify if the survived nodes are clustered all together\\nor if they form small disconnected clusters which hinder\\nthe network’s function.\\n\\nNon-homogeneous random networks are known to be\\nvery robust to random disruptions but very sensitive to\\ntargeted attacks. In fact, our ﬁndings conﬁrm that both\\nthe Internet and the Darknet are fairly robust to random\\n\\nfailures, whereas they are more damaged by targeted at-\\ntacks (see Supplementary Figures 2, 3 and 4). It is worth\\nremarking that the critical point, i.e. the fraction of dis-\\nruptions for which the size largest connected component\\nof the network is minimum, is very diﬀerent for the two\\nnetworks. In fact, while it is enough to target the 10%\\nof Internet nodes to reach the critical point, in the case\\nof the Darknet much more eﬀorts are needed, requiring a\\n40% of disruptions (this result is in excellent agreement\\nwith expectation from our model, see Supplementary Fig-\\nure 6). The corresponding relative diﬀerences between\\nthe two networks are explicitly shown in Fig. 5A, where\\nit is evident that the Darknet is by orders of magnitude,\\nmore resilient than the Internet, even with respect to\\n\\nFIG. 4. “Rich club” structure of Internet and Darknet\\nin 2015. Ratio between the rich-club coeﬃcient calculated\\nfor the empirical networks and its random expectation (see the\\ntext for further details) as a function of the degree threshold.\\nCoeﬃcient not shown for degree values for which the number\\nof nodes is smaller than 100 (about 2% of Darknet and 0.2%\\nof Internet).\\n\\n\\x0crandom disruptions.\\n\\nB. Resilience to dynamical failures\\n\\nAnother type of disruption, very suitable for commu-\\nnication networks, is based on the inducing cascade fail-\\nures. The rationale behind this method is that a node\\ni in a communication network is characterized by a cer-\\ntain capacity Ci, a ﬁxed feature quantifying the maximum\\namount of load they can operate with, and a load Li(τ ),\\na dynamical feature depending on the state of the net-\\nwork. Nodes with higher degree are assumed to be the\\nones with higher capacity, and at any time the total load\\nof the network is constant, i.e. L = (cid:80)\\nLi(τ ). If a node\\ni\\n\\nwith high capacity is disrupted, its load must be redis-\\ntributed among the other nodes of the network: but if the\\nnew loads exceed their capacities, a new set of nodes will\\nsuﬀer a disruption, redistributing the loads through the\\nremaining nodes and so on, thus generating a cascade of\\nfailures that can paralyze the system. The dynamics of\\ncascade failures and the resilience of the network can be\\nstudied as a function of a parameter α which improves\\nthe capacity of each node to (1 + α)Ci. By varying α\\nand calculating the relative size of the largest connected\\ncomponent at the end of the cascade, we can estimate\\nthe required enhancement in capacity to make the net-\\nwork resilient to this attack. The detailed results are\\nshown in Supplementary Figures 2, 3 and 4, whereas the\\ndiﬀerences are shown in Fig. 5B. Again, the Darknet is\\nmuch more resilient than the Internet to this catastrophic\\ncascade of failures, requiring just α ≈ 0.2 to remain fully\\noperative, whereas the Internet requires at least α = 0.28\\nto keep operative almost the 90% of its nodes (full op-\\nerations is guaranteed for values of α close to 1). This\\nresult is, one more time, in excellent agreement with ex-\\npectation from our model (see Supplementary Figure 6).\\nThe relative diﬀerences between the resilience of the two\\nnetworks clearly indicate that before and close to the crit-\\nical point the Darknet is more resilient than the Internet.\\nThis property has direct economic implications, because\\nlarger the value of α higher the costs to make the network\\nmore robust.\\n\\nV. CONCLUSIONS AND DISCUSSION\\n\\nWe have investigated the structural properties of the\\nDarknet, the communication network developed in the\\nlast two decades to guarantee safe and anonymous nav-\\nigation. The Darknet exhibits some interesting features\\nthat are not shared by the structure of the Internet.\\nTriadic closure in the Darknet is more likely than in\\nthe Internet, with communication paths much shorter in\\nthe former. Like the Internet, the Darknet is character-\\nized by a non-homogenous connectivity distribution and\\nthe presence of higher-order degree-degree correlations.\\n\\n6\\n\\nHowever, the topology of the Darknet is more interesting\\nbecause of the peculiar heavy-tailed scaling of the degree\\ndistribution, with scaling exponent close to -1 and cut-\\noﬀ, at variance with the Internet, appearing more like a\\npower-law with scaling exponent close to -2 and no evi-\\ndent cutoﬀ.\\n\\nThe rich-club analysis has revealed the lack of a core of\\nhighly central nodes interconnected each other, at vari-\\nance with the Internet where this eﬀect is remarkable. We\\nargue that such topological diﬀerences are responsible for\\nthe diﬀerent resilience exhibited by the two communica-\\ntion systems in response to random disruption, target at-\\ntacks and induced cascade failures. We have thoroughly\\nshown that the peculiar topology of the Darknet, charac-\\nterized by highly clustered communication circuits, small\\ncharacteristic distance between hops and lack of a rich\\ncore, makes this network much more resilient than the\\nInternet as a result of adaptive changes in response to\\nthe attempts of dismantling it across time.\\n\\nWhile the resilience of the Internet is not signiﬁcantly\\nchanging over time, the resilience of the Darknet is still\\nchanging. In fact, its resilience to topological disruption\\nslightly decreases between 2013 and 2014, remaining un-\\nchanged in 2015, whereas in the same year the Darknet\\nbecome slightly less resilient to induced cascade failures.\\nTogether with the trends revealed by other structural de-\\nscriptors, such as decreasing clustering, slightly increas-\\ning characteristic length and increasing assortativity, we\\nargue that the Darknet might be undergoing a transition\\nfrom decentralization to centralization of its services. It\\nwill be interesting to conﬁrm this prediction in the future,\\nwhen longer historical data will be available.\\n\\nBy mimicking how the Darknet actually works, we\\nhave proposed a model – based on a preferential at-\\ntachment mechanism depending on exogenous properties\\nsuch as aging and bandwidth and independent on endoge-\\nnous properties such as node’s degree – to reproduce the\\nempirical degree distribution with remarkable accuracy.\\nThe analysis shows that our model is suﬃcient to under-\\nstand the structural correlations and the robustness of\\nthe Darknet.\\n\\nWe recognize that there are many possible ﬂaws in the\\nrepresentation of both systems, the Darknet and the In-\\nternet, as to claim to have the true topological networks.\\nNevertheless, from the data available it is indeed possible\\nto start thinking about properties of the structure and its\\nimplications. The comparison between both structures\\nhas been developed at a descriptive level from the under-\\nlying graphs, with no other goal than using the Internet\\nas a benchmark to better highlight some salient features\\nof the Darknet. Finally, the proposal of a model driven\\nby the main features of the Darknet seems to be enough\\nto capture its more prominent topological features.\\n\\nSumming up, the main result of this work is the indica-\\ntion that the mechanisms adopted to guarantee anony-\\nmous traﬃc in the Darknet and to improve the cyber-\\nsecurity of its users could be the main responsible for the\\npeculiar topology of the Darknet observed so far, and its\\n\\n\\x0c7\\n\\nFIG. 5. Relative diﬀerences in resilience. (A) Diﬀerences between the Darknet and the Internet in resilience to random\\nand targeted attacks (see Supplementary Figure 5 for the diﬀerences in topological resilience in 2013 and 2014) and (B) induced\\ncascade failures.\\n\\nresilience.\\n\\nACKNOWLEDGMENTS\\n\\nThe authors\\n\\nthank Robert Annessi and Martin\\nSchmiedecker for providing the Tor raw data and sup-\\nport on data processing. MDD acknowledges ﬁnancial\\nsupport from the Spanish program Juan de la Cierva\\n(IJCI-2014-20225). AA acknowledges ﬁnancial support\\nfrom ICREA Academia and James S. McDonnell Foun-\\ndation and Spanish MINECO FIS2015-71582.\\n', 'Resilient Wireless Data Communication for  \\nCritical Infrastructure \\n\\n1\\n\\nMatthias van Doorn, product mgr., Ethernet, licensed radio systems, FreeWave Technologies, Inc. \\n\\n Abstract–Computer  technology  and  the  proliferation  of \\nnetworks  that  enabled  data  exchange  between  computers  gave \\nbirth to the Internet and mankind realized the dawn of a new, \\nvirtual  environment  aptly  named  “cyberspace.”  If  you  think \\nabout critical infrastructure, things that come to mind are all of \\nthe  services  and  assets  that  make  civilized  life  possible.  The \\nevolution of Smart Grid Technology promises the ability to have \\nreal-time  access  to  data.  All  of  this  is  made  possible  by \\nautomation  and  data  communication  systems  that  enable  the \\nintegration  of  critical  infrastructure  into  cyberspace.  But  as \\ncyberspace  evolves, \\nis  becoming  more  vulnerable  to \\nexploitation  and  attacks.  Today,  there  are  Frequency  Hopping \\nSpread  Spectrum  technologies  that  can  make  communication \\nnetworks more resilient to potential cyber security threats. This \\npaper  will  give  a  background  on  the  risks  as  well  as  how  to \\n“harden” a wireless communication network in order to protect \\nour critical infrastructure. \\n\\nit \\n\\nIndex Terms –                     \\nAccess control \\nComputer crime \\nData communication \\nFrequency hop communication \\nJamming \\nNetworks \\nSecurity \\n\\nI. CRITICAL INFRASTRUCTURE \\n\\nW \\n\\nHEN  you  think  about  critical  infrastructure,  what \\ncomes  to  mind  are  all  of  the  services  and  assets  that \\nmake  civilized  life  possible.  It  includes:  our  water  supply \\n(drinking  water,  waste  water  and  sewage);  heating  (e.g. \\nnatural  gas  or  heating  oil);  electricity  (from  generation, \\ntransmission  and  distribution \\nto  our  consumption); \\ntelecommunication;  oil  and  gas  as  fuels  or  for  chemical \\nproduction  (oil  and  gas  products  production,  transport, \\nrefineries,  distribution);  transportation  systems  (roadways \\nand bridges, railways, airports, harbors, inland shipping etc.); \\nfinancial services (banking); public health services (hospitals, \\nambulances)  or  public  safety  and  security  (police,  fire, \\nmilitary) and many others.  \\n\\nThese components of our infrastructure are critical to our \\ndaily  lifestyles  and  essential  for  the  efficient  functioning  of \\nour society and economy[1]. \\n\\n[1] According to the \"Presidential Decision Directive 63\" (PDD-63) from \\nMay 22, 1998: “critical infrastructures are those physical and cyber-based \\nsystems essential to the minimum operations of the economy and \\ngovernment.” \\n\\n978-1-61284-788-7/11/$26.00 ©2011 IEEE\\n\\nFig.1. Oil rig for oil production. \\n\\nII. CYBERSPACE \\nintroduction  of  computer \\n\\nthe \\n\\nWith \\n\\nthe \\nproliferation of networks has enabled data exchange between \\ncomputers  and  given  birth  to  the  Internet.  Now,  mankind  is \\nexperiencing  the  dawn  of  a  new,  virtual  environment  aptly \\nnamed “cyberspace.” \\n\\ntechnology, \\n\\nThe  implementation  of  new  technology  and  cyberspace \\nnot  only  has  reshaped  our  daily  activities,  but  has \\nrevolutionized  our  social  interactions.  In  fact,  the  impact  of \\ncyberspace  on  our  lives  has  been  staggering.  From  the  way \\nwe  do  business,  to  gathering  information  and  knowledge \\nabout health issues, to the way we get the news or receive our \\nentertainment  (music  or  movies)  or  how  we  share  our \\ninterests  and knowledge  about  subject  matters  within  online \\ncommunities. \\n\\nThese  days,  we  can  review  and  pay  our  electric  bills \\nonline,  rather  than  using  physical  paper  and  the  good-old \\nU.S. Postal Service. The evolution of Smart Grid Technology \\neven  promises  to  have  real-time  access  to  data  that  shows \\nhow  much  electricity  we  are  using  this  very  minute,  and  at \\nwhat cost, thereby giving us the opportunity to influence our \\nconsumer behaviors (and reduce our bill in the process). \\n\\nAuthorized licensed use limited to: Ryerson University Library. Downloaded on May 01,2022 at 17:05:51 UTC from IEEE Xplore.  Restrictions apply. \\n\\n \\n \\n \\n \\n \\n                                                 \\n \\n \\n \\n \\n \\n \\n \\n \\n\\x0cAll  of  this  is  made  possible  by  automation  and  data \\ncommunication systems that have enabled the integration of \\ncritical infrastructure into cyberspace. \\n\\nHowever,  the  evolution  of  cyberspace  has  made  it  more \\nattractive  and  more  vulnerable  to  exploitation.  There  has \\nbeen  an  increase  in  attacks,  stealing,  corruption,  harm  and \\ndestruction  to  our  systems.  In  fact,  the  actual  threat  of \\nhackers attacking critical infrastructure from communication \\nnetworks to financial institutions or even the electric grid has \\nbecome very real. \\n\\nAttacks  on  critical  infrastructure  themselves  are  nothing \\nnew. For example, back in World War II the electric grid in \\nGermany was the target of bombing raids aimed at disrupting \\nfactories  and \\ninterrupting  or \\nindustrial  production  by \\ncompletely denying the much-needed supply of electricity.   \\n\\nThese  days,  America’s  enemies  could  exploit  our  very \\nown  cyberspace  security  vulnerabilities  to  interrupt  our \\nthe  electric  grid,  as \\ncritical \\nacknowledged  by  both  the  Pentagon  and  the  Department  of \\nHomeland Security. \\n\\ninfrastructure,  such  as \\n\\nIn  fact,  military  officials  now  describe  cyberspace  as  the \\nfifth domain of war (following land, sea, air, and space) and \\nnote that cyberspace is unique, as it is the only battlefield to \\nbe invented by humans. \\n\\nWith  threats  to  our  information  infrastructure  and  data \\ncommunication  networks \\n(including  wireless  SCADA \\nnetworks responsible for critical infrastructure) increasing in \\nboth frequency and sophistication, it is no wonder that many \\norganizations,  and  even  branches  of  the  government  are  \\nlooking at addressing the issue with new policies and security \\nstandards[2].  \\n\\nThe  Cybersecurity  Enhancement  Act  of  2010,  H.R.  4061 \\nor  the  grant  for  a  National  Electric  Sector  Cyber  Security \\nOrganization for Cybersecurity for Energy Delivery Systems, \\nfunded  by  the  NETL  and  the  US  Department  of  Energy \\n(DoE) are other good and more recent examples. \\n\\nIII. THREATS \\n\\nThe  two  most  common  threats  to  data  communication \\n\\nnetworks today are Denial of Service (DoS) and Intrusion. \\n\\nA.  Denial of Service  \\n\\nDenial  of  Service  is  an  attempt  to  make  a  computer \\nresource or network unavailable to its intended users. Denial \\nof  Service  could  be  as  simple  as  jamming  an  electric  or \\nelectromagnetic  signal  or  as  sophisticated  as  saturating  a \\nsystem  or  network  with  communication  and  data  traffic \\nintended  to  overwhelm  and  avoid  legitimate  data  to  get \\nthrough and be processed. The consequences of DoS attacks \\n\\n[2] See “The National Strategy to secure Cyberspace,” The Department of \\nHomeland Security, February 2003. \\n\\n2\\ncan  range  from  being  simply  irritating,  for  example,  when \\nservices are unavailable or slow to respond – to dire – such \\nas  when  critical  control  signals  don’t  reach  the  intended \\ndestination.   For  example,  a  valve does  not  open  to  provide \\ncoolant liquid to a system threatening to overheat or a pump \\nthat  does  not  turn  on  as  intended  to  reduce  fluid  levels \\nthreatening to flood an area. \\n\\nB.  Intrusion \\n\\nrequires  a  different \\n\\nPenetrating  and  intruding  into  a  network  or  computer \\nlevel  of  sophistication. \\nresource \\nConsequences  can  range  from  simply  spying  or  stealing \\ninformation \\nto  corrupting  data  or  maliciously  and \\nintentionally  causing  harm  or  destruction  by  taking  over \\nnetwork and/or computers and control systems. For example, \\nintentionally  opening  valves  or  controlling  pumps  in  a \\nwastewater system resulting in contamination or pollution or \\nremotely opening pressure valves on a pipeline, allowing oil \\nor gas to escape into the environment. \\n\\nBy  no  means  is  this  a  complete  list  of  threats  and \\npotential attacks, after all, there are many published cases of \\ndisgruntled  employees  causing  all  sorts of  security  breaches \\nand havoc in the workplace. \\n\\nSophisticated  command  and  control  attacks,  packet \\nspoofing,  hijacking  of  sessions,  replay  attacks,  the  use  of \\nworms,  Trojans  and  remote  controllable  Trojans  (Back \\nOrifice),  the  use  of  a  Virus  and  Anti-forensic  techniques  as \\nwell  as  attacks  on  DNS  infrastructure  are  not  limited  to \\nwireless networks and need to get addressed as part of part of \\nan overall IT security strategy. \\n\\nIV. WIRELESS DATA COMMUNICATIONS \\n\\nUnlike  traditional  wire-lined  data  communication,  which \\ntypically  uses  copper  or \\nfiber-optic  cable  between \\ncommunication  endpoints,  wireless  data  communication  is \\nbased on electromagnetic waves using radio frequencies (RF) \\npropagating  through  open  space,  literally  the  air.  This  gives \\nwireless  some  unique  advantages,  as  communication \\nendpoints don’t need to be tied down to a fixed location and \\ndependent upon a physical cable. In addition, running cable, \\nconduit  or  even  digging  trenches  between  communication \\nendpoints  can  be  a \\ntime-consuming,  expensive  and \\nsometimes even a potentially dangerous proposition. \\n\\nHowever, the flexibility of wireless data communication \\ncomes  at  a  price.  Electromagnetic  waves  are  non-\\ndiscriminatory  when  it  comes  to  access.  While  a  wired \\nconnection  requires  physical  access  to  the  cable,  wireless \\nconnections can be made anywhere along the path on which \\nthe electromagnetic waves propagate. Consequently, security \\n(as  in  secure  access)  becomes  much  more  important  for \\nwireless data communication. \\n\\nA case and point; who has not heard the story of a guy in \\nthe  parking  lot  that  hacked  a  Wi-Fi  connection  to  steal \\nInternet access or gain access to private data (like credit card \\n\\nAuthorized licensed use limited to: Ryerson University Library. Downloaded on May 01,2022 at 17:05:51 UTC from IEEE Xplore.  Restrictions apply. \\n\\n \\n \\n \\n \\n  \\n \\n                                                 \\n \\n \\n \\n \\n\\x0cor  bank  information)  through  an  unprotected  wireless \\nnetwork?  A  case  that  actually  made  the  news  was  that  of  a \\n21-year-old Michigan man who attempted to steal credit card \\nnumbers  from  a  Lowe’s  home  improvement  store  through \\ntheir unsecured Wi-Fi network from inside his vehicle in the \\nstore’s parking lot back in 2004 and who was sentenced to 9 \\nyear in prison after he was caught[3]. \\n\\nAnd who did not  wish  that  the  movie  theatre or  church \\nused  a  cell  phone  jamming  device  (even  though  their  usage \\nisn’t legal in our country) when listening to the interrupting \\nring  tone  of  a  cell  phone?  Or  worse,  annoying  phone  calls \\nmade  in  the  middle  of  a  movie  or  sermon,  in  order  to \\nsuppress  those  pesky  wireless  cell  phone  calls  by  people \\noblivious to their environment? \\n\\nBesides thwarting attempts of insurgents to remotely and \\nwirelessly  detonate  improvised  explosive  devices,  those \\nforeign-made  jamming  devices  are  perfectly  suitable  for \\nkeeping the peace and not just on foreign battlefields. \\n\\nV. WIRELESS RESILLIENCY \\n\\nIt was back in 1941 when Hedy Lamarr, an Austria born \\nactress,  together  with  George  Antheil  co-patented  a  “secret \\ncommunication  system”  which  allowed  radio  control  of \\ntorpedoes that could not be easily discovered, deciphered or \\njammed[4].  \\n\\nHer secret: frequency hopping!  \\n\\nCoordinated,  rapid  changes  in  radio  frequencies  would \\nliterally “hop” in the radio spectrum, thus evading detection \\nand  the  potential  of  interference,  in  other  words,  being \\nsuppressed or jammed. \\n\\nEven  though  her  idea  was  ahead  of  its  time  and  not \\nimplemented  in  the  U.S.  until  1962,  when  it  was  used  by \\nU.S.  military  ships  during  a  blockade  of  Cuba  (after  the \\npatent had expired), it is now the basis for modern Frequency \\nHopping  Spread  Spectrum  (FHSS)  wireless  communication \\nsystems. \\n\\nA.  Frequency Hopping Spread Spectrum \\n\\nFrequency  Hopping  Spread  Spectrum  (FHSS)  wireless \\nsystems are very resilient when it comes to impairments such \\nas  interference  (deliberate  or  coincidental)  and  “jamming.” \\nOther  effects  can  be  observed  when  wireless  signals  travel \\nthrough space, such as the “multipath” phenomenon, simply \\nbecause they use only very small amounts of radio spectrum \\nat a time and don’t dwell (or remain) at that frequency long, \\ninstead  “hop”  to  another  frequency  quickly.  Statistically, \\nchances are that the signal does not “land” at the interfering \\nfrequency, thereby successfully evading the jamming signal.  \\n\\n[3] For more information on the specific case, see \\nhttp://www.securityfocus.com/news/10138 \\n[4] Copy of the US Patent 397,412 by Hedy Lamarr and George \\nAntheil \\n\\n3\\n\\nFig. 2.   Frequency Hopping. \\n\\nThis makes a Denial of Service (DoS) attacks on FHSS \\nsystems  very  difficult,  albeit,  if  not  completely  impossible. \\nHowever,  a  resilient  wireless  system  needs  more  than  a \\nrugged transmission system. \\n\\nVI. ACCESS CONTROL \\n\\nThere  are  many  positive  attributes  of  “industry \\nstandards”  based  wireless  devices.  However,  one  of  the \\nnegative aspects is that the only requirement to connect this \\nwireless device is an “off-the-shelf,” standards-based device \\n--  compatible  with  the  ones  used  in  a  specific  wireless \\nnetwork -- for access.  \\n\\nCase and point: a less than $50 Wi-Fi card is all I would \\nneed  to  try  to  gain  access  to  the  electromagnetic  waves \\nemitted  by  my  neighbor’s  Wi-Fi  Access  Point  and  Internet \\nconnection.  And  if  he  did  not  protect  it,  that’s  all  I  need  to \\nget “free” Internet access through his Wi-Fi network. \\n\\nProprietary  systems  and  devices  (especially  when  they \\noffer many “knobs” and configuration options to create more \\nprivate  networks)  actually  offer  a  higher  degree  of  security. \\nBut even those devices can be acquired, if you know where \\nto  get  them  -  a  well-known  Internet  auction  place  often \\nserves  as  the  source,  so  that  a  patient  hacker  can  figure  out \\nsettings to gain access, even if it may take a while. \\n\\nTherefore,  Access  Control  is  one of  the  most  important \\nto  prevent  unauthorized  access  and \\n\\nsecurity  features \\nintrusion. \\n\\nA.  Authentication, Authorization and Accounting \\n\\nAccess control is the cyberspace is the equivalent of the \\nsecurity  guard  at  the  main  door  of  an  office  building  that \\nmakes sure only people with the correct badge can enter. So \\ntoo,  the  goal  of  access  control  is  to  only  allow  network \\naccess  by  authorized  devices  and  to  disallow  access  to  all \\nothers.  Access  should  be  authorized  and  provided  only  to \\ndevices  whose  identity  has  been  established  (authenticated) \\nand  whose  placement  on  the  network  is  approved  in \\naccordance with network plans, designs or policy. \\n\\nThe  verification  of  identity,  or  Authentication,  is  based \\non the presentation of unique credentials to that system. The \\n\\nAuthorized licensed use limited to: Ryerson University Library. Downloaded on May 01,2022 at 17:05:51 UTC from IEEE Xplore.  Restrictions apply. \\n\\n \\n \\n \\n \\n \\n \\n \\n                                                 \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n\\x0cunique  serial  number  of  a  wireless  device  for  example  (that \\nhopefully can neither be “spoofed” nor counterfeited) may be \\nsuch a unique credential. \\n\\nRemote  Authentication  Dial  in  User  Service  (aka \\n\"RADIUS\")  is  a  popular  method  to  provide  centralized \\nAuthentication,  Authorization  and  Accounting  (“AAA”)  to \\nmanage access to wireless networks. \\n\\nVII. PRIVACY \\n\\nA good network security strategy should go even further \\nand protect data “in transit” as well. Even if an unauthorized \\ndevice  manages  to  gain  access  to  the  network,  it  doesn’t \\nnecessarily gain access to the actual data without passing yet \\nanother layer of security. \\n\\nFor thousands of years, cryptography provided this extra \\nlayer and maintained the privacy of the actual data between \\nthe  sender  and  recipient,  even  if  others  had  access  during \\ntransit or transmission. \\n\\nA.  Encryption \\n\\nMethods  of  encryption  and  deciphering  have  come  a \\nlong  way  since  then.  Today,  the  Advanced  Encryption \\nStandard (AES) is “the” industry standard for encryption. No \\nwonder,  considering  that  its  roots  go  back  to  the  National \\nInstitute for Standards and Testing (NIST) acting on the need \\nfor  a  new  encryption  algorithm  capable  of  protecting  top \\nsecret  information.  As  a  Federal  Government  standard  and \\neven used by the NSA, it can be trusted to protect sensitive \\ninformation and maintain data privacy. \\n\\nVIII. SECURITY POLICIES \\n\\nThe  aforementioned  are  only  a  few  basic  features  that \\nresilient  wireless  data \\n\\ncan  help  with  creating  a \\ncommunication system for critical infrastructure.  \\n\\nHowever,  a  good  network  security  strategy  needs  to \\naddress  and  implement  policies  that  serve  as  safeguards, \\nwhich make it difficult to circumvent security measures and \\nlimit the potential impact of a security breach of the wireless \\nnetwork. Consider those added layers of security. \\n\\nA.  Limitation of Permitted Activities \\n\\nOne  method  to  implement  safeguards  is  to  limit \\npermitted  activities  on  the  wireless  network  to  only  those \\nabsolutely  required  on  the  network.  The  basic  idea  is  if  a \\nwireless network were to be compromised, the impact would \\nbe limited.  In other words, a wireless network primarily used \\nfor  sensor  data  collection  and  remote  control  of  devices \\nshould  not  allow  a  hacker  that  compromised  the  network  to \\ngain  access  to  financial  or  other  critical  data.  Such  a \\nlimitation  of  permitted  activities  can  be  achieved  through \\nvarious means of security measures. \\n\\n4\\n\\nB.  Firewalls and Packet Filters  \\n\\nThese essentially separate the information needed on the \\nwireless  network  from  that  available  on  other  parts  of  the \\nnetwork.  \\n\\nC.  Virtual LAN’s (Virtual Local Area Networks) \\n\\nThese  are  used  to  separate  the  wireless  network \\ninfrastructure  and  its  management  from  the  production \\nnetwork, devices and/or communication endpoints. By using \\nvirtual  LAN’s,  we  see  the  introduction  of  another  level  of \\nsecurity,  especially  if  combined  with  Quality  of  Service \\n(QoS)  mechanisms.  Think  of  it  as  an  emergency  access  to \\nyour wireless network infrastructure for remote management \\nand  control,  in  case  a  Denial  of  Service  (DoS)  attack \\noverwhelms the actual payload and production network.   \\n\\nD.  User Level Access  \\n\\nBy implementing user level access (password protected), \\nyou  can  provide  access  to  your  wireless  infrastructure  and \\ndevices  to  e.g.  maintenance  personnel,  but  limited  to \\nmonitoring  system  health  or  performance  without  opening \\nthe  system  up  to  misuse  or  sabotage  because  configuration \\nand other privileges are reserved for a different user level and \\npassword.  \\n\\nE.  Access limitation of local ports  \\n\\nBy  controlling  who  is  allowed  access  from  local  ports \\n(e.g.  through  MAC  address  filtering)  or  even  completely \\nturning  off  local  port  access  when  they  are  not  in  use,  you \\ncan essentially make it impossible (or at least very hard) for \\nsomeone  who  gained  physical  access  to  your  network \\ninfrastructure and devices to get connected and gain access to \\nyour network. \\n\\nF.  Audit Logs \\n\\nNot really limiting permitted activities, but activity logs \\ndo provide a trail of access and activities and can be a useful \\ntool  in  auditing  and  tracing  potential  security  breaches  and \\nissues. \\n\\nAgain, this is by no means a complete list of options to \\nsecure  a  data  communication  network.  It  does,  however, \\nprovide  a  good  baseline  and  should  be  considered  if  your \\nwireless data communication equipment and devices support \\nthese  advanced  features.  Even  Secure  Shell  (SSH)  for  their \\nown  configuration  menus \\nreally  only  provide  basic \\nconnectivity, especially when they are being used for critical \\ninfrastructure applications.  \\n\\nIX. CONVENIENCE \\n\\nOften,  convenience  is  the  main  reason  behind  opening \\nFirewalls,  giving  users  too  many  privileges  and  too  much \\naccess, or, even worse, using default settings and passwords \\nthat  render  other  protective  measures  useless,  thereby \\nviolating  any  cyber-security  best  practices.  This  presents \\nmajor cyber vulnerabilities and an imminent threat to critical \\ninfrastructure  where  disruptions  could  result  in  catastrophic \\ndamage up to loss of life and property.  \\n\\nAuthorized licensed use limited to: Ryerson University Library. Downloaded on May 01,2022 at 17:05:51 UTC from IEEE Xplore.  Restrictions apply. \\n\\n \\n \\n \\n \\n \\n \\n\\x0c5\\n\\nSecurity  should  come  first  and  not  be  treated  as  an \\nafterthought.  Security  should  never  be  compromised  for \\nconvenience. \\n\\nX. CONCLUSION \\n\\nAny  chain  is  only  as  strong  as  its  weakest  link.  If  we \\ndon’t  start  building  and  implementing  adequate  protections \\nfor  our  wireless  data  communication  networks,  (especially \\nfor  our  critical  infrastructure,  with  the  goal  of  making  them \\nmore  resilient)  malicious  hackers  will  keep  exploiting, \\nattacking and ultimately destroying our way of life. \\n\\nXI. BIOGRAPHY \\n\\nMatthias  van  Doorn  is  a  native  of  Germany.  Mr. \\nvan  Doorn  holds  a  B.Sc.  degree  in  electrical \\nengineering and an MBA in international business. \\nMatthias  van  Doorn  is  the  Product  Manager  for \\nEthernet  and  licensed  radio  systems  at  FreeWave \\nTechnologies Inc. (www.freewave.com) \\n\\nMatthias  van  Doorn  brings  more  than  15  years  of \\nexperience  in  the  telecommunications  industry, \\nincluding  developing  comprehensive  SWOT  and \\ncompetitive  analyses;  positioning,  training  and \\nsales support; and, product life cycle  management, in accordance with ISO \\n9001  processes  working  with  cross-functional  teams  –  from  engineering  to \\noperations.  He  has  direct  industry  experience  working  for  a  number  of \\nrelated  companies,  including  CalAmp  Corp.,  ADC  Telecommunications, \\nDigi International and Siemens. \\n\\nAuthorized licensed use limited to: Ryerson University Library. Downloaded on May 01,2022 at 17:05:51 UTC from IEEE Xplore.  Restrictions apply. \\n\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n\\x0c', '1\\n\\nA Project to Develop a Trustworthy Cyber \\n Infrastructure for the Power Grid (TCIPG) \\n\\nPeter W. Sauer, Life Fellow IEEE   and William H. Sanders, Fellow IEEE    \\n\\nAbstract — This panel presentation discusses the research and \\neducation efforts of a center-scale project to develop a secure \\nenvironment  for  the  electric  power  grid  of  the  future.    It  in-\\nvolves  five  universities,  numerous  companies,  and  collabora-\\ntion  between  electrical  engineers,  computer  engineers,  com-\\nputer  scientists,  and education specialists.  In 2005, this team \\nembarked  on  an  ambitious  project  to  investigate  the  security \\nand  resilience  of  the  cyber  infrastructure  associated  with  the \\nexisting  electric  power  grid  and  future  expansions.    The \\npresentation  will  give  a  status  update  of  this  work  and  pro-\\nspects for future work.     \\n\\nIndex  Terms  —  Power  System  Cyber  Infrastructure, \\nCyber Security, Cyber Physical Systems. \\n\\nI.  A MULTI-UNIVERSITY CENTER-SCALE PROJECT \\n\\nW\\n\\nITH  funding  from  the  U.S.  National  Science \\nFoundation,  the  University  of  Illinois  at  Urbana-\\nChampaign  teamed  with  Dartmouth  College,  Cornell \\nUniversity and Washington State University to initiate a \\nmultidisciplinary  effort  to  investigate  the  challenges  of \\ncreating  a  trustworthy  cyber  infrastructure  for  the  elec-\\ntric  power  grid.    With  the  support  of  DOE  and  DHS, \\nthis  effort  was  expanded  to  include  four  major  thrust \\nareas  and  three  cross-cutting  efforts.    With  the  move-\\nment of a faculty member from Cornell to the University \\nof California at Davis, it also expanded to five universi-\\nties. \\n\\nThe  unique  aspect  of  this  project  is  the  collaboration \\nbetween  traditional  electric  power  engineering  people, \\ncomputer  engineers,  computer  scientists,  and  a  large \\nnumber  of  industry  advisors.    The  following  web  site \\nincludes information on the project: \\n\\nhttp://tcipg.org/ \\n\\nThis work was partially supported by the U.S. Department of En-\\nergy,  the  U.S.  Department  of  Homeland Security, the Power Systems \\nEngineering Research Center (PSERC) and the Grainger Endowments \\nto the University of Illinois. \\n\\nP. Sauer and W. Sanders are with the University of Illinois at Ur-\\nbana-Champaign,  Urbana,  IL    61801,  USA  (psauer@illinois.edu  and \\nwhs@illinois.edu). \\n\\nThe  following  sections  describe  the  basic  organization \\nof  the  project  and  further  information  associated  with \\nthe efforts. \\n\\nII.  FOUR CLUSTERS \\n\\n     The  research  for  this  project  has  the  following  four \\nclusters with associated threads: \\n\\n(cid:190)  Trustworthy Technologies for Wide-Area Moni-\\n\\ntoring and Control \\no  Communication and Data Delivery \\n\\n(5 activities) \\n\\no  Applications (2 activities) \\no  Component Technologies (2 activities \\n\\n(cid:190)  Trustworthy  Technologies  for  Local  Area  Man-\\nagement,  Monitoring,  Management,  and  Con-\\ntrol \\no  Active Demand Management (3 activities) \\no  Distribution Networks (2 activities) \\n\\n(cid:190)  Responding to and Managing Cyber Events \\n\\no  Design  of  Semi-automated  Intrusion  Detec-\\ntion and Response Techniques (6 activities) \\n\\n(cid:190)  Trust Assessment \\n\\no  Model-based Assessment (6 activities) \\no  Experiment-based Assessment (5 activities) \\n\\nThe  research  efforts  in  these  four  clusters  focus  on  the \\nmany  activities  within  each  thread.    Highlights  of  the \\nprogress in these activities will be presented in the panel \\nsession. \\n\\nIII.  THREE CROSS-CUTTING EFFORTS \\n\\nThree major efforts of this project cut across all clusters \\nand threads.  They include:   \\n\\n(cid:190)  Test bed Initiatives \\n\\no  Testbed development \\no  External involvement \\n\\n(cid:190)  Industry Interaction and Technology Transition \\n\\no  Activity Involvement \\no  Visits and Collaboration \\no  Technology Transfer \\n\\n978-1-4673-2729-9/12/$31.00 ©2012 IEEE\\n\\nAuthorized licensed use limited to: Ryerson University Library. Downloaded on May 02,2022 at 01:43:34 UTC from IEEE Xplore.  Restrictions apply. \\n\\n \\n  \\n \\n \\n \\n \\n                                                           \\n \\n \\n \\n \\n \\n \\n \\n     \\n \\n\\x0c2\\n\\n(cid:190)  Education and Engagement \\n\\no  K-12 Education \\no  Outreach and Workforce Development \\no  Consumer Education and Public Information \\n\\nIV.   SUMMARY \\n\\nThis  panel  presentation  will  present  the  status  of  the \\nresearch and education activities being conducted in this \\nproject with a focus on the four clusters and three cross-\\ncutting efforts. \\n\\nV.  BIOGRAPHY \\n\\nPeter  W.  Sauer  (StM’73,  M’77,  SM’82, \\nF’93,  LF’12)  received  his  BSEE  from  the \\nUniversity  of  Missouri  at  Rolla  and  the \\nMSEE  and  Ph.D.  degrees  from  Purdue \\nUniversity.  He has power facilities design \\nexperience with the US Air Force and was \\na  cofounder  of  the  PowerWorld  Corpora-\\ntion.  He  is  a  registered  Professional  Engi-\\nneer  in  Virginia  and  Illinois,  a  Fellow  of \\nthe  IEEE,  and  a  member  of  the  U.  S.  Na-\\ntional Academy of Engineering.  He has been a faculty member at the \\nUniversity  of  Illinois  since  1977,  and  he  is  currently  the  Grainger \\nChair Professor of Electrical Engineering. \\n\\nAuthorized licensed use limited to: Ryerson University Library. Downloaded on May 02,2022 at 01:43:34 UTC from IEEE Xplore.  Restrictions apply. \\n\\n \\n \\n \\n \\n  \\n \\n \\n\\x0c', '16 October 2020 \\n\\nA Resilient National Timing \\nArchitecture \\n\\nSECURING TODAY’S SYSTEMS, ENABLING TOMORROW’S \\n\\nDR MARC WEISS, DR PATRICK DIAMOND, MR DANA A. GOWARD  \\n\\n© RNT Foundation - Reproduction and distribution authorized provided RNT Foundation is credited. \\n\\n0 | P a g e  \\n\\n \\n \\n \\n \\n      \\n\\x0cA Resilient National Timing Architecture \\n\\n“Everyone  in  the  developed  world  needs  precise  time  for  everything  from  IT  networks  to \\ncommunications. Time is also the basis for positioning and navigation and so is our most silent \\nand important utility.” The Hon. Martin Faga, former Asst Secretary of the Air Force and retired \\nCEO, MITRE Corporation \\n\\nExecutive Summary \\n\\nTiming is essential to our economic and national security. It is needed to synchronize networks, \\nfor digital broadcast, to efficiently use spectrum, for properly ordering a wide variety of \\ntransactions, and to optimize power grids. It is also the underpinning of wireless positioning and \\nnavigation systems. \\n\\nAmerica’s over-reliance for timing on vulnerable Global Positioning System (GPS) signals is a \\ndisaster waiting to happen. Solar flares, cyberattacks, military or terrorist action – all could \\npermanently disable space systems such as GPS, or disrupt them for significant periods of time. \\n\\nFortunately, America already has the technology and components for a reliable and resilient \\nnational timing architecture that will include space-based assets. This system-of-systems \\narchitecture is essential to underpin today’s technology and support development of \\ntomorrow’s systems.  \\n\\nThis paper discusses the need and rationale for a federally sponsored National Timing \\nArchitecture. It proposes a phased implementation using Global Navigation Satellite Systems \\n(GNSS) such as GPS, eLoran, and fiber-based technologies. These were selected because they: \\n\\n•  Provide maximum diversity of sources and least common failure modes,  \\n•  Are mature, have repeatedly been demonstrated to perform at the required levels, and \\n\\nare ready to deploy, \\n\\n•  Have the potential for further development to increase accuracy, resilience, and cyber \\n\\nsecurity,  \\n\\n•  Are already supported, to varying degrees, by existing infrastructure, and \\n•  Require relatively modest investments.  \\n\\n1 | P a g e  \\n\\n \\n \\n \\n \\n \\n \\n\\x0cTiming is essential to maintaining our economy and national security. Today’s over-reliance on \\nvulnerable  GPS  satellite  signals  is  a  disaster  waiting  to  happen.  America  already  has  the \\ntechnology and components for a reliable and resilient national timing architecture to underpin \\ntoday’s technology, and support development of tomorrow’s systems. All that is needed is to \\nbring all the parts together. \\n\\nI. Imperatives \\n\\nPNT Essential, GPS Users Threatened \\n\\nThe last ten years have seen ever more sophisticated ways of disrupting satellite-based \\npositioning, navigation, and timing (PNT) services, as well as sharp yearly increases in the \\nnumber of disruptions reported. Compounding this, the U.S. Federal Communications \\nCommission has recently permitted an operation forecast to interfere with space based PNT for \\nmany users. \\n\\nAt the same time thousands of business models are built upon the assumption of continuously \\navailable, wide-area, wireless PNT. More and more lives depend upon uninterrupted PNT \\nservices. More and more new technologies - aerial drones, autonomous vehicles, intelligent \\ntransportation systems - are advancing, often just assuming PNT will be available.   \\n\\nThe National PNT Architecture1 is America’s plan for sufficiently robust PNT to ensure national \\nand economic security. Of P, N and T, the “T” is unquestionably foundational. GPS satellites, \\nLoran transmitters, and other wide-area systems are just radios broadcasting time signals from \\nknown locations. \\n\\nThus, in building a National PNT Architecture, the first and most important step is Timing. \\n\\nImportant and Urgent \\n\\nEstablishing a National Timing Architecture that serves the entire nation has become an \\nincreasingly important and urgent task. \\n\\nCurrent Dependence, Support to New Technology - While GPS signals were never intended \\nto be the nation’s time standard, their low barrier to entry, precision, and wide availability \\nhave made them the de facto national reference. At the same time, such wide adoption \\nmeans their vulnerabilities pose a near-existential threat.  \\n\\nThese vulnerabilities are problematic for existing systems and can limit development of \\nPNT-dependent technologies. The following are examples of particularly dependent sectors:  \\n\\n2 | P a g e  \\n\\n \\n \\n \\n\\x0c•  5G telecommunications - While many systems appear to have alternate and diverse \\ntiming sources and pathways, such as use of the IEEE 1588-2019 Precision Time \\nProtocol (PTP),2 many, if not most, of these trace back to GPS as the primary \\nreference. Thus, while 5G is moving forward, it is doing so with GPS time being a \\ncritical single point of failure.  \\n\\n•  Autonomy – As remarked by a senior U.S. Department of Transportation official, \\n\\n“No one is going to accept autonomous vehicles without a rock-solid foundation of \\nlocation and navigation.” Drones losing GPS signals and crashing as they are \\ncaptured by the wind, autonomous vessels being set on the rocks, demonstrations \\nof cars in self-drive mode being forced off the highway by white-hat hackers – all \\nreinforce the notion that reliable and robust PNT is on the critical path to further \\nsignificant advances in autonomy. \\n\\n• \\n\\n•  Transportation – Wireless PNT from GPS has been incorporated into every mode of \\ntransportation. Without it, every mode would slow, have less capacity, and be more \\naccident prone.  \\nIntelligent Transportation Systems (ITS) – Traffic routing applications such as \\nWaze,TM ride share services like UberTM and Lyft,TM train/bus arrival notifications, \\noptimized delivery service programs, traffic signal phase and timing coordination - all \\nare early implementations of ITS. In the absence of GPS’ wireless PNT none of these \\nwould be possible. Many businesses would either cease to exist or require massive \\nretooling and capital investment. Implementation of future ITS features will likewise \\nrequire robust, resilient, reliable PNT as part of their foundation.  \\n\\n•  Electric Power - Smart grid technology using synchrophasers for real time control \\n\\nwill bring greatly increased safety and efficiency to electrical power distribution. This \\nis unable to move forward, though, without multiple, differently routed Coordinated \\nUniversal Time (UTC) time signals to ensure system reliability. \\n\\n•  Financial Services – Consumer financial services (ATMs, checking, banking) depend \\nupon GPS’ PNT for timestamping transactions and for network synchronization. \\nFinancial services regulated by the Security and Exchange Commission use GPS for \\nsome applications, but typically also maintain their own internal time “epochs” with \\nsuites of clocks to create timestamped event records, fiber, microwave links, etc. \\nWhile they may be less vulnerable to disruption as a result, the large amounts of \\nmoney involved make them a more tempting target for malicious PNT disruption. \\n\\n•  Digital Broadcast & Land Mobile Radios – GPS’ precise timing is used to enable \\n\\ngreatly increased use of fixed spectrum in digital radio and television broadcasts, as \\nwell as mobile radio networks, over what was available with earlier analog systems. \\nAs an example, in their analog form handheld and mobile radios used by security, \\nfirst responder, military and others were able to support only one transmitter to be \\n\\n \\n\\x0con-air at a time, and one conversation on a frequency. Users had to be careful to \\npush their radio key to talk and say “over” to indicate they were done before \\nreleasing the key and freeing up the frequency for a reply. With digital systems \\nleveraging GPS’ precise time signals to divide up the conversations into packets, \\nmultiple conversations can be had simultaneously on the same frequency. \\n\\nExistential Contingency – Timing is an essential function for a wide variety of critical \\ninfrastructure. No developed nation can afford to risk losing timing.  \\n\\nThis has led to many nations beginning to establish more robust and resilient terrestrial \\ntiming architectures to complement and backup GNSS. As examples: \\n\\n•  Europe has a well-developed 1588 PTP network infrastructure linking national timing \\n\\nclock suites. \\n\\n•  The United Kingdom is establishing a virtual National Timing Centre with distributed \\n\\nsuites of atomic clocks at critical nodes throughout the nation. They are also \\ntransmitting precise time from a single eLoran source and appear to be \\ncontemplating additional transmitters. \\n\\n•  China has an exceptionally precise 1588 PTP network linking atomic clocks, and a \\n\\nrobust Loran time network. Its stated goal of “comprehensive PNT” represents the \\nworld’s most complete PNT architecture. China has mentioned in a recent publicly \\navailable paper that they will be constructing at least three new Loran transmission \\nsites and advancing the capability of their system.3 \\n\\n•  No information is immediately available about Russian 1588 PTP implementation, \\n\\nthough it is clear from their Radionavigation Plan4 that the Russian variant of Loran \\nwill continue to play an important role in national PNT.  \\n\\nProgress in the United States does not appear to be nearly as advanced. Several \\ngovernment departments and labs have distributed clock systems, though they do not \\nappear to be linked in any way to provide national timing resilience. These might, however, \\nhave the potential to be incorporated into and benefit the National Timing Architecture. See \\n“Technologies” section below. \\n\\nLegislation – While progress on system coordination and implementation does not appear \\nwell advanced in the U.S. as in some nations, general awareness of the importance of timing \\nresilience has increased. This has resulted in congressional interest and action. The National \\nTiming Resilience and Security Act of 2018,5 mandates the Department of Transportation \\nestablish at least one terrestrial timing system to backup GPS services by December of 2020.  \\n\\n \\n\\x0cThis legislation both documents the existential imperative of ensuring non-space-based \\nsources of timing and is a legal imperative in its own right.  \\n\\nII. Considerations \\n\\nArchitectural Considerations \\n\\nTiming Architecture Goals \\n\\nEstablishment of a National Timing Architecture must: \\n\\n▪ \\n\\nIncrease time resilience and redundancy across 100% U.S. land area & maritime \\nExclusive Economic Zone (EEZ),  \\n\\n▪  Provide trusted time via multiple authenticated, cybersecure sources that can also \\n\\nvalidate each other, \\n\\n▪  Support critical infrastructure and be a basis for commercial enhancement services, \\n▪  Provide a solid timing infrastructure upon which new technologies, research, and \\n\\nscientific applications can build,  \\n\\n▪  Ensure wireless access everywhere across 50 states and the EEZ to 500 nanoseconds or \\n\\nbetter accuracy relative to UTC, \\n\\n▪  Ensure wireless access everywhere in major metro areas to 100 nanoseconds or better \\n\\naccuracy relative to UTC, \\n\\n•  Provide Network Access Points (NAPs) in metro areas with 100 nanoseconds or better \\n\\naccuracy relative to UTC for further network distribution/use,  \\n\\n•  Ensure critical users have access to a minimum of three sources of timing (for \\n\\nredundancy & voting) relative to their required accuracies, and \\n\\n•  Ensure operational reliability is maintained to a “five 9’s” level of performance.  \\n\\nCharacteristics \\n\\nRedundancy - One of the more important principles of systems engineering and \\narchitecture is redundancy of critical systems. And the more critical the system, the \\nmore important redundancy. In the most important instances triplication is required.  \\n\\nFrom a concise on-line discussion: \\n\\n5 | P a g e  \\n\\n \\n \\n \\n \\n \\n \\n \\n\\x0cIn many safety-critical6 systems, such as fly-by-wire and hydraulic systems \\nin aircraft, some parts of the control system may be triplicated7 which is formally \\ntermed triple modular redundancy (TMR). An error in one component may then \\nbe out-voted by the other two. In a triply redundant system, the system has three \\nsub-components, all three of which must fail before the system fails. Since each \\none rarely fails, and the sub components are expected to fail independently, the \\nprobability of all three failing is calculated to be extraordinarily small; often \\noutweighed by other risk factors, such as human error. Redundancy may also be \\nknown by the terms \"majority voting systems\"8 or \"voting logic\".9 \\n\\nThe safety-critical nature of timing services means that the National Timing Architecture \\nmust be a hybrid network, or system of systems.  \\n\\nDiversity – Ensuring that the major timing sources in the architecture are as different \\nfrom each other as possible will help avoid common vulnerabilities, threats, and failure \\nmodes. It will also help safety-critical users maximize triple modular redundancy. \\n\\nCoordinated Universal Time (UTC) – Relative time is often sufficient for synchronization \\nof networks and in many other applications. However, UTC with the government’s \\nimprimatur (by the National Institute of Standards and Technology (NIST) and the \\nUnited States Naval Observatory (USNO)) must be the basis from which the National \\nTiming Architecture provides absolute time across the nation. \\n\\nResponsibility for Sources – The architecture must provide multiple diverse pathways \\nfor users to access and maintain time. Responsibility for providing these sources will \\nvary. For example, the responsibility to establish and maintain UTC, as well as the GPS \\nsatellite constellation, is clearly that of the federal government. Holdover clocks, when \\nneeded or appropriate, are clearly the responsibility of users. Responsibility for other \\nportions of the architecture will be the subject of policy decisions. \\n\\ndeath or serious injury to people \\nloss or severe damage to equipment/property \\nenvironmental harm \\n\\n\\n \\n \\n \\n \\n \\n \\n\\x0cRequirements \\n\\nCurrent Dependence, Support to New Tech – Available literature10 indicates that the \\nfollowing are representative of national requirements: \\n\\n•  5G telecommunications - Requires 1.1 microseconds accuracy relative to UTC for \\n\\nRadio Synchronization and overall network latency.11   \\n\\n•  Autonomy – Still in development and expected to vary by platform. Requirements \\n\\nfor lane keeping in vehicles are expected to range from 5 to 10 centimeters. This will \\nlikely exceed what can be reliably provided by infrastructure and require on-vehicle \\nsensors/ augmentation. Establishment of the national timing architecture will still be \\nkey to provide a solid foundation upon which innovators can build. \\n\\n•  Transportation – Requirements vary by application. For consumer-level applications, \\n100 nanoseconds timing and ten meters location accuracy appear to be sufficient.  \\nIntelligent Transportation Systems (ITS) – Same as telecommunications \\nrequirements above.  \\n\\n• \\n\\n•  Electric Power - Synchrophasers for real time control require multiple differently \\n\\nrouted UTC time signals at the 1 microsecond level or better.12 13 \\n\\n•  Financial Services – Individual firms frequently employ sufficient fiber and clock \\nsuites to maintain internal synchronization within their own epoch to very \\ndemanding limits, sometimes within a nanosecond. However, federal regulations \\nonly require firms to maintain 100 microseconds accuracy relative to UTC.  \\n\\nTechnologies \\n\\nUTC Access – Coordinated Universal Time (UTC) for the United States is maintained by \\nthe US Naval Observatory (USNO) in Washington, DC, and the National Institute of \\nStandards and Technology (NIST) in Boulder, CO. To use and distribute UTC, a \\ntechnology must synchronize with one of these two sources. Depending on the desired \\nlevel of accuracy, this can be done in a variety of ways including Two Way Satellite Time \\nTransfer (TWSTT), fiber connection, microwave link, GPS Common View, or from a GPS \\nreceiver.  \\n\\n\\n \\n \\n \\n \\n\\x0cIt is even possible to “physically” transfer time. Before the digital and communications \\nrevolution, entities would bring suites of atomic clocks to USNO to synchronize, and \\nthen transport those clocks to sites like Loran and Omega transmitting stations as a way \\nof distributing UTC.  \\n\\nGlobal Navigation Satellite Systems (GNSS)/GPS – The cornerstone of the National \\nTiming Architecture will be GPS which has a U.S. government supported 78 ns accuracy.  \\nApproval by the Federal Communications Commission (FCC) of Europe’s Galileo to be \\nused within the United States allows this second GNSS to also be included. This gives \\nadded resilience to the space-based portion of the architecture. - Note that GPS actual \\nperformance is almost always better than nominal. Accuracies of < 10 ns for timing and \\n< 10 ft for location are typical (1 ns ≈ 1 foot). \\n\\nLEO PNT – Numerous government and commercial endeavors are examining the \\nviability and benefits of providing PNT services from satellites in low earth orbit (LEO). \\nThis could be inferred from signals of non-PNT constellations. LEO PNT systems could \\nalso be created by sharing payloads with other missions, or with purpose-built and \\ndeployed constellations. We note that at least one vendor already offers time as a \\nsubscription service from LEO satellites.  \\n\\nNetworks / Fiber – Various levels of timing accuracy are available by networks and fiber \\nranging from about tens of milliseconds for NTP, to about 1 ns for dedicated bi-\\ndirectional wavelengths, each pair in a single fiber. Commercial providers have \\ntechnology available to provide users with localized, point, and autonomous timing to \\nmeet requirements for better than 100 ns accuracy.14 A newly released update to IEEE \\n1588-2019, also known as PTP, contains a “High-Accuracy Option.”15 This is a \\ngeneralization for wide area usage of the White Rabbit standard developed at CERN for \\nsub-nanosecond synchronization accuracy of more than 1,000 nodes via connections up \\nto 10 km of length.  \\n\\nWide Area Broadcast – Demonstrations in the United States and United Kingdom have \\nshown that eLoran technology broadcasting at 100 kHz is capable of providing better \\nthan 1 microsecond accuracy over distances up to 1,600 km from the transmitter, and \\nbetter than 100ns within 55 km of a differential reference station.16   \\n\\n \\n\\x0cNote that WWVB broadcasting at 60 kHz could conceivably be developed for this \\npurpose also. DARPA’s STOIC program also envisions a wide area time service using Very \\nLow Frequencies (VLF).  \\n\\neLoran – eLoran is a form of wide area broadcast using 100 kHz. It is at TRL 9, requiring \\nno development, and is compatible with other Loran systems in operation around the \\nworld. This provides significant technology synergies as well as the potential for positive \\nand beneficial engagement with other national operators.  \\n\\neLoran performance as a timing signal has been demonstrated to the U.S. Department \\nof Homeland Security as part of a Cooperative Research and Development Agreement,17 \\nand by research in the United Kingdom.18 A national eLoran timing system is also among \\nthe most recent recommendations of the US National Space-based PNT Advisory \\nBoard.19 In 2015 the US President’s National Space-based PNT Executive Committee \\ncommitted to establishment of an eLoran-based timing system.20  \\n\\nLocal Area Broadcast – Local broadcasts can provide timing, along with positioning and \\nnavigation information. The accuracy and geographic coverages of these local systems \\nvary with the technology, density of transmitters, and other factors. Systems have been \\ndemonstrated to have pico-second level accuracy in some instantiations.  \\n\\nDistributed Clocks – The federal government maintains various federal clock suites for \\nits own purposes that appear to be able to independently maintain a 1 microsecond \\nlevel of accuracy relative to UTC indefinitely. \\n\\n•  The Department of Defense, in addition to maintaining UTC at the US Naval \\nObservatory, Washington, DC, has a backup capability at Schriever AFB. \\nSynchronization is maintained via two way satellite time transfer (TWSTT). DoD \\nalso maintains a Defense Regional Clock Program. \\n\\n•  The Department of Commerce also maintains UTC at NIST Boulder, CO, with a \\nbackup at Ft Collins, CO. Synchronization is maintained by GPS Common-View \\nTime Transfer. NIST Gaithersburg, MD also maintains a clock suite using GPS \\nCommon View for synchronization. NIST is exploring synchronizing these sites \\nwith fiber networks, potentially at the 1 nanosecond level. \\n\\n•  The Department of Energy maintains suites of clocks at Oakridge, Sandia, and \\n\\nLawrence Livermore. \\n\\n\\n \\n \\n\\x0cNetwork Access Points NAPs – NAPs are physical locations, usually in major cities, \\nwhere Interexchange carriers, Independent Local Exchange Carriers, Competitive Local \\nExchange Carriers, National Carriers, Local Fiber Carriers, etc. “interconnect” with each \\nother’s services. All participating operators contribute to the cost. The national network \\nis made up of hundreds of these NAPs. \\n\\nThe fiber component of the National Timing Architecture will have these interconnect \\n“touch points” at its heart. All monitoring probes, testing, configurations, and \\nconnections for further, more localized distribution will occur at these locations. \\n\\nNetwork Control & Performance Assurance – Coherent networks require management \\nand control systems to ensure their operation and performance. These involve \\ngeographically distributed sensors, testing, performance and fault reporting. Such a \\ncontrol system requires its own redundancy and resilience. GPS, Loran-C and similar \\nsystems have ensured that full network monitoring and control is available at two or \\nmore geographical locations remote from each other.   \\n\\nCybersecurity – While not a technology in and of itself, authentication, access controls, \\nsystem and user cybersecurity must be considered throughout. The ability of users to \\ntrust the timing they receive is paramount. If, as has been seen around the world with \\npositioning, timing is not trustworthy, it may not be used. Worse, it could provide \\npotentially hazardously misleading information.  \\n\\nPolicy Considerations  \\n\\nFederal Leadership - The first duty of government is to afford protection to its citizens.21 \\n\\nTiming’s criticality and essentiality to such a broad spectrum of the public and critical \\ninfrastructure means that government has a responsibility to ensure such an architecture is \\nestablished, and quickly.22  \\n\\nThe essentiality of time to a nation’s economy and security has been recognized since at least \\n1714. The British “Longitude Act” of that year might have been better titled “The Time Keeping \\nAct.” It led to development of Harrison’s chronometer and untold immediate benefits to the \\nRoyal Navy and merchant fleets. In the United States, USNO has been dropping a time ball since \\n1845 to mark mean solar noon. Since then, the U.S. government has been communicating time \\nacross increasingly large sections of the nation at increasing levels of accuracy.  \\n\\n \\n \\n\\x0cThe federal role is also essential as the government’s imprimatur is required for a time signal to \\nbe credible, nationally interchangeable and as useful as possible. Any sufficiently stable time \\nsource is adequate for “relative time” to synchronize interconnected sources and other \\napplications that require events to be coordinated only with each other, but not the world at \\nlarge. Macro, national enterprise synchronization and interoperability, though, is only possible \\nwith a widely communicated time signal endorsed by the sovereign. \\n\\nAs discussed earlier, while the National Timing Architecture must provide multiple diverse \\npathways for delivery of authoritative time, responsibility for providing these sources will vary. \\nDirect federal involvement (leadership, funding, etc.) must ensure all citizens have reasonable \\naccess to more than one path to UTC to prevent time being a single point of failure. Other \\naspects of the architecture such as augmentations that increase accuracy, hold-over time in the \\nevent no external sources are available, and supplemental space-based signals may be the \\nresponsibility of users. \\n\\nThe federal government’s role in establishment and communication of national time is a \\ncritically important one. Yet it need not be onerous. Experience with similar efforts such as \\nFirstNet and the FAA’s ADS-B system has shown that often the least cost and quickest path to \\nsystem implementation is a partnership between the government and the commercial sector.  \\n\\nFurther reducing the burden on government is a recent technology demonstration done by the \\nDepartment of Transportation. It showed that sufficient systems exist today to complete a \\nrobust National Timing Architecture. \\n\\nCosts - There are risks and costs to action. But they are far less than the long-range risks of \\ncomfortable inaction. – Attributed to President John F. Kennedy \\n\\nNo discussion of a proposed federal investment would be complete without at least a general \\nconsideration of costs to both the federal government and users. These costs will be relatively \\nmodest, yet absolutely necessary. \\n\\nRelatively Modest – By leveraging public-private-partnerships, service-agreements, and the \\nlike, government can encourage and establish the infrastructure described herein at a cost \\nmeasured in tens of millions of dollars per year. This is relatively modest when compared to \\nannual expenditures on GPS which exceed $1B.  \\n\\nThe cost of end-user equipment will undoubtedly decline as more and more users access the \\nfiber-based and wireless signals. As was the case with GPS and most other technologies, early \\nuser equipment will likely be larger and more expensive than in later receiver models. An early \\npallet-sized GPS receiver, complete with two operator chairs, was budgeted for hundreds of \\n\\n11 | P a g e  \\n\\n \\n \\n \\n \\n \\n \\n\\x0cthousands of dollars. Miniaturization, technological advances, and mass production have \\nenabled production of the cheapest GPS for several dollars each.  \\n\\nUser costs will also be offset by the need to recapitalize equipment and improvements in utility.  \\n\\nAfter implementation of the National Timing Architecture there will be little incentive for \\nproduction of GPS/GNSS-only timing receivers. Just as manufacturers have incorporated other \\nGNSS systems alongside GPS in almost all new receiver models, so too will they almost certainly \\ninclude over time the ability to use the architecture’s terrestrial systems. Thus, the additional \\ncost for new builds and recapitalized equipment will be only marginally greater than it would \\nhave been otherwise in these cases.   \\n\\nMore resilient and reliable time will also provide many users increased functionality by virtually \\neliminating disruptions and providing a higher guaranteed accuracy. As one example of \\nincreased utility, this could allow reduced error margins in multiplexing wireless signals, \\nenabling greater use of existing spectrum allocations.  \\n\\nAbsolutely Necessary – Often lost in calculating the cost of doing something are the costs of \\ndoing nothing. When GPS fails, transportation-related systems immediately suffer. They \\nbecome less efficient/ more costly, can carry less capacity, and are more accident prone. Land-\\nmobile radio systems and digital broadcasts degrade or fail. In prolonged outages, two-thirds of \\nU.S. wireless networks are projected to fail after about 24 hours. Then, as backup clocks de-\\nsynchronize, more network and other failures will ensue, including the loss of consumer \\nfinancial services and impacts to utilities. One Air Force-sponsored academic paper projected \\ncivil unrest within 72 hours.  \\n\\nQuantitative analyses of the impact of GPS outages have always struggled. Most openly admit \\ntheir inability to gauge the overall impact to the national economy and limit themselves to \\nspecific applications or sectors. Notable studies have estimated prolonged disruption of GPS \\nsignals costing the US economy across a wide range of $1B23 to $82B24per day. \\n\\nIt is perhaps not possible to capture GPS’ true economic value and the impact of its potential \\nloss or prolonged outage. Dollar numbers may not have sufficient meaning in this context. As \\none writer replied when asked about the value of GPS – “What’s the value of oxygen?”25  \\n\\nPNT services, especially timing services, are an existential necessity for life in the United States \\nas we know it. Not ensuring they will always be available poses unthinkable risks and costs. \\n\\n\\n \\n \\n\\x0cAdoption \\n\\nWide adoption and use of the National Timing Architecture’s terrestrial systems is key to its \\nsuccess. Merely making them available will not increase national and economic security a whit. \\n\\nFortunately, America’s experience with implementation and adoption of GPS and other GNSS \\nprovides some lessons in this regard. And the government has a variety of tools available to \\nencourage this process \\n\\nThe GPS Experience – While there were a number of technical and historical factors in the \\nunparalleled wide adoption of GPS, the following were key: \\n\\n•  No cost access – GPS is free to access for anyone who can afford a receiver.26 Access to \\nthe basic terrestrial services in the National Timing Architecture should be without \\ncharge also. This does not preclude the government, one of its partners, or another \\nentity from providing fee-based services. But, in the interest of national and economic \\nsecurity, the service levels outlined herein must be without charge, to encourage wide \\nuse. \\n\\n•  Broad availability – GPS is available to anyone with a view of the sky. This means that it \\nis not location dependent. Something developed for use with GPS in New York also \\nworks in California and Alaska. The architecture’s terrestrial systems must be available \\nto all users in the United States, regardless of location. The entire nation and its coastal \\nwaters will have an accuracy of <500 ns, with densely populated areas having <100 ns \\nrelative to UTC. However, after implementation of Phase III, any 70-mile wide area can \\nbe upgraded to <100 ns with the installation of a (<$75,000) differential reference \\nstation. This is relatively inexpensive when compared to the $400,000+ cost of a \\nDifferential GPS site. \\n\\n•  Open source – This has been a dual edged sword for GPS and other GNSS. While it \\nallows for easy (and wide) adoption, use, and integration of signals into myriad \\napplications, it has also made the system much easier to jam and spoof. America’s \\nterrestrial systems must walk a fine line between encouraging wide and wise use and \\ndoing as much as possible to prevent interference. There are many methods for doing \\nthis, including having parallel services (perhaps an open system for free public use and a \\nclosed, more secure one for government and fee-based use). Encryption, authentication \\nand other security measures will be important aspects of development and operation. \\n\\n•  Government agencies leading the way – The initial goal of GPS was for the Air Force to \\n“…put five bombs in the same hole.”27 Early in its implementation, though, many \\n\\n \\n\\x0cmilitary leaders saw no need for the system and actively opposed it. In fact, at the end \\nof the first Gulf War there was no plan to install GPS in military aircraft. Congress had to \\ninsist on it. Adoption and use of GPS by the government was key to its broader adoption \\nacross society. This led to a virtuous cycle of improved performance and usability with \\ndecreasing costs. The current administration’s Executive Order on responsible use of \\nPNT28 already mandates federal leadership by mandating future federal contracts \\ninclude a requirement for use of resilient PNT equipment and systems.  \\n\\nEvery agency at every level of government has ample reasons to adopt terrestrial \\nservices from the National Timing Architecture. Dispatch, asset coordination, land \\nmobile radios, networks – all are degraded or disabled in GPS-denied environments. \\nImagine the National Guard responding to a disaster without the ability to navigate \\neasily or use their handheld radios. Government agencies and forces will need to use \\nthese terrestrial systems, if for no other reason than to ensure continuity of \\ngovernment. \\n\\nThe GNSS Experience \\n\\nGPS was the world’s first satellite navigation system available to consumers. As Russian and \\nEuropean systems became available, receiver manufacturers began incorporating the \\ncapability to use them on most of their products. This is happening again with inclusion of \\nsignals from the recently completed Chinese Bei Dou system. For years most receivers in the \\nUnited States, for example, have included the ability to access Russia’s GLONASS satnav \\nsystem, despite federal prohibitions on its use. Many manufacturers ensure this feature is \\ndisabled while the equipment is within the U.S. but include it nonetheless. This is because: \\n\\n•  The additional cost is minimal due to decades of technological advancement, \\n•  Building receivers to be as capable as possible is a competitive advantage, or at \\n\\nleast prevents a competitive disadvantage, \\n\\n•  Making different receivers for different markets is not cost effective, and \\n•  Users don’t want their equipment restricted by geography and expect it to operate \\n\\nat maximum efficiency everywhere. \\n\\nWe can expect that as receiver technology develops and improves in the critical areas of \\nsize, weight, power and cost, more and more receivers will include the ability to use the \\nterrestrial components of the National Timing Architecture as part of their timing and \\nnavigation solutions.  \\n\\nIncorporation of eLoran will be especially incentivized as compatible signals are already \\navailable across a significant portion of the globe (see graphic).  \\n\\n \\n\\x0cGovernment Encouragement & Requirements  \\n\\nOfficials truly concerned about the impact of timing resilience on the nation’s security and \\neconomy have multiple tools at their disposal to encourage adoption of better systems and \\npractices.  \\n\\nThe February 2020 Presidential Executive Order on Responsible Use of PNT29 outlined the \\nadministration’s plan to use educational efforts and government contracting requirements \\nto stimulate increased PNT resilience across critical infrastructure and industries.  \\n\\nShould these efforts not sufficiently protect the nation, greater incentives and requirements \\nshould be considered and implemented. In the past these have included things like tax \\ncredits for installing new equipment and performance-based regulations. \\n\\nPutting Together the Pieces \\n\\nPut simply, we find time transfer by eLoran and fiber are mature technologies easily capable of \\nspanning the nation. When combined with GNSS, users will have three independent pathways \\nfor authoritative Coordinated Universal Time. \\n\\n \\n \\n \\n \\n \\n\\x0cMaintaining and reinforcing America’s network and IT infrastructure is more important now \\nthan ever.  \\n\\nCyber security needs are increasing. Demands on telecommunications service providers are \\nincreasing. Space is more and more crowded. GNSS intentional or unintentional interference is \\nincreasing. \\n\\nThe COVID pandemic has greatly increased our reliance on networks and distributed work. The \\nnumber of people who must work remotely, often in locations outside of major metropolitan \\nnetwork nodes has grown significantly. A failure or even temporary outage in any part of our \\nfar-flung networks will have much greater impact that it would have had even a year ago.  \\n\\nAdding to domestic concerns, we must also maintain the nation’s competitiveness and standing \\nin the world. Europe, China, and others have and are establishing foundational timing systems, \\nsometimes as part of coherent architectures, to provide innovators and engineers needed \\ninfrastructure for current and yet-to-be-developed systems. \\n\\nWhile the technologies we propose are mature, and the structure fairly uncomplicated, \\nbringing a National Timing Architecture into reality will have its difficulties. Network design, \\nimplementation, contract and project management, ongoing operation – all will be challenges. \\nThe experiences of projects like FirstNet and ADS-B, though, will be good guides. \\n\\nMost important and fundamental will be fostering and maintaining the political understanding \\nand imperative for action outlined in the National Timing Resilience and Security Act of 2018.  \\n\\nThe task is a relatively straight forward one.  \\n\\nWe can ill afford to do less. \\n\\n16 | P a g e  \\n\\n \\n \\n\\x0cII. Proposed Architecture \\n\\nStructure & Implementation  \\n\\nRecognizing the differences in readiness levels of various solutions, and the differences in cost \\nand ease of implementation, this proposal takes a phased approach to implementing the \\nNational Timing Architecture. \\n\\nImplementing by increments also provides opportunities for user feedback before the entire \\nsystem is built out. If solutions are not adopted or prove difficult, the architecture and the \\nsystems it includes can be modified or changed completely without incurring major costs. \\n\\nThis proposal also: \\n\\n•  Recognizes the higher demand for timing services and concurrently higher return on \\n\\ninvestment in geographic centers of population and infrastructure,  \\n\\n•  Conforms to the National PNT Architecture final report, \\n•  Uses the layered principled outlined in the US Department of Defense PNT Strategy.30  \\n\\nTechnologies \\n\\nGNSS, eLoran, and fiber-based timing were selected as the primary sources for the National \\nTiming Architecture because they: \\n\\n•  Provide maximum diversity of sources and least common failure modes,  \\n•  Are mature and ready to deploy, \\n•  Have the potential for further development to increase accuracy, resilience, and cyber \\n\\nsecurity, and  \\n\\n•  Are already supported, to varying degrees, by existing infrastructure \\n\\no  GNSS is clearly fully deployed and in use  \\no  eLoran primary transmitter sites are already owned by the US government \\no  Fiber networks and government distributed clock suites are extant and continue \\n\\nto grow. \\n\\nAnd while a comparative cost analysis is not part of this paper, prima facia, the terrestrial \\nsystems listed above are of modest cost relative to GNSS and other terrestrial systems. \\n\\nThe selection of eLoran over other mature broadcast technologies is also based upon extensive \\nresearch in the U.S. and U.K. showing its effectiveness (see previous references). Also, \\nalternative analyses performed by the U.S. government show it as the only technology that \\ncombines wide area coverage with sufficient accuracy.31  \\n\\n \\n\\x0cNetwork Control & Performance \\n\\nOperational performance integrity will be key to acceptance and use of the National Timing \\nArchitecture. Critical users will demand “always on” performance, the ability to view the \\noperational stability in real time, an automated failover capability, centralized reporting, and \\nmanagement in the event of a fault. Just as the Air Force commits to and publishes a \\nperformance standard for the broadcast of GPS signals, so too the government must commit to \\na performance standard for the terrestrial portions of the National Timing Architecture. \\n\\nNotional Phases  \\n\\nThe following notional implementation phases are suggested to progressively support critical \\ninfrastructure, technology development and maximize the practical use for citizens.  \\n\\n18 | P a g e  \\n\\n \\n \\n\\x0cPhase I National Timing Architecture \\n\\nGlobal Layer \\n\\nGNSS \\n78ns \\n\\nLEO PNT \\n\\nContinental Layer \\nN. Clock \\neLoran \\nNtwk \\n<1 µs \\n<100 ns \\n6 sites \\n\\nLocal Layer \\n\\nDf eLoran \\n<100 ns  \\n\\nNAP \\n<100 ns \\n\\nUser \\nClocks \\n\\nFixed Users \\nw/ntwk access \\nEverywhere \\n(50 states, EEZ) \\nMajor Metro \\n\\nFixed Users w/ \\nNo ntwk access \\nEverywhere \\n(50 states, EEZ) \\nMajor metro \\n\\nMobile Users \\nEverywhere \\n(50 states, EEZ) \\nMajor Metro \\n\\nSelected  \\n\\nSelected  \\n\\nSelected \\n\\n*Selected \\n\\n* \\n\\n* \\n\\nGovt sponsored/PPP, No/low barrier to entry \\n\\nAvailable, commercial, fee based \\n\\nPhase I Notes: \\n\\nNational Clock Network (N. Clock Ntwk) - Fiber: Connect \\n\\n•  NIST Boulder with USNO to establish <10 ns sync. \\n•  Selected (TBD) major metros, eLoran differential transmitters, and eLoran primary \\n\\ntransmitters <100 ns sync \\n\\neLoran: Establish 6 primary transmitter sites (4 in CONUS, 1 each in AK & HI) \\n\\nDifferential (Df) eLoran: Establish differential sites in selected (TBD) metro areas \\n\\n*If GNSS location information is available to a mobile receiver, eLoran time info will be usable \\nand, if properly integrated, can make receivers much less susceptible to GNSS disruption. \\n\\n19 | P a g e  \\n\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n\\x0c32 \\n\\n32 Graphics adapted with permission from UrsaNav presentations \\n\\n20 | P a g e  \\n\\n \\n \\n \\n\\x0cPhase II National Timing Architecture \\n\\nGlobal Layer \\n\\nGNSS \\n78ns \\n\\nLEO PNT \\n\\nContinental Layer \\nN. Clock \\neLoran \\nNtwk \\n<500 ns \\n<100 ns \\n12 sites \\n\\nDf eLoran \\n<100 ns \\n75 sites \\n\\nLocal Layer \\n\\nNAP \\n<100 ns \\n\\nUser \\nClocks \\n\\nFixed Users \\nw/ntwk access \\nEverywhere \\n(50 states, EEZ) \\nMajor Metro \\n\\nFixed Users w/ \\nNo ntwk access \\nEverywhere \\n(50 states, EEZ) \\nMajor metro \\n\\nMobile Users \\nEverywhere \\n(50 states, EEZ) \\nMajor Metro \\n\\n* \\n\\n* \\n\\n* \\n\\n* \\n\\nGovt sponsored/PPP, No/low barrier to entry \\n\\nAvailable, commercial, fee based \\n\\nPhase II Notes: \\n\\nN. Clock Ntwk - National Clock Network (Fiber) Connect:  \\n•  National Laboratories & other federally endorsed clock suites. Maintain accuracy at the \\n\\n100ns level or better (to be determined) relative to UTC. \\n\\n•  Connect to Network Access Points and differential eLoran sites in major metro areas at \\n\\n<100 ns level relative to UTC for possible further distribution by govt/ commercial services. \\n\\neLoran: Establish 6 additional primary transmitter sites in CONUS (system total of 10 in CONUS, \\n1 ea AK & HI) for <500 ns relative UTC (exception are remote areas of AK <1 µs) \\n\\nDifferential (Df) eLoran: Establish total of 75 differential sites to serve the 50 largest metro \\nareas, 50 busiest airports, 50 busiest seaports in CONUS, 3 locations in AK and 1 in HI. \\n\\n21 | P a g e  \\n\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n\\x0c*If GNSS location information is available to a mobile receiver, eLoran time broadcast info will \\nbe usable. If properly integrated, eLoran signals can make receivers much less susceptible to \\nGNSS disruption. \\n\\n22 | P a g e  \\n\\n \\n \\n \\n \\n\\x0cPhase III National Timing Architecture \\n\\nGlobal Layer \\n\\nGNSS \\n78ns \\n\\nLEO PNT \\n\\nContinental Layer \\nN. Clock \\neLoran \\nNtwk \\n<500 ns \\n<100ns \\n≈25 sites \\n\\nDf eLoran \\n<100 ns \\n75 sites \\n\\nLocal Layer \\n\\nNAP \\n<100 ns \\n\\nUser \\nClocks \\n\\nFixed Users \\nw/ntwk access \\nEverywhere \\n(50 states, EEZ) \\nMajor Metro \\n\\nFixed Users w/ \\nNo ntwk access \\nEverywhere \\n(50 states, EEZ) \\nMajor metro \\n\\nMobile Users \\nEverywhere \\n(50 states, EEZ) \\nMajor Metro \\n\\nGovt sponsored/PPP, No/low barrier to entry \\n\\nAvailable, commercial, fee based \\n\\nPhase III Notes: \\n\\nNational Clock Network:  Link in-development and future optical clocks for scientific and \\nresearch. Frequency accuracies pushing the boundaries of science and human imagination. \\n\\neLoran: Establish ≈13 additional primary transmitter sites (total of ≈16 CONUS, 6 in AK, 3 in HI) \\n\\nGPS/GNSS-Independent Positioning, Navigation, and Timing – Accessing terrestrial wireless \\ntime for mobile users requires their locations be known. Sufficient primary eLoran transmitters \\nare deployed in Phase III to provide that information without regard to signals from space. This \\nalso enables positioning and navigation based solely on eLoran, in the event that signals from \\nspace become unavailable. Continuous synchronization with UTC by fiber or other means to \\none or more points in the primary eLoran transmitter network and the ability of the network to \\nself-synchronize enables it to operate indefinitely providing PNT in the event of a prolonged \\nGPS/GNSS outage.  \\n\\n23 | P a g e  \\n\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n\\x0c24 | P a g e  \\n\\n \\n \\n \\n\\x0cAbout the Authors \\n\\nMarc Weiss, PhD   \\n\\nDr. Weiss worked at the NIST Time and Frequency Division from 1979 through 2013. He has since been a \\nconsultant on precision timing systems for NIST and for various companies. He received several awards \\nduring his tenure at NIST. He led the NIST program to support the GPS program office in developing their \\nclocks and timing systems. In 1992, Dr. Weiss founded and has continued to lead the Workshop on \\nSynchronization and Timing Systems (WSTS), now the premier conference on timing and synchronization \\nin industry. In April, 2019, Dr. Weiss was awarded the Marcel Ecabert Lifetime Achievement Award “For \\nhis key contributions to remote clock comparisons, to time scale algorithm development and to accurate \\nsynchronization for science and industry.”  \\n\\nPatrick Diamond, PhD  \\n\\nDr. Diamond has 40+ years in development and design of network technologies. His tenure in the \\nnetwork technology, design and implementation marketplace has been, specifically in the commercial \\nmarketplace. He has and is a participant in Standards body development organizations, IEEE, IETF, ITU. \\nHe has helped develop numerous Wide Area Network technologies such as SONET/SDH, TCP/IP, IEEE \\n1588, IEEE 802.1AS, 3GPP and numerous others specifically dedicated to precision timing in networks \\nand end user systems. He developed and managed organizations that created highly complex System on \\na Chip technologies in semiconductors for these end implementations. He now serves and a member of \\nthe US National Space-Based Positioning, Navigation and Timing Advisory Board. \\n\\nDana A. Goward, SES (ret), CAPT (ret) \\n\\nMr.  Dana  A.  Goward  is  President  of  the  Resilient  Navigation  and  Timing  Foundation,  a  scientific  and \\neducational charity dedicated to protecting GPS/GNSS signals and users.  \\n\\nHe is a lifelong practical navigator orienteering ashore, serving as a ship’s navigator at sea, and in the air \\nas a career Coast Guard helicopter pilot. \\n\\nHe retired in 2013 from the Senior Executive Service as the maritime navigation authority for the United \\nStates and now serves as a member of the US National Space-Based Positioning, Navigation, and Timing \\nAdvisory Board. He is also a senior advisor to Space Command’s Purposeful Interference Response \\nTeam, is an emeritus Chairman of the Board for the Association for Rescue at Sea, and is the proprietor \\nat Maritime Governance, LLC. \\n\\n25 | P a g e  \\n\\n \\n \\n \\n \\n\\x0c', '2021 13th International Conference on Cyber Conflict \\nGoing Viral\\n\\nT. Jančárková, L. Lindström, G. Visky, P. Zotz (Eds.)\\n\\n2021 © NATO CCDCOE Publications, Tallinn\\n\\nPermission  to  make  digital  or  hard  copies  of  this  publication  for  internal \\nuse within NATO and for personal or educational use when for non-profit or \\nnon-commercial purposes is granted providing that copies bear this notice \\nand a full citation on the first page. Any other reproduction or transmission \\nrequires prior written permission by NATO CCDCOE.\\n\\nCyber Personhood\\n\\nNeal Kushwaha\\nFounder and Advisor\\nIMPENDO Inc.\\nOttawa, Canada\\nneal@impendo.com\\n\\nKeir Giles\\nConflict Studies Research Centre\\nNorthamptonshire, United Kingdom\\nkeir.giles@conflictstudies.org.uk\\n\\nTassilo Singer\\nConsultant Manager \\n(Cyber Security & AI)\\nAtos Information Technology GmbH\\nMunich, Germany\\ntassilo.singer@atos.net\\n\\nBruce W. Watson\\nChief Scientist and Advisor\\nIP Blox and IMPENDO Inc.\\nEindhoven, Netherlands, and Ottawa, \\nCanada\\nbruce@ip-blox.com and \\nbruce@impendo.com\\n\\nAbstract: In early 2020, the rapid adoption of remote working and communications \\ntools  by  governments,  companies,  and  individuals  around  the  world  increased \\ndependency on cyber infrastructure for the normal functioning of States, businesses, \\nand societies. For some, the urgent need to communicate whilst safeguarding human \\nlife  took  priority  over  ensuring  that  these  communications  tools  were  secure  and \\nresilient. But as these tools become firmly embedded in everyday life worldwide, the \\nquestion arises whether they should be considered as critical infrastructure, or perhaps \\neven something more important.\\n\\nIn  a  number  of  States,  the  critical  importance  of  the  environment  for  preservation \\nof human life has been recognised by extending legal personhood – and thus, legal \\nrights  –  to  environmental  entities.  Countries  such  as  Colombia,  Ecuador,  New \\nZealand, and India have granted legal rights to various rivers, lakes, parks, and nature \\nin  general.  This  paper  explores  the  future  possibility  and  cases  where  States  may \\nconsider granting legal rights to other non-sentient but critically important entities. \\nLooking into a future where human life becomes increasingly dependent upon highly \\ninterdependent  systems  in  cyberspace,  is  there  a  possibility  that  these  systems  are \\ngranted personhood? \\n\\nRemote  work  and  its  cybersecurity  implications  could  lead  to  an  entirely  new \\nrecognition of the importance of cyberspace dependencies and, consequently, a new \\n\\n.\\n\\n.\\n\\n.\\n\\n9\\n9\\n2\\n8\\n6\\n4\\n9\\n1\\n2\\n0\\n2\\n9\\n3\\n9\\n1\\n5\\nN\\nO\\nC\\nY\\nC\\n/\\n9\\n1\\n9\\n3\\n2\\n0\\n1\\n1\\n2\\n0\\n2\\n©\\n0\\n0\\n1\\n3\\n$\\n/\\n1\\n2\\n/\\n7\\n-\\n5\\n-\\n5\\n6\\n5\\n9\\n-\\n6\\n1\\n9\\n9\\n-\\n8\\n7\\n9\\n|\\n)\\nn\\no\\nC\\ny\\nC\\n(\\n\\n.\\n\\nt\\nc\\ni\\nl\\nf\\nn\\no\\nC\\nr\\ne\\nb\\ny\\nC\\nn\\no\\ne\\nc\\nn\\ne\\nr\\ne\\nf\\nn\\no\\nC\\n\\nl\\n\\na\\nn\\no\\ni\\nt\\na\\nn\\nr\\ne\\nt\\nn\\n\\nI\\n\\nh\\nt\\n3\\n1\\n1\\n2\\n0\\n2\\n\\nAuthorized licensed use limited to: Ryerson University Library. Downloaded on May 03,2022 at 01:17:07 UTC from IEEE Xplore.  Restrictions apply. \\n\\n275\\n\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n\\x0clegal treatment. Against the backdrop of extended debate on the legal regulation of \\ncyberspace, including the law of armed conflict, this would raise even more complex \\nlegal considerations, especially in the light of cross-border dependencies and systems \\nthat affect multiple jurisdictions.\\n\\nBy  way  of  cyber  biomimicry,  this  paper  adopts  a  blue-sky  conceptual  approach  to \\nstudying  policy  considerations  and  potential  implications  if  highly  interdependent \\ncyber systems in the distant future are granted the same protections as elements of \\nthe environment.\\n\\nKeywords:  cyber  personhood,  environmental  personhood,  cyber  attack,  highly \\ninterdependent cyber systems\\n\\n1. INTRODUCTION\\n\\nUnder Canadian and U.S. environmental law, rivers, parks, and other natural resources \\nupon which life depends do not have standing in their respective jurisdictional courts. \\nInstead, in order for there to be standing, harm to any of these natural features must \\nhave resulted in injury to human beings. But what if natural resources were widely \\nrecognised  in  courts  and  had  legal  rights,  with  injuries  to  these  natural  resources \\nrecognised as crimes with victims in and of themselves?\\n\\nIf  so,  could  this  be  extrapolated  to  a  distant  future  where  highly  interdependent \\nresources  in  cyberspace  upon  which  life  depends  are  also  recognised,  on  the  basis \\nthat these too are dynamic systems that have standing so that courts can recognise \\ntheir injuries? This concept may appear unlikely, but so did the idea of environmental \\npersonhood  decades  ago,  and  today  it  is  reality.  In  a  world  where  our  dependence \\non cyber systems is ever increasing, the idea of States granting cyber personhood to \\nhighly interdependent cyber systems of the future could be a logical progression of a \\nnumber of current trends.\\n\\nThis paper examines environmental personhood and how a small number of States \\nhave granted it to certain natural resources. Through examples, we then describe the \\nterm “cyber personhood,” align it to the precedent set by environmental personhood, \\npresent  candidates  for  cyber  personhood,  and  identify  where  we  believe  cyber \\npersonhood could not apply and where it may.\\n\\nFinally, we examine certain policy considerations and potential implications of cyber \\npersonhood and provide our thoughts on the wider adoption of this concept.\\n\\n276\\n\\nAuthorized licensed use limited to: Ryerson University Library. Downloaded on May 03,2022 at 01:17:07 UTC from IEEE Xplore.  Restrictions apply. \\n\\n\\x0cIn order to digest the content presented in this paper, we urge the reader to (1) look \\nfar  into  the  future  to  help  visualise  these  highly  interdependent  cyber  systems  and \\n(2)  not  consider  current  cyber  systems  as  candidates  for  cyber  personhood.  To \\nhelp standardise our discussion across the political, policy, legal, and technological \\ndomains, we present the following definitions.\\n\\n•  Cyberspace:  “The  environment  formed  by  physical  and  non-physical \\ncomponents to store, modify, and exchange data using computer networks.”1 \\n•  Cyber infrastructure: “The communications, storage, and computing devices \\n\\nupon which information systems are built and operate.”2\\n\\n•  Critical infrastructure: \\n\\ni. \\n\\n“Physical or virtual systems and assets of a State that are so vital that \\ntheir incapacitation or destruction may debilitate a State’s security, \\neconomy, public health or safety, or the environment.”3\\n\\nii.  “…infrastructure  sectors  whose  assets,  systems,  and  networks, \\nwhether  physical  or  virtual,  are  considered  so  vital  to  the  United \\nStates  that  their  incapacitation  or  destruction  would  have  a \\ndebilitating effect on security, national economic security, national \\npublic health or safety, or any combination thereof.”4\\n\\n•  Cyber  system:  “One  or  more  interconnected  computers  with  associated \\nsoftware and peripheral devices. It can include sensors and/or (programmable \\nlogic) controllers, connected over a computer network. Computer systems \\ncan  be  general  purpose  (e.g.  a  laptop)  or  specialised  (e.g.  the  ‘blue  force \\ntracking system’).”5\\n\\n•  Highly interdependent cyber systems of the future: Defined by examples in \\n\\nthe following section.\\n\\n2. HIGHLY INTERDEPENDENT CYBER SYSTEMS\\n\\nWe are already on the brink of a future in which we depend so much on key cyber \\nsystems  that  governments,  societies,  corporations,  and  individuals  are,  in  some \\ncases, unable to function without them. Current trends indicate that this dependence \\non  always-on,  always-reliable  cyber  systems  will  deepen.  During  the  coronavirus \\npandemic,  without  the  ability  to  operate  remotely,  many  more  companies  would \\nhave  failed  and  more  individuals  relying  on  their  services  would  have  suffered.  In \\nthe spring of 2020, governments and companies scrambled to increase secure remote \\n\\n\\n\\x0caccess  capacities  and  adopt  remote  voice  and  video  communication  methods.  For \\nsome, these voice and video communications systems now rely on a complicated mix \\nof on-premise systems, service providers, cloud hosting providers, and Internet access \\nto  residences.  This  delicate  balance  of  a  service  offering  relies  on  the  availability \\nof each service component within and is an example of our existing dependency on \\nalways-on  and  always-reliable  cyber  systems.  So  far,  the  roles  and  responsibilities \\nremain clear.\\n\\nNear-future examples demonstrating this include fully autonomous vehicles (without \\nsteering  wheels)  and  systems  that  are  critically  dependent  on  synchronised  time \\nsignals, not only for waking you up in the morning and scheduling your day but also \\nfor  key  tasks  such  as  ensuring  your  digital  identity  and  encryption  for  connecting \\nto  your  common  services  in  cyberspace.  The  roles  and  responsibilities  in  such  a \\ntechnological system begin to blur, as they all depend on time. As an example, given \\nthat  satellite  time  signals  can  be  manipulated  or  jammed,6  common  services  that \\ndepend on time, such as locations on maps and certificate expirations that influence \\nidentities  and  cryptography,  could  cease  to  function  as  intended.  These  temporary \\neffects, described in the example, demonstrate the potential for harm to the operations \\nof systems dependent on a synchronised time signal.\\n\\nFurther  into  the  future,  societies  may  rely  on  cyber  systems  based  on  emergent \\nphenomena  in  complexity  theory  systems,7  or  cyber  physical  systems8  managed \\nentirely  by  artificial  intelligence  (AI)  systems,  where  the  original  human-written \\nalgorithms of the system are regularly rewritten by the learning process of the system \\nitself. The closer cyber systems get to sentience, the more rational it becomes to treat \\nthem as legal entities in their own right, capable not only of suffering harm but also of \\ntaking decisions that cause harm independently of human input.\\n\\nNow consider multiples of these future cyber systems being highly interdependent on \\neach other, where they feed and receive data from each other and also consume each \\nother’s  deeply  nested  computing  capacities.  These  systems  would  be  managed  by \\ncompanies or governments and potentially poorly designed by individuals, like many \\n\\n\\x0cother systems today (e.g. a great many commercial software packages). The roles and \\nresponsibilities that were once complicated will become complex. If, in the future, \\nthese highly interdependent cyber systems were to become temporarily unavailable \\nor significantly harmed, it could impact a State’s (or various States’) ability to deliver \\nhealthcare or to maintain international obligations, cause a shutdown of the economy, \\nand possibly cause civil unrest. If, as you read this, you find yourself trying to align \\nour description of these highly interdependent cyber systems with Critical National \\nInfrastructure or trying to align to software and/or services you may use today, then \\nwe  ask  that  you  look  much  further  into  the  future  and  set  aside  any  alignment  to \\nservices that currently exist.\\n\\nIn the following section, we explore the position States  have  taken with  respect  to \\nenvironmental personhood and later align this behaviour and thought to our example-\\nbased definition of highly interdependent cyber systems of the future to discuss cyber \\npersonhood. \\n\\n3. ENVIRONMENTAL PERSONHOOD\\n\\nIt is simple to understand a corporation having its own rights as a legal entity, and \\nthereby corporate personhood. These corporate entities can enter into contracts, own \\nproperties, and be recognised as legal persons in courts. But in addition to corporations, \\nnatural resources in certain States have been granted personhood rights.\\n\\nThe germination of environmental personhood is credited to the 1972 paper “Should \\nTrees Have Standing? Toward Legal Rights for Natural Objects” by Christopher D. \\nStone.9 The paper proposed giving legal rights to rivers, oceans, forests, or any natural \\nenvironmental  systems.10  He  referred  back  to  a  time  when  discussing  rights  for \\ncorporations, women, and others had seemed unthinkable.11 He went on to describe \\nhow corporations do not have rights similar to those of a legal person and how certain \\npersons such as inmates or children have limited rights.12 He argued that “holders of \\nlegal rights” must satisfy all of the following three criteria:13\\n\\n1.  “[They may] institute legal actions at [their] behest;”\\n2.  “In  determining  the  granting  of  legal  relief,  the  court  must  take  injury  to \\n\\n[them] into account; and”\\n\\n3.  “Relief must run to [their] benefit.”\\n\\n\\x0cStone suggested that these natural environmental systems be assigned legal guardians \\nwho  could  advocate  for  the  rights  of  these  systems.14  In  his  blue-sky  paper,  he \\nsuggested not only rights but also liabilities, using the example of a trust fund which \\ncompensates those who suffered damages from floods.15\\n\\nSince Stone’s paper, some nations have shifted slightly from anthropocentric views \\ntoward biocentric ones, adopting environmental personhood in a number of different \\nways. Several papers have been published regarding the interpretation and challenges \\nof State laws regarding environmental personhood. Examples include:\\n\\n•  Bangladesh: In 2019, Bangladesh granted legal personhood rights to all of its \\nrivers, with legal guardianship assigned to the National River Conservation \\nCommission.16\\n\\n•  Bolivia:  In  2010,  Bolivia  passed  a  “Law  on  the  Rights  of  Mother  Earth” \\n(Ley de Derechos de la Madre Tierra), thereby granting her, a living system, \\nlegal personhood rights.17\\n\\n•  Colombia:  In  2016,  Colombia’s  Constitutional  Court  granted  legal \\npersonhood  rights  to  the  Atrato  River  (Rio  Atrato)  basin  under  joint \\nguardianship  of  the  government  and  the  indigenous  community  living \\nin  the  basin.18  In  2018,  Colombia’s  Supreme  Court  recognised  the  rights \\nto  the  Amazon  River  and  its  surrounding  ecosystem,  reaching  a  unique \\ndecision involving multiple stakeholders to safeguard the life and health of \\nColombia’s Amazon (Amazonas Colombiano).19\\n\\n•  Ecuador:  Leading  the  charge  in  2008,  Ecuador’s  constitution  recognises \\nlegal personhood for “Mother Nature” (Panchamama) with rights “to exist, \\npersist, maintain and regenerate its vital cycles, structure, functions and its \\nprocesses in evolution.” Any person or persons can petition on her behalf.20\\n\\n\\x0c• \\n\\nIndia: In 2017, India’s Uttarakhand High Court granted legal personhood \\nrights to two rivers, the Ganges and the Yamuna, their respective Gangotri \\nand  Yamunotri  glaciers,  and  other  natural  objects21  in  the  State  of \\nUttarakhand under the guardianship of Uttarakhand, the State in which the \\nrivers originate. Later that same year, India’s Supreme Court issued a stay of \\nthe Uttarakhand High Court’s 2017 decision.22 In March 2020, the Punjab \\nand Haryana High Court granted Sukhna Lake personhood rights.23\\n\\n•  New  Zealand:  New  Zealand  granted  legal  personhood  rights  to  the  Te \\nUrewera  National  Park  in  2014,24  the  Whanganui  River  in  2017,25  and \\nMount Taranaki in 2017,26 with legal guardianship assigned to the Crown, \\nthe Whanganui people, and eight Māori tribes, respectively.\\n\\nWe  recognise  that  with  the  exception  of  India,  these  States  may  not  be  globally \\nperceived as legal opinion defining States. With the further exception of Ecuador and \\nBolivia, we also recognise that not all aspects of the State’s environment are granted \\nlegal personhood and that only specific rivers, forests, and parks have been granted \\nlegal personhood. It is most likely for these reasons that environmental personhood is \\nnot a rule in public international law or included in customary international law.\\n\\nRather than explore the legal constructs developed to create a concept of environmental \\npersonhood, this paper builds on the established notion to consider a distant future \\nwhere some States grant personhood rights to highly interdependent cyber systems. It \\nis with this frame of reference that we propose cyber personhood.\\n\\n\\x0c4. CYBER PERSONHOOD\\n\\nOur paper suggests that in the distant future, States may grant or consider granting \\ncertain  highly  interdependent  cyber  systems  legal  personhood  rights,  in  a  manner \\nsimilar to how States have granted certain natural environment systems environmental \\npersonhood. In common with environmental personhood, the rights and liabilities of \\nthese cyber systems would, and most likely should, vary from system to system.\\n\\nWe propose the following definition of cyber personhood: the granting of legal-person \\nrights to a highly interdependent cyber system under legal frameworks whereby the \\nhighly interdependent cyber system would have legal standing to claim injuries and \\nremain accountable for any injuries it may cause.\\n\\nThe  notion  of  granting  legal  personhood  to  a  computer-based  system  may  seem \\nradical and exotic at present, but far less so than the idea of environmental personhood \\ndid in 1972. While environmental concerns have slowly achieved broad acceptance \\ndespite  being  stigmatised  by  industry-minded  or  politically  motivated  interests, \\ndependency on cyber systems is developing much more rapidly. Where it took over \\n35  years  for  environmental  personhood  to  take  hold  in  Ecuador,  it  is  possible  that \\ncyber  personhood  will  mirror  the  velocity  of  acceptance  of  cyber  systems,  greatly \\nreducing the time required to arrive at appropriate legal changes to recognise the new \\nreality, or dismiss it.\\n\\nA. Candidates for Cyber Personhood\\nJust as with corporate legal entities or inmates, the highly interdependent systems of the \\nfuture would probably fall into a category of their own, requiring different treatment, \\nincluding  in  terms  of  their  rights  and  obligations,  as  well  as  forms  of  ownership \\nand oversight. To help understand the types of systems that may be considered for \\ncyber personhood, we have categorised them as follows. For each scenario, our focus \\nremains on the highly interdependent cyber systems of the future, States’ and their \\nsocieties’ inability to function without them, and existing legal constructs that may \\napply,  which  essentially  negates  the  concept  of  cyber  personhood  for  the  first  two \\ncandidates described below.\\n\\n1. \\n\\nIndividually  owned  cyber  systems  (personal):  Many  people  have  small \\nnetworks in their homes providing connections between devices within their \\nhome, such as their computers, mobile devices, and televisions, and fringe \\ndevices such as refrigerators, toasters, coffee makers, door locks, and other \\nInternet  of  Things  objects.  This  candidate  is  not  a  highly  interdependent \\ncyber  system  but  can  be  impacted  if  it  is  reliant  upon  upstream  highly \\ninterdependent cyber systems that are no longer available. Nevertheless, if \\n\\n282\\n\\nAuthorized licensed use limited to: Ryerson University Library. Downloaded on May 03,2022 at 01:17:07 UTC from IEEE Xplore.  Restrictions apply. \\n\\n\\x0cthis example’s services were to be unavailable, it would not gravely impact \\nState ability to function, and any damages can be claimed by the owner. We \\nbelieve such personal systems are not candidates for cyber personhood.\\n\\n2.  Corporate- or State-owned cyber systems (single entity): These systems \\nare  required  by  corporate  or  State  entities  to  operate  their  daily  business, \\nand  if  they  were  made  unusable,  the  impact  would  be  localised  to  their \\noperations. These systems would likely not be granted cyber personhood, as \\nany damages to them can be claimed by the owner, and any damages from \\nthe system can be paid by the owner.\\n\\n3.  Multi-entity-owned  cyber  systems  in  a  single  jurisdiction:  In  this \\ninstance, several national companies combined with or without the State’s \\nowned  systems  leverage  their  respective  cyber  services  to  jointly  offer \\nservices from highly interdependent cyber systems to residents of a single \\njurisdiction. An example of this would be a nation that is able to provide cyber \\nservices to its residents thanks to its extensive sovereign cyber capabilities \\nat State and/or corporate levels. These interdependent cyber systems could \\nmaintain separate accountabilities, leaving each entity responsible for their \\nportion  of  the  system.  It  may  also  simply  fall  under  the  responsibility  of \\nthe  State,  especially  when  trying  to  limit  control  from  larger  and  more \\npowerful corporations such as Alphabet, Facebook, Amazon, and Microsoft. \\nAlternatively,  States  may  implement  a  private-public  partnered  governing \\nbody to govern the system as a single unit, especially when the boundaries \\nof the individual units within the system become difficult to ascertain. For \\nexample,  what  would  happen  if  one  entity  or  service  provider  within  the \\noverall  highly  interdependent  cyber  system  decides  to  stop  providing  its \\nservice, thereby adversely impacting all entities and the overall service to \\nthe residents of the State? We believe it is possible for States to grant such a \\nsystem cyber personhood.\\n\\n4.  Multi-entity-owned cyber system across multiple jurisdictions: Building \\nupon the previous candidate, consider several multinational companies and/\\nor several States that jointly offer a service through a highly interdependent \\nset  of  cyber  services  to  the  residents  of  several  jurisdictions,  including \\njurisdictions  beyond  their  own  with  complex  and  deeply  nested  roles  and \\nresponsibilities. Depending on the public’s reliance on the services of the \\nsystem  and  the  level  of  impact  to  the  public  when  the  services  offered \\nthrough the system are lost, we believe such systems may be considered by \\nsome States to be deserving of cyber personhood.\\n\\n\\x0c5. USE AND POLICY CONSIDERATIONS\\n\\nIn addition to candidates of cyber personhood that would require new legal treatment \\nas  described  above,  specific  instances  of  actions  affecting  (or  indeed  carried  out \\nby) highly interdependent cyber systems would require careful consideration when \\nestablishing a conceptual framework for cyber personhood. Had we had the foresight \\nto  strategise  or  “pre-think”  our  handling  of  the  coronavirus  pandemic,  globally  we \\nwould have been in a better position than where we arrived a year later. This paper \\nsuggests that States pre-think the idea of cyber personhood to help them decide how \\nthey would respond if certain States adopt such a position.\\n\\nThe  following  is  a  non-exhaustive  list  of  considerations  influencing  rights  and \\nobligations  of  legal  persons  that  would  have  a  distinctive  impact  when  applied  to \\nhighly interdependent cyber systems of the future that States and their societies would \\nbe unable to function without.\\n\\n• \\n\\nInjuries: the nature of highly interdependent cyber systems of the future, \\nexisting in the physical world yet managing data in the virtual one, means \\nthat the potential for damage caused by cyber systems also extends across \\nmultiple domains. In the data sphere, highly interdependent cyber systems \\ncould  be  liable  and  receive  relief  for  breach  of  confidentiality,  damage  to \\nintegrity, or breach of access, or damage or destruction of systems or data. \\nIn  the  physical  world,  harm  could  be  caused  to  any  system  –  including \\nlife  support  systems  –  which  is  dependent  on  the  network  for  its  correct \\nfunctioning.  Interdependencies  introduce  further  complexity  when,  for \\ninstance, one entity’s components of the highly interdependent cyber system \\ncause harm to another entity’s components of the same system, where one or \\nboth has been designated as a legal person.\\n\\n•  Cyber  attack  (outside  of  armed  conflict):  In  the  future,  when  a  highly \\ninterdependent  cyber  system  becomes  the  victim  of  a  cyber  attack,  its \\nrights and duties depend on the existence of an organisational body and the \\nprevailing degree of organisation, as well as on its “legal” recognition by \\nStates on a national and international level. \\n\\n○ \\n\\nIf  the  highly  interdependent  cyber  system  has  been  granted  cyber \\npersonhood  by  a  State  in  which  its  rights  can  be  invoked,  then \\nthose rights (and duties – like a duty to notify/report authorities on \\nserious breaches) can be exercised in front of a national jurisdiction. \\nFurthermore, the executive branch could be asked for assistance in \\nthe form of, for example, preventive protection or services such as \\n\\n\\x0cattribution sourcing and security monitoring. As a result of such a \\nlegal  remedy,  the  most  basic  expectation  would  be  a  return  to  the \\npre-attack status of the highly interdependent cyber system. \\n\\n○  On the international level, a cyber attack could result in a demand \\nby  interested  parties27  to  protect  the  system,  restore  it  to  its  pre-\\nattack  status,  or  to  retaliate  with  sanctions.  Additionally,  if  the \\nrules of the customary law on State responsibility for States can be \\ntransferred to a highly interdependent cyber system, “third States” \\nwith common interests would be permitted to invoke them and could \\noffer assistance.28 Due to the necessity and/or criticality of the highly \\ninterdependent cyber system we have proposed, it is suggested that \\nStates also consider transferring these rules to such a non-State entity \\nin order to support international laws of State responsibility.\\n\\n•  Cyber attack (armed conflict):29 The protection under the law of armed \\nconflict depends on how the highly interdependent cyber system is qualified. \\nIf  it  is  equivalent  to  critical  infrastructure,  it  enjoys  a  high  standard  of \\nprotection.30 If the cyber system is used exclusively for civilian purposes, \\nit is qualified as a civilian object and thus also protected.31 Unfortunately, \\nif a highly interdependent cyber system is abused by one party to an armed \\nconflict, it could lose its status. When it becomes a civilian object used for \\nmilitary purposes, it can be qualified as a military objective.32 Since an attack \\non  a  military  objective  results  in  a  military  advantage,  a  cyber  attack  on \\nsuch a highly interdependent cyber system would be lawful. Legal reasons \\njustifying  protection  could  be  an  agreement  of  States  on  the  neutrality  of \\nhighly interdependent cyber systems or to qualify them as a “digital” non-\\ndefended locality.33 Even more interestingly, due to the similar understanding \\n\\nInternational  organisations  as  a  comparable  concept:  A  related \\npractice-oriented  solution  for  multi-jurisdictional  systems  can  be \\nan  international  governing  body  and/or  international  organisation \\n(IO)  deriving  from  and  in  accordance  with  international  law.  The \\nrequired  pressure  and/or  need  to  organise  certain  IT  issues  on  an \\ninternational level is comparable and similar to the ICANN (Internet \\nCorporation  for Assigned  Names  and  Numbers,  whose  duty  is  to \\nmaintain important databases related to namespaces and numerical \\nspaces  of  the  Internet)  or  the  ISO  (International  Organisation  for \\nStandardization, an association under Swiss law), which, however, \\nare not governed precisely like an IO in the international law sense. \\nIt is therefore suggested that the practical idea of ICANN et al. be \\nmerged with the concept of an IO in international law. This might be \\nexplicitly suitable for a sophisticated AI complex.\\n\\nTo establish an international organisation, an agreement by at least \\ntwo  States  in  the  form  of  an  international  treaty  is  required.  In \\nthis treaty, the subject matter will be defined as well as its and the \\nparticipating States’ rights, duties, and funding.35 From a practical \\nperspective, it would be necessary to define the area of applicability \\nprecisely  and  thereby  to  determine  and  differentiate  the  highly \\ninterdependent  cyber  systems  which  are  governed,  guarded,  and \\nrepresented by the IO.\\n\\nThe  creation  of  an  international  entity  for  a  particular  highly \\ninterdependent  cyber  system  would  entail  the  need  for  its  own \\ngovernance mechanisms. Furthermore, the integration of such a legal \\npersonhood in practice (i.e. procedural and representative questions) \\ncould be challenging; it could be addressed in a similar manner to \\nexisting specific IOs. On the other hand, the IO solution offers a clear \\nand transparent framework based on States’ consensus to govern a \\ngrey area and to answer legal and practical needs. Finally, particular \\nadvantages gained by creating this international entity could be:\\n\\n▪  The  monitoring  and  observance  of  (digital)  human  rights \\n\\n(e.g. with a view to surveillance or big data AI);\\n\\n▪  A  fair  and  equal  share  of  high-level  technology  (e.g.  for \\n\\ndeveloping States);\\n\\n▪  To  keep  critical  communication  and  information  infra-\\n\\nstructure worldwide functioning (as a backbone);\\n\\n\\nShared  responsibility  and  shared  burdens  with  a  view  to \\nsustainability  (to  prevent  environmental  damage,  or  to \\nfoster decarbonisation); and/or\\n\\n▪  A  common  control  and  reciprocal  acceptance  of  a  pivotal \\ntechnology (sophisticated, eventually somewhat dangerous \\nAI).\\n\\n6.   CONCLUSION\\n\\nThe information revolution has already brought about profound changes in the lives of \\nmost humans and in what is considered normal and natural human behaviour. The pace \\nof this change continues to increase, and to a greater extent than in previous periods of \\nhuman history, legal practice is considered only after the systems are already in place. \\nThe extent to which the development of cyber systems and capabilities has outpaced \\nlegal norms is demonstrated not only by the constant need to update domestic computer \\nand information legislation36 to reflect new uses and capabilities for information and \\ncommunications  technologies  but  also  by  the  ongoing  discussions  of  the  nature  of \\ncyber activities and what constitutes a “cyber attack” between States.37\\n\\nOur  paper  is  written  to  help  States  pre-think  the  concept  of  cyber  personhood. \\nThe  example  of  environmental  personhood  cited  above  provides  a  template  for \\nconsideration  of  whether  cyber  personhood  is  a  viable  means  for  ensuring  that \\nthe  legal  treatment  of  highly  interdependent  cyber  systems  of  the  future  remains \\nboth  relevant  and  fit  for  purpose,  and  sufficiently  flexible  to  accommodate  as-yet-\\nunforeseen  developments  in  the  relationships  between  humans  and  computing \\ndevices.  Christopher  Stone’s  1972  paper  first  proposing  environmental  personhood \\ncame at a very early stage in the development of mass awareness of the vulnerability \\nof  the  environment,  and  of  its  need  for  protection,  based,  not  least  of  all,  on  its \\ncritical importance for sustaining human life. The process of achieving widespread \\nacceptance of the notion that corporate profit and individual convenience needs to be \\nbalanced against environmental protection was a long one, and in some areas is still \\nnot complete. However, we believe that events such as the coronavirus pandemic will \\naccelerate the analogous process for cyber systems by emphasising the essential and \\nirreplaceable  nature  of  highly  interdependent  cyber  services  for  the  functioning  of \\nfuture societies.\\n\\n\\x0cThe  legal  regime  governing  actions  against,  through,  or  by  computer  networks \\nwill  inevitably  develop  and  change,  evolving  significantly  from  its  current  state.  It \\nmay  be  that  cyber  personhood  is  not  the  concept  through  which  legal  mechanisms \\naccommodate the new reality of critical human dependence on online services. But \\nthe  example  of  environmental  legislation  argues  strongly  that  this  path  could  be \\nconsidered a key means of resolving substantial challenges to applying existing legal \\nregimes to cyber rights and responsibilities by way of cyber biomimicry.\\n\\nStudying  and  remaining  aware  of  potential  future  scenarios  enables  us  to  better \\nposition ourselves to withstand them. For many reasons, environmental personhood \\nis  not  widely  accepted  or  recognised;  however,  it  may  be  that  cyber  personhood \\nis  embraced  as  highly  interdependent  cyber  systems  become  indispensable  to \\ngovernments, societies, corporations, and individuals.\\n\\nThe concept of cyber personhood is not so far removed from possibility and deserves \\ndiscussion, particularly as the tools to govern it are already available. The questions \\nthat  remain  are:  which  cyber  systems  will  develop  the  criticality  and  complexity \\ndeemed to be worthy of being governed under international law, and which countries \\nare bold enough to make this concept a reality?\\n\\nAuthorized licensed use limited to: Ryerson University Library. Downloaded on May 03,2022 at 01:17:07 UTC from IEEE Xplore.  Restrictions apply. \\n\\n289\\n\\n\\x0c', 'computer law & security review 43 (2021) 105627 \\n\\nAvailable online at www.sciencedirect.com \\n\\njournal homepage: www.elsevier.com/locate/CLSR \\n\\nCyber-insurance in EU policy-making: Regulatory \\noptions, the market’s challenges and the US \\nexample \\n\\nDimitra Markopoulou \\n\\nVrije Universiteit Brussel (LSTS), Faculty of Law & Criminology, Pleinlaan 2, 1050 Brussels, Belgium \\n\\na r t i c l e \\n\\ni n f o \\n\\na b s t r a c t \\n\\nKeywords: \\nCyber security \\nCyber insurance \\nEiopa \\nNis directive \\nCyber coverage \\nCyber loss \\n\\nOver the last decades digital technologies have penetrated our daily lives affecting all as- \\npects of our societal and economic activities. Even though the benefits of relying on infor- \\nmation systems to run everyday tasks, organise one’s business, interact with each other or \\nenjoy public services are undisputable, the increasing use of digital technologies comes with \\na price: the growing exposure to cyber risks. This new type of threat has been in the center of \\nthe EU agenda for over 15 years during which a solid legislative framework for the protection \\nS of network and information systems against cyber incidents has been developed. However, \\nsecurity and resilience of infrastructures and networks is one parameter of the challenge. \\nDealing with the financial risk emerging from a cyber incident, is another, equally important \\none. The need to mitigate these risks led to the emergence of a new insurance market, the \\ncyber insurance market. Despite though the constantly growing demand for this type of in- \\nsurance coverage, the market is still under development. The fast-evolving nature of cyber \\nthreats, the lack of a common language as regards risks, losses and coverages and the lack of \\nhistorical data on cyber incidents are listed among the factors that slow down the market’s \\ngrowth. Currently, all involved stakeholders in the insurance field are considering specific \\ninitiatives that would accelerate the process of turning the EU market more competitive \\nand efficient against its many challenges. The example of the US cyber insurance market, \\nwith its shortcomings and know-how, could also contribute to this effort, as an example of \\na market that has been intensively facing these challenges for almost twenty years. \\n\\n© 2021 Dimitra Markopoulou. Published by Elsevier Ltd. All rights reserved. \\n\\n1. \\n\\nIntroduction \\n\\nThe increased dependency on digital technologies has created \\ngreat opportunities for innovation and productivity. Reliance \\non information systems has transformed our daily lives, af- \\nfecting the way we run our everyday tasks and interact with \\neach other, as well as the way we create and organise our busi- \\nnesses or enjoy public services. This rapidly changing envi- \\nronment is depicted in both the number of the Internet users \\n\\nE-mail address: Dimitra.Markopoulou@vub.be \\n\\naround the world, which grew from 1 billion in 2005 to more \\nthan 5 billion in 2020, as well as, in the number of smart de- \\nvices that communicate wirelessly (the Internet of Things) \\nthat has increased from 2 billion devices in 2006 to 200 bil- \\nlion in 2020.1  2 \\nRoughly one million more people join the \\n\\ncomputer law & security review 43 (2021) 105627 \\n\\nInternet every day which could lead to more than 7,5 billion \\ninternet users in 2030.3 \\nHowever, the increasing use of digi- \\ntal technologies in our economic and societal activities has \\nled to increased digital security risks, also known as cyber \\nrisks, and has made cybersecurity an issue of strategic im- \\nportance at global level. Cybersecurity risks were identified \\nby the World Economic Forum,4 \\nas one of the five top risks \\ncurrently faced by governments, organisations and civil so- \\ncieties across the world. More specifically, cyberattacks and \\nmassive data fraud appear both in the list of the top five \\nglobal risks, an expected result following the 2017 notorious \\ncyber-attacks, among which the Wannacry and NotPetya at- \\ntacks. Ransomware made history again in 2020 contributing \\nto the first reported death related to a cyberattack. Specifically, \\nin September of that year the Dusseldorf University Hospital \\ncould not admit a patient who needed urgent medical care \\nas it was in the midst of dealing with a ransomware attack \\nthat hit its networks.5 \\nAccording to Forbes, malware increased \\nby 358% in 2020 and ransomware by 435% compared to 2019 \\nwhile at the same time Google has registered 2.145.013 phish- \\ning sites as of January 2021.6 \\n\\nThe immediate result of this growing number of cyber in- \\ncidents is economic loss, but it is not the only one. There \\nare also intangible costs to society, such as reputational dam- \\nage to businesses, risks to national security, failures of critical \\ninfrastructures and insecurity in doing business, to mention \\nsome. Safeguarding a resilient and safe cyberspace has there- \\nfore developed into a high priority, with cybersecurity being \\nthe first line of defence against cybercrime. In this context, \\ncybersecurity has monopolised the interest of the European \\nand international community for many years already. At EU \\nlevel, cybersecurity-related issues have been addressed since \\n2004, when ENISA was founded.7 \\nSeveral EU policies and ini- \\ntiatives followed in the context of the EU Cybersecurity Strat- \\negy, which was adopted by the EU in 2013 8 \\nand which, together \\nwith the European Agenda on Security,9 \\nset the framework for \\nthe protection against cybercrime and the promotion of cyber \\nresilience. The main legislative instrument of the Cybersecu- \\nrity Strategy is the NIS Directive,10 \\nthat entered into force in \\nAugust 2016.11 \\nIn addition to that, the European Commission \\nintroduced the Cybersecurity Act, in September 2017, as part \\nof a set of measures to deal with cyberattacks and to build \\nstrong cybersecurity in the EU. The Act entered into force in \\nJune 2019.12 \\nProtection of critical infrastructures against cy- \\nber threats has also been in the EU agenda since 2004,13 \\nwith \\nthe Directive on European Critical Infrastructures 14 \\nbeing in \\nthe center of this effort. Finally, the General Data Protection \\nRegulation 15 \\nset a new framework for the notification of data \\nbreaches and the imposition of penalties to the violating par- \\nties. In July 2020, a Communication from the Commission was \\nreleased on the EU Security Union Strategy, which tackled, \\namong other issues, cybersecurity and cybercrime.16 \\n\\nThe adoption of policies and legislation as well as the im- \\nplementation of organisational and technical measures that \\naim to make network and information systems more secure \\nand resilient, is one parameter of the challenge. Dealing with \\nthe financial risk emerging from a cyber incident, is another, \\nequally important one. Along with an increasing number of \\ncyber incidents come the increased consequences and risks \\nfor the businesses that suffer them. A 2017 study of 254 com- \\npanies  across  seven  countries  (Australia, France, Germany, \\nItaly, Japan, United Kingdom and the United States) put the \\nannual cost of responding to cyberattacks at US$11.7 million \\nper company, a year on-year increase of 27.4%. The cost of cy- \\nbercrime to businesses over the next five years is expected to \\nbe US$5,2 trillion.17 \\nThe need to mitigate these risks led to the \\nemergence of a new insurance market, the cyber insurance \\nmarket. While not a substitute for investing in cyber security \\nand cyber resilience, insurance coverage for cyber risks pro- \\nvides a safety net for companies and individuals, as it allows \\nthem to transfer a portion of their financial exposure to insur- \\nance markets. \\n\\nlevel of security of network and information systems across the \\nUnion. \\n\\n3 \\n\\nDespite though the constantly growing demand for this \\ntype of insurance coverage, the market is still under develop- \\nment. Today the standalone cyber insurance market remains \\na fraction of the size of other commercial property and lia- \\nbility insurance markets, with penetration levels near 30% of \\ncompanies in almost all countries.18 \\nThere are several factors \\nthat slow down its level of maturity, with the fast-evolving \\nnature of cyber threats, the lack of a common language as \\nregards risks, losses and coverages and the lack of historical \\ndata on cyber incidents being some of them. Currently, the \\nEU and international Organisations work together with the in- \\nsurance industry in order to accelerate the process of turning \\nthe market more competitive and efficient against its many \\nchallenges. The example of the US cyber insurance market \\ncould also contribute to this effort, as an example of a mar- \\nket that has been intensively facing these challenges for al- \\nmost twenty years. At the same time, the increasing number \\nof cyber incidents, the continued digital transformation, and \\nthe new regulatory initiatives in the European Union, are all \\nexpected to raise awareness and boost the demand for cyber \\ninsurance. \\n\\nThis paper aims to clarify the different parameters that \\ncompose this relatively new segment of the insurance market \\nand ultimately convey the current trends in the EU cyber in- \\nsurance industry in terms of policy-making and cooperation \\nbetween different organisations and market players, as well \\nas, to identify the challenges it is confronted with. In terms \\nof structure, this article is divided into five chapters: the first \\nchapter tries to shed some light on the much-disputed no- \\ntions that compose the core of cyber insurance, more specif- \\nically, these of “cyber incident”, “cyber risk”, “cyber loss” and \\n“cyber coverage”. The second chapter discusses the reasons \\nthat led to the emergence of cyber insurance as a new seg- \\nment of the insurance market, as well the current develop- \\nments in the field.. In the third chapter, the case of the US \\ncyber insurance market is examined, as an example of a ma- \\nture market that could contribute to the development of the \\nEuropean market. Finally, the challenges that the industry is \\ncurrently faced with, as well as relevant measures to address \\nthese challenges, are presented in chapters four and five re- \\nspectively. \\n\\nFor consistency purposes it is clarified that this paper only \\naims to elaborate upon the recent developments in the EU \\ncyber insurance market from an EU policy-making perspec- \\ntive, through presentation of the steps that have been under- \\ntaken so far in the field by different European organisations \\nand through examination of the several initiatives that have \\nbeen adopted at EU level to address the challenges of the cy- \\nber insurance landscape. Accordingly, the examination of the \\nnumerous legal issues related to substantive cyber insurance \\nlaw lie beyond the purposes of this analysis; its argumenta- \\ntion on the legal concerns that arise from the insurability of \\ncyber risks is aimed at contributing towards the emergence \\nof a more consistent EU cyber insurance market rather than \\nas an attempt to analyse concrete insurance law and contract \\nclauses. \\n\\nSetting the cyber insurance landscape: how \\n\\n2. \\nare cyber insurance and cyber-related terms \\ndefined \\n\\n2.1. \\n\\nThe prevailing definitions on cyber insurance \\n\\nWhen it comes to defining cyber insurance, there is no gen- \\nerally accepted approach among the insurance industry. Cy- \\nber insurance is a broad term used for all insurance poli- \\ncies that address first and third-party losses as a result of a \\ncomputer-based attack or malfunction of a firm’s information \\ntechnology systems.19 \\nEIOPA defines cyber insurance as cov- \\nering losses arising from malicious and non-malicious inci- \\ndents relating to the handling, storage, and transmission of \\nelectronic data, including through the Internet and computer \\nnetworks.20 \\nENISA understands cyber insurance as an insur- \\nance product used to protect businesses (and individual users) \\nfrom internet-based risks, and more generally from risks relat- \\ning to information technology infrastructure and activities.21 \\nIn the US, the Department of Homeland Security defines cyber \\ninsurance as follows: “Cyber-security insurance is designed \\nto mitigate losses from a variety of cyber incidents, including \\ndata breaches, business interruption, and network damage.”22 \\nThere may not be a common definition on cyber insurance, \\nhowever all definitions include a common element, the pro- \\ntection against losses from risks relating to the Internet or, \\nas broadly referred to, cyber risks. However, the definition of \\ncyber insurance is only the starting point in trying to under- \\nstand this, relatively new, concept. Questions such as in what \\ncontext is coverage for losses and damages resulting from cy- \\nber incidents provided, how is cyber risk defined and what are \\nthe most common cyber incidents covered by cyber insurance \\npolicies, or what types of losses are usually covered in insur- \\nance policies, are some of the issues that will be addressed by \\nthe analysis that follows. \\n\\n2.2. \\nCyber incident, cyber risk and cyber threat: the \\ngeneral and the insurance market approach on defining these \\nthree terms \\n\\nOur perspective of cyber insurance is closely linked to the no- \\ntion of cyber incident. Unluckily, there is no generally accepted \\ndefinition of the term, on the contrary, definitions on cyber in- \\ncident may vary depending on the regulatory framework or \\nthe conditions of the market that deploys them. It could safely \\nbe concluded that the inconsistency that characterises the EU \\ncyber insurance market is attributed, to a great extent, to the \\nlack of coordination on this matter. Given that a deep under- \\n\\ncomputer law & security review 43 (2021) 105627 \\n\\nstanding of the insured risk is interdependent to understand- \\ning the notion and the extent of the insurance coverage of- \\nfered, a short presentation of the prevailing definitions on cy- \\nber incident is deemed necessary. Before examining the insur- \\nance market perspective regarding the definition of the term, \\na short analysis of the more generic definitions that have been \\nadopted in the context of the EU cyber security policy is con- \\nsidered essential. In addition, the notion of cyber incident will \\nbe examined together with similar terms, such as cyber threat \\nor cyber risk, in an effort to further clarify the three concepts, \\ntheir differences and their relation to each other. \\n\\nIn this context, the general approach (not cyber insurance \\nspecific) of cyber incident could include any incident that af- \\nfects the security of network and information systems in any \\nsector of the society. An analytical definition of cyber incident \\nhas been adopted by ENISA, which defines it as “any occur- \\nrence that has impact on any of the components of the cyber \\nspace or on the functioning of the cyber space, independent if \\nit’s natural or human made; malicious or non-malicious in- \\ntent; deliberate, accidental or due to incompetence; due to \\ndevelopment or due to operational interactions. Also, we call \\ncyber incident any incident generated by any of cyber space \\ncomponents even if the damage/disruption, dysfunctionality \\nis caused outside the cyber space”.23 \\nA same approach is fol- \\nlowed by the NIS Directive which defines “incident” as any \\nevent having an actual adverse effect on the security of net- \\nwork and information systems.24 \\n\\nAgain, under a general perspective cyber risk is defined as \\n“the combination of the probability of cyber incidents occur- \\nring and their impact”.25 \\nAnother definition can be found in \\nthe NIS Directive, where risk is defined as “any reasonably \\nidentifiable circumstance or event having a potential adverse \\neffect on the security of network and information systems”.26 \\nFinally, when it comes to cyber threats plenty of references \\non the definition of the term may be found in different offi- \\ncial texts. For instance, according to the definition introduced \\nby the Cybersecurity Act,27 \\n“cyber threat means any poten- \\ntial circumstance, event or action that could damage, disrupt \\nor otherwise adversely impact network and information sys- \\ntems, the users of such systems and other persons”. The cy- \\nber lexicon defines cyber threat as “a circumstance with the \\npotential to exploit one or more vulnerabilities that adversely \\naffects cyber security”.28 \\n\\nFrom a cyber insurance perspective, a similar but not iden- \\ntical approach has been adopted by the insurance sector when \\nreference to the above terms is made. Same as with other sec- \\ntors, different rules-makers and involved actors in the cyber \\ninsurance sector refer indiscriminately to cyber incidents, cy- \\nber threats or cyber risks. For instance, ENISA uses the term \\ncyber threat in its analysis on the impact of the cyber threat \\n\\n\\nlandscape on cyber insurance.29 \\nThe OECD lists types of cyber \\nincidents when analysing the cyber insurance market.30 \\nNev- \\nertheless, because the insurance sector is a risk-oriented sec- \\ntor, it is necessary to place emphasis to the definition of cyber \\nrisks in particular. In this context, a number of definitions has \\nbeen put forward by associations of insurance companies. For \\ninstance, the Geneva Association,31 \\nhas suggested the follow- \\ning definition: \"any risk emerging from the use of information \\nand communication technology that compromises the confi- \\ndentiality, availability, or integrity of data or services.32 \\n\\nIn addition, in a paper published by the CRO Forum 33 \\nin \\n2014 cyber risk was defined as the risk of doing business in the \\ncyber environment, a rather generic approach which was fur- \\nther elaborated in a later paper, published in 2016. In it, cyber \\nrisk was defined as “any risks emanating from the use of elec- \\ntronic data and its transmission, including technology tools \\nsuch as the internet and telecommunications networks. It also \\nencompasses physical damage that can be caused by cyberse- \\ncurity incidents, fraud committed by misuse of data, any lia- \\nbility arising from data storage, and the availability, integrity, \\nand confidentiality of electronic information − be it related \\nto individuals, groups, or governments”.34 \\nIAIS, the Interna- \\ntional Association of Insurance Supervisors, has adopted the \\nsame definition.35 \\nFinally, the Prudential Regulatory Authority \\n(PRA) of the Bank of England in its latest guidance to the insur- \\nance market, that was published in July of 2017, defined cyber \\nrisks, from an underwriting perspective, as follows: “cyber in- \\nsurance underwriting risk is defined as the set of prudential \\nrisks emanating from underwriting insurance contracts that \\nare exposed to cyber-related losses resulting from malicious \\nacts (e.g. cyber-attack, infection of an IT system with malicious \\ncode) and non-malicious acts (e.g. loss of data, accidental acts \\nor omissions) involving both tangible and intangible assets.”36 \\nThe list of different definitions on the cyber-related terms \\nconstitutes a notable example of the lack of harmonisation \\n\\nand the confusion that characterises the cyber insurance mar- \\nket in the EU. Notwithstanding the substantial differences \\namong the above terms, they are often used interchangeably \\nto refer to any “event” that targets components of the cyber \\nspace. The insurance sector is not fully aligned yet when it \\ncomes to conceptually defining cyber risks. Neither a stan- \\ndard definition of cyber risk used broadly by the insurance \\nsector, nor any explicit reference to it in the existing regula- \\ntory framework on insurance exists.37 \\nThis however may not \\ncome as a surprise, in view of both the relatively recent emer- \\ngence of cyber risk as an insured risk and its constantly evolv- \\ning nature. At the same time this inconsistency forms a severe \\nimpediment to the law-making process and makes the need \\nfor alignment at both general and sector specific level imper- \\native \\n\\n2.3. \\n\\nTypes of cyber losses \\n\\nFrom an insurance perspective, cyber incidents cannot be per- \\nceived independently but rather in combination with the dif- \\nferent types of losses they may lead to. Cyber loss is there- \\nfore another parameter that complements the notion of cy- \\nber insurance. According to Knutsen and Stempel “a cyber loss \\nrefers to a loss or liability arising out of the use of electronic \\nequipment or electronically stored information”.38 \\nCyber inci- \\ndents may result to different types of losses, including dam- \\nages to tangible and intangible assets, losses related to busi- \\nness disruption seeand theft, as well as various forms of liabil- \\nity to customers, suppliers, employees and shareholders. The \\ncost of cyber losses to policy holders may range, as well. For \\ninstance, a data breach may cost the insured party millions \\nin case the breach targets sensitive or large volumes of data. \\nIn the same context, a denial-of-service attack 39 \\nmay have a \\nserious financial impact if the victim of the attack is a bank \\nor a large organisation, whose operation has been severely \\naffected by the attack. Classification of cyber losses may dif- \\nferentiate among different insurers. The lack of awareness of \\npotential cyber losses among businesses is a factor that con- \\ntributes to this incoherence. The OECD states in its report that \\n“although the level of awareness of cyber risk and senior man- \\nagement attention to cyber security appear to be increasing, \\nthere appears to be a gap in terms of translating cyber risk into \\nestimates of potential losses which would normally be a pre- \\nrequisite to any decision on the purchase of insurance cover- \\nage” .40 \\nTo remedy this inconsistency several bodies and organ- \\nisations have provided guidance in categorising cyber losses \\nper cyber incident.41 \\n\\n2.4. \\npolicies versus stand-alone ones \\n\\nProviding greater clarity on coverage for cyber risk was iden- \\ntified as one of the five most important factors to support \\nthe development of the cyber insurance market – and the \\nmost important action on the list of insurance companies –\\nby participants in an OECD conference.42 \\nSimilar to cyber risks \\nand cyber losses, lack of commonality in the terminology em- \\nployed about cyber coverage, creates great confusion to both \\ninsurers and insured. \\n\\nSpecifically, cyber insurance can be offered as a stand- \\nalone product or as an add-on coverage to traditional lines of \\ninsurance business, such as property, general liability, direc- \\ntors’ and officers’ liability, errors and omissions/professional \\nindemnity, crime  and  all-risk  policies. The  introduction  of \\nstand-alone cyber insurance policies was the industry’s an- \\nswer to the exclusions that were introduced in traditional in- \\nsurance policies, when the first claims for cyber losses were \\nraised. When this new request made its entrance in the in- \\nsurance scenery, policy holders’ first reaction was to attempt \\nto find coverage for these risks within existing policies. Ac- \\ncordingly, the insurers’ first reaction was to rely on existing \\nexclusions so as to avoid providing coverage for losses that \\nresulted from cyber incidents. Therefore, the implicit cover- \\nage or the indirect exclusion of coverage for cyber losses had \\nto be “discovered” as a result of a claim or litigation. In the \\nmore mature US market, the debate on the interpretation of \\nendorsements or exclusions regarding cyber coverage in tra- \\nditional insurance policies has produced important case law \\nand the relevant claims have been addressed in detail by the \\ncourts of the United States. \\n\\nNext step for the insurance market was to clear up the \\nlandscape by introducing specific exclusions in order to avoid \\nproviding coverage for cyber losses under the existing insur- \\nance policies. According to the OECD there are three main \\ntypes of general exclusions that may be found in traditional \\npolicies: general exclusion for all losses resulting from a cyber- \\nattack, general exclusion for losses related to specific types of \\nincidents (i.e. data breach) and general exclusion for specific \\ntypes of losses (i.e. data and software loss).43 \\nHowever, as the \\noccurrence of cyber incidents increased and the demand for \\ncoverage for cyber losses was growing, insurance companies \\ndecided to endorse relevant requests in their traditional insur- \\nance policies by either explicitly or implicitly. The last case, \\nwhere no explicit inclusion nor exclusion coverage for a cy- \\nber risk exists, refers to as so-called non-affirmative or silent \\nrisk.44 \\n\\nTraditional policies do not always exclude or implicitly in- \\nclude coverage for cyber losses. In several policies there is \\na specific affirmative reference to this type of coverage. In \\nthe case where there is a specific provision for coverage for \\ncyber risk in traditional policies, this usually includes busi- \\nness interruption and physical damage within the context of \\n\\n\\ncomputer law & security review 43 (2021) 105627 \\n\\nproperty insurance, incident response costs, fines and penal- \\nties, product  liability  and  professional  indemnity  when  li- \\nability  insurance  is  called  for, financial  theft  and  fraud  in \\ncrime/fidelity insurance and cyber ransom and extortion in \\nkidnap and ransom insurance policies. \\n\\nOnce again, the absence of a common language and com- \\nmon rules implemented by the insurance industry as regards \\nthe coverage offered within traditional insurance policies fur- \\nther complicates the operation of the market by creating con- \\nfusion and uncertainty to all the parties involved. Under these \\ncircumstances, insurers are attempting to move cyber risks to \\nspecialised policies, while policy holders are also more willing \\nto invest into a new stand-alone cyber insurance policy. One \\nshould not reach the wrong conclusion that stand-alone cy- \\nber policies adopt a catch-all risks approach and that they do \\nnot include exclusions that apply to both first party and third- \\nparty liability sections. Prior knowledge of circumstances, pre- \\nvious breach events, reasonable precautions, wilful, malicious \\nor criminal acts are some of the exclusions clauses that may \\nbe found in this type of insurance contracts.45 \\nThe emergence \\nof standalone cyber insurance policies and the current devel- \\nopments in the field will be explored in the final section of this \\nanalysis. \\n\\nThe cyber insurance market: background \\n\\n3. \\nand current developments \\n\\n3.1. \\n\\nThe birth of cyber insurance \\n\\nInsurance, in some form, has existed for centuries as a means \\nof mitigating risks to individuals and companies. The birth of \\nmodern insurance dates back to the late 16th century (1680), \\nwhen Edward Lloyd first introduced the notion of marine in- \\nsurance. By 1688, his infamous coffee house had become a \\nvenue for the transaction of insurance business, while in 1779, \\nthe “Lloyd’s policy” became a standard form of marine insur- \\nance. The insurance industry has grown, since then, to one \\nof the most significant segments of the global economy with \\nbillions of dollars being spent every year on insurance under- \\nwritting. At the same time, during all these years, the insur- \\nance industry has managed to stay tuned to the economic and \\nsocietal developments by understanding the market’s needs, \\nby offering new insurance products or by modernising the ex- \\nisting ones. As a result, the insurance coverage spectrum has \\nexpanded in order to cover different types of risks and losses, \\nfrom property losses to losses associated with a person’s life \\nor health and from losses associated with fire and natural dis- \\nasters to legal expenses and general liability. The increased \\nreliance on digital technologies has exposed businesses and \\nindividuals to a different type of risks, security risks. Because \\nof the constantly growing number of cyber incidents, the in- \\nsurance industry has, once again, been brought against a new \\nchallenge, that is to address businesses’ need for coverage for \\ncyber losses. \\n\\nEven though coverage for cyber risk by insurers is still con- \\nsidered to be at an early stage, the first cyber insurance pol- \\n\\n\\nicy was written more than twenty years ago by US insurers. \\nThe initial focus of the cyber insurance market was on pro- \\nviding error and omission coverage for companies providing \\ntechnology-based services.46 \\nGradually, cyber insurance poli- \\ncies evolved and by the mid-1990s the idea behind a policy \\nwas to support an entity in the event of third-party liability \\nclaims.47 \\nHowever, the increasing occurrence of cyber inci- \\ndents together with the establishment of privacy breach noti- \\nfication requirements and penalties, beginning in 2003 in the \\nState of California,48 \\nresulted in new exposures, such as inci- \\ndent response costs, that insurers had not considered when \\ndrafting property and liability insurance contracts. The US in- \\nsurance market’s reaction to this new type of risks and the \\nrole of the US case law in shaping the new insurance land- \\nscape will be further elaborated below.49 \\n\\nWhile this was happening in the US, in the EU the first \\ndata breach notification requirements appeared in Directive \\n2009/136/EC,50 \\nwhich amended Directive 2002/58/EC. However, \\nthe breach notification process introduced by the Directive \\nwas limited to the electronic communications sector. The no- \\ntification obligation was horizontally imposed to all personal \\ndata controllers through the implementation of the GDPR in \\n2018.51 \\nThe EU market lacked therefore, until recently, the \\nmain incentive that apparently triggered the US cyber insur- \\nance market, namely the imposing of fines for data breach vi- \\nolations. However, the need for specified cyber insurance poli- \\ncies was first formally identified by the European Commission \\nin 2013, when, in its Cybersecurity Strategy for the European \\nUnion, it invited public and private stakeholders to “develop, \\nin cooperation with the insurance sector, harmonised metrics \\nfor calculating risk premiums, that would enable companies \\nthat have made investments in security to benefit from lower \\nrisk premiums”.52 \\nIn the same context, in a Scientific Opin- \\nion delivered by the High-Level Group of Scientific Advisors to \\nthe Commission in 2017, a tension was recorded regarding the \\nneed for promoting an insurance market. More specifically, it \\n\\n7 \\n\\nwas recognised that “the need for some insurance intermedi- \\nary is broadly recognised, as this would enable greater partici- \\npation in the digital market especially of citizens and small \\nbusiness when they are insured against the risks of cyber- \\ncrime”.53 \\nAlthough therefore the EU market is behind the US \\nas regards the level of maturity of cyber insurance, the need \\nfor investing in this type of insurance is well identified and \\nseveral initiatives have been undertaken already to this direc- \\ntion. \\n\\n3.2. \\nHow is the global cyber insurance market shaped \\ntoday: the US as the leading player in the cyber insurance \\nfield and the role of the EU \\n\\nDemand for cyber insurance is growing rapidly. Current pre- \\ndictions of the size of the global cyber insurance market sug- \\ngest that over the next five years its size will increase to over \\n20 billion USD by 2025 from around 7 billion USD in 2020.54 \\nAdmittedly, global statistics on the cyber insurance market \\nare mainly derived from the US market. It is estimated that \\n90% of the standalone cyber insurance market is located in \\nthe US, while the European market is estimated to account \\nfor approximately 5–9%.55 \\nA British market research firm re- \\nported in 2018 that 30% of major US companies have pur- \\nchased stand-alone policy coverage for cyber risks, while only \\n5% of the companies in Europe have done the same.56 \\nAs al- \\nready mentioned, the main event that triggered the US cyber \\ninsurance market, besides of course the frequency of cyber in- \\ncidents, was the establishment of privacy breach notification \\nrequirements and penalties, which began as early as in 2003 \\nin California.57 \\nCyber insurance products underwent a shift \\nin response to these new notification requirements towards \\nindemnifying the costs associated with a major data breach. \\nMost of the losses that have been paid under cyber policies \\nhave been for costs incurred based on these state notification \\nlaws. The transition to this new insurance environment was \\nby no means easy. Disputes over the application of the provi- \\nsions of traditional insurance policies to data breaches, ran- \\nsomware and other cyber-related attacks eventually reached \\nthe US courts. The courts’ findings on whether these policies \\nshould or should not cover the new type of losses are listed in \\nchapter 3. \\n\\n\\nCalifornia was the first state to enact such a law, which became \\neffective July 1, 2003. Known as the Security Breach Information \\nAct, or Senate Bill 1386 (SB1386), the statute requires any agency \\nor business that conducts business in California, and “that owns \\nor licenses computerized data that includes personal information”\\nto notify affected residents of California of any security breach if \\n“personal information was, or is reasonably believed to have been \\naccessed by an unauthorized person.”\\n\\nThe US may be the biggest cyber insurance market, but Eu- \\nrope is catching up. Although still small in size, the European \\ncyber insurance industry is growing rapidly, with an increase \\nof 72% in 2018 in terms of gross written premium for the in- \\nsurers, amounting to EUR 295 million in 2018 compared to EUR \\n172 million in 2017.58 \\nThe growing demand for cyber insurance \\nin the EU has made global insurers to change their approach \\nin respect of the insurance solutions they offer to their non-US \\ncustomers. More specifically, while traditionally global insur- \\ners have been repackaging their US cyber offerings for Europe, \\nthey are now focusing on developing cyber insurance offer- \\nings that target European priorities, regulations, and cultural \\nnorms.59 \\nCyber insurance is currently on the agenda of all EU \\norganisations and insurance associations. ENISA, EIOPA and \\nof course the European Union, all have recognised the need \\nfor an efficient and more coherent cyber insurance market. \\nSeveral guidelines and opinions have been published to this \\neffect, reference to which can be found in the following sec- \\ntions. In addition, several initiatives that aim to strengthen the \\ncyber insurance market have also been undertaken at national \\nlevel.60 \\nThe expected growth for the European market is antic- \\nipated to be further accelerated by the recent adoption of the \\nGDPR and NIS Directive. In a relatively recent survey 33% of \\ncyber insurance buyers have identified “regulatory change” as \\nwithin the three most important reasons for obtaining cyber \\ninsurance.61 \\n\\nThe US cyber insurance market: how can \\n\\n4. \\nthe US example and respective US case law \\ncontribute to a more sustainable EU cyber \\ninsurance market \\n\\n4.1. \\n\\nGeneral \\n\\nThis chapter examines typical examples of US cases on cy- \\nber insurance and assesses how the US case law has shaped \\nand continues to affect the US insurance market in terms of \\ndefining cyber insurance coverage. The purpose of this chap- \\nter is not to delve into the US legislative framework on insur- \\nance, which would be both impossible, within the constraints \\nof this analysis and impractical due to its differences to the \\nEU regulatory regime. Nor does it aim to provide an update \\non the current case law on different cyber insurance topics. \\nHowever, an overview of US case law on specific aspects of \\ncyber insurance was considered essential for three reasons: \\n\\ncomputer law & security review 43 (2021) 105627 \\n\\nFirst, the US courts have been dealing with cyber insurance \\ndisputes for over twenty years. Therefore, their contribution \\nto help us understand this new segment of the insurance mar- \\nket is undeniable, especially in view of the lack of any EU case \\nlaw on this subject. Second, the US courts during these two \\ndecades of examining cyber insurance cases have focused on \\ndefining key concepts in cyber insurance policies. Third and \\nmost important, the abundance of, conflicting, case law on cy- \\nber insurance claims, that is mainly the result of the US mar- \\nket’s practice to apply CGL policies on claims related to cy- \\nber losses, could be viewed as the market’s call for the devel- \\nopment of stand-alone policies to address the growing need \\nfor this type of coverage. Reference to US case law in the next \\nparagraphs is carried out in this limited, yet enlightening per- \\nspective, namely as a useful tool to acquire a better insight \\ninto cyber insurance coverage issues. With this assumption \\nin mind, the cases that are examined in the next paragraphs \\nfocus on claims regarding damage to software and destruc- \\ntion or loss of data as well as on data breaches that arise from \\ntraditional insurance policies in an effort to demonstrate how \\ncyber risks are handled within the general liability insurance \\npolicies in the USA. By contrast, examination of US case law \\nresulting from stand-alone policies, as well as of the exclusion \\nclauses included in them, are not dealt with under the present \\nanalysis, because they are deemed of little, direct at least, rel- \\nevance to the formulation of an EU comprehensive policy and \\nlaw on cyber insurance.62 \\n\\nMost of the case law regarding potential coverage for cyber \\nincidents involves commercial general liability (CGL) policies. \\nCGL insurance is the most common type of coverage found in \\nUS corporate insurance programs.63 \\nThe CGL form has been in \\neffect since the 1940s and has been purchased by the majority \\nof businesses to cover a wide range of risks, but it was not de- \\nsigned to protect the insured from any and all risks.64 \\nGiven its \\nwide spectre of coverage, it comes as no surprise that policy \\nholders have traditionally turned to this policy to ask cover- \\nage for losses arising from different incidents, including cyber. \\nHowever, the CGL policy when first drafted was not intended \\nto cover cyber risks. Therefore, there are no express terms for \\n“cyber” incidents, “data breaches” or “privacy breaches” in the \\nCGL policy forms. As a result, insurance companies usually \\ndeny offering coverage for cyber losses under a typical CGL \\npolicy.65 \\nToday the coverage available in a typical CGL policy is \\ndivided into three categories: (1) Coverage A: Bodily Injury and \\nProperty Damage Liability; (2) Coverage B: Personal and Adver- \\ntising Injury Liability (e.g., defamation, privacy violation, intel- \\nlectual property infringement, etc.); and (3) Coverage C: Med- \\nical Payment. With regard to cyber coverage in particular, the \\ndebate of whether it is covered or not under this traditional in- \\n\\n4.2. \\nDefining property damage coverage: do damaged or \\ncorrupted software or data constitute tangible property? The \\nUS courts approach and the role of the ISO \\n\\nThe CGL policy was designed to provide coverage for any oc- \\ncurrence of property damage. According to the pre-2001 CGL \\nform, property damage was defined as a physical injury to tan- \\ngible property, including all resulting loss of use of that prop- \\nerty or loss of use of tangible property that is not physically \\ninjured. At that time companies’ records were physical so the \\ndefinition of property damage was adequately setting the cov- \\nerage spectrum in most cases. As more information started \\nto get stored digitally, the courts had to decide whether the \\nloss of data and the damage of software could be classified as \\nproperty damage under the existing CGL policy. More specifi- \\ncally they had to decide whether damaged or corrupted soft- \\nware, hardware, or data constitute \"tangible property\" and if \\nyes whether they are subject to physical injury or loss. In prac- \\ntice, when a policy did not contain a separate clause, as this \\nis mostly the case in CGL policies, insurers usually denied to \\nprovide coverage for a claim that concerned damaged soft- \\nware or lost data on the basis that computer software or elec- \\ntronic data had not suffered actual \"physical\" damage within \\nthe meaning of the policy.66 \\n\\nThe concept of tangible property and physical loss have \\nbeen intensively addressed by the US Courts and several deci- \\nsions have been issued in favour or against the coverage of cy- \\nber related claims under the property damage definition, not \\nalways in a uniform manner.67 \\nSpecifically, in 2000, in a case \\nwhich involved an incident where a power outage took down \\nthe insured’s mainframe computer and was required to repro- \\ngram the lost data,68 \\nthe court found that \"’physical damage’ \\nis not restricted to the physical destruction or harm of com- \\nputer circuitry but includes loss of access, loss of use, and loss \\nof functionality\".69 \\nHowever in an opposite court ruling it was \\ndecided that software and data were not “tangible property”\\nand any “loss of use” was excluded.70 \\nDifferent was the ap- \\nproach adopted by the court in “Retail Systems, Inc. v CNA In- \\nsurance Cos .”71 \\nwhere, the Court ruled that a lost tape with its \\nembedded data falls within the definition of loss of tangible \\nproperty as the data recorded on the tape was merged with \\nthe tape itself. \\n\\n\\nIn a leading case in favour of coverage,72 \\n\\nthe court exam- \\nined the plaintiff’s argument that his computer crashed due to \\nits infection with spyware after he visited the company’s web- \\nsite. The result was that the plaintiff lost data and incurred \\ncosts to repair his computer system. Despite the insurance \\ncompany’s argument that “software, data or other informa- \\ntion that is in electronic form” is not “tangible property”, the \\nCourt ruled that the plaintiff alleged the loss of use of his com- \\nputer which falls within the general liability policy’s defini- \\ntion of “property damage”. However, this argument was not \\naccepted in “Cyber, Inc. v. Federal Insurance Company ”.73 \\nThere, \\nan insurance general liability claim was made against a soft- \\nware installation company for the negligent installation of a \\nfinancial management software system. The court, however \\nfound that this was “not a case of losing the use of tangible \\ncomputer systems rather than the plaintiff’s new software in- \\nadequacies.” Coverage, therefore, was denied.74 \\n\\nConsequently, the US courts are not aligned as regards their \\napproach to categorising lost data or damaged software as \\n“property damage” under a typical CGL policy. Policyholders \\nmay only rely on judicial precedent if they wish to estab- \\nlish that \"physical loss” does not require actual physical de- \\nstruction of property, but it could suffice that the damage has \\ncaused the policyholder to suffer a \"loss of use\" of the in- \\nsured property. This uncertainty has been addressed by ISO 75 \\nwith several amendments to the template CGL forms. More \\nspecifically, when the first case law on coverage was issued, \\nISO amended the definition of “property damage” to explic- \\nitly state that electronic data is not tangible property. Since \\n2001, the CGL definition of “property damage” has included a \\nclear provision stating that for the purposes of the CGL, elec- \\ntronic data is not tangible property.76 \\nIn 2004, ISO made an- \\nother amendment to the CGL form, an exclusion that was in- \\ntended to eliminate coverage in connection with loss of elec- \\ntronic data. The new language eliminated coverage for “dam- \\nages arising out of the loss of, loss of use of, damage to, cor- \\nruption of, inability to access, or inability to manipulate elec- \\ntronic data.”77 \\nThe current Commercial General Liability Cov- \\nerage Form published by ISO in 2019 78 \\nincludes the following \\nwording with regard to the electronic data exception: this in- \\n\\n4.3. \\nbreaches handled under US insurance coverage \\n\\nPersonal and advertising injury coverage is the second field of \\nUS litigation that will be examined in the context of this anal- \\nysis. Emphasis will be given to the way US courts interpret \\nthe term “publication”, that triggers the “personal and adver- \\ntising” coverage, in the privacy breach context. In other words, \\nthe question that this section aims to answer is to what degree \\ndata breach cases fall within a typical CGL policy. \\n\\nInitially, \"advertising injury\" was defined as \"injury aris- \\ning out of an offense committed during the policy period oc- \\ncurring in the course of the named insured’s advertising ac- \\ntivities, if such injury arises out of libel, slander, defamation, \\nviolation of right of privacy, piracy, unfair competition, or in- \\nfringement of copyright, tide or slogan”.80 \\nThe advertising in- \\njury definition was amended in 1985 to include, among others, \\ninjury “arising out of the following act (among others): Oral or \\nwritten publication of material that violates a person’s right \\nof privacy”. In 2001, in response to the growing technological \\nenvironment and the expanded use of the media, ISO broad- \\nened the relevant clause to its current wording form: “Oral or \\nwritten publication, in any manner, of material that violates a \\nperson’s right of privacy . . . .”. The “in any manner” insertion \\nwas intended to address Internet and electronic publications, \\nand their impact on personal and advertising injury offenses \\nwhich may arise from publication via e-mail or a website.”81 \\nAccordingly, important US case law examines whether the \\nevent that led to the loss of personal information constitutes a \\n“publication,” which amounts to a violation of a person’s right \\nto privacy, and thus falls within the personal and advertising \\ninjury provisions of CGL terms. In the first case 82 \\nthe court \\nwas called to decide whether a loss of 130 IBM data tapes that \\nincluded unencrypted personal information for 500,000 past \\nand present IBM employees by Recall Total Information Man- \\nagement (the tapes fell out of the back of a van while in transit \\nand were taken by an unknown person and never recovered) is \\na publication and if yes whether the plaintiff should be com- \\npensated under the CGL coverage. The insurers denied the \\nclaim, arguing that “publication” requires a showing of “ac- \\ncess,” and because there was no evidence anyone “accessed”\\nthe information on the tapes there was no “publication.” The \\ncourt determined that the insurance policy did not cover the \\ndata breach in question because, although IBM had incurred \\nsubstantial expense addressing the data loss, this could not \\n\\n\\x0c10 \\n\\ncomputer law & security review 43 (2021) 105627 \\n\\nsatisfy the “personal injury” requirement of its policy. The ap- \\npellate court affirmed the lower court’s decision. \\n\\nIn another case 83 \\n\\nhackers compromised Sony’s PlayStation \\nNetwork and stole consumer personal information. There was \\nno allegation or evidence that the thieves further dissemi- \\nnated the stolen information: In summarizing its position on \\nthe issue, the court again focused on the exposure of the in- \\nformation, regardless of form, from a secure location. How- \\never, the court held that the policies’ coverage for the oral or \\nwritten publication of materials that violate a person’s right \\nto privacy could not be triggered through the actions of third \\nparties, in this case, the hackers that stole confidential infor- \\nmation from Sony’s Playstation Network.84 \\nLikewise in St. Paul \\nFire & Marine Ins. Co. v. Rosen Millenium Inc. the court de- \\nnied defence coverage to Rosen Hotels following a credit card \\nbreach caused by malware installed on the hotel’s payment \\nnetwork on the basis that the injuries at issue resulted from \\nthe actions of third parties and not those of the insured.85 \\nAn- \\nother relevant decision is Travelers Indemnity Co. of America \\nv. Portal Healthcare Solutions, LLC.86 \\nIn this case the district \\ncourt confirmed CGL coverage for claims where confidential \\nmedical information was made available online as this con- \\nstitutes a publication under the personal and advertising in- \\njury provision. The court reasoned that “publication” requires \\nonly that information be “placed before the public,” and that \\nthe mere availability of the information online is sufficient, re- \\ngardless of whether it’s ever accessed or viewed by anyone.87 \\nISO’s  reaction  to  the  above  case  law  US  litigation  was \\nsimilar to property damage coverage for lost data and dam- \\naged software. As seen in the previous subsections, as data \\nbreaches became more frequent and severe, ISO took steps to \\nconstrain CGL policies from responding to privacy and data \\nbreach claims. In April 2013, ISO created a brand-new endorse- \\nment, the sole purpose of which is to allow insurance compa- \\nnies to delete the entire “publication, in any manner” defini- \\ntion of personal and advertising injury. In May 2014, ISO also \\nmade available an exclusion specifically designed to eliminate \\ncoverage for breach of privacy liability, excluding personal and \\nadvertising injury arising out of any access to or disclosure of \\nany person’s or organization’s confidential or personal infor- \\nmation, including financial information, credit card informa- \\ntion, health information or any other type of non-public infor- \\nmation.88 \\n\\n\\nSee Commercial General Liability, CG 21 06 05 14 available at: \\n\\n4.4.  What can the US cyber insurance market teach us? \\n\\nThe analysis of US case law and of the ISO’s response to it \\nwhen examining the meaning of disputed concepts in CGL \\nforms from a cyber insurance perspective, confirms what has \\nbeen established so far in this analysis: Cyber-related terms, \\nand especially coverages for cyber losses is a grey area for the \\ninsurance industry. The US market, in spite of its level of ma- \\nturity, has not yet reached a satisfactory level of consensus on \\nthe definition of cyber coverage or on the most appropriate \\nmodel to promote insurance products that cover cyber losses \\nto its customers. Both US courts and ISO have tried to shed \\nsome light on the unclarity that surrounds these terms when \\ninvoked by the policy holders. Even though there are several \\ncourt rulings that point to one or the other direction, which \\nhave been invoked by both the insurers and the insured when \\ndefending their claims, it is obvious that the market’s stability \\nand growth cannot depend on conflicting case law. It is also \\ntrue that ISO has contributed to the disambiguation of the \\ninsurance landscape. Nevertheless, ISO is an advisory organi- \\nsation and not a regulatory authority. In practice, this means \\nthat it may provide some guidance to the market stakehold- \\ners, but it is not a policy maker. Essentially the more than two \\ndecades experience of the US insurance industry on handling \\nclaims on cyber coverage clearly demonstrates the shortcom- \\nings of applying CGL policies to address issues related to cyber \\nlosses. The significant load of conflicting case law on claims \\narising from the use of these policies and the need for ISO to \\nconstantly intervene by suggesting new insurance language to \\naddress the current trends are a strong indicator that stand- \\nalone cyber insurance policies is the best way forward. The \\nUS market has already made a turn to stand-alone cyber in- \\nsurance policies and to this effect a number of case law has \\nalready been formulated.89 \\nIt is therefore argued that the US \\nexample could serve as a strong motivation for the EU market \\nto move directly to the stand-alone option by skipping alto- \\ngether the obvious, yet problematic, implementation of tradi- \\ntional insurance policies to cover cyber losses. This argument \\nhowever will be discussed in the final chapter of this paper \\nas it is believed to be one of the major challenges the cyber \\ninsurance market is called to address. \\n\\nIdentifying the main challenges of the \\n\\n5. \\ncyber insurance market \\n\\nDespite the market’s obvious call for insurance coverage to \\naddress the risk of cyber losses, either as adds-on to existing \\ntraditional policies or as stand-alone solutions, the cyber in- \\nsurance industry and the businesses themselves are still hesi- \\ntant when considering investing in the specific insurance field. \\nThere are several factors that have kept the market from grow- \\ning together with the constantly increasing number of cyber \\nincidents and the disastrous effects these could have in terms \\nof money losses for the businesses that suffer them. Whereas \\nthere is no doubt that cyber losses are the new stressful reality \\nfor organisations of all sizes, it seems that both the insurers \\nand the insured have not yet reached a common ground for \\n\\n\\nworking together towards this direction. The main challenges \\nthat, according to this analysis, slow down the growing pace \\nof the cyber insurance market are presented in the chapters \\nthat follow in the expectation that, once they are identified, \\nboth the market and the policy regulator will undertake the \\nnecessary initiatives that will lead eventually to the market’s \\nmaturity and stability. \\n\\n5.1. \\n\\nUnclarity around cyber risk \\n\\nThe need for a deeper understanding of cyber risk is a core \\nchallenge for the cyber insurance industry as it directly causes \\nother challenges or makes more difficult the apprehension \\nof concepts that are related to cyber insurance, such as cy- \\nber loss or cyber coverage. There are several parameters that \\ncontribute to the lack of clarity surrounding cyber risk. At the \\nsame time, based on a cause and effect reasoning, the same \\nparameters could be perceived as the outcome of this unclar- \\nity. \\n\\nThe  first  parameter  that  contributes  to  the  confusion \\naround the notion of cyber risk is the lack of awareness and \\neven the misconception regarding this type of risk, that is \\noften encountered in all involved stakeholders in the cyber \\ninsurance market. The policy holders on the one hand, are \\nnot qualified to understand their vulnerabilities against cy- \\nberattacks nor to evaluate what consequences a cyber inci- \\ndent could potentially have to their business operation. The \\ninsufficient level of understanding of the risks and, accord- \\ningly, of the products that are on offer affects severely the \\ncompanies’ decision to purchase an insurance product in the \\nfirst place. Insurance companies on the other hand, do not en- \\njoy the benefit of decades’ worth of uniform policy language \\nthat has been tested in court, as they do for other lines of in- \\nsurance. As a result, they find underwriting extremely chal- \\nlenging. The lack of feedback from their clients as well as the \\nlack of specialised underwritters with a better knowledge of \\nthe technical aspects of cyber risks makes this task even more \\ndemanding.90 \\n\\n5.2. \\n\\nThe lack of commonality in policy language \\n\\nThe lack of commonality in policy language in the cyber in- \\nsurance sector and, accordingly, the lack of standardized poli- \\ncies across the industry is another challenge the cyber insur- \\nance market is facing, which is directly connected to the dif- \\nferent understanding of cyber risks by different players. The \\nlack of consistency in the terminology used by the industry \\nhas been examined in the first part of this analysis. Despite \\nthe attempts from the industry itself, as well as from differ- \\nent EU and international bodies with competence on this sub- \\nject matter, such as ENISA, OECD or EIOPA, for a broader con- \\nsensus as regards the cyber related terms, this has not been \\nachieved so far. In practice, this is translated into differenti- \\nations in the insurance products sold in the market in terms \\n\\n90 \\n\\nA survey conducted by EIOPA showed that the second biggest \\nconcern of the market is the lack of understanding of the risks by \\nunderwitters/brokers, see EIOPA Understanding Cyber insurance- \\na structured dialogue with insurance companies, 2018. \\n\\nof both the cyber losses that are covered, as well as the cover- \\nage provided for each loss. Variations in coverage will be sep- \\narately examined in the paragraph that follows. Besides the \\ndifferent approach adopted by different stakeholders, when \\nit comes to understand and define cyber risks, there are ad- \\nditional reasons that make harmonisation as regards policy \\nterms and conditions difficult to achieve. The evolving nature \\nof the cyber threats is one of them. What is considered a cyber \\nthreat today will be obsolete tomorrow, when a new unknown \\nthreat will have taken up its place. At the same time, the con- \\nsequences of an existing threat may vary depending on the \\nvictim of the cyberattack or the magnitude of the threat. Cy- \\nber threats do not have geographical limits and may, at the \\nsame time, generate consequences in different jurisdictions \\nwith any implications this may bring along. Finally, the lack of \\nhistorical data on cyber incidents, that will be examined in the \\nfollowing paragraph as a separate challenge, is another factor \\nthat contributes to the lack of commonality in the industry. \\n\\n5.3. \\n\\nThe lack of historical data \\n\\nThe lack of historical data on the frequency and severity of \\ncyber incidents is another challenge of the cyber insurance \\nmarket. It works as both a primary obstacle to a detailed un- \\nderstanding of fundamental aspects of cyber risk and, at the \\nsame time, as a barrier to achieve language harmonisation. El- \\ning notes: “Not only is the lack of data a major concern for in- \\nsurance managers and empirical researchers, but the dynamic \\nnature of cyber risk also carries an immense risk of change. It \\nis thus far from clear whether the little historical data we have \\nis indicative of future outcomes”.91 \\nThe lack of consistent in- \\nformation on cyber incidents is due to several reasons. The \\nfirst is that cyber risk is a relatively new peril meaning there \\nare limited records of past incidents. At the same time, the \\nfast-evolving nature of cyber risk further restrains the value \\nof the existing data. The general reluctance of the victims of \\ncyber incidents to share information on these events, mainly \\nout of fear that their reputation may be affected, puts another \\nbarrier to the already limited access to historical data. As ob- \\nserved by ENISA, “lack of data makes it very difficult for insur- \\ners to properly understand which industries are facing which \\nthreats, what is the motivation behind them, what is the loss \\nfrequency or severity, what is the loss correlation between in- \\ndustries, countries etc. On top of that, cyber insurance carriers \\nare very reluctant to share their existing information amongst \\nthem. The resulting unavailability of incident data makes it \\nvery hard to produce consistent and converging risk assess- \\nment models”.92 \\n\\nAnother factor that makes access to data on past incidents \\ndifficult is the obligation of insurance companies to comply \\nwith specific requirements for the protection of personal or \\nconfidential information they collect and process. These re- \\nquirements may be imposed by regulatory instruments, such \\nas the GDPR, or by sector-specific legislation, imposed by in- \\n\\nsurance regulators or supervisors,93 \\nor even be the result of \\nconfidentiality clauses in the insurance contracts between in- \\nsures and policy holders. Each of these parameters seems to \\nfurther complicate the development of an incident data shar- \\ning initiative. At the end of the day a balance of interest will \\ndefine whether insurance regulators and supervisors should \\nrelax any provisions that impede the sharing of data for the \\nbenefit of enhancing the data availability and accordingly re- \\ninforce the cyber insurance market. \\n\\nVariations in coverage: how are fines and ransom \\n\\n5.4. \\npayments treated under insurance policies \\n\\nVariations  in  coverage  is  the  last, but  not  least, challenge \\nthat will be tackled in the context of this analysis. As already \\nmentioned in the relevant section, coverage for cyber-related \\nlosses may be provided through stand-alone cyber insurance \\npolicies or through endorsements to traditional policies, ei- \\nther explicitly or “silently” by not excluding the specific cyber \\nrisk from the policy’s coverage. However, as it was analysed \\nabove, US case law has not always been clear as regards the \\neligibility of coverage for cyber incidents under typical CGL \\npolicies. Controversial decisions together with the reluctance \\nof the insurance companies to compensate for cyber losses \\non the basis of the existing traditional insurance products has \\ncreated confusion and insecurity to both the insurers and the \\ninsured with, ultimately, a negative impact on the market’s \\ndevelopment. \\n\\nIn terms of coverage unclarity it is not only the different \\nlanguage used by the insurers or the different interpretation \\nof coverage terms by the courts that contribute to it. The in- \\nsurability of specific cyber incidents and subsequent losses is \\nanother factor that should be taken into consideration. For the \\npurposes of this analysis two types of losses will be evaluated, \\nas additional indicators of the level of complexity that is in- \\nherent when insuring against cyber risks, fines and penalties, \\nwith a focus on fines imposed as a result of a data breach and \\nransom payments.94 \\n\\nRegarding the first category, insurability of fines and risks \\nhas been a burning issue for the US insurance market since \\nthe introduction of the privacy legislation in the US. As re- \\ngards the EU market, concerns have been raised since the im- \\nplementation of the GDPR and are expected to grow as the \\nfirst severe fines are being imposed. In view of the costs a \\ndata breach may incur, the demand for insurance coverage \\nthat will respond to claims for violation of privacy is grow- \\ning. The practices followed by the insurance companies with \\nregard to regulatory fines vary depending on the jurisdiction \\nwhere the fine is imposed, national law, the type of the fine \\n(civil/administrative or criminal) and the nature of the act be- \\n\\n93 \\n\\nIn Portugal, legislation governing insurance contracts imposes \\na general obligation on insurance companies to maintain the se- \\ncrecy of all information that is disclosed as part of the execution of \\nthe insurance policy. See also OECD’s report, Enhancing the avail- \\nability of data for cyber insurance underwriting- the role of public \\npolicy and regulation, 2020 \\n94 \\n\\nSee  LaCroix  K.,  Are  GDPR  fines  and  penalties  insurable?, \\nthe D&O Diary, available at https://www.dandodiary.com/2018/11/ \\narticles/cyber-liability/gdpr-fines-penalties-insurable/ \\n\\ning penalised. Based on a survey conducted by the OECD,95 \\nin most countries the vast majority of cyber insurance poli- \\ncies offer some coverage for fines and penalties. However, in \\nall of the policies reviewed any coverage for fines and penal- \\nties is subject to conditions, such as insurability under appli- \\ncable law or exclusion of civil and criminal fines and penal- \\nties.96 \\nUltimately, where there are no direct or specific legal or \\nregulatory impediments to providing coverage, insurability or \\nuninsurability is subject to interpretation by the insurer and \\npotentially to disputes and litigation.97 \\n\\nA similar approach is adopted when it comes to the insur- \\nability of ransom payments. Cyber extortion attacks (whether \\nransomware or other types of extortion) could lead to a num- \\nber of losses, including potentially ransom payments to termi- \\nnate the attack or threat of attack. The OECD reviewed thirty- \\nfive stand-alone cyber insurance policies and concluded that \\nmany among them provided explicit coverage for ransom pay- \\nments, sometimes with conditions related to insurability or \\nlegality.98 \\nIn this context, in some jurisdictions ransom pay- \\nments could be considered inconsistent with public policy as \\nsuch payments could encourage further extortion attempts \\nand therefore should not be covered by insurance contracts. \\nRegardless of these findings however, some countries encour- \\nage reimbursement for this type of cyber loss.99 \\n\\nInitiatives to address the challenges at \\n\\n6. \\nregulatory and industry level \\n\\nFrom unclarity and inconsistency in insurance language to \\nhesitance on adopting data sharing initiatives, the challenges \\nof the cyber insurance market may be overcome if the in- \\ndustry and the policy regulator work together to this effect. \\n\\n\\nCoverage- the Role of Public Policy and Regulation, Chapter 3. \\n96 \\n\\nIn the EU, GDPR fines for non-compliance are administrative \\nfines although each Member State may establish additional rules \\non penalties for infringements that may be either criminal or ad- \\nministrative in nature. In a number of EU countries, administra- \\ntive fines imposed under GDPR may be found to be uninsurable \\nas counter to public order or to the principle that the negligent \\nparty should bear the cost, although there is no specific legisla- \\ntion or clear jurisprudence. In most (if not all) countries, criminal \\nfines and penalties are not insurable based on the principle that \\na person (legal or natural) that has committed a (by definition) in- \\ntentional and malicious (criminal) act should be required to bear \\nthe consequences (penalties) of that act. \\n97 \\n\\nFor the insurability of fines for data breaches, see also Baldwin \\nD.J, Buckley J. P, and Slaugh D.R. in Insuring against privacy claims \\nfollowing a data breach, Penn State Law Review, Vol 122:3, 2018. \\n98 \\n\\nFor the issue of illegality of ransom payments under English \\n\\nlaw see also see Celso de Azevedo, ibid, p. 166 ff. \\n99 \\n\\nFor instance, some countries, such as Australia and the United \\nStates, have explicit policies against paying ransoms Other coun- \\ntries, including Brazil, Colombia, Italy, Portugal and Russia, specif- \\nically prohibit insurance coverage and/or indemnification for kid- \\nnapping (and related ransom payments). In Germany, where guid- \\nance has been issued to ensure that kidnap and ransom insurance \\npractices are consistent with public policy, the German Financial \\nSupervisory Authority has issued a specific clarification indicat- \\ning that the reimbursement of ransom payments related to cyber- \\nextortion is permitted but cannot be advertised. \\n\\n\\x0ccomputer law & security review 43 (2021) 105627 \\n\\n13 \\n\\nThe initiatives presented in the following paragraphs take into \\nconsideration the market’s particularities and specifically its \\nnovel character as an emerging segment within the insurance \\nfield as well as the absence of a specific regulatory frame- \\nwork that will govern its function. However, given the mar- \\nket’s immaturity and the stakeholders’ reservations regarding \\nthe possibility of over-regulation, it is considered preferable \\nthat any suggestions on policy-making focus mainly on the \\nadoption of organisational initiatives that could contribute to \\nresolving the market’s lack of clarity and coordination. Sim- \\nilarly, any legislative initiatives that are presented in the fol- \\nlowing sections are outlined under the same assumption, that \\nof light-handed interim intervention. \\n\\nData sharing as a response to lack of data on cyber \\n\\n6.1. \\nincidents \\n\\nEnhancing the availability of data for cyber insurance under- \\nwriting is emerging as a top priority for all stakeholders in the \\ninsurance market. In the more mature US market, steps have \\nalready been taken to this direction. Specifically, insurers are \\nrequired to use the NAIC Cyber Supplement to report their \\nnumber of claims (both first-party and third-party), direct pre- \\nmiums written and earned, direct losses paid and incurred, \\nand number of policies in-force.100 \\nAt EU level, even though \\nthere is no database for insurers to share data on incidents, \\nclaims and premiums, several initiatives have been under- \\ntaken so far towards strengthening information sharing on cy- \\nber incidents and enhancing the cooperation among Member \\nStates. At regulatory level, the introduction of mandatory in- \\ncident reporting schemes within the European Union through \\nthe implementation of the NIS Directive and the GDPR,101 \\nis \\nanticipated to be a source of useful incident data for insur- \\nance companies. In addition to the notification process, the \\nestablishment of a network of the national CSIRTs (the CSIRTs \\nNetwork) and the creation of the Cooperation Group by the \\nNIS Directive will enhance the sharing of information on risks \\nand incidents. Both the CSIRTs and the DPAs collect data on \\nincidents that they handle and data on data breaches that are \\nreported to them respectively,102 \\nwhich may be used to gener- \\nate statistics on trends in the types of cyber incidents.103 \\n\\n100 \\n\\nThe  NAIC  recently  released  its  report  on  the  2020  Cyber \\nSupplement,  reflecting  information  filed  by  577  U.S.  insurers \\nwho submitted data for calendar year 2019 regarding cyberse- \\ncurity  insurance  policies  provided  to  businesses  and  individ- \\nuals.  The  data  showed  a  cyber  insurance  market  of  roughly \\n$  3.15  billion  in  direct  written  premiums.  Insurers  writing \\nstand-alone cybersecurity insurance products reported approx- \\nimately  $1.91  billion  in  direct  written  premiums,  and  those \\nwriting cybersecurity insurance as part of a package policy re- \\nported  roughly  $1.24  billion  in  direct  written  premium.  The \\nreport is available at https://content.naic.org/sites/default/files/ \\ninline-files/Cyber _ Supplement _ 2019 _ Report _ Final _ 1.pdf\\n\\nData availability on cyber threats is also expected to be \\nstrengthened by the Information Sharing and Analysis Cen- \\ntres (ISACs) initiative.104 \\nISACs are non-profit organizations \\nthat provide a central resource for gathering information on \\ncyber threats (in many cases to critical infrastructure) and al- \\nlow two-way sharing of information between the private and \\nthe public sector about root causes, incidents and threats.105 \\nBoth the Cybersecurity Act and the NIS Directive promote the \\ncreation of ISACs.106 \\nDifferent models of ISACs exist in several \\nEU Member States.107 \\nSome are country-focused, while others \\nare sector specific ISACs that encourage the cooperation on \\nthe sectorial level of critical infrastructure or essential/vital \\nsector; 108 \\nin addition, there are international ISACs that bring \\ntogether multi-stakeholder members from Europe and third \\ncountries.109 \\n\\nFinally, there have also been a number of efforts within \\nthe insurance sector to make information on past cyber losses \\nand claims available. The CRO Forum has recognised the im- \\nportance of the ability to share cyber loss and digital event \\ndata across and within different sector stakeholders in order \\nto build up a “loss data base”. To this effect, it has engaged \\nin a multi-year effort to begin to address the lack of data for \\nunderstanding digital risks and cyber exposure. In 2014, the \\nwork focused on identifying the gap and began with an effort \\n\\n104 \\n\\nISACs were originally created in the USA. In 1997, after the first \\nterrorist attacks on World Trade Center (1993) and Oklahoma City \\n(1995), President Clinton appointed the President’s Commission \\non Critical Infrastructure Protection (PCCIP). Its objective was to \\nidentify the possibility of cooperation between public and private \\nsector so that the US critical infrastructure could be properly pro- \\ntected. Chaired by Robert T. Marsh, the Commission presented the \\nso called “Marsh report” with many recommendations about rais- \\ning the level of critical infrastructure protection in the US. One of \\nits main recommendations was to establish Information Sharing \\nand Analysis Centres (ISACs), so as to build and strengthen coop- \\neration between public administration and the industry. \\n105 \\n\\nAt European level, Sectoral Information Sharing and Analysis \\nCentres (ISACs) and corresponding CSIRTs can play a key role in \\npreparing for and responding to cyber incidents. (See European \\nCommission, Strengthening Europe’s Cyber Resilience System and \\nFostering a Competitive and Innovative Cybersecurity Industry, \\nCOM(2016) 410 final). \\n106 \\n107 \\n\\nSee recital 29 of the Act. \\nSee ENISA’s report on Information Sharing and Analysis Cen- \\n\\ntres (ISACs), 2017. \\n108 \\n\\nIn  the  Netherlands, for  instance, ISACs  are  established  by \\nthe Government’s National Cyber Security Centre on a sector-by- \\nsector basis (water, energy, finance etc). In the United Kingdom, a \\nvery similar setup has been introduced, organised by the govern- \\nment’s Centre for the Protection of National Infrastructure (CPNI). \\nIn Germany, UP KRITIS is a large co-regulatory initiative in which \\ncritical infrastructure organisations participate (both private and \\npublic entities) Within UP KRITIS, information is shared based on \\nthe Traffic Light Protocol (TLP) as the information cannot always be \\nmade public. Information is shared via emails and standard tem- \\nplates provided by the Federal Office for Information Security (BSI). \\n109 \\nEU FI- ISAC – a European ISAC that serves the financial sector, \\nEE-ISAC – a European ISAC created in 2015 that serves the energy \\nsector. European ISAC in Aviation sector – an ISAC under creation, \\ninitiated in February 2017 by the private sector in cooperation with \\nENISA and EASA (European Union Aviation Safety Agency). \\n\\n\\x0c14 \\n\\ncomputer law & security review 43 (2021) 105627 \\n\\nto develop a taxonomy, which was published in 2016,110 \\nthat \\nset out a potential basis for a common language that could \\nbe used to describe digital events. In 2017, that taxonomy was \\ntested through a pilot exercise to determine if the categori- \\nsation could be used to capture data on incidents in a way \\nthat could provide analytical value for companies while also \\nsharing this data anonymously. In 2018 the CR-Forum cyber \\nworking group published a paper with the findings from that \\ntrial.111 \\n\\nAnother international think tank of the insurance industry, \\nthe Geneva Association, recently created a business plan and \\nconcept proposal for a cyber incident data exchange reposi- \\ntory (CIDER) to enable insurance and reinsurance companies \\nto share data. Another association that has been motivated \\nto this direction is Insurance Europe, which has developed a \\ntemplate as a possible way to meet the obligation of data con- \\ntrollers to notify data breaches. The template is set up in such \\na way that the information gathered can be shared without \\nthe need to be anonymised or aggregated, as it will not be pos- \\nsible to identify a company through the information it submit- \\nted.112 \\nFinally, EIOPA recently suggested that a European-wide \\ncyber incident reporting database based on a common taxon- \\nomy could support the development of the European cyber in- \\nsurance market.113 \\n\\nThe need for access to data on past incidents has been \\nrecognised by all the parties involved as a high priority. The \\nprocess is still in its infancy and there are several difficulties \\nthat need to be tackled before a generally accepted framework \\nfor data sharing is implemented. The insurers’ unwillingness \\nto share information for fear of disclosing their competitive \\nadvantage or compromising sensitive business information, \\nthe legal requirements imposed upon them under data pro- \\ntection and privacy legislation, or the specific rules imposed by \\ninsurance regulators and supervisors relevant to the handling \\nof personal or confidential information in the context of the \\ninsurance contracts, are some of the obstacles that need to be \\noverridden in order for a general solution for a cyber data ex- \\nchange mechanism to be achieved. In this effort, ENISA, as the \\nEuropean Agency for Cybersecurity, could be the appropriate \\nEU platform to initiate such discussions. This after all is sug- \\ngested by the Cybersecurity Act itself, according to which sup- \\nporting information sharing in and between sectors is listed \\n\\n6.2. \\npolicy language: the benefits of standards and common \\nterminology. What could the role of regulation be? \\n\\nIn the previous sections of this analysis it was demonstrated \\nhow the lack of harmonisation in the terminology used by the \\ninsurers globally and the inconsistency in the types of cyber \\nlosses and offered coverages under different insurance poli- \\ncies have been an impediment to the market’s growth and ma- \\nturity. The development of a standard policy language and the \\nintroduction of common terms and conditions in insurance \\npolicies could contribute to the achievement of harmonisa- \\ntion in the cyber insurance market. The role of regulation in \\nsupporting consistency is yet to be determined. Even though \\nthe need for standardisation is undisputable, there are voices \\nin the industry that argue that any regulatory intervention \\naimed at achieving standard terms and conditions for cyber \\ninsurance could impede innovation in the market as risks be- \\ncome quickly outdated. On the other hand, it is understood \\nthat any guidance by governments, insurance market author- \\nities, insurance supervisors and regulators could shed some \\nlight in the uncertain cyber insurance landscape, thus help- \\ning the market mature and grow. The market’s mixed feelings \\non this issue are depicted in a survey conducted by EIOPA on \\ncyber regulation and the role of governments. Participants in \\nthe survey showed “a relative eagerness to welcome regula- \\ntory measures however such eagerness was accompanied by \\na clear urge of moderation regarding these measures in order \\nto avoid the imposition of overly stringent requirements to the \\nmarket.”.115 \\n\\nAny regulatory initiatives should therefore aim at address- \\ning the unclarity that characterises the cyber insurance mar- \\nket, mainly in terms of the types of cyber coverage offered by \\ndifferent insurers. This could be achieved through the sugges- \\ntion of harmonisation and standardisation of coverage terms \\nand conditions, through the provision of clarifications on out- \\nstanding issues (e.g. the insurability of fines and ransomware) \\nas well as through the development of standards and good \\npractices and the introduction of conducts of business, as \\nmoderate regulatory interventions. However, both the Finan- \\ncial Stability Board (FSB) and the International Association of \\nInsurance Supervisors (IAIS) have so far refrained from de- \\nveloping concrete standards. The FSB has published a stock- \\ntake on cybersecurity regulatory and supervisory practices,116 \\nwhereas IAIS 117 \\nhas introduced its Insurance Core Principles \\nand Common Framework for the Supervision of Internation- \\nally Active Insurance Groups. Similarly, the Geneva Associ- \\nation  has  indicated  that  it  might  be  \"important  to  estab- \\n\\nIAIS is a voluntary membership organization of insurance su- \\npervisors and regulators from more than 200 jurisdictions, con- \\nstituting 97% of the world’s insurance premiums. It is the inter- \\nnational standard-setting body responsible for developing and as- \\nsisting in the implementation of principles, standards and other \\nsupporting material for the supervision of the insurance sector. \\n\\n\\x0ccomputer law & security review 43 (2021) 105627 \\n\\n15 \\n\\nlish standards with regard to definitions, coverages and pre- \\ncoverage risk assessment\" as a means to address challenges to \\nthe development of the cyber insurance market-particularly \\nas new companies enter the market.118 \\n\\nIn terms of EU legislative initiatives, the importance of cy- \\nber insurance has already been officially recognised.119 \\nHow- \\never, a more concrete EU strategy that would indicate the ben- \\nefits of cyber insurance in the achievement of a strong Eu- \\nropean security ecosystem and which would suggest specific \\nmeasures that could contribute to the market’s consistency, \\nis still missing. In this context, Governments could, for in- \\nstance, recognise the potential contribution of insurance to \\nrisk management in national cyber security strategies. In ad- \\ndition, insurance organisations like EIOPA could contribute to \\nthe harmonisation efforts by providing guidance on issues of \\nterminology, coverages and exclusions and by introducing or- \\nganised practices to achieve standardisation. In the same con- \\ntext, a harmonised, EU-level supervisory framework for all in- \\nsurance companies across countries could contribute to the \\nmarket harmonisation. The existing Solvency II framework, \\nthe first harmonised, sound and robust prudential framework \\nfor insurance firms in the EU,120 \\ncould be more efficient if a \\nnew line of business codes covering cyber risks was intro- \\nduced in its text. This need was highlighted by several insur- \\nance companies that participated in the survey conducted by \\nEIOPA where it was suggested that the introduction of a new \\nline of business code(s) in Solvency II, could help provide more \\ninsights into the quantitative dimension of cyber insurance. \\nFinally, the review of the NIS Directive, which is currently un- \\nder discussion, could be a solid ground for the introduction of \\nan explicit reference to cyber insurance, perhaps as a manda- \\ntory part of any national cybersecurity policy.121 \\nEven though \\nthis may sound premature and challenging, it would officially \\nput in the map the role of insurance against cyber threats as \\nan important element of any cyber resilience policy. \\n\\nHow can the industry contribute to the market’s \\n\\n6.3. \\nstability and growth: is stand-alone cyber insurance policies \\na possible way forward? \\n\\nAs described in the beginning of this analysis, cyber insurance \\nmay be provided either as an add-on to traditional policies or \\nas a stand-alone policy. Despite the apparent merits of buy- \\ning stand-alone cyber coverage, that will be detailed below, its \\nmarket penetration remains relatively low. In fact, net writ- \\nten premiums in the United States totalled only US$1.94 bil- \\nlion in 2018—of which 58 percent (US$1.12 billion) generated \\nby stand-alone policies and the remaining 42 percent by cyber \\ncoverage included in standard commercial policies. In view of \\nthe market’s shortcomings with regard to its response to the \\n\\n\\nneed for specific insurance products to address cyber risks \\ncoverage, the Deloitte center for Financial Services surveyed \\nexecutives responsible for buying cyber insurance at middle- \\nmarket companies in an effort to understand what has dis- \\ncouraged them from purchasing standalone policies.122 \\nRe- \\nsponses included the high cost of the insurance product, the \\nlow coverage limits, and the restrictive or unclear coverage \\nterms and exclusions, the brokers’ unwillingness to promote \\nthis type of insurance to their customers as well as the latters’ \\nunawareness of the fact that cyber coverage is even available \\nas a standalone policy. \\n\\nOther than providing greater clarity on coverage for cyber \\nrisks than the general language included in traditional poli- \\ncies, there are several advantages to covering cyber risks un- \\nder a stand-alone policy. Companies are becoming more so- \\nphisticated and so are their needs when they address the con- \\nsequences of a cyber incident. Given the constantly growing \\nfrequency and severity of these incidents, companies need a \\nmore concrete insurance framework that could operate as a \\nsafety net and which would help them feel more secure and \\nmore confident when they design their security and cyber re- \\nsilience plan. Cyber focused insurance packages are already \\navailable in the market and they cover a broad range of cy- \\nber losses, including bodily injury, intellectual property theft, \\nfinancial theft and fraud, reputational damage, cyber ransom \\nand extortion, business interruption, data and software loss, \\nbreach of privacy compensation, and fines and penalties.123 \\nFurthermore, businesses could also benefit from other ser- \\nvices offered by several insurance companies, in addition to \\ncoverage for the expenses incurred as a result of a cyber inci- \\ndent. These may include the provision of fraud specialists who \\ncan assist through the recovery process, active cyber moni- \\ntoring to help prevent or minimise a cyber loss, forensic in- \\nvestigative services necessary to identify the source of any \\nbreach, legal assistance to help manage legal and regulatory \\nrequirements and potential liability public relations compa- \\nnies to minimise the reputational impact of cyber incidents \\nand others. \\n\\nOffering stand-alone policies could prove beneficial for the \\ninsurers as well. Through the process of designing specific \\nproducts many insurance companies have developed signifi- \\ncant internal expertise and knowledge on this highly demand- \\ning type of risks. They can therefore offer a better service, \\nstarting by directing their customers to the right cyber cov- \\nerage package. Creating policies specifically designed for such \\nrisks could also help insurers avoid potential claim disputes \\nover “silent” coverage in a standard package policy, whereby \\ncyber is neither specifically named nor specifically excluded. \\nIn addition, the exclusive focus on cyber oriented insurance \\nproducts could accelerate the implementation of a common \\npolicy language, which is a basic barrier to the market’s devel- \\nopment and a main reason for the insurers’ lack of trust when \\nthey  design  and  sell  cyber  insurance. Insurers  face  there- \\nfore a major challenge to convince policyholders they need \\n\\ncomputer law & security review 43 (2021) 105627 \\n\\nstand-alone coverage, at least to supplement, if not substitute, \\nany cyber coverage they may already have in standard policies. \\nTo achieve this, they should address the issues of affordability \\nand coverage limitations that seem to be an obstacle to pro- \\ncurement. The cost of cyber insurance coverage is high rela- \\ntive to other types of insurance coverage - it has been reported \\nthat cyber insurance coverage for the same amount is three \\ntimes more expensive than general liability coverage and six \\ntimes more expensive than property coverage.124 \\nThe level of \\nfuture demand on stand-alone cyber insurance will depend \\non the frequency of high-profile cyber incidents as well as on \\nthe evolving legislative and regulatory environment for pri- \\nvacy protections in many countries. The implementation of \\nthe GDPR and the NIS Directive in the EU could lead to sig- \\nnificant growth of an independent cyber insurance market. In \\npractice, the new security and notification requirements im- \\nposed to organisations by both legal instruments have high- \\nlighted the need for a higher level of data and cyber security \\nrisk management within the organisations’ structures. At the \\nsame time though these requirements are accompanied by \\nsignificant fines and sanctions when not observed. On this \\nbasis, companies of all sizes need to realise that insurance \\ncan play a vital role to mitigate cyber risk. Stand-alone cy- \\nber policies in particular are expected to contribute to this \\neffect by offering specialised insurance products to address, \\namong others, the costs arising from security and notifica- \\ntions breaches.125 \\n\\n7. \\n\\nConclusion \\n\\nOver the last years the increasing frequency and severity of \\ncyber-attacks has highlighted the need for a sustainable so- \\nlution in terms of insurance coverage for cyber losses. Even \\nthough insurance should not be perceived as a substitute for \\ninvesting in cybersecurity, it may help companies build their \\ncyber resilience and, most importantly, it provides them with \\na safety net against the consequences of risks that are unpre- \\ndictable and in many cases non-affordable. Taking into con- \\nsideration these parameters the insurance industry has made \\nhuge efforts over the last few years towards the direction of \\nidentifying the best vehicle to provide its customers with cov- \\nerage for cyber losses. Either as an endorsement in traditional \\ninsurance policies or as a standalone contract, cyber insur- \\nance has evolved into a separate segment of the insurance \\nmarket that is constantly growing. \\n\\nDespite the progress made so far though, the cyber insur- \\nance market has not yet reached satisfactory levels of matu- \\n\\nrity whereas the penetration percentage is still relatively low \\ncompared to other insurance policies. The insurance industry \\nis confronted with many challenges that are mainly due to the \\nspecial nature of cyber risks and the unclarity that surrounds \\nall cyber related terms regardless of the sector and context \\nthey are being used in. Lack of commonality in the insurance \\npolicy language worldwide, lack of historic data on past inci- \\ndents, and variations in coverage are some of the obstacles \\nthe market needs to overcome. In this effort, the US insurance \\nmarket, that has been dealing with these issues for over two \\ndecades already, could be used as an example on how case law \\ntogether with the contribution of the industry have shed some \\nlight to disputed terms and have accordingly succeeded into \\nbetter level of commonality in the language used by different \\ninsurers. \\n\\nAt EU level, the need for cyber insurance has been recog- \\nnised in official EU documents whereas several EU organisa- \\ntions, from the European Commission to ENISA and EIOPA, \\nhave undertaken several initiatives to address the challenges \\nthe  industry  is  currently  faced  with. Data-sharing  mecha- \\nnisms and the introduction of common language and stan- \\ndard terms are some of the solutions that have been exam- \\nined in this context. Regulatory intervention is also on the ta- \\nble, even though it has received mixed reactions from market \\nstakeholders. All the initiatives undertaken so far have been \\nin the right direction, however, given the market’s particular- \\nities, the industry itself should stand up to the challenge and \\nlead the way to a standalone cyber insurance template. As cy- \\nber incidents increase and become more complicated and se- \\nvere and as demand for coverage for fines and penalties that \\nare imposed to organisations in the context of the GDPR or the \\nNIS Directive grows, standalone cyber insurance policies seem \\nthe best way forward for a sustainable and effective cyber in- \\nsurance market. \\n\\nDeclaration of Competing Interest \\n\\nThe authors declare that they have no known competing fi- \\nnancial interests or personal relationships that could have ap- \\npeared to influence the work reported in this paper. \\n\\nThe  authors  declare  the  following  financial  inter- \\nests/personal  relationships  which  may  be  considered  as \\npotential competing interests: \\n\\nData for reference \\n\\nNo data was used for the research described in the article. \\n', 'Ahmet Naci Ünal\\n5. Cyberspace and Chaos: A Conceptual \\nApproach to Cyber Terrorism\\nAbstract: Internet technology, which entered our lives in the 1990s, was called \\ncyber environment or cyber world. Nowadays, the sensors used in various fields \\nwith embedded systems can communicate with other sensors besides Internet con\\x02nection. This expanding network structure is defined as cyberspace. This process \\nhas led to the introduction of cyber prefix in front of many concepts such as cyber \\nresilience, cyber bullying, cyber security and cybercrime. One of these areas is cyber \\nterrorism. In this study, the concepts of terrorism and terrorism are explained first. \\nThen, the concept of cyber terrorism, measures to be taken against cyber terrorism, \\ncyber terrorism threat analysis, cyber threat classification, evaluation of cyber threat \\neffects, cyber deterrence, determination of cyber attacker profile and current cyber \\nthreats are examined. Following the general evaluation, chapter ends.\\nKeywords: Decision Support Systems, Information Systems, Information \\nManagement, Cyber Terrorism, Cyber Security\\n5.1 Introduction\\nHuman beings have felt the necessity to store their crops, starting from the \\nperiod that we call the Agricultural Society, wanting to reach these crops \\nintact after a certain period of time, and started marketing activities by \\nproducing various products from these crops. After this process, which \\nlasted for thousands of years, the product was replaced by data, which was \\ndefined as the “structural code of a phenomenon” by Vercellis (2009: 6). \\nEspecially in the 2000s, as Sanders (2016: 224) showed in Fig. 5.1, data \\nentered into a transformation process.\\nIn this process, data have been processed for a defined purpose or \\npurposes and transformed into information, information has been devel\\x02oped and transformed into knowledge, and using this knowledge, wisdom \\nhas been achieved. Within the scope of this transformation, accessing, pro\\x02cessing and storing information come to the fore, and the present informa\\x02tion is used personally or stored for future use.\\nIn today’s world, the rapid increase of the amount of data and the direct \\neffect of this increase on the life of the community leads to increases in \\nCopyright 2020. Peter Lang GmbH, Internationaler Verlag der Wissenschaften.\\nAll rights reserved. May not be reproduced in any form without permission from the publisher, except fair uses permitted under U.S. or applicable copyright law.\\nEBSCO Publishing : eBook Collection (EBSCOhost) - printed on 5/30/2022 11:21 PM via RYERSON UNIVERSITY\\nAN: 2404904 ; Necla Keles, Ahu Ergen.; Whats Happening in Cyber Space? : An Interdisciplinary Approach\\nAccount: ryerson.main.ehost\\n104 Ahmet Naci Ünal\\nissues or problems faced by individuals. This acceleration requires that \\nthe process of solving the problem areas should also be fast. This inten\\x02sity and the desire to produce quick solutions directly affect the daily lives \\nof societies, particularly those with high and rapid data flow. The more \\nstructured this process, the more regular the daily lives of these societies. \\nThe changes that will disrupt this order increase the level of anxiety at \\nvarious degrees based on social strata. This increase in the level of anx\\x02iety increases the level of risk, which is a probability-based word used \\nto describe the dangerous situations and concerns that people may face, \\nalong with an uncertain impact on individuals. It is almost impossible to \\nliken the risks encountered in the past with the risks emerging today. In the \\nmost general sense, the concept of risk is the multiplication of the proba\\x02bility of occurrence of any event with the effect it will generate if realized. \\nTherefore, since all activities are structured in the cyberspace dimension \\nin today’s IT world, the impact value can be high even if there is a low \\nprobability of occurrence. Therefore, this risk expectation brings along \\nuncertainty. Uncertainty, on the other hand, represents an environment \\nthat cannot be fully perceived due to the lack of sufficient data in the hands \\nof the individual and society at large. This new environment inevitably \\nreveals the concept of chaos that can be expressed as irregular and unpre\\x02dictable behavior of complex, nonlinear dynamic systems. This process \\nleads to the deterioration of the structured lives of societies and increases \\ntheir anxiety levels.\\nWisdom\\nKnowledge\\nInformation\\nData\\nFig. 5.1: The Journey of Data (Sanders, 2016: 224)\\n EBSCOhost - printed on 5/30/2022 11:21 PM via RYERSON UNIVERSITY. All use subject to https://www.ebsco.com/terms-of-use\\nCyberspace and Chaos: A Conceptual Approach to Cyber Terrorism 105\\nOne of the factors that will increase the level of social anxiety by \\nincreasing the level of risk in our daily lives in today’s world is the concept \\nof terrorism. Terror is defined in the Cambridge Dictionary as “extreme \\nfear, or violent action that causes fear” while it is defined as “the use of \\nextreme fear to intimidate people” in the Oxford Dictionary.\\nAlthough the definition of terror is generalized enough to enter into \\ndictionaries, the same is not valid for the concept of terrorism (Tab. 5.1).\\nTab. 5.1: Definition of Terrorism by Some Countries (OECD)\\nIntention of Terrorist Act Means Used Targets/Effects\\nAustralia Action done or threat \\nmade, with the intention \\nof advancing a political, \\nreligious or ideological \\ncause, with the intention \\nof coercing or influencing \\nby intimidation of the \\ngovernment of Australia \\nor the Australian States \\nor Territories, or a foreign \\ncountry, or intimidating \\nthe public.\\nAn act (or \\nthreat of an \\nact), that is \\nnot advocacy, \\nprotest, dissent \\nor industrial \\naction, that \\ncauses specified \\ndamage.\\nAn action that causes \\nserious harm to a person, \\nserious damage to \\nproperty, causes death \\nor endangers life or \\ncreates a serious health \\nor safety risk, or seriously \\ninterferes with, or disrupts \\nor destroys an electronic \\nsystem.\\nAustria To influence the government \\nor put the public or any \\nsection of the public in fear.\\nAct or threat of \\nviolence.\\nHuman life, tangible or \\nintangible property or \\ninfrastructure.\\nGermany Acts committed for \\npolitical, religious, ethnic \\nor ideological purposes \\nsuitable to create fear in the \\npopulation or any section of \\nthe population and thus to \\ninfluence a government or \\npublic body.\\nThe insurer shall indemnify, \\nif this has been specially \\nagreed, in respect of insured \\nproperty which is destroyed, \\ndamaged or lost due to:\\na) fire, explosion,\\nb) impact or crash of \\naircraft or aerial bodies \\nand vehicles, also craft, \\nof all kinds, their parts or \\ntheir cargo,\\nc) Other malicious damage, \\ninsofar as the mentioned \\nperils are caused by an act \\nof terrorism committed \\nin the Federal Republic of \\nGermany.\\nContinued on next page\\n EBSCOhost - printed on 5/30/2022 11:21 PM via RYERSON UNIVERSITY. All use subject to https://www.ebsco.com/terms-of-use\\n106 Ahmet Naci Ünal\\nTab. 5.1: continued\\nIntention of Terrorist Act Means Used Targets/Effects\\nUnited \\nKingdom\\nActs committed for \\npolitical, religious, ethnic \\nor ideological purposes \\nsuitable to create fear in the \\npopulation or any section of \\nthe population and thus to \\ninfluence a government or \\npublic body.\\nAct of violence Commercial property \\nand consequent business \\ninterruption costs arising \\nfrom an act of terrorism.\\nUnited \\nStates\\nPart of an effort to coerce \\nthe civilian population of \\nthe United States, or to \\ninfluence policy or affect \\nthe conduct of the US by \\ncoercion.\\nViolent act or \\ndangerous act\\nEndanger human life, \\nproperty or infrastructure \\nthat results in damages \\nwithin the United States, \\nor outside the US in the \\ncase of an attack of an \\nair carrier or vessel, or \\npremises of a US mission.\\nAlthough there are various approaches to the definition of terrorism, \\nit is an undisputed reality that the target of terrorism is human lifestyle \\nand human life. The problems experienced in the definition of terrorism \\ncan also be experienced in the classification of terrorism and therefore, \\nit is structured in different ways. In addition, some scientists working \\non terrorism limit the subject to only their own fields of science, and \\nare moving away from the fact that terrorism is an interdisciplinary \\nconcept.\\nWithin this context, the classification compiled from studies conducted \\nby Anatasescu and Voicu (2015: 12–15), Chalk (1996: 12–22), Jenkins \\n(2006: 117–130), Petrevska et al. (2016: 76–77), and Şimşek (2016: 323–\\n326) and cited in many studies is depicted in Fig. 5.2.\\n EBSCOhost - printed on 5/30/2022 11:21 PM via RYERSON UNIVERSITY. All use subject to https://www.ebsco.com/terms-of-use\\nCyberspace and Chaos: A Conceptual Approach to Cyber Terrorism 107\\nFurthermore, Chalk (1996: 12–22) states that the main characteristics \\nof terrorism include the fact that it is a political activity and a psycholog\\x02ical form of war, such activities affect the civilian population in general, it \\nis systematic in itself, and it aims awareness.\\nToday, cyber terrorism is almost as significant as terrorism. Although \\ncyber terrorism is shown as a branch of terrorism in Fig. 5.2, they are \\nconsidered equivalent threat elements in the context of the effect they can \\ncreate in society.\\nTerrorism\\nTypes\\nReasons\\nMethods\\nUsed\\nObjectives\\nNational (In-Country) Terrorism\\nInternational Terrorism\\nState Terrorism\\nState Supported Terrorism\\nCyber Terrorism\\n...\\nSocioeconomic Factors\\nAbduction/Hostage\\nRegime Change\\nTerritorial Change\\nPolicy Change\\nSocial Control\\nContinuation of Status Quo\\n...\\nAssassination\\nBombing\\nSuicide Bombing\\n...\\nIdeological Factors\\nPolitical Factors\\nEthnic Factors\\nReligious Factors\\n...\\nFig. 5.2: Stages of Terrorism\\n EBSCOhost - printed on 5/30/2022 11:21 PM via RYERSON UNIVERSITY. All use subject to https://www.ebsco.com/terms-of-use\\n108 Ahmet Naci Ünal\\n5.2 What Is Cyber Terrorism?\\nDenning (2000: 1) defines cyber terrorism as illegal threats and damaging \\nattacks on computers, network systems, information and databases of \\npolitical, social strata and individuals in order to intimidate and create \\npressure on such strata and persons. The National Infrastructure Protection \\nCenter (NIPC) defines cyber terrorism as “a criminal act conducted with \\ncomputers and resulting in violence, destruction, or death of targets in an \\neffort to produce terror with the objective of coercing a government to \\namend its policies.” And the FBI defines cyber terrorism as any “premedi\\x02tated, politically motivated attack against information, computer systems, \\ncomputer programs, and data which results in violence against non\\x02combatant targets by sub-national groups or clandestine agents” (Alford, \\n2017: 13). Based on these definitions, it can be said that malicious people \\naim to harm the masses with cyber terrorism, to weaken the economy, to \\ndeteriorate the morale-motivation of people, and to harm national security.\\nAccording to Jarvis, Nouri and Whiting (2014: 28), the main goal of \\ncyber terrorism, or in other words a cyber-attack is to differentiate cyber \\nterrorism from other types of attacks motivated for a political purpose. \\nEnney (2015: 1) points out that confusion about cyber terrorism is, in part, \\ncaused by attempts by hacktivism and terrorists to broaden the Internet to \\nfacilitate traditional terrorist acts.\\nThe sections that make up cyber terrorism and the sub-sections of these \\nsections can change over the years and are expressed in different ways. In this \\nregard, utilizing the studies conducted by Salleh et al. (2016: 1035), Mazari \\net al. (2016: 11–18), Yalman (2018: 259–279), Ahmad et al. (2012:232), \\nit is possible to reach the six main sections, namely, the objectives, moti\\x02vation, means, effect, intention and actual methods as shown in Fig. 5.3. \\nHowever, what should be considered in this segmentation is that cyber ter\\x02rorism is a dynamic process. Cyber terrorism is similar to a living organism \\nas in other technological systems. For this reason, it constantly renews \\nitself and transforms. Although there are various differences in the scope of \\nthe definitions, the tools of attack are the information and communication \\ntechnologies that have been increasing rapidly in people’s daily life (Saygili \\nand Unal, 2018: 247). Therefore, the adapted structure shown in Fig. 5.3\\nis not a final representation, but only a case finding.\\n EBSCOhost - printed on 5/30/2022 11:21 PM via RYERSON UNIVERSITY. All use subject to https://www.ebsco.com/terms-of-use\\nCyberspace and Chaos: A Conceptual Approach to Cyber Terrorism 109\\nCyber\\nTerrorism\\nObjectives\\nMotivation\\nMeans\\nEffect\\nIntention\\nActual\\nMethods\\nCritical Infrastructures\\nSocial and National Identity\\nPrivate Industry or Entities\\nPsycho-Social\\nAdvanced Persistant Threat (APT)\\nGain Political Advantages\\nGain Social Advantages\\nGain Militarily Advantages\\nGain Ideological Advantages\\nMalware Software\\nDistributed Denial of Service (DDoS)\\nRansomware\\nPhishing\\nSocial\\nCultural religion\\nPolitical\\nIdeological\\nViolence\\nDestruction and/or Disruption of Services\\nDamages\\nHarm Individuals and Groups\\nComputer\\nCommunication Technologies\\nNetworks\\nIoT Sensors\\nInformation Systems\\nFig. 5.3: Cyber Terrorism\\n EBSCOhost - printed on 5/30/2022 11:21 PM via RYERSON UNIVERSITY. All use subject to https://www.ebsco.com/terms-of-use\\n110 Ahmet Naci Ünal\\nHere, the areas targeted by cyber terrorism are shown under objectives. \\nThe resources used to implement cyber terrorism are in the motivation \\nsection. The tools used by cyber terrorism are classified under means. \\nThe effect section includes the targeted impacts on society or in the infor\\x02mation system through realization of cyber terrorism. The intention sec\\x02tion includes the intended objectives using cyber terrorism. The actual \\nmethods section includes cyber-attack methods, which are used with the \\nhelp of technological developments. Another point to be noted here is \\nthe ability of conventional terrorist groups to use cyberspace and cyber \\nterrorism itself are different phenomena. When the study of Evan, et al. \\n(2017: 13–17) is examined in this regard, the structuring shown in Fig. 5.4\\nis encountered.\\nAs depicted in Fig. 5.4, terrorist groups use cyberspace for enabling, \\ndisruptive, and destructive purposes. When these three main sections are \\nexamined:\\n• Within the scope of an enabling activity, they can communicate through \\nweb pages established by terrorist organizations or terrorist groups, and \\nCyber Capabilities of Terrorist Group\\nEnabling\\nDestructive\\nDisruptive\\nSensor Spoofing\\nControl Engineering Compromise\\nDamage or Disabling Infrastructure\\nScaled Destruction of Multiple Targets\\nTerror Group Website\\nVideo & Social Media\\nFunding Operations Manual\\nEncrypted Communications\\nDefacement of websites\\nDoS Website Take-down\\nData Exfiltration\\nCyber Heist\\nFig. 5.4: Cyber Capabilities of Terrorist Groups (Evant, 2017: 13–17)\\n EBSCOhost - printed on 5/30/2022 11:21 PM via RYERSON UNIVERSITY. All use subject to https://www.ebsco.com/terms-of-use\\nCyberspace and Chaos: A Conceptual Approach to Cyber Terrorism 111\\nthey can conduct illegal propaganda activities with videos and other \\nvisual documents. They can also use web-based systems as an encrypted \\ncommunication tool among themselves.\\n• Disruptive activity includes activities such as terrorist groups’ seizing the \\ntargeted web sites, leaving them completely dysfunctional, making them \\ninto zombie computers, making them part of DDoS attacks, performing \\nvarious infiltration activities and cyber theft. Destructive Activity is con\\x02sidered to be the highest level accessible by terrorist elements. The activ\\x02ities of terrorist groups reaching this level can be summarized as sending \\nfake data to secure systems using sensors that connect with cyberspace, \\ninfringing and attacking various software-controlled systems and orga\\x02nizing attacks on critical infrastructure facilities and simultaneously \\norganizing attacks on different targets.\\n5.3 A Conceptual Approach to Counter Cyber Terrorism\\nIt is not possible to talk about a 100 % safe environment in cyberspace \\nand furthermore, all systems are under the influence of the cyberspace. The \\nreason for this is that the threat elements constantly develop and increase \\nthe risk level. Cyber threats are the most significant factors that increase \\nthis risk level. A detailed risk analysis is needed to reduce the risk level. In \\norder to make this analysis healthy, it is first necessary to determine the \\nexistence of the threat. Therefore, it is necessary to recognize the threat, \\nto identify the threat by analyzing the recognized threat data and to deter\\x02mine the type of threat and the attack phase. In other words, the following \\nquestions about the threat should be answered:\\n– What is it?\\n– Where is it?\\n– What does it do?\\nWhen the threat comes from the cyberspace dimension, it becomes difficult \\nto find answers to the questions mentioned, and the time for the threat \\ndetermination is prolonged. The key concepts in recognizing cyber  threats \\ninclude cyber threat analysis, cyber-threat classification, cyber-threat \\nimpact assessment, cyber deterrence, and identification of cyber-aggressive \\nprofiles.\\n EBSCOhost - printed on 5/30/2022 11:21 PM via RYERSON UNIVERSITY. All use subject to https://www.ebsco.com/terms-of-use\\n112 Ahmet Naci Ünal\\n5.3.1 Threat Analysis in the Scope of Cyber Terrorism\\nWe have already mentioned that cyber threats are constantly developing and \\nevolving. Therefore, one of the most important impacts in identifying cyber \\nthreats is proportional to developing cyber-threat-based thinking. For this \\nreason, the “Cyber Attack Life Cycle” developed by cyber security researchers, \\nused effectively and shown in Fig. 5.5, is an important turning point.\\nThis figure illustrates the steps taken by attackers against entities. The \\nfirst step after the target of the cyber-attack is determined, or in the determi\\x02nation phase is to gather information about the target system. This process \\nis conducted by using methods such as port scanning, social engineering, \\ntraffic monitoring, and so on. In this way, the weakness areas of the system \\nto be attacked are determined. Once the weaknesses of the target system \\nhave been identified, the strategy determination for the acquisition of the \\ntarget system will begin. At this stage, which cyber-attack tools such as \\nviruses, Trojans, worms, zero day attacks, phishing attacks, ransomware to \\nbe used are decided upon. Upon this decision, the target system is attacked. \\nFollowing the cyber attack, it is necessary not to leave traces in the target \\nsystem, because leaving a trace means expediting identification of the \\nanomaly in the target system. For this reason, cyber tracks are attempted \\nto be destroyed as effectively as possible. In the final stage, whether the \\nbenefit obtained as a result of this attack is productive is investigated. Once \\nGoal Setting\\nBenefits/Gains\\nStrategy\\nDetermination Deletion of Traces\\nInformation Gathering\\nExploitation\\nFig. 5.5: Cyber Attack Life Cycle (Erol and Sagiroglu, 2018: 115)\\n EBSCOhost - printed on 5/30/2022 11:21 PM via RYERSON UNIVERSITY. All use subject to https://www.ebsco.com/terms-of-use\\nCyberspace and Chaos: A Conceptual Approach to Cyber Terrorism 113\\nthe cycle is completed as such, the search for a new target will begin. The \\nproper evaluation of this cycle will be useful in obtaining important clues \\nduring spotting, identifying, and tracing the cyber attacker.\\n5.3.2 Classification of Cyber Threats\\nIn order to identify any issue or problem, we need to go down to the \\nroot causes of that issue or problem and from that point on, we should \\nmove upwards with scientific analysis methods. In other words, we need \\nto properly model or classify the process between the root cause and \\nproblem. Thanks to this classification, we can concentrate our attention \\non the event, as we will narrow the area we will focus on, and we can \\nplan the energy we will use properly. The process that can be the basis for \\nthis planning was modeled by Bucci (2009: 2) and classified as shown in \\nFig. 5.6. This classification is called the Cyber Threat Spectrum.\\nWhile this spectrum is being created, scaling involves classifying the \\ndanger levels of cyber threats as low and high. In this context, individual \\nhackers are considered to be the lowest-level cyber threat in this seven\\x02stage cyber threat classification, while the nation-state cyber-enabled kinetic \\nLow\\nLevel of Danger\\nHigh\\nCyber Threats\\nSmall-time criminals\\nIndividual hackers\\nCyber espionage\\nTerrorist use of internet\\nOrganized crime\\nNation-state cyber\\x02enabled kinetick attack\\nNation-state cyber\\nattack\\nFig. 5.6: Cyber Threat Spectrum (Bucci, 2009: 2)\\n EBSCOhost - printed on 5/30/2022 11:21 PM via RYERSON UNIVERSITY. All use subject to https://www.ebsco.com/terms-of-use\\n114 Ahmet Naci Ünal\\nEvolution\\nOver \\nTime\\nDuration of Attacks\\nIntensity\\nof Attack\\nDo more intense \\nattacks mean\\nproportionately \\nmore damage or is\\nthere a level of\\ndamage that no\\namount of enemy \\neffort can achieve?\\nOver time, the number of\\nvulnerabilities, and hence \\nthe susceptibility of\\nsystems to attack, should\\ndecrease, but systems are \\ngetting more complex, are \\nbeing more intricately\\nlinked, and are relied on\\nfor more things. \\nThe longer attacks go on, the more\\ndifficult subsequent attacks are \\nlikely to be. \\nFig. 5.7: Three Dimensions of the Efficacy of Cyberattacks (Libicki, 2009: 60)\\nattack classification is considered to be of the highest level. The most impor\\x02tant factor that should not be ignored in this consideration is that each of \\nthese classified threats can select individuals, institutions or states as targets. \\nOf course, the ability to measure cyber-attack effects or cyber-attack activity \\nis as important as the classification or scaling of cyber threats.\\n5.3.3 Evaluation of Cyber Threat Effects\\nThe human brain evaluates the phenomena around it in three dimensions \\nand when analyzing any problem, it also shapes the solution set in a \\nthree-dimensional environment. For this reason, in the definition of cyber\\x02attack activity made by Libicki (2009:  60), a three-dimensional cyber\\x02attack space was used as shown in Fig. 5.7.\\nThe three-dimensional cyber-attack space is seen to consist of the axes \\nof “intensity of attack”, “evolution of time”, and “duration of attacks”. \\nTherefore, the effectiveness of the attacks in this space can be evaluated \\ndifferently in three dimensions as shown in Fig. 5.7.\\n EBSCOhost - printed on 5/30/2022 11:21 PM via RYERSON UNIVERSITY. All use subject to https://www.ebsco.com/terms-of-use\\nCyberspace and Chaos: A Conceptual Approach to Cyber Terrorism 115\\nFor example, let us assume that the letters A, B, and C shown in Fig. 5.8\\nrepresent three different cyber attacks. Here, when we look at the traces \\nof the cyber threats A, B and C in all three dimensions, we see that the \\neffect values are different. For example, it is seen that in the Intensity of \\nAttack dimension B1 > A1 > C1, in the Evolution Over Time dimension \\nC2 > B2 > A2, and in the Duration of Attacks dimension C3 > B3 > A3. \\nIn other words, the cyber-attack source B has the most significant effect \\non the intensity of attack dimension, while the cyber-attack source C has \\nthe greatest impact on Evolution Over Time and Duration of Attacks \\ndimensions. Therefore, it is of great importance to classify the differences \\nin the threat assessment phase. The speed of our assessment of this threat \\nand the speed of our response time will be directly proportional to the level \\nof deterrence we have.\\nEvolution\\nOver \\nTime\\nDuration of Attacks\\nIntensity\\nof Attack\\nA\\nB\\nC\\nB1\\nA1\\nC1 A2 B2 C2\\nA3\\nB3\\nC3\\nFig. 5.8: Sample Impact Assessment\\n EBSCOhost - printed on 5/30/2022 11:21 PM via RYERSON UNIVERSITY. All use subject to https://www.ebsco.com/terms-of-use\\n116 Ahmet Naci Ünal\\nDiplomatic and economic\\nCyber\\nPhysical force\\nLess belligerent\\nMore belligerent\\nNuclear force\\nFig. 5.9: Responses by Rough Order of the Level of Belligerence (Libicki, \\n2009: 29)\\n5.3.4 Evaluation of the Level of Cyber Deterrence\\nThe concept of deterrence is the ability to neutralize the opposing side \\nwithout making any attacks with the means we have. Although this con\\x02cept was mostly used in the military literature until the 2000s, cyberspace’s \\ndomination of the physical environment, especially after the 2000s, re\\x02vealed the concept of cyber deterrence.\\nThe study conducted by Libicki (2009: 29) on deterrence, also including \\ncyber capabilities, is depicted in Fig. 5.9.\\nIn this classification, diplomatic and economic initiatives take place in \\nthe lowest level, while cyber skills exist on it. On this layer, it is seen that \\nthere is physical force, and at the top, there is nuclear power. Therefore, ac\\x02cording to this scale, the warrior capabilities of the countries with nuclear \\npower are at the highest level. Six years after this study that was conducted \\nin 2009, Bendiek and Metzger (2015: 11) conducted another study, which \\nis shown in Fig. 5.10.\\n EBSCOhost - printed on 5/30/2022 11:21 PM via RYERSON UNIVERSITY. All use subject to https://www.ebsco.com/terms-of-use\\nCyberspace and Chaos: A Conceptual Approach to Cyber Terrorism 117\\nWhen the graph shown in Fig. 5.10 is examined, it is seen that nuclear \\npower is still naturally located at the top, while cyber attacks are located \\nabove and below the kinetic pulse. This shows that a large-scale cyber \\nattack has become almost equivalent to nuclear power in today’s world. \\nIn fact, because of the long-term effect they will create if they are used, \\nnuclear weapons continue to act only as a deterrent while a large-scale \\ncyber attack can be effective in many areas. It is also easier to control \\nnuclear power since it is under the control of the states. However, cyber \\nattacks can be easily performed by cyber attackers at different levels as \\nshown in Fig. 5.6 (the cyber spectrum) as well. Therefore, the identifica\\x02tion of cyber-aggressive profiles in combating cyber terrorism is of great \\nimportance, too.\\n5.3.5 Evaluation of Profiles of Cyber Attackers\\nIdentifying the profiles of the attackers who plan and perform cyber \\nattacks is also an important aspect. One of the important studies on this \\nsubject is the study by Rogers (2006: 98) where he proposed nine different \\nprofiles based on four different types of attackers on a two-dimensional \\ncircumplex circle model. The types here are financial, notoriety, curiosity, \\nand revenge. These eight fields are determined as follows:\\n• Novice (NV),\\n• Cyber-punks (CP),\\n• Internals (IN),\\nPolitical and economic sanctions\\nLow scale cyberattacks\\nLarge cyberattacks\\nNuclear\\nEscalation Kinetic strikes\\nFig. 5.10: A Possible Model of Escalation (Bendiek and Metzger 2015: 11)\\n EBSCOhost - printed on 5/30/2022 11:21 PM via RYERSON UNIVERSITY. All use subject to https://www.ebsco.com/terms-of-use\\n118 Ahmet Naci Ünal\\n• Petty Thieves (PT),\\n• Virus Writers (VW),\\n• Old Guard hackers (OG),\\n• Professional Criminals (PC),\\n• Information Warriors (IW),\\n• Political Activist (PA).\\nFig. 5.11 shows the above-mentioned four types and eight profiles on the \\ncircle circumplex.\\nIn Fig. 5.11, the technical ability of the attacker increases as the distance \\naway from the center increases, and each circle of the circumplex shows a \\ncategory of motivation. The technical capability of the attacker increases \\nas s/he moves away from the center within the circle.\\n+ +\\n+\\n+\\nCP PA\\nPT\\nPC\\nIW\\nIN\\nVW\\nOG\\nNV\\nCuriosity Notoriety\\nRevenge Financial\\nSkill Level\\nFig. 5.11: The Two-Dimensional Circumflex Model (Rogers, 2006: 100)\\n EBSCOhost - printed on 5/30/2022 11:21 PM via RYERSON UNIVERSITY. All use subject to https://www.ebsco.com/terms-of-use\\nCyberspace and Chaos: A Conceptual Approach to Cyber Terrorism 119\\n5.3.6 Evaluation of Current Cyber Threat Techniques\\nThe most general classification of cyber threats can be made in the form \\nof viruses, worms and Trojans. As the years go by, the contents of these \\nbasic harmful objects, their ways of harm and degree of impact increased \\nand they are used with different techniques. These techniques have evolved \\nover the years, resulting in the transformation of cyber threats. The trans\\x02formation processes of these threats over the years are as shown in the \\ngraph in Fig. 5.12.\\nWhen this graph is examined, it is seen that attackers had a high \\nlevel of knowledge in the 1980s but attack sophistication values were \\nlow. However, as the years progressed, these evaluations changed in an \\ninversely proportional manner. In other words, hackers have become able \\nto perform highly effective cyber attacks with lower level of knowledge. \\nFor example, the data generated by ENISA (2019: 9) based on 2017 and \\n2018 malware rankings are shown in Tab. 5.2.\\nTab. 5.2 shows that even the rankings of the threats used each year \\nmay change among themselves. When the threats here are examined, we \\nsee that the first four types of attacks remain valid, threats number five \\n1980\\nLow\\nIntruder Knowledge\\nAttack Sophistication\\nHigh\\n1985\\nPassword Guessing\\nSelf-Replicating Code\\nPassword Cracking\\nExploiting Known Vulnerabilities\\nHijacking Sessions Attackers\\nSniffers\\nGUI\\nDistributed Attack Tools\\nZombies\\nBOTS\\nMalicious Code\\nMorphing\\n“Stealth”/Advanced\\nScanning Techniques\\nDenial of Service\\nNetwork Management Diagnostics\\nSweepers\\nBack Doors\\nDisabling Audits\\nWWW Attacks\\nAutomated Probes/Scans\\n1990 1995 2000 2005 2010\\nPacket Spoofing\\nFig. 5.12: The Increasing Complexity of Threats as Attackers Proliferate (IAEA, \\n2011: 38)\\n EBSCOhost - printed on 5/30/2022 11:21 PM via RYERSON UNIVERSITY. All use subject to https://www.ebsco.com/terms-of-use\\n120 Ahmet Naci Ünal\\nand six mutually changed places, the Ransomware threat fell to the fourth \\nrank and the cryptojacking technique entered in the list in 2018. The \\nCryptojacking concept listed here is just like botnet information systems, \\nwhich can be defined as the unauthorized use of someone else’s computer \\nto produce crypto money. Here, just like creating a botnet, malicious soft\\x02ware is sent to the information system to be attacked and unauthorized \\ndata mining is performed on that computer.\\n5.4 General Evaluation\\nThe question of how we will be safe in such an intense threat environment \\nis on the agenda. In this context, it is useful to re-examine Fig. 5.3, which \\nshows the lower sections of cyber terrorism. The target of cyber terrorism \\npeople and cyberspace based systems that make people’s lives easier.\\nIn today’s world, the age of reaching cyberspace covers a wide range, \\nstarting from the pre-school period and covering the time until people \\ndie. For this reason, individuals, societies, organizations, states, in short, \\nTab. 5.2: Top Cyber Threats (ENISA, 2019: 9)\\nTop Threats 2017 Top Threats 2018 Change in ranking\\n1. Malware 1. Malware Same\\n2. Web-Based Attacks 2. Web-Based Attacks Same\\n3. Web Application Attacks 3. Web Application Attacks Same\\n4. Phishing 4. Phishing Same\\n5. Spam 5. Denial of Service Going up\\n6. Denial of Service 6. Spam Going down\\n7. Ransomware 7. Botnets Going up\\n8. Botnets 8. Data Breaches Going up\\n9. Insider Threat 9. Insider Threat Same\\n10. Physical Manipulation/\\nDamage/Theft/Loss\\n10. Physical Manipulation/\\nDamage/Theft/Loss\\nSame\\n11. Data Breaches 11. Information Leakage Going up\\n12. Identity Theft 12. Identity Theft Same\\n13. Information Leakage 13. Cryptojacking NEW\\n14. Exploit Kits 14. Ransomware Going down\\n15. Cyber Espionage 15. Cyber Espionage Same\\n EBSCOhost - printed on 5/30/2022 11:21 PM via RYERSON UNIVERSITY. All use subject to https://www.ebsco.com/terms-of-use\\nCyberspace and Chaos: A Conceptual Approach to Cyber Terrorism 121\\nall kinds of actors need to determine their cyberspace utilization policies, \\nthreat assessments, and behavioral patterns.\\nIt should also be noted that the measures to be developed in cyberspace \\nrequire an interdisciplinary approach that includes almost all branches \\nof science. Although cyber techniques and technologies are developed \\nby engineers, it should be remembered that end users of these products \\nare people of all demographic groups. In addition, any type of activity in \\ncyberspace triggers a process and these processes are integrated into other \\nprocesses and continue on their own way.\\nTherefore, the Cyber Security Life Cycle Framework (NIST-1, \\n2018: 7–8) shown in Fig. 5.13 consists of five sections: identify, protect, \\ndetect, respond and recover.\\nThe contents of these sections are summarized below:\\n• Identify\\nIncludes development of people, systems, assets, data, and capabilities \\nwith an institutional understanding to manage cyber security risk.\\n• Protect\\nIncludes limiting the impact of a potential cyber security incidents to \\nensure the delivery of critical services or developing and implementing the \\nRECOVER\\nRESPOND\\nDETECT\\nPROJECT\\nIDENTIFY\\nCYBERSECURITY\\nFRAMEWORK\\nFig. 5.13: Cyber Security Life Cycle (NIST-2, 2018)\\n EBSCOhost - printed on 5/30/2022 11:21 PM via RYERSON UNIVERSITY. All use subject to https://www.ebsco.com/terms-of-use\\n122 Ahmet Naci Ünal\\nnecessary measures. In order to achieve this, access to digital and physical \\nassets should be controlled, processes should be established to secure the \\ndata and protective technologies should be used.\\n• Detect\\nThis dictates a rapid identification of cyber security violations. The detec\\x02tion process involves the timely recognition of anomalies that constitute \\ncyber security events.\\n• Respond\\nRefers to the development and implementation of appropriate meas\\x02ures to take action against a detected cyber security event. To this end, a \\nresponse plan should be prepared, friendly communication lines should be \\nidentified, information about the activities should be collected and ana\\x02lyzed, and all necessary activities should be carried out to eliminate the \\nmalicious event.\\n• Recover\\nIncludes developing and implementing appropriate activities to restore all \\ncapabilities or services that have been corrupted due to a cyber security \\nincident.\\nIt should be kept in mind that cyber terrorists realize their activities by \\nusing the opportunities of cyberspace. Therefore, the measures that should \\nbe taken in addition to the cyber security life cycle summarized below \\nare composed of individual and corporate cyber security practices. Within \\nthis framework, it is of great importance that institutions keep their cyber \\nsecurity strategies and cyber security implementation policies up-to-date, \\nand create short-, medium- and long-term cyber security plans within the \\nscope of these policies and strategies.\\nAt the very beginning of these plans, different levels of cyber security \\ntrainings should be designed and implemented in a practical way to ensure \\ncyber security consciousness and awareness in all layers of society, and \\nto provide interaction between those layers. It should be kept in mind \\nthat all software required for sensitive technology, including critical infra\\x02structure hardware and software, must contain national source codes and \\nthat it should be written in accordance with the current software-building \\nstandards.\\n EBSCOhost - printed on 5/30/2022 11:21 PM via RYERSON UNIVERSITY. All use subject to https://www.ebsco.com/terms-of-use\\nCyberspace and Chaos: A Conceptual Approach to Cyber Terrorism 123\\nThe fact that cyber-attacks today are mostly carried out with artifi\\x02cial intelligence software can cause these infiltration activities not to be \\ndetected in time by target information systems. In this context, it would be \\nappropriate to develop projects in order to increase the “speed of threat \\ndetection” by prioritizing the use of artificial intelligence methods in \\ntargeting information system protection as well. It should be noted that in \\nall activities in cyberspace, the weakest link is usually the human being and \\noriginal projects should be realized related to subjects such as cyber-threat \\nanalysis, cyber-threat classification, cyber-threat impact assessment, cyber \\ndeterrence, and identification of cyber-aggressive profiles. Please do not \\nforget that cyberspace is almost like a living system. It constantly updates \\nand transforms itself and its effects.', '2018 IEEE Secure Development Conference\\n\\nDesigning Secure and Resilient Embedded Avionics Systems  \\n\\nJason H. Li\\nIntelligent Automation Inc.\\nRockville, MD, USA\\nEmail: jli@i-a-i.com\\n\\nNicholas Evancich\\nIntelligent Automation Inc.\\nRockville, MD, USA\\nnevancich@i-a-i.com\\n\\nDouglas Schafer\\nAir Force Research Laboratories\\nRome, NY, USA\\ndouglas.schafer.6@us.af.mil\\n\\nKyung Joon Kwak\\nIntelligent Automation Inc.\\nRockville, MD, USA\\nkkwak@i-a-i.com\\n\\nDavid Whelihan\\nMIT Lincoln Laboratory\\nLexington, MA, USA\\ndavid.whelihan@ll.mit.edu\\n\\nMichael Vai\\nMIT Lincoln Laboratory\\nLexington, MA, USA\\nmvai@ll.mit.edu\\n\\nStefano Lassini\\nGE Aviation Systems\\nGrand Rapids, MI, USA\\nstefano.lassini@ge.com\\n\\nHaley Whitman\\nMIT Lincoln Laboratory\\nLexington, MA, USA\\nhaley.whitman@ll.mit.edu\\n\\nWith  an  increased  reliance  on  Unmanned  Aerial  Systems \\n(UAS) as mission assets and the dependency of UAS on cyber \\nresources,  cyber  security  of  UAS  must  be  improved  by \\nadopting  sound  security  principles  and relevant  technologies \\nfrom  the  computing community.  On  the  other  hand,  the \\ntraditional avionics community, being aware of the importance \\nof  cyber  security,  is  looking  at  new  architecture  and  designs \\nthat  can  accommodate  both  the  safety  oriented  principles as\\nwell as the cyber security principles and techniques. \\n\\nThe Air Force Research Laboratories (AFRL) Information \\nDirectorate has created the Agile Resilient Embedded System \\n(ARES) program to investigate mitigations that offer a method \\nto  “design-in”  cyber protections  while  maintaining  mission \\nassurance.  ARES  specifically  seeks  to  ‘build  security  in’  for \\nunmanned aerial vehicles incorporating security and hardening \\nbest practices, while inserting resilience as a  system attribute \\nto  maintain  a  level  of  system  operation  despite  successful \\nexploitation of residual vulnerabilities. \\n\\nthe  different \\n\\nFigure  1 shows  the  high-level  ARES  architecture,  which \\nembodies  core  security  precepts,  modularity,  and  decoupled \\ninterfaces.  The  component-based  architecture  allows  for \\nto  be  decoupled. \\nmodularity  and \\nComponentization  enables \\nfunction  and  data \\nisolation,  testability,  interface  control,  security,  and  damage \\nlimitation. The interfaces effectively communicate with diverse \\ncombinations of hardware components from different vendors, \\nand \\nwhich \\nlow-impact \\nexperimentation  of  new  hardware,  operating \\nsystems, \\nvirtualization, and applications.\\n\\nlayers \\nimproved \\n\\ndevelopment \\n\\nenables \\n\\nrapid \\n\\ncan be applied to the avionics challenge by creating layers of \\ncyber  protection  around  those  avionics  functions  that  require \\nhard  real-time  performance,  mediating  inputs  and  outputs  of \\ncritical real-time  functionality to ensure that cyber threats are \\nisolated before they reach critical real-time functions.\\n\\nWe  would  like  to  be  able  to  separate  survival-critical \\nfunctionality  from  mission-critical  functionality.  We  choose \\nwhich  functions  to  separate  based  on  their  criticality.  For \\ninstance,  since  the  Operational  Flight  Program  (OFP)  is \\nsurvival-critical, it must be either fully trusted (i.e., it has been \\nverified  to  have  no  vulnerabilities),  or  it  must  be  sequestered \\naway to limit interaction with other elements of the system.\\n\\nWithin  ARES,  we  employ  two  ways  to  separate  system \\nsoftware  components:  virtual  separation,  via  trusted  software \\nsuch as the seL4 separation kernel, and physical separation in \\nwhich  software  is  run  on  physically  different  processors  with \\nrigidly  controlled  interfaces.  Table  1 illustrates  the  result  of \\napplying  both  virtual  and  physical  separation  to  an  industry \\nbaseline  unmanned  system  (2nd column).  The  adoption  of \\nsoftware  separation  (3rd column),  was  able,  and  demonstrated \\nvia  DARPA  HACMS,  to  add  additional  security.  ARES  goes \\nbeyond  software  separation  by  utilizing  a  heterogeneous \\narchitecture  incorporating  a  high  performance  symmetric \\nmulti- processor (SMP) and a lower performance, but easier to \\nverify  real-time  processor.  Hardware  separation  (4th column) \\ndoes address meeting the real-time assurance requirements, yet \\nis  limited  in  its  positive  affect  on  security.  ARES  has \\ndeveloped  and  used  a  convergent approach to  determine  an \\n“optimal” set of cyber protections and mitigation techniques to \\nboth harden the system and create a level of resilience based on \\nassessed  parameters  and performance  constraints.  The \\nconvergence  of  these  factors  (last  column)  addressed  early  in \\nthe design phase can result in a system meeting the collective \\nrequirements for operational cyber assurance.\\n\\nFigure 1: ARES high level architecture.\\n\\nPlatform  avionics  represent  a  special  class  of  embedded \\nsystems that supports high availability, high integrity and real-\\ntime  operation \\nin  a  variety  of  challenging  physical \\nenvironments.  The  evolving  cyber  threat  to  avionics  systems \\nadds an additional layer of security considerations that need to \\nbe addressed without compromising real-time performance or \\navailability  of  the  avionics  system.  The  ARES  methodology \\n\\nSystem \\nSetup\\n\\nSecurity\\n\\nReal-time \\nAssurance\\n\\nExample \\n\\nCOTS \\nSMP\\n\\nLow\\n\\nNo\\n\\nCurrent \\nMission \\nComputers\\n\\nSMP + \\nseL4\\n\\nMedium\\n\\nNo\\n\\nHACMS\\nMission\\nComputer\\n\\n978-1-5386-7662-2/18/$31.00 ©2018 IEEE\\nDOI 10.1109/SecDev.2018.00035\\n\\n139\\n\\nTable 1: Summary of Design Choices\\nSoftware \\nSeparation\\n\\nHardware \\nSeparation\\n\\nIndustry \\nBaseline \\n\\nSecurity  & \\nResilience \\n\\nSMP +seL4+ \\nReal-time \\nprocessor\\n\\nHigh\\n\\nYes\\n\\nSMP + \\nReal-time \\nprocessor\\n\\nLow\\n\\nYes\\n\\nImproved\\nAvionics\\n\\nARES \\nSystem\\n\\nAuthorized licensed use limited to: Ryerson University Library. Downloaded on May 03,2022 at 01:31:38 UTC from IEEE Xplore.  Restrictions apply. \\n\\n\\x0c', 'Chapter 12\\nFuture Work in Security Design of CPSs\\n\\n12.1 Research Directions: Advanced Attack Models\\n\\nThis book has presented a cross-layer framework to design secure and resilient\\ncyber-physical control systems. As we have seen in the previous chapters, the\\nmodel that we choose for the cyber or the physical layer relies on the attack\\nmodel and the control objectives of the CPSs. In particular, we have discussed in\\nPart II cryptographic solutions to provide data conﬁdentiality and integrity, and in\\nPart III game-theoretic methods to enrich the attack models with the dimensions\\nof incentives, resources, and information structures. In Chap. 7, we have used\\nFlipIt game to capture the interactions between an attacker and a defender in\\nan APT attack. In Chap. 8, we have used a zero-sum stochastic game model for the\\njamming attacks on CBTC systems, and in Chap. 9, a signaling game model for data\\nintegrity attacks in CPSs. In this section, we discuss two attack models that can be\\nincorporated into the cross-layer framework as a future research direction.\\n\\n12.1.1 Man-in-the-Middle Attack\\n\\nIn a Man-in-the-Middle (MITM) attack [145], the attackers send fake or false\\nmessages to the operators or agents. Figure 12.1 illustrates an example of the Man-\\nin-the-Middle Attack in computer networks. The attacker ﬁrst cuts off the original\\nconnection between the user and the web applications; then, it creates two new links\\nto the user and the web application, respectively. During the attack, the attacker can\\nstay stealthy and send fake data to both the users and the web application, misleading\\nthem to choose the wrong actions, e.g., leaking sensitive information.\\n\\n© The Editor(s) (if applicable) and The Author(s), under exclusive license to\\nSpringer Nature Switzerland AG 2020\\nQ. Zhu, Z. Xu, Cross-Layer Design for Secure and Resilient Cyber-Physical Systems,\\nAdvances in Information Security 81, https://doi.org/10.1007/978-3-030-60251-2_12\\n\\n179\\n\\n\\x0c180\\n\\n12 Future Work in Security Design of CPSs\\n\\nFig. 12.1 An example of the Man-in-the-Middle Attack in computer applications: the attacker\\nﬁrst cuts off the original connection between the user and web applications; then, it creates two\\nnew links to the user and the web application, respectively\\n\\nThe MITM attacks can create fatal losses to CPSs. For example, we consider\\na multi-agent Unmanned Aerial Vehicle (UAV) system with a control center that\\nsends references to all the UAVs. If the attacker successfully launches a MITM\\nattack, creating links with a certain number of UAVs. Then, the attacker can deviate\\nthe UAVs from their original trajectories by sending fake references. Even worse,\\nthe attacker can mislead the compromised UAVs to collide with other normal UAVs.\\nBy compromising a partial number of UAVs in the system, the attacker can damage\\nthe entire system based on a successful MITM attack.\\n\\n12.1.2 Compromised-Key Attack\\n\\nA key is a secret code that is necessary to interpret the secure information. Once\\nan attacker obtains the secret key of the secure mechanism, we consider this attacks\\na Compromised-Key (C-Key) Attack [26]. Figure 12.2 illustrates the concept of\\nthe C-Key attack. If the attacker succeeds in a C-Key attack, then it can gain\\naccess to a secured communication without the perception of the sender or receiver\\nby using the compromised key. The attacker can decrypt, modify the transmitting\\ndata with the keys. Besides, the attacker might use the compromised key to ﬁgure\\nout the additional keys, allowing the attacker to access other communications\\nchannels. The C-Key attack can also have a signiﬁcant on CPSs. For example,\\ngiven the compromised key, the attacker can study the sensitive parameters of the\\nby decrypting the transmitting data. Besides privacy attacks, the attacker can also\\nlaunch a data-integrity attack by modifying the transmitting data. These two attacks\\nwill incur severe losses for CPSs.\\n\\n\\x0c12.2 Research Directions: Data-Availability Issues in CPSs\\n\\n181\\n\\nFig. 12.2 An Compromised-Key Attack: the attacker ﬁrst steal the secret key of the security\\nmechanism; then it can use the compromised key to decrypt or modify the transmitting data\\n\\n12.2 Research Directions: Data-Availability Issues in CPSs\\n\\nIn this book, we have focused on data conﬁdentiality and integrity. In Chaps. 4\\nand 5, we have used cryptographic solutions to provide conﬁdentiality and integrity\\nto sensor and actuator signals. In Chaps. 9 and 11, we have used game-theoretic\\nand POMDP approaches to address data integrity attacks on CPSs. Data availability\\nplays an equally signiﬁcant role in security issues of CPSs. A CPS has physical\\ncomponents and devices, which require real-time data coming from the cyber\\nworld. Attackers can disable material data by blocking cyber communications. If\\nthe physical system is a typical control system, then a data-availability attack can\\nincur instability of the physical system since it requires feedback control inputs to\\nguarantee stability at each sampling time.\\n\\nAvailability attacks are often easier to launch. For example, in a cloud-enabled\\nCPS, the attacker can impede the communications between the CPS and cloud\\nby sending false messages to the CPS [177]. Even though the CPS can verify\\nthe data, the massive false data will occupy all the buffer memory and make the\\ndata unavailable for the CPS. Hence one important research direction is to design\\nmechanisms that can guarantee resiliency at the physical layer while assuring data\\navailability at the cyber layer. In the following subsections, we discuss two potential\\nsolutions from both cyber and physical ends to mitigate the data-availability attack.\\n\\n12.2.1 Safe-Mode Mechanism\\n\\nOne potential solution against data-availability attacks is to develop a safe-mode\\nmechanism. Figure 12.3 illustrates the of the safe-mode tool based on an example\\nof an automatic assembling line. In the safe-mode design, we develop a safe-mode\\ncontroller that only require local data to realize essential functions and requirements\\n(e.g., guaranteeing the stability) for the physical system.\\n\\n\\x0c182\\n\\n12 Future Work in Security Design of CPSs\\n\\nFig. 12.3 The Safe-Mode Protection: We design a safe-mode controller for the physical system.\\nWhen the attacker disables the cyber-mode controller by blocking the cyber communications, the\\nphysical system will activate the safe-mode controller, which only requires local data, to meet the\\nrequirements, e.g., stabilizing the physical system\\n\\nBesides a safe-mode controller, the assembling line also has a cyber-mode\\ncontroller, which can receive cyber data from remote users. In the proposed\\nmechanism, if the attacker disables the cyber-mode controller by blocking the cyber\\ncommunications, then the physical system will activate its safe-mode controller to\\nguarantee the essential requirements, protecting the system.\\n\\n12.2.2 Availability of a Partially Compromised System\\n\\nAnother potential solution against the data-availability attack is to ensure availabil-\\nity when the attacker only compromises some non-critical parts of the CPSs. In such\\nsituations, malicious attacks may not gain direct access to the critical components\\nof CPSs. When the detector detects the compromised parts, the mechanism should\\nbe able to isolate the compromised parts while maintaining the availability of the\\nCPSs. After separating from the compromised elements, the core parts of the CPSs\\ncan still realize essential functions.\\n\\n\\x0c12.3 Conclusions\\n\\n12.3 Conclusions\\n\\n183\\n\\nIn this ﬁnal chapter, we have discussed several research directions that are motivated\\nby advanced attack models. We could use our cross-layer design framework to\\ncouple the cyber solutions that address these attacks with the physical layer\\ncontrol system design. The overarching goal of this book is to introduce cross-\\nlayer designs as a design methodology for secure and resilient CPSs. One key\\nchallenge to attaining this objective is the need to bridge the gap between multiple\\ndisciplines. In this book, we have connected cryptography with control theory\\nand bridged game theory with control theory to provide design methodologies for\\nsystems under different attack models. Another key challenge is the domain-speciﬁc\\nknowledge to guide the CPS designs. We have used multiple case studies from\\nUAVs, CBTC systems, cyber manufacturing, and robotic systems to illustrate the\\nproposed methodologies. It is clear that each system has its own distinct features in\\nterms of system constraints, speciﬁcations, and performance requirements. Hence\\ndomain knowledge plays an important role in selecting the right model for cyber\\ndefense and control design. Cross-layer design is not limited to the applications\\ndiscussed in this book. On the contrary, it has broad applications in emerging\\nareas such as autonomous driving systems, smart and connected health, sustainable\\nenergy and water systems. Security and resiliency will be a prominent concern in\\nthese systems. The cross-layer design paradigm would be a promising approach to\\naddress this concern.\\n\\n\\x0c', 'Copyright  2013  by  Northwestern  University  School  of  Law \\nNorthwestern  University  Law  Review \\n\\nPrinted  in  U.S.A. \\nVol.  107,  No.  4 \\n\\nArticles \\n\\n REGULATING CYBER-SECURITY \\n\\nNathan Alexander Sales \\n\\ntargets \\n\\nin  cyber-conflicts,  we  should \\n\\nABSTRACT—The  conventional  wisdom  is  that  this  country’s  privately \\nowned  critical  infrastructure—banks,  telecommunications  networks,  the \\npower  grid,  and  so  on—is  vulnerable  to  catastrophic  cyber-attacks.  The \\nexisting academic literature does not adequately grapple with this problem, \\nhowever,  because  it  conceives  of  cyber-security  in  unduly  narrow  terms: \\nmost scholars understand cyber-attacks as a problem of either the criminal \\nlaw or the law of armed conflict. Cyber-security scholarship need not run in \\nsuch established channels. This Article argues that, rather than thinking of \\nprivate  companies  merely  as  potential  victims  of  cyber-crimes  or  as \\npossible \\nin \\nadministrative  law  terms.  Many  firms  that  operate  critical  infrastructure \\ntend  to  underinvest  in  cyber-defense  because  of  problems  associated  with \\nnegative externalities, positive externalities, free riding, and public goods—\\nthe same sorts of challenges the modern administrative state faces in fields \\nlike  environmental  law,  antitrust  law,  products  liability  law,  and  public \\nhealth law. These disciplines do not just yield a richer analytical framework \\nfor  thinking  about  cyber-security;  they  also  expand  the  range  of  possible \\nresponses.  Understanding  the  problem  in  regulatory  terms  allows  us  to \\nadapt various regulatory solutions—such as monitoring and surveillance to \\ndetect  malicious  code,  hardening vulnerable  targets,  and  building  resilient \\nand  recoverable  systems—for  the  cyber-security  context.  In  short,  an \\nentirely new conceptual approach to cyber-security is needed. \\n\\nthink  of \\n\\nthem \\n\\nAUTHOR—Assistant  Professor  of  Law,  George  Mason  University  School \\nof Law. Thanks to Jonathan Adler, Stewart Baker, Derek Bambauer, Bobby \\nChesney,  Eric  Claeys,  Tim  Clancy,  Orin  Kerr,  Michael  Krauss,  Deirdre \\nMulligan, Steve Prior, Jeremy Rabkin, Paul Rosenzweig, J.W. Verret, Ben \\nWittes, and Todd Zywicki for their helpful comments. I’m also grateful to \\nparticipants  in  workshops  at  Syracuse  University  College  of  Law  and  the \\nRepublic of Georgia’s Ministry of Justice. Special thanks to the Center for \\nInfrastructure  Protection  and  Homeland  Security  for  generous  financial \\nsupport. \\n\\n1503\\n\\n \\n \\n\\x0cN O R T H W E S T E R N  U N I V E R S I T Y  L A W  R E V I E W \\n\\nINTRODUCTION ........................................................................................................... 1504 \\nI.  AN EFFICIENT LEVEL OF CYBER-SECURITY .......................................................... 1510 \\nII.  CYBER-SECURITY FRAMEWORKS, CONVENTIONAL AND UNCONVENTIONAL ......... 1519 \\nA.  The Conventional Approaches: Law Enforcement and Armed Conflict .... 1521 \\nB.  Cyber-security as an Environmental Law Problem .................................. 1525 \\n. . . as an Antitrust Problem ...................................................................... 1528 \\nC. \\n. . . as a Products Liability Problem ......................................................... 1533 \\nD. \\n. . . as a Public Health Problem ................................................................ 1539 \\nE. \\nIII.  REGULATORY PROBLEMS, REGULATORY SOLUTIONS .......................................... 1544 \\nA.  Monitoring and Surveillance .................................................................... 1546 \\nB.  Hardening Targets .................................................................................... 1552 \\nC.  Survivability and Recovery ....................................................................... 1561 \\nD.  Responding to Cyber-attacks .................................................................... 1564 \\nCONCLUSION .............................................................................................................. 1567 \\n\\nINTRODUCTION \\n\\nThe Red Army had been gone for years, but it still had the power to \\ninspire  controversy—and  destruction.1  In  April  2007,  the  government  of \\nEstonia  announced  plans  to  relocate  a  contentious  Soviet-era  memorial  in \\nits capital city of Tallinn. Known as the Bronze Soldier, the Soviets erected \\nthe  statue  in  1947  to  commemorate  their  sacrifices  in  the  Great  Patriotic \\nWar and their “liberation” of their Baltic neighbors. The local population, \\nwhich suffered under the Bolshevik boot for decades, understandably saw \\nthe monument in a rather different light. Not long after the announcement, \\nthe  tiny  nation  was  hit  with  a  massive  cyber-attack.  Estonia,  sometimes \\nnicknamed  “E-stonia,”  is  one  of  the  most  networked  countries  in  the \\nworld—its  citizens  bank,  vote,  and  pay  taxes  online2—and  it  ground  to  a \\nhalt  for  weeks.  The  country’s  largest  bank  was  paralyzed.  Credit  card \\ncompanies took their systems down to keep them from being attacked. The \\ntelephone  network  went  dark.  Newspapers  and  television  stations  were \\nknocked offline. Who was responsible for launching what has come to be \\n\\n\\n \\n \\n\\x0c107:1503 (2013) \\n\\nRegulating Cyber-security \\n\\nknown as Web War I?3 The smart money is on Russia, though no one can \\nsay for sure. \\n\\nthan \\n\\nlament \\n\\nfor  years.4  Others \\n\\nthe  September  11,  2001 \\n\\nIt  could  happen  here.  Government  officials  like  Richard  Clarke,  the \\nformer  White  House  cyber-security  czar,  have  been  warning  of  “an \\nelectronic  Pearl  Harbor” \\nthe  “gaping \\nvulnerabilit[ies]”5  in  America’s  cyber-defenses  and  speculate  that  the \\neconomic  effect  of  a  major  assault  could  be  “an  order  of  magnitude” \\nterrorist  attacks.6  Academic \\ngreater \\ncommentators generally agree. Some see the danger as “monumental”7 and \\nthe  country’s  “most  pervasive  and  pernicious  threat.”8  Others  predict  that \\nAmerica’s failure to secure its cyber-assets “could take down the nation’s \\nentire security and economic infrastructure”9 and “bring this country to its \\nknees.”10 It has even been suggested that “[t]he very future of the Republic” \\ndepends  on  “protect[ing]  ourselves  from  enemies  armed  with  cyber \\nweapons.”11 There are some naysayers,12 but the consensus that we stand on \\nthe brink of a cyber-calamity is both broad and deep. \\n\\n\\x0cN O R T H W E S T E R N  U N I V E R S I T Y  L A W  R E V I E W \\n\\nA large-scale cyber-attack on this country, as in Estonia, likely would \\ntarget  privately  held  critical  infrastructure—banks,  telecommunications \\ncarriers, power companies, and other firms whose compromise would cause \\nwidespread harm.13 Indeed, America’s critical infrastructure, approximately \\n85%  of  which  is  owned  by  private  firms,14  already  faces  constant \\nintrusions.15  Yet  the  private  sector’s  defenses  are  widely  regarded  as \\ninadequate.  Companies  are  essentially  on  their  own  when  it  comes  to \\nprotecting  their  computer  systems,  with  the  government  neither  imposing \\nsecurity requirements nor bearing a share of the resulting costs.16 According \\nto  Bruce  Smith,  the  United  States  follows  a  “bifurcated  approach  to \\nnetwork  security”  that  “relie[s]  predominantly  on  private  investment  in \\nprevention and public investment in prosecution.”17 Christopher Coyne and \\nPeter Leeson likewise stress that our defensive strategy “is simply the sum \\nof dispersed decisions of individual users and businesses.”18 Regular firms \\nthat  operate  in  competitive  markets  (such  as  online  retailers)  may  be \\n\\nInflation in Cybersecurity Policy 6–7 (Mercatus Ctr. at George Mason Univ., Working Paper No. 11-24, \\n2011), available at http://mercatus.org/sites/default/files/WP1124_Loving_cyber-_bomb.pdf. \\n\\n \\n\\x0c107:1503 (2013) \\n\\nRegulating Cyber-security \\n\\nadequately  protecting  their  systems  against  ordinary  intruders  (such  as \\nrecreational  hackers).  But  strategically  significant  firms  in  uncompetitive \\nmarkets  (such  as  power  companies  and  other  public  utilities)  seem  less \\nlikely  to  maintain  defenses  capable  of  protecting  their  systems  against \\nskilled and determined adversaries (such as foreign intelligence services). \\n\\nlegal  scholarship  approaches  cyber-security  from \\n\\nThe  poor  state  of  America’s  cyber-defenses  is  partly  due  to  the  fact \\nthat  the  analytical  framework  used  to  understand  the  problem  is \\nincomplete.  The  law  and  policy  of  cyber-security  are  undertheorized. \\nVirtually  all \\nthe \\nstandpoint of the criminal law or the law of armed  conflict.19 Given these \\nanalytical commitments, it is inevitable that academics and lawmakers will \\ntend  to  favor  law  enforcement  and  military  solutions  to  cyber-security \\nproblems. These are important perspectives, but cyber-security scholarship \\nneed not run in such narrow channels. An entirely new approach is needed. \\nRather  than  conceiving  of  private  firms  merely  as  possible  victims  of \\ncyber-crimes, or as potential targets in cyber-conflicts, we should think of \\nterms.20  Many  companies \\nthat  operate  critical \\nthem \\ninfrastructure  tend  to  underinvest  in  cyber-defense  because  of  negative \\nriding,  and  public  goods \\nexternalities,  positive  externalities, \\n\\nin  regulatory \\n\\nfree \\n\\n \\n\\x0cN O R T H W E S T E R N  U N I V E R S I T Y  L A W  R E V I E W \\n\\nproblems—the  same  sorts  of  challenges  the  modern  administrative  state \\nencounters in a variety of other contexts. \\n\\nFor instance, cyber-security resembles environmental law in that both \\nfields are primarily concerned with negative externalities. Just as firms tend \\nto underinvest in pollution controls because some costs of their emissions \\nare  borne  by  those  who  are  downwind,  they  also  tend  to  underinvest  in \\ncyber-defenses  because  some  costs  of  intrusions  are  externalized  onto \\nothers. An attack on a power plant will not harm just the intended target; it \\nwill also harm the company’s customers and those with whom the company \\nhas  no  relationship.  Because  firms  do  not  bear  the  full  costs  of  their \\nvulnerabilities, they have weaker incentives to secure their systems. Cyber-\\nsecurity also resembles an antitrust problem. Antitrust law seeks to prevent \\nanticompetitive  behavior,  and  it  traditionally  has  been  skeptical  of \\ninterfirm  cooperation  could \\ncoordination  among  competitors.  Some \\nimprove  cyber-security—sharing  information  about  vulnerabilities  and \\nthreats,  for  example,  or  developing  industry-wide  security  standards.  Yet \\nfirms  are  reluctant  to  do  so  because  they  fear  antitrust  liability.  Cyber-\\nsecurity raises tort problems as well. Products liability law uses the threat \\nof money damages to incentivize firms to take reasonable precautions when \\ndesigning  their  products,  but  this  threat  is  almost  entirely  absent  in  the \\ncyber-security context. Companies face little risk of liability to those who \\nare harmed by attacks on their systems or products, and they therefore have \\nweaker  incentives  to  identify  and  patch  vulnerabilities.  Finally,  cyber-\\nsecurity  resembles  public  health.  A  key  goal  of  public  health  law  is \\nprevention—keeping those who have contracted a disease from spreading it \\nto  the  healthy,  a  form  of  negative  externality.  Public  health  law  uses \\nvaccinations to promote immunity, biosurveillance to detect outbreaks, and \\nquarantines  to  contain  infectious  diseases.  Cyber-security  has  similar \\ngoals—ensuring  that  critical  systems  are  immune  to  malware,  quickly \\ndetecting  outbreaks  of  malicious  code,  and  preventing  contaminated \\ncomputers from infecting clean systems—and could use similar tools. \\n\\nApproaching cyber-security from a regulatory vantage point does not \\njust  yield  a  richer  analytical  framework.  It  also  expands  the  range  of \\npossible  responses.  If  cyber-insecurity  resembles  problems  that  arise  in \\nother  regulatory  contexts,  then  perhaps  some  of  their  solutions  can  be \\nadapted here; the more frameworks available, the longer the menu of policy \\nchoices. Taken together, these disciplines suggest four groups of responses: \\n(1) monitoring  and  surveillance  to  detect  malicious  code,  (2) hardening \\nvulnerable  targets  and  enabling  them  to  defeat  intrusions,  (3) building \\nresilient systems that can function during attacks and recover quickly, and \\n(4) responding in the aftermath of attacks. \\n\\nFirst, public health law’s distributed biosurveillance network might be \\nused as a model for detecting cyber-intrusions. Rather than empowering a \\nsingle regulator to monitor Internet traffic for outbreaks of malicious code, \\nprivate  firms  could  be  tasked  with  reporting  information  about  the \\n\\n1508 \\n\\n\\x0c107:1503 (2013) \\n\\nRegulating Cyber-security \\n\\nvulnerabilities and threats they experience in the same way hospitals report \\nto public health authorities. To incentivize participation in this distributed \\nsurveillance  network,  firms  might  be  offered  various  subsidies  (on  the \\ntheory that cyber-security data is a public good that the market will tend to \\nunderproduce)  and  liability  protections  (such  as  an  exemption  from  the \\nantitrust laws). Second, we might harden targets by adopting industry-wide \\nsecurity standards for companies that operate critical infrastructure. These \\nprotocols  should  not  be  issued  in  the  form  of  traditional  regulatory \\ncommands.  Instead,  as  is  sometimes  the  case  in  environmental  law  and \\nother fields, the private sector should actively participate in formulating the \\nstandards. Tort law has a role to play as well: threats of liability and offers \\nof immunity might be used to incentivize firms to implement the protocols. \\nThird,  because  it  is  inevitable  that  some  cyber-attacks  will  succeed,  it  is \\nimportant  that  critical  systems  are  able  to  survive  and  recover.  Public \\nhealth  law  offers  several  strategies  for  improving  resilience.  Systems  that \\nare  infected  with  malware  might  be  temporarily  isolated  to  prevent  them \\nfrom  spreading  the  contagion.  Or  firms  might  build  excess  capacity  into \\ntheir  systems  that  can  be  deployed  in  emergencies—the  equivalent  of \\nstockpiling  vaccines  and  medicines.  Finally,  although  retaliation  is \\nthoroughly  addressed  in  the  existing  criminal  law  and  armed  conflict \\nliteratures, there is one possible response that deserves brief mention here: \\n“hackbacks,”  in  which  a  victim  counterattacks  the  attacker.  Because  the \\ncounterattack might fall on a third party whose system has been conscripted \\nby  the  intruder,  hackbacks  can  incentivize  those  third  parties  to  prevent \\ntheir systems from being so commandeered. Hackbacks also might weaken \\nattackers’ incentives: if assailants know that counterattacks can render their \\nintrusions ineffective, they are less likely to commit them in the first place. \\nThis  Article  proceeds  in  three  parts.  Part  I  considers  whether  private \\ncompanies are investing socially optimal amounts in cyber-defenses. Part II \\ndescribes  four  regulatory  frameworks—environmental  law,  antitrust  law, \\nproducts liability law, and public health law—and explains their relevance \\nto  cyber-security.  Part  III  surveys  solutions  used  by  these  regulatory \\ndisciplines and considers how to adapt them for the cyber-security context. \\nSeveral  preliminary  observations  are  needed.  First,  I  use  the  terms \\n“cyber-attack”  and  “cyber-intrusion”  interchangeably  to  denote  any  effort \\nby  an  unauthorized  user  to  affect  the  data  on,  or  to  take  control  of,  a \\ncomputer  system.  As  used  here,  the  terms  include  all  of  the  following: \\n“viruses”  (a  piece  of  code  that  “infects  a  software  program  and  then \\nensures  that  the  infected  program  reproduces  the  virus”21);  “worms”  (“a \\nstand-alone program that replicates itself”22); “logic bombs” (malware that \\n\\n\\x0cN O R T H W E S T E R N  U N I V E R S I T Y  L A W  R E V I E W \\n\\n“tells a computer to execute a set of instructions at a certain time or under \\ncertain  specified  conditions”23);  and  distributed  denial-of-service  (DDOS) \\nattacks  (in  which  a  “master”  computer  conscripts  “zombies”  and  orders \\nthem to disable a victim by flooding it with traffic24). Second, this Article \\nemphatically is not a paean to traditional command-and-control regulation. \\nThe  conventional  wisdom  is  to  avoid  cyber-security  regulation,25  in  part \\nbecause  of  doubts  about  the  government’s  ability  to  manage  such  a \\ndynamic field. But, as I hope to show in the following pages, cyber-security \\nneed  not,  and  in  many  cases  should  not,  be  pursued  with  heavy-handed \\nregulatory tools. It is possible to promote better cyber-defenses with private \\nlaw, such as by modifying traditional tort law doctrines. As for public law, \\nregulation  need  not  take  the  form  of  rigid  legal  commands  backed  by  the \\nthreat of sanction; regulatory objectives often can be attained by appealing \\nto  private  firms’  self-interest—by  offering  positive  incentives  to  improve \\ntheir defenses, not just by punishing them when they fall short. The private \\nsector’s  poor  defenses  may  represent  a  market  failure,  as  some  have \\nargued,26  but  “[t]here’s  not  much  point  in  replacing  a  predictable  market \\nfailure with an equally predictable government failure.”27 \\n\\nI.  AN EFFICIENT LEVEL OF CYBER-SECURITY \\n\\nOur  national  security  depends  on  the  security  of  our  critical \\ninfrastructure.28 A cyber-attack on these assets, most of which are held by \\nprivate  firms,  could  be  devastating:  with  a  few  keystrokes,  adversaries \\ncould  hack  into  banks  and  corrupt  customer  data,  take  control  of  power \\nplants and bring down the electricity grid, open the floodgates of dams, and \\ntake  telecommunications  networks  offline.29  Or  worse.  Despite  the \\nmagnitude of the threat, the conventional wisdom is that the private sector \\nis  not  adequately  protecting  itself.30  This  section  surveys  the  available \\n\\n \\n\\x0c107:1503 (2013) \\n\\nRegulating Cyber-security \\n\\nevidence  on  the  extent  of  private  cyber-security  expenditures.  It  then \\npredicts  that  ordinary  firms  in  competitive  markets  (like  online  retailers) \\nare more likely to be investing socially optimal amounts in cyber-defense, \\nwhile  strategically  significant  firms  in  uncompetitive  markets  (like  public \\nutilities) are more likely to be underinvesting. \\n\\nThe optimal level of cyber-intrusions is not zero, and the optimal level \\nof  cyber-security  expenditures \\ninfinity.  From  an  economic \\nis  not \\nperspective,  the  goal  is  to  achieve  an  efficient  level  of  attacks,  not  to \\nprevent  all  attacks.31  Suppose  that  the  expected  cost  to  society  of  a  given \\ncyber-attack—its  cost  discounted  by  the  probability  that  it  will  occur—is \\n$5  billion.  It  would  be  efficient  for  society  to  invest  up  to  $5  billion  in \\ncountermeasures  to  prevent  the  attack.  If  the  necessary  countermeasures \\ncost  more  than  $5  billion,  the  cost  of  preventing  the  attack  would  exceed \\nthe  resulting  security  gains.32  Relatedly,  some  intrusions  are  more \\nproblematic  than  others.  Cyber-security  is  a  form  of  risk  management, \\nwhere  risk  is  a  function  of  three  variables:  vulnerabilities,  threats,  and \\nconsequences.33  A  company  with  easily  hacked  systems,  that  faces  a  high \\nprobability of attacks from sophisticated foreign intelligence services, and \\nwhose  compromise  would  cause  severe  social  harm  raises  very  different \\nproblems than a company with relatively robust defenses, that is unlikely to \\nface  skilled \\nfew \\nconsequences for society. \\n\\nintruders,  and  whose  compromise  would  have \\n\\nin  cyber-defense?  Most  observers  believe \\n\\nAre  individual  firms,  and  society  as  a  whole,  investing  the  right \\namount \\nthat  firms  are \\nunderinvesting—and  are  missing  the  mark  by  a  wide  margin.  Richard \\nClarke proclaims the private sector response an “unmitigated failure,”34 and \\nscholars  generally  agree.35  Very  little  empirical  data  is  available,  but  the \\nconsensus view has at least some  anecdotal support. Studies conducted in \\n\\n\\n \\n\\x0cN O R T H W E S T E R N  U N I V E R S I T Y  L A W  R E V I E W \\n\\n2009 and 2011 by McAfee, a computer security firm, revealed low levels \\nof investment in cyber-defense. The  studies found that many firms regard \\ncyber-security as little more than “a last box they have to check,”36 and that \\nthey  neglect  network  security  because  they  find  it  too  expensive.37  In \\nparticular,  McAfee  found  that  companies  often  have  weak  authentication \\nrequirements38—tools  that  can  verify  that  the  person  who  is  accessing  a \\nsystem is who he says he is, and is authorized to access the system. Even \\nfewer  have  systems  that  can  monitor  network  activity  and  identify \\nanomalies.39  Other  studies  reveal  that  some  companies’  defenses  are  so \\npoor  they  don’t  even  know  when  they’ve  suffered  an  attack.  Verizon \\nreported  that  “fully  75  percent  of  the  intrusions  they  investigated  were \\ndiscovered by people other than the victims and 66 percent of victims did \\nnot even know an intrusion occurred on the system.”40 Finally, a 2011 study \\nby  the  Ponemon  Institute  found  “that  73  percent  of  companies  surveyed \\nhad been hacked, but 88 percent of them spent more money on coffee than \\non securing their Web applications.”41 \\n\\nAre these levels of investment efficient? Whether a particular firm is \\nmaking  socially  optimal  investments  in  cyber-security—and  the  related \\nissue of who should pay for that company’s cyber-defenses—is a function \\nof  two  intersecting  questions.  First,  what  is  the  defending  firm?  Is  it  a \\nregular  company  in  a  competitive  market,  an  operator  of  critical \\ninfrastructure  in  an  uncompetitive  market,  or  something  in  between? \\nSecond,  who  is  the  anticipated  attacker?  Is  it  a  recreational  hacker,  a \\nforeign intelligence service, or someone in between? \\n\\n\\n \\n\\x0c107:1503 (2013) \\n\\nRegulating Cyber-security \\n\\nThe range of possibilities can be depicted in a simple graph: \\n\\nThe  x-axis  depicts  the  firms  that  might  be  subject  to  a  cyber-attack. \\nThey  are  arranged  from  left  to  right  in  order  of  increasing  strategic \\nsignificance. A strategically significant company is one whose compromise \\nwould  result  in  substantial  social  harms.  On  the  far  left  are  relatively \\ninsignificant  firms  in  competitive  markets—markets  in  which  many \\ncompanies  offer  the  same  good  or  service,  and  where  disappointed \\nconsumers therefore may defect from one to another. An example would be \\nonline  retailers,  such  as  Amazon.com.  To  the  right  are  financial \\ninstitutions,  which  rate  high  on  the  strategic  significance  scale.  Former \\nDirector of National Intelligence Mike McConnell predicted that an attack \\non a single bank “would have an order-of-magnitude greater impact on the \\nglobal economy” than 9/11.42 Banks operate in fairly competitive markets, \\nas consumers can easily move their accounts from one to another. Another \\nstep \\n(ISPs)  and \\ntelecommunications carriers. They, too, are strategically significant. When \\nRussia crippled Georgia’s communications systems during their 2008 war, \\ncitizens “could not connect to any outside news or information sources and \\n\\nInternet  Service  Providers \\n\\nright  are \\n\\nthe \\n\\nto \\n\\n\\x0cN O R T H W E S T E R N  U N I V E R S I T Y  L A W  R E V I E W \\n\\ncould  not  send  e-mail  out  of  the  country.”43  These  markets  are  less \\ncompetitive; consumers typically have only a handful of Internet providers \\nor  telephone  companies  to  choose  from.  At  the  far  right  are  power \\ncompanies and other public utilities. These firms rate high on the strategic \\nsignificance  scale.  A  cyber-attack  on  the  power  grid  would  be  truly \\ncatastrophic.  The  industrial  control,  or  SCADA,44  systems  used  by  power \\nplants  and  other  utilities  are  increasingly  connected  to  the  Internet.45 \\nHackers  could  exploit  this  connectivity  to  disrupt  power  generation  and \\nleave tens of millions of people in the dark for months.46 They could even \\ndestroy  key  system  components  like  turbines.47  In  2009,  the  Stuxnet \\nworm—“the  most  sophisticated  cyberweapon  ever  deployed”48—caused \\nsimilar  physical  damage  to  Iran’s  nuclear  program.49  Utility  markets  are \\nuncompetitive.  Municipalities  typically  have  only  one  power  company  or \\nnatural gas supplier, and there is no meaningful prospect that disappointed \\nconsumers will switch to a competitor. \\n\\nThe  y-axis  depicts  the  assailants  that  might  commit  a  cyber-attack. \\nThey are arranged from bottom to top in order of increasing sophistication. \\nA  sophisticated  attacker  is  capable  of  compromising  the  most  secure \\nsystems;  unsophisticated  attackers  are  only  able  to  compromise  relatively \\nunsecured  systems.  At  the  bottom  are  recreational  hackers—intruders  out \\nfor “a digital joy ride.”50 One step above are “hacktivists.” Hacktivists are \\nrelatively  skilled  hackers  who  use  cyber-intrusions  to  advance  a  political \\n\\n\\x0c107:1503 (2013) \\n\\nRegulating Cyber-security \\n\\nagenda; they typically do not group themselves into formal organizations.51 \\nAn  example  is  “Anonymous,”  a  loose  association  that  in  late  2010 \\nlaunched  DDOS  attacks  on  financial  institutions  that  refused  to  let \\ncustomers  send  money  to  WikiLeaks,  an  antisecrecy  group  that  had \\npublished  a  number  of  classified  documents.52  Next  are  organized  crime \\nsyndicates,  such  as  those  operating  out  of  Russia.53  They,  too,  are  fairly \\nsophisticated. They engage in cyber-intrusions primarily for financial gain \\nand by definition they are structured organizations.54 International terrorists \\nmight be placed here as well, though they have shown little enthusiasm or \\naptitude  for  cyber-attacks  thus  far.55  However,  al  Qaeda  reportedly \\nestablished  “an  academy  of  cyber-terrorism”  in  Afghanistan,56  and \\ncomputers  taken  from  members  contained  information  about  SCADA \\nsystems  in  the  United  States.57  At  the  top  are  foreign  governments’ \\nmilitaries  and  intelligence  services.  These  are  the  most  sophisticated \\nadversaries of all, and they are capable of breaking into even highly secure \\nsystems. Internet giant Google recently saw its Gmail service penetrated by \\nChinese  spies  who  wanted  to  eavesdrop  on  the  Dalai  Lama.58  Similarly, \\nRSA—a  software  firm  that  issues  online  security  credentials  for  the \\nPentagon,  defense  contractors,  and  other  sensitive  enterprises—was \\ncompromised  so  badly  (probably  by  China)  that  it  had  to  offer  new \\ncredentials to all its customers.59 \\n\\nThe curve roughly predicts the combinations of victims and attackers \\nthat are likely to occur. Quadrant (4) involves high-frequency, low-severity \\nattacks.  Retailers  and  other  relatively  insignificant  firms  will  be  targeted \\nfairly  often  by  comparatively  unsophisticated  recreational  hackers  and, \\nperhaps,  by  more  sophisticated  hacktivists  who  disapprove  of  their \\ncorporate policies. (The Anonymous attacks on banks are a good example.) \\nQuadrant  (2)  involves  attacks  that  are  low-frequency  and  high-severity. \\nMore strategically significant firms like ISPs and public utilities will face \\nattacks from sophisticated militaries and intelligence services, and perhaps \\n\\n\\x0cN O R T H W E S T E R N  U N I V E R S I T Y  L A W  R E V I E W \\n\\nfrom  organized  crime  syndicates  seeking  to  extract  blackmail  payments. \\nThese  attacks  will  occur  rarely,  but  they  are  likely  to  be  devastating.  In \\nquadrant  (3),  recreational  hackers  and  hacktivists  might  launch  attacks \\nagainst  utilities  and  similarly  significant  enterprises,  but  these  targets  are \\nprobably  less  attractive  to  them  than  they  are  to  foreign  militaries  or \\nintelligence services.60 In quadrant (1), foreign governments are unlikely to \\ntarget  insignificant  firms  like  retailers,  because  they  gain  little  by \\ncompromising  them,  though  organized  crime  may  do  so  (again,  for \\nblackmail purposes). \\n\\nWe  are  now  in  a  position  to  make  predictions  about  various \\ncompanies’ cyber-security expenditures. The closer we are on the curve to \\nthe lower left corner, the higher the probability that the firm is investing a \\nsocially  optimal  amount  in  cyber-defense.  This  is  so  in  part  because  the \\nexpected  social  cost  of  an  attack  on  an  ordinary  company  is  fairly  low. \\nSociety  will  not  grind  to  a  halt  if  Amazon.com  is  knocked  offline; \\nbookworms might experience minor annoyance but they will still be able to \\nbuy a copy of Gilead from Barnes & Noble. In addition, these companies \\nare unlikely to face attacks by skilled and determined foreign governments, \\nso it is not necessary for them to spend huge sums of  money on the very \\nbest  and  most  impregnable  defenses.  The  efficient  level  of  cyber-security \\ninvestment  for  them  thus  is  fairly  low.  Importantly,  market  forces  may \\nprovide  these  firms  with  meaningful  incentives  to  protect  their  systems \\nagainst  cyber-attacks.  Retailers,  banks,  and  similar  companies  operate  in \\ncompetitive markets. The risk of customer exit provides them with strong \\nincentives to cater to customer demand. If consumers want the companies \\nwith  which  they  do  business  to  provide  better  security  against  cyber-\\nattacks—the  jury  is  out  on  that  question,  incidentally61—they  will  have \\ngood reason do so.62 \\n\\nRegulating Cyber-security \\n\\nThe  closer  we  are  on  the  curve  to  the  upper  right  corner—low-\\nfrequency,  high-severity  cyber-attacks—the  lower  the  probability  that  the \\nfirm  is  adequately  investing  in  cyber-security.  First,  the  expected  social \\ncost of such an intrusion is monumental. The consequences of an attack on, \\nsay,  the  power  grid  would  reverberate  throughout  the  economy,  causing \\nharm  to  the  utility,  its  customers,  and  countless  third  parties.  Because  the \\nexpected cost of an attack on these firms is so high, it is efficient to invest \\ngreater  sums  in  securing  them  against  intruders.  In  addition,  the  modest, \\nlow-cost defenses that are usually capable of thwarting recreational hackers \\nwill  do  nothing  to  prevent  intrusions  by  foreign  governments;  more \\nexpensive  countermeasures  are  needed \\nthese \\nexceptionally  sophisticated  adversaries.  The  socially  optimal  level  of \\ncyber-security investment for these firms is thus fairly high. \\n\\nto  protect  against \\n\\nSecond, power companies and other utilities are not subject to market \\nforces that might incentivize them to improve their cyber-defenses. Utilities \\nface little if any competition; a given customer typically will be served by \\nonly one power company. Customer exit is essentially impossible, and the \\nutility  therefore  has  weaker  incentives  to  supply  what  its  customers \\ndemand.  This  absence  of  beneficial  market  forces  may  help  explain  why \\npublic  utilities  often  fail  to  implement  even  relatively  costless  security \\nmeasures.63  Many  electric  companies  use  vendor  default  passwords  to \\nprotect their SCADA systems,64 and a recent study found that they take an \\naverage  of  331  days  to  implement  security  patches  for  these  systems.65 \\nPerhaps  not  coincidentally,  hackers—most  likely  Chinese  and  Russian \\nspies—have been able to insert logic bombs into the power grid.66 \\n\\nIf  this  analysis  is  correct,  then  strategically  significant  firms  in \\nuncompetitive markets are less likely to adequately invest in cyber-security \\nthan  ordinary  firms  in  competitive  markets.  The  question  then  becomes \\nwho  should  be  responsible  for  securing  these  most  sensitive  companies \\nagainst  the  most  dangerous  adversaries.  Economists  often  argue  that  risk \\nshould be allocated to the low cost avoider.67 If the government can reduce \\na  vulnerability  more  efficiently  than  a  firm,  it  should  pay;  if  the  firm  can \\nreduce  the  vulnerability  more  efficiently,  it  should  pay.  But  there  is  no \\nsingle  low  cost  avoider  in  this  context.  Defending  critical  infrastructure \\n\\n \\n\\x0cN O R T H W E S T E R N  U N I V E R S I T Y  L A W  R E V I E W \\n\\nagainst  sophisticated  cyber-attackers  is  a  task  that  features  dueling \\ncomparative advantages. Private firms typically know more than outsiders, \\nincluding the government, about the architecture of their systems, so they \\noften are in a better position to know about weaknesses that intruders might \\nexploit.68 The private sector thus has a comparative advantage at identifying \\ncyber-vulnerabilities.  On  the  other  hand,  the  government’s  highly  skilled \\nintelligence  agencies  typically  know  more  than  the  private  sector  about \\nmalware  used  by  foreign  governments  and  how  to  defeat  it.69  The \\ngovernment  thus  has  a  comparative  advantage  at  detecting  sophisticated \\nattacks  and  developing  countermeasures.  This  suggests  that  responsibility \\nfor  defending  the  most  sensitive  systems  against  the  most  sophisticated \\nadversaries should be shared. \\n\\nWhat  might  such  a  partnership  look  like?  All  private  firms  might  be \\nasked  to  provide  a  baseline  level  of  cyber-security—modestly  effective \\n(and modestly expensive) defenses that are capable of thwarting intrusions \\nby  adversaries  of  low  to  medium  sophistication.  The  government  would \\nthen assume responsibility for defending public utilities and other sensitive \\nenterprises  against  catastrophic  attacks  by  foreign  militaries  and  other \\nhighly  sophisticated  adversaries.70  This  division  of  labor—basic  security \\nprovided by firms, supplemental security provided by the government—is \\nin  a  sense  the  opposite  of  what  we  see  in  realspace  criminal  law.  In \\nrealspace, the government offers all citizens a baseline level of protection \\nagainst  criminals  in  the  form  of  police  officers,  prosecutors,  and  courts. \\nIndividuals may supplement these protections at their own expense, such as \\nby  installing  alarm  systems  in  their  homes  or  hiring  private  security \\nguards.71  This arrangement  also  is  consistent  with  our  intuitions  about  the \\nrespective roles of government and the private sector in times of conflict.72 \\nConsider  another  realspace  analogy:  in  World  War  II,  factories  were  not \\nexpected  to  install  anti-aircraft  batteries  to  defend  themselves  against \\nLuftwaffe  bombers.73  Nor  should  we  expect  power  plants  to  defend \\nthemselves  against  foreign  governments’  cyber-attacks.  Protecting  vital \\nnational  assets  from  destruction  by  foreign  militaries  is  a  quintessential, \\nperhaps the quintessential, government function.74 \\n\\nThe  division  of  labor  I  suggest  also  seems  sound  from  an  economic \\nstandpoint.  If  a  firm  invested  in  extraordinarily  expensive  cyber-defenses \\n\\n\\n \\n\\x0c107:1503 (2013) \\n\\nRegulating Cyber-security \\n\\ncapable  of  thwarting  doomsday  attacks  by  foreign intelligence  services,  it \\nwould  effectively  be  subsidizing  the  rest  of  the  population.  The  company \\nwould  capture  some  benefits  of  increased  security,  but  a  large  portion  of \\nthe  benefits  would  be  in  the  form  of  a  positive  externality  conferred  on \\nothers.75 In other words, the firm would be providing a public good, a good \\nthat  is  both  nonrivalrous  and  nonexcludable.76  Economic  theory  predicts \\nthat  public  goods  will  be  underprovided  on  the  market;77  a  standard \\nresponse  is  to  subsidize  their  production.78  Here,  the  government  might \\nprovide a sensitive enterprise with a subsidy equal in value to its costs of \\ndefending  against  the  most  sophisticated  cyber-attackers.79  This  subsidy \\ncould  take  many  forms.  The  government  could  either  pay  for  the  firm’s \\ndefenses directly or reimburse it for its cyber-security expenditures. Or the \\ncompany  could  be  offered  various  tax  credits,  deductions,  and  other \\nbenefits.  Or  it  could  be  granted  immunity  from  certain  forms  of  legal \\nliability. (In that case, the subsidy would not run from society as a whole, \\nbut from those who were injured by the firm’s otherwise unlawful conduct \\nand  whose  entitlement  to  redress  had  been  extinguished.  This  sort  of \\nsubsidy  is  potentially  regressive.)  Or  the  government  might  provide  the \\ncompany with intelligence about the types of attacks it may face. This sort \\nof  subsidy  appears  to  be  occurring  already:  the  National  Security  Agency \\n(NSA)  reportedly  is  providing  malware  signature  files  to  Google  and \\ncertain  banks  to  help  them  detect  sophisticated  intrusions  into  their \\nsystems.80 \\n\\nIn  short,  private  companies—especially  firms  that  operate  critical \\ninfrastructure in uncompetitive markets—may not be adequately investing \\nin  defenses  against  the  most  devastating  forms  of  cyber-attacks.  The  next \\nsection  explores  several  regulatory  models  that  might  be  consulted  when \\ndevising an appropriate response. \\n\\nII.  CYBER-SECURITY FRAMEWORKS, CONVENTIONAL AND \\nUNCONVENTIONAL \\n\\nCyberspace  is  beset  by  externalities.81  An  externality  is  “an  effect  on \\nthe market the source of which is external to the market”;82 it occurs when \\n\\n\\n \\n\\x0cN O R T H W E S T E R N  U N I V E R S I T Y  L A W  R E V I E W \\n\\nan  actor’s  conduct  results  in  the  imposition  of  a  cost  or  benefit  on  a \\nnonconsenting third party. Externalities can be either positive or negative. \\n“Positive  externalities  occur  whenever  an  activity  generates  benefits  that \\nthe  actor  is  unable  to  internalize,”  such  as  through  prices;  “[n]egative \\nexternalities  occur  when  one’s  activity  imposes  costs  on  others”  that \\nlikewise are not transmitted through prices.83 Economic theory predicts that \\nthe  market  will  oversupply  negative  externalities  relative  to  socially \\noptimal  levels  “because  the  producer  will  internalize  all  benefits  of  the \\nactivity  but  not  all  of  the  costs.”84  It  also  predicts  that  the  market  will \\nundersupply  positive  externalities  because  third  parties  will  free  ride.85 \\nExternalities  thus  represent  a  form  of  market  failure.86  The  standard \\ngovernment  response  to  a  negative  externality  is  to  discourage  the \\nresponsible  conduct  (e.g.,  with  taxation  or  regulation);  the  standard \\nresponse  to  a  positive  externality  is  to  encourage  the  responsible  conduct \\n(e.g., with a subsidy).87 \\n\\nCyber-security can be understood in these terms. If a company suffers \\nan intrusion, much of the harm will fall on third parties; the attack results in \\na  negative  externality.88  It  can  be  extraordinarily  difficult  to  internalize \\nthese costs. The class of persons affected by the intrusion will often be so \\nlarge  that  it would  be prohibitively  expensive  to  use  market  exchanges  to \\ninternalize  the  resulting  externalities;  the  transaction  costs  are  simply  too \\ngreat. Nor can tort law internalize the costs, as firms generally do not face \\nliability  for  harms  that  result  from  cyber-attacks  on  their  systems  or \\nproducts.89  Because  many  companies  do  not  bear  these  costs,  they  ignore \\nthem  when  deciding  how  much  to  spend  on  cyber-defense  and  therefore \\ntend to underinvest relative to socially optimal levels. (This is true both of \\nsoftware \\ncompanies \\nmanufacturers,  and  companies  that  use  them,  such  as  ISPs  and  utility \\ninvolves  positive  externalities.90  A \\ncompanies.)  Cyber-security  also \\ncompany that secures itself against intruders makes it harder for assailants \\nto  commandeer  its  systems  to  attack  others.  Investments  in  cyber-defense \\nthus  effectively  subsidize  other  firms.  Because  the  investing  company \\ndoesn’t capture the full benefit of its expenditures, it has weaker incentives \\nto secure its systems. And because other companies are able to free ride on \\nthe  investing  firm’s  expenditures,  they  have  weaker  incentives  to  adopt \\ndefenses of their own. \\n\\nthat  produce  computer  products, \\n\\nsuch  as \\n\\nRegulating Cyber-security \\n\\nThese externality and free-rider problems are largely overlooked in the \\nlaw  review  literature.  The  vast  majority  of  commentary  regards  cyber-\\nsecurity as a problem of the criminal law or the law of armed conflict.91 The \\nproblem  is  not  that  these  conventional  approaches  are  mistaken.  The \\nproblem is that they are incomplete. Treating cyber-security as a matter for \\ncops or soldiers brings certain challenges into sharper focus. But it tends to \\nobscure  other  problems—problems  that  may  be  illuminated  if  we  consult \\nalternative  regulatory  frameworks,  such  as  environmental  law,  antitrust \\nlaw,  products  liability  law,  and  public  health  law.  In  short,  a  wider \\nselection of analytical lenses allows us to fully comprehend cyber-security \\nchallenges in all their complexity. The following sections will explore these \\nframeworks and their relevance for cyber-security. \\n\\nA.  The Conventional Approaches: Law Enforcement and Armed Conflict \\nScholars  typically  use  a  pair  of  analytical  frameworks  to  understand \\ncyber-attacks:  criminal  law  and  the  law  of  armed  conflict.  Consider  the \\nformer  first.  Broadly  speaking,  the  criminal  law  seeks  to  protect  people \\nfrom  unjustified  acts  of  violence  against  their  persons  or  property.  The \\ncriminal  law  pursues  this  objective  by  imposing  sanctions,  such  as \\nincarceration, on those adjudged to have violated the law. These penalties \\nwill punish those who have transgressed society’s moral code (retribution), \\ndissuade the perpetrator or others from committing similar offenses in the \\nfuture  (specific  or  general  deterrence),  isolate  the  dangerous  perpetrator \\nfrom  society  (incapacitation),  or  teach  the  misguided  perpetrator  the  error \\nof  his  ways  (rehabilitation).  Cyber-attacks  fit  into  this  conceptual \\nframework  fairly  comfortably.  A  person  who  hacks  into  another’s \\ncomputer  may  have  thereby  violated  any  number  of  laws,  such  as  the \\nfederal  Computer  Fraud  and  Abuse  Act.92  Society  regards  this  sort  of \\nconduct as sufficiently blameworthy that it proscribes it and subjects those \\nwho engage in it to criminal penalties of varying severity. \\n\\nScholars  who  approach  cyber-security  from  a  law  enforcement \\nperspective  focus  on  the  “whodunit”  questions.  Who  was  responsible  for \\nlaunching  this  particular  attack?  Was  it  an  individual  hacker  or  a  larger \\ncriminal  enterprise?  This  framework  also  emphasizes \\njurisdictional \\nquestions.93 Which courts properly may exercise subject matter jurisdiction \\nover  a  given  cyber-attack?94  State  courts,  federal  courts,  or  perhaps \\ninternational tribunals? Should jurisdiction be determined by the location of \\nthe  target?  By  the  location  of  the  attacker?  By  the  location  in  which  the \\neffects  of  the  attack  are  felt?  Should  cyber-attacks  be  subject  to universal \\n\\n\\njurisdiction—the  notion  that  a  court  may  try  certain  crimes  regardless  of \\nwhere  in  the  world  they  occurred?95  How  might  courts  gain  personal \\njurisdiction  over  those  suspected  of  committing  the  attack,  especially  if \\nthey  are  overseas?  Do  existing  extradition  treaties  cover  the  range  of \\noffenses  that  cyber-criminals  might  commit?  Should  the  United  States \\nnegotiate new bilateral agreements with key international partners, such as \\nour European allies, or with countries in which cyber-attacks are likely to \\noriginate,  such  as  China  and  Russia?  Or  should  there  be  a  multilateral \\nglobal  convention  on  cyber-crime,  one  that  will  facilitate  extradition  of \\nsuspects  from  their  home  countries  to  the  states  in  which  they  will  stand \\ntrial for their alleged crimes? \\n\\nThe  law  enforcement  framework  also  emphasizes  punishment  and \\ndeterrence.96 Certain economic theories of criminal law posit that a person’s \\nwillingness to commit crimes is a function of the expected penalty for that \\nactivity—i.e.,  the  sanction  for  the  particular  offense  discounted  by  the \\nprobability that the person will get caught.97 The greater the sanction, and \\nthe  greater  the  likelihood  of  detection  and  punishment,  the  less  likely  a \\nperson will choose to commit that crime. The question then becomes what \\nshould  be  done  to  increase  the  deterrent  effect  of  laws  that  proscribe \\nvarious cyber-intrusions. Should the penalties for violating these statutes be \\nincreased? Should society invest more resources in detecting cyber-crime, \\nthereby  increasing  the  probability  that  perpetrators  will  be  caught  and \\npunished?98 Or should lawmakers pursue “cost deterrence,” the objective of \\nwhich is to increase the costs one must incur to perpetrate cyber-crime?99 \\n\\nThe  second  conventional  approach  regards  cyber-attacks  from  the \\nstandpoint of the law of armed conflict (LOAC). The LOAC, also known \\nas international humanitarian law (IHL), is a body of international law that \\nregulates a state’s ability to use force in several ways. First, it sets forth the \\ncircumstances in which a state lawfully may engage in armed conflict—the \\njus ad bellum regulations. For instance, the United Nations Charter forbids \\nsignatories “from the threat or use of force against the territorial integrity or \\npolitical independence of any state,”100 but also recognizes an inherent right \\n\\nRegulating Cyber-security \\n\\nto use force in self-defense against an “armed attack.”101 Second, the LOAC \\nregulates  what  kinds  of  force  may  be  used  during  an  authorized  armed \\nconflict—the  jus  in  bello  regulations.  For  instance,  a  state  may  not \\ndeliberately kill civilians or destroy civilian infrastructure (the “distinction” \\nor  “discrimination”  principle),  may  not  inadvertently  inflict  harm  on \\nthe \\ncivilian  populations  and  structures \\nimportance of the military objective (“proportionality”), and may not cause \\nmore  harm  to  legitimate  targets  than  is  needed  to  achieve  the  military \\nobjective (“necessity”).102 \\n\\nis  disproportionate \\n\\nthat \\n\\nto \\n\\nScholars  who  see  cyber-security  as  an  armed  conflict  problem \\ntypically  focus  on  determining  who  was  responsible  for  a  particular \\nattack.103  Was  this  attack  launched  by  a  state  or  an  international  terrorist \\norganization, in which case the LOAC  may permit some form of  military \\nretaliation? Or was it carried out by criminals, in which case the distinction \\nprinciple  likely  would  rule  out  a  military  response?  If  the  attacker  was  in \\nfact a state or terrorist group, which one? Was it China, or maybe Russia, \\nor  perhaps  North  Korea?  Or  was  it  al  Qaeda,  or  al  Qaeda  in  the  Arabian \\nPeninsula, or Hezbollah? Until the identity of the assailant is known, it will \\nbe  unclear  against  whom  to  retaliate—or  whether  retaliation  is  lawful  at \\nall.104 \\n\\nAnother  set  of  important  questions  concerns  how  to  characterize  a \\ncyber-incident. Is a given intrusion espionage or an attack? It can be quite \\ndifficult to answer that question because the steps an intruder would take to \\nsteal information often are identical to the steps it would take to bring down \\na system. If the intrusion is properly understood as an attack, does it rise to \\nthe  level  of  an  “armed  attack”  that  triggers  the  right  of  self-defense?105 \\nShould these questions be resolved with an “instrument-based” test, which \\ncounts  a  cyber-intrusion  as  an  armed  attack  when  it  causes  harms  that \\npreviously  could  have  been  caused  only  by  a  kinetic  attack?106  Or  a  less \\ndemanding  “effects-”  or  “consequence-based”  test,  which  counts  a  cyber-\\nintrusion as an armed attack when it has a sufficiently harmful effect on the \\ntargeted  state?107  Or  an  even  less  demanding  “intent”  test,  which  counts  a \\n\\n\\ncyber-intrusion  as  an  armed  attack  whenever  it  evinces  a  hostile  intent, \\nregardless of whether it causes actual damage?108 The LOAC approach also \\naddresses  possible  responses.  When  a  nation  suffers  a  cyber-attack,  is  it \\nlimited to responding with a cyber-intrusion of its own?109 Or may a victim \\nretaliate by launching a kinetic attack?110 How severe must the cyber-attack \\nbe before a kinetic response would be justified? \\n\\nOther  problems  for  the  LOAC  arise  from  the  fact  that  much  of  the \\nworld’s  critical  infrastructure  is  dual  use—it  serves  a  state’s  civilian \\npopulation  but  the  state’s  political  leadership  and  armed  forces  also  rely \\nupon it.111 In the United States, for instance, civilian networks carry up to \\n98% of the federal government’s communications traffic,112 including 95% \\nof defense-related traffic.113 When, if ever, may a combatant direct a cyber-\\nattack  at  an  adversary’s  dual-use  infrastructure?114  Finally,  the  LOAC \\nfocuses  on  deterrence.  Given  the  differences  between  cyber-conflicts  and \\nkinetic  ones,  how  can  a  state  dissuade  its  adversaries  from  committing \\ncyber-attacks?  Key  differences  include  the  difficulty  in  determining  who \\nwas  responsible  for  a  given  intrusion,  the  possibility  that  a  retaliatory \\ncyber-strike  might  end  up  harming  innocent  third  parties  more  than  the \\nactual  assailant,  and  the  fact  that  different  nations  are  more  or  less \\ndependent  on  cyber-infrastructure  and  therefore  have  more  or  less  to  lose \\nfrom an exchange of cyber-weapons.115 \\n\\nA  central  problem  for  both  the  law  enforcement  and  armed  conflict \\napproaches  to  cyber-security  is  determining  the  identity  of  the  assailant. \\nAttribution  is  extraordinarily  difficult;  the  challenges  are  “staggering”116 \\nand “[n]o one has come close to solving” them.117 The problem is inherent \\n\\n108 WALTER  GARY  SHARP,  SR.,  CYBERSPACE  AND  THE  USE  OF  FORCE  129–31  (1999).  Some \\nscholars describe the intent test as a form of “strict liability.” See, e.g., Graham, supra note 19, at 91; \\nSklerov, supra note 19, at 55. This seems incorrect. A strict liability regime imposes liability solely on \\nthe basis of the social harm produced by the actor’s conduct, without reference to his mens rea. WAYNE \\nR. LAFAVE, CRIMINAL LAW § 5.5 (5th ed. 2010). It would be more accurate to say that the intent test \\nimposes liability solely on the basis of mens rea, without any requirement that the actor’s conduct result \\nin social harm. \\nRegulating Cyber-security \\n\\nin  the  basic  architecture  of  the  Internet.  The  Internet’s  TCP/IP  protocol118 \\nwas designed to move packets of data as efficiently as possible; it is utterly \\nunconcerned with who sent them.119 As such, it is fairly easy for attackers \\nto obscure their true identities by routing their intrusions through a series of \\ndispersed  intermediary  computers.120  These  attribution  difficulties  can \\nseverely  frustrate  the  law  enforcement  and  armed  conflict  approaches  to \\ncyber-security. \\n\\nB.  Cyber-security as an Environmental Law Problem \\n\\nGiven  the  limits  of  the  conventional  cyber-security  frameworks,  it’s \\nadvisable  to  look  for  guidance  in  other  legal  disciplines—particularly  the \\nregulatory disciplines that confront the same sorts of problems seen in the \\ncyber-security context. For instance, a principal goal of environmental law \\nis  to  regulate  externalities.  Various  forms  of  environmental  degradation \\ninvolve  negative  externalities—i.e.,  spillover  costs  that  are  imposed  on \\nthird parties and that are not transmitted through prices.121 Sometimes these \\nexternalities  are  geographic:  toxins  emitted  by  a  factory  in  Ohio  might \\naffect  residents  of  New  York.122  Sometimes  they  are  temporal:  carbon \\nemissions today might affect the planet’s climate for future generations.123 \\nThe  critical  point  is  that  these  costs  are  borne  by  people  other  than  those \\nwho  are  responsible  for  the  pollution,  and  market  transactions  cannot \\nreadily  be  used  to  internalize  the  costs  onto  the  polluter.  Many  scholars \\ntherefore  believe  that  regulatory  controls  are  necessary.124  These  controls \\noften take the form of strict limits on regulated activity backed by the threat \\nof  civil  damages  or  criminal  sanctions,125  though  less  coercive  forms  of \\nregulation exist. \\n\\nCyber-security can be understood in terms of negative externalities.126 \\nA  given  firm—whether  it  is  a  company  that  produces  or  uses  computer \\n\\n\\x0cN O R T H W E S T E R N  U N I V E R S I T Y  L A W  R E V I E W \\n\\nproducts—will not bear the full costs of its cyber-insecurities. (By “cyber-\\ninsecurity,”  I  mean  a  firm’s  failure  to  implement  defenses  capable  of \\ndefeating  a  cyber-attack.)  Instead,  some  of  these  costs  are  borne  by  third \\nparties;  they  are  partially  externalized.127  Imagine  a  cyber-attack  that \\ndisables  a  power  plant.  The  intrusion  would  harm  the  utility  as  well  as \\nconsumers  who  buy  electricity  from  it128—hospitals,  manufacturers,  and \\nothers. The attack also would harm a number of third parties who have no \\nrelationship  with  the  power  company—hospital  patients,  downstream \\nmanufacturers in the supply chain, and so on. These “indirect effects of a \\ncyber  attack  are  almost  always  more  important  to  the  attacker  than  the \\ndirect  effects.”129  And  it  would  be  prohibitively  expensive  to  internalize \\nthem through market exchanges; the transaction costs would be staggering, \\nin part because it is extraordinarily difficult to identify the universe of third \\nparties affected by the intrusion. \\n\\nincentives \\n\\nThe  fact  that  many  costs  of  cyber-attacks  are  externalized  is \\nenormously  significant.  Some  commentators  have  argued  that  firms  have \\nstrong  “financial \\nto  protect  [their  systems]  from  cyber \\nattacks.”130  Those  incentives  are  weaker  than  might  be  supposed.  A  firm \\nthat is deciding how much to invest in securing its systems will not account \\nfor  the  costs  that  an  attack  will  impose  on  third  parties.131  Firms  tend  to \\noversupply  pollution,  since  they  capture  all  the  benefits  of  the  associated \\nproductive activity but not all of the resulting costs. In a similar way, firms \\ntend to oversupply cyber-insecurity—or, to say the same thing, they tend to \\nundersupply cyber-defense—because they internalize all of the benefits but \\nonly some of the costs.132 Firms thus may invest less in cyber-defense than \\nwould be optimal from a societal standpoint. \\n\\nThe  point  can  be  illustrated  with  a  simple  hypothetical.  Imagine  a \\ncyber-attack  that  will  result  in  $1  million  in  expected  costs  for  the  target \\nfirm  and  $10  million  in  expected  costs  for  third  parties.  From  a  societal \\nstandpoint,  it  would  be  worthwhile  to  invest  up  to  $11  million  to  prevent \\nthe attack. But from the company’s standpoint, it would only be worthwhile \\nto invest up to $1 million. If the firm spent more than that, the cost of the \\n\\nthe Internet is socially beneficial because it produces network effects; by joining the network, the user \\nincreases its value to all users. POST, supra note 94, at 47–49. \\n\\n\\nRegulating Cyber-security \\n\\nprecautions  would  exceed  the  benefit  to  the  firm  and  the  firm  would  be \\nconferring  uncompensated  benefits  on  third  parties.  Thus,  there  is  a  gap \\nbetween the welfare of the company and the welfare of society as a whole. \\nLevels  of  cyber-security  investment  that  are  efficient  for  particular  firms \\nmay turn out to be inefficient for society at large.133 \\n\\nCyber-security can also be understood as a positive externality. When \\na firm expends resources to defend itself against intruders, that investment \\ncan make other users’ systems marginally more secure as well. This is so \\nbecause the defenses not only help prevent harm to the company’s system, \\nthey also help prevent the firm’s system from being used to inflict harm on \\nothers’ systems.134 If Pepsi’s network is well-defended, it is less likely to be \\ninfected by a worm and thus less likely to transmit the malware through the \\nInternet  to  Coke.  The  effect  is  to  decrease  the  overall  incidence  of \\ninfection, but the investing firm does not capture the full benefit. A classic \\npositive  externality.  Cyber-defenses  can  differ  from  realspace  defenses  in \\nthis respect. If I install an  alarm in  my  home, that  might prevent burglars \\nfrom  breaking  into  my  house,  but  it  will  not  necessarily  decrease  the \\noverall incidence of burglary. The alarm might simply displace the burglar \\nwho  would  have  targeted  me  onto  my  neighbor135—a  form  of  negative \\nexternality. By contrast, cyber-defenses can make my system more secure \\nat the same time they increase the overall security of the Internet.136 \\n\\nRelatedly, some aspects of cyber-security resemble public goods.137 A \\npublic  good  is  both  nonrivalrous  (one  person’s  use  of  the  good  does  not \\nreduce its availability for use by others) and nonexcludable (the owner of \\nthe  good  cannot  prevent  particular  persons  from  using  it).138  A  classic \\nexample of a public good is a large municipal park: the park is open to all \\ncomers, and one person enjoying a crisp fall afternoon on a bench generally \\ndoes  not  prevent  anyone  else  from  doing  the  same.  Some  scholars  argue \\nthat  cyber-security  information—information  about  the  vulnerability  of  a \\nparticular system, or the most effective way to counter a particular cyber-\\n\\n\\nthreat—is a public good that the market will tend to underproduce.139 There \\nis  also  a  sense  in  which  defensive  measures  themselves  are  public  goods. \\nLike a municipal park, cyber-defenses can be nonrivalrous.140 When Pepsi \\nexpends  resources  to  secure  its  computer  network,  that  does  not  decrease \\nthe amount of security available for Coke. Doing so can actually increase \\nsecurity for third parties, as attackers will be unable to use Pepsi’s secured \\nsystem as a platform to launch attacks on other companies. Cyber-defenses \\nalso  can  be  nonexcludable.141  When  Pepsi  secures  its  system  against \\nconscription  into  a  botnet—a  network  of  “zombie”  computers  ordered  by \\nthe  “master”  to  commence  a  DDOS  attack142—it  isn’t  possible  to  specify \\nwhich third parties will enjoy the benefit of Pepsi’s immunity; for instance, \\nprotecting Coke but not Snapple. All such users are thereby protected from \\nattacks launched from Pepsi’s system. \\n\\nEnvironmental law and the underlying economic principles it reflects \\nthus provide an important framework to understand the tendency of some \\nfirms to neglect cyber-defense. It’s a free-rider problem.143 Companies tend \\nto  underinvest  in  cyber-defenses  for  the  same  reason  they  tend  to \\nunderinvest  in  pollution  controls—because  insecurities  that  result  in \\nsuccessful  attacks  produce  negative  externalities  that  are  borne  by  third \\nparties.  Firms  also  tend  to  underinvest  in  cyber-defenses  because  such \\nexpenditures create positive externalities and provide opportunities for free \\nriding.  “The  individual  undertaking  the  security  precautions  does  not \\ninternalize all the benefits, and will seek to free-ride off of the efforts taken \\nby others”; as a result, “theory predicts that security will be undersupplied \\non  the  market.”144  Understood  in  these  terms,  the  challenge  for  a  cyber-\\nsecurity regime is to internalize the externalities—to ensure that firms that \\nfail to secure their systems are made to bear the resulting costs. \\n\\nC.  . . . as an Antitrust Problem \\n\\nAntitrust  law  is  another  useful  framework  for  understanding  cyber-\\nsecurity  problems.  The  ultimate  goal  of  antitrust,  promoting  consumer \\nwelfare, \\nin \\nanticompetitive  conduct.  Antitrust  law  is  especially  concerned  about  the \\npossibility  that  firms  will  take  coordinated  action  that  undermines \\n\\nis  achieved  by  restraining  businesses  from  engaging \\n\\n \\n\\x0c107:1503 (2013) \\n\\nRegulating Cyber-security \\n\\ncompetition—an agreement to divide a market, for instance. Antitrust also \\nis  apprehensive  about  information  sharing  among  competitors;  such \\nexchanges,  it  is  feared,  “can  facilitate  anti-competitive  collusion  or \\nunilateral  oligopolistic  behavior.”145  Hence  Section 1  of  the  Sherman  Act \\nsweepingly prohibits “[e]very contract, combination in the form of trust or \\notherwise,  or  conspiracy,  in  restraint  of  trade  or  commerce  among  the \\nseveral States.”146 \\nAntitrust \\n\\nlaw  often  subjects  coordinated  conduct  by  multiple \\ncompetitor  firms  to  stricter  scrutiny  than  isolated  conduct  by  a  single \\nfirm.147  The  law  condemns  many  such  arrangements—namely,  “naked” \\nrestraints  or  coordinated  actions  that  are  “formed  with  the  objectively \\nintended purpose or likely effect of increasing price or decreasing output in \\nthe short run”148—under a per se rule against cartelization.149 With a per se \\nrule, there is no need to inquire whether a particular arrangement actually \\nhas  anticompetitive  effects.  Antitrust  law  takes  a  shortcut  and  simply \\npresumes  that  the  conduct  is  harmful.150  This  approach  may  lead  to  the \\noccasional  false  positive—coordinated  action  that  is  actually  beneficial  to \\nconsumers  but  that  nevertheless  is  condemned  as  unlawful.  But  the \\nconventional  wisdom  is  that  the  costs  of  these  false  positives  would  be \\ndwarfed by the decision costs of distinguishing the small number of naked \\nrestraints  that  are  procompetitive  from  the  much  larger  number  that  are \\nanticompetitive. \\n\\nYet  some  interfirm  cooperation  is  beneficial  to  consumers,151  and \\nantitrust  law  can  struggle  to  determine  whether  a  given  instance  of  joint \\naction  is  pro-  or  anticompetitive.152  In  the  cyber-security  context,  various \\nforms of coordination and information sharing can help firms better defend \\nthemselves  against  intrusions,  and  thus  prevent  consumers  from  incurring \\nlosses.  Firms  in  a  particular  industry  might  agree  to  exchange  threat \\ninformation.153 An ISP that discovers it has been victimized by a particular \\nform of malware could alert others to be on the lookout for the same threat. \\nOr firms could share vulnerability information.154 A power plant that learns \\nthat  its  SCADA  system  can  be  compromised  by  a  particular  type  of \\nintrusion  could  tell  other  companies  about  the  vulnerability.  Firms  also \\n\\n\\nmight  share  countermeasure  information.  A  company  might  discover  an \\nespecially  effective  way  to  defend  against  a  DDOS  attack,  and  the \\ncompany  might  notify  other  firms  to  use  the  same  technique.  Finally,  an \\nindustry might agree to establish a uniform set of cyber-security standards, \\nalong  with  monitoring  and  enforcement  mechanisms  to  ensure  that  all \\nmembers are implementing the agreed-upon measures. They might, in other \\nwords, form something like a cartel. \\n\\nfully \\n\\nabout \\n\\n“major \\n\\nsector’s \\n\\nconcerns \\n\\nWhich brings us to the problem. Coordinating on cyber-defense could \\ngive  rise  to  antitrust  liability,  and  firms  therefore  are  reluctant  to  share \\ninformation or to adopt common security standards.155 These liability fears \\nappear  to  be  fairly  widespread.  A  2002  analysis  found  that,  among  the \\nprivate \\ncommunicating \\ncybervulnerabilities,”  one  of  the  most  important  is  “the  potential  for \\nantitrust  action  against  cooperating  companies.”156  In  a  2009  report,  the \\nAmerican  Bar  Association  (ABA)  likewise  recounted  the  concerns  of \\nseveral  firms  that  “antitrust  laws  created  a  barrier  to  some  forms  of \\nsharing” cyber-security information.157 Government officials have reported \\nthe  same  fears.  The  White  House’s  2009  Cyberspace  Policy  Review \\nacknowledged that some interfirm coordination takes place, but went on to \\nreport  that  “some  in  industry  are  concerned  that  the  information  sharing \\nand  collective  planning  that  occurs  among  members  of  the  same  sector \\nunder  existing  partnership  models  might  be  viewed  as  ‘collusive’  or \\ncontrary to laws forbidding restraints on trade.”158 \\n\\nThese concerns seem well-founded. There are a number of scenarios in \\nwhich  cyber-security  coordination  could  trigger  liability  under  federal \\nantitrust  statutes.  For  instance,  suppose  that  firms  in  a  particular  industry \\n\\n155 Cf.  Jonathan  H.  Adler,  Conservation  Through  Collusion:  Antitrust  as  an  Obstacle  to  Marine \\nResource  Conservation,  61  WASH.  &  LEE  L.  REV.  3  (2004)  (arguing  that  antitrust  regulation \\ndiscourages cooperative interfirm efforts to control effects of pollution on marine life). \\n\\n156 Frye, supra note 153, at 374. The other two reported concerns are “an increased risk of liability” \\n\\nand the “loss of proprietary information.” Id. \\n\\n AM. BAR ASS’N, supra note 18, at 10. \\n\\n\\n \\n\\x0c107:1503 (2013) \\n\\nRegulating Cyber-security \\n\\nagree  to  implement  a  uniform  set  of  cyber-security  practices.159  It  is \\nimprobable  that  these  new  standards  would  be  costless.  Whether  the \\ncompanies have agreed to purchase and install new firewall software, or to \\ntransition  from  vulnerable  commercial-off-the-shelf  (COTS)  systems  to \\nmore expensive proprietary systems, the measures are likely to affect their \\nbottom  lines.  Industry  members  might  decide  to  absorb  these  increased \\ncosts,  depending  on  the  elasticity  of  consumer  demand  for  the  goods  or \\nservices they offer. But they might further decide to pass on these costs to \\nconsumers, either in the form of a general price hike or as a free standing \\nsurcharge.  Would  the  arrangement  be  lawful?  This  sort  of  venture  may \\namount to price fixing in violation of Section 1 of the Sherman Act.160 Even \\nif the participating firms do not set a specific price for their products (e.g., \\neveryone  will  now  charge  $50  for  widgets  instead  of  $45),  they  still \\nestablish a premium that will be assessed for their products (e.g., everyone \\nwill increase the price they charge for their widgets by $5). The economic \\neffect is the same. Indeed, the arrangement may even amount to a “naked” \\nrestraint that results in reflexive condemnation under the per se rule.161 \\n\\nAs  a  second  example,  consider  an  arrangement  that  imposes  no  new \\ncosts  on  consumers—at  least  not  directly.  Suppose  firms  in  a  particular \\nindustry  agree  to  install  intrusion-detection  or  -prevention  capabilities  to \\nscan  for  malware  on  their  networks.162  These  systems  rely  on  a  technique \\nknown  as  “deep-packet  inspection,”  in  which  all  data  traversing  the \\nnetwork  is  scanned  and  checked  against  signature  files  of  known \\nmalware.163  The  effect  is  often  to  slow  down  the  network’s  performance, \\nsometimes dramatically.164 Suppose further that the firms decide to absorb \\nthe costs of the monitoring or detection system rather than pass them on to \\ntheir  consumers.  Would  that  forbearance  save  the  arrangement  from \\n\\nNotice \\n\\nantitrust  liability?  Not  necessarily.  The  shared  security  standards  still \\nplausibly could be described as an unlawful price-fixing agreement. While \\nthe  participating  companies  have  not  agreed  to  raise  prices  directly,  they \\nhave  indirectly  accomplished  something  similar;  instead  of  requiring \\nconsumers  to  pay  a  higher  price  for  the  same  product,  the  firms  have \\nagreed  to  require  consumers  to  pay  the  same  price  for  a  lesser  product \\n(where speed is an important component of the product’s value). \\nthat  clear  and  unambiguous  prohibitions  on \\n\\ninterfirm \\ncoordination may not be necessary to deter businesses from participating in \\njoint  cyber-security  ventures.  Mere  uncertainty  about  the  applicability  of \\nthe antitrust laws—and the corresponding risk of liability—may be enough. \\nThe deterrent effect is likely to be especially strong because of the severe \\nsanctions  that  may  be  imposed  on  antitrust  defendants.  Firms  that  are \\nalleged to have violated federal antitrust laws face criminal prosecutions as \\nwell  as  federal  civil  actions,165  state  civil  actions,166  and  lawsuits  by \\naggrieved private parties.167 Each type of civil litigation carries the prospect \\nof  treble  damages  payouts  to  the  successful  plaintiffs.168  Private  firms \\ntherefore  will  have  good  reasons  to  avoid  coordinating  their  efforts  to \\nimprove cyber-security. \\n\\nTo  be  sure,  fear  of  antitrust  liability  is  not  the  only  reason  firms  are \\nreluctant  to  coordinate  and  share  information.  The  difficulties  of  forming \\nand maintaining cartels are well-known. Among other problems, individual \\ncartel  members  have  strong  incentives  to  cheat,  such  as  by  offering  a \\ngreater quantity of product or by charging a different price than allotted by \\nthe cartel.169 In the cyber-security context, businesses will have comparable \\nincentives to shirk their responsibilities to implement any agreed-upon (and \\nlikely  costly)  security  standards.  In  addition,  firms  may  be  especially \\nreluctant to share information with their competitors.170 If a firm discovers \\nan effective  way to defend its systems against  a particular form  of cyber-\\nintrusion, that information gives it a comparative advantage over rivals that \\nmay  not  be  as  adept  at  protecting  their  own  networks.  Sharing  the \\ninformation  with  competitors  enables  them  to  free  ride  and  thereby \\neliminates  the  firm’s  comparative  advantage.  As  such,  even  if  fears  of \\nantitrust  liability  were  eliminated  completely,  it  is  doubtful  that  firms \\nwould  fully  cooperate  with  one  another.  Nevertheless,  liability  concerns \\nappear  to  be  a  significant  impediment  to  cyber-security  coordination  and \\n\\nRegulating Cyber-security \\n\\ninformation  sharing.  Reducing  these  fears  would  not  by  itself  ensure \\ncooperation, but might make it more likely at the margin. \\n\\nD.  . . . as a Products Liability Problem \\n\\nPrivate  investment  in  cyber-security  also  resembles  a  tort  problem—\\nmore precisely, a products liability problem. Broadly speaking, the law of \\nproducts  liability  has  two  complementary  goals.171  First,  from  an  ex  post \\nperspective,  the  law  seeks  to  compensate  consumers  injured  by  products \\nthat  did  not  perform  as  expected.  Second,  from  an  ex  ante  perspective, \\nproducts liability law uses the risk of money damages to incentivize firms \\nto take reasonable precautions when designing and manufacturing products. \\nThe  branch  of  products  liability  law  that  is  most  relevant  to  cyber-\\nsecurity  is  design  defects.  In  a  design  defect  case,  the  theory  is  that  “the \\nintended  design  of  the  product  line  itself  is  inadequate  and  needlessly \\ndangerous.”172 (By contrast, a manufacturing defect occurs when a product \\nsuffers  from  “a  random  failing  or  imperfection,”173  such  as  a  crack  in  a \\nCoke bottle that causes it to explode,174 and a marketing defect occurs when \\nan  otherwise  safe  product  “become[s]  unreasonably  dangerous  and \\ndefective if no information explains [its] use or warns of [its] dangers.”)175 \\nIn its infancy, products liability law typically assigned blame on a theory of \\nstrict  liability.176  A  plaintiff  could  recover  damages  by  establishing  that  a \\ngiven product had a defective design and that he was injured by that defect; \\nit  wasn’t  necessary  to  show  that  the  manufacturer  was  negligent,  or \\notherwise  blameworthy,  in  producing  the  defect.177  The  modern  approach \\nabandons strict liability in favor of a negligence standard.178 How do courts \\ndetermine whether a manufacturer was at fault when it produced a product \\nwith a design defect? One common approach is the risk–utility test.179 The \\ntest, which has its roots in Learned Hand’s negligence formula,180 compares \\n\\n\\n \\n\\x0cN O R T H W E S T E R N  U N I V E R S I T Y  L A W  R E V I E W \\n\\n“the  risks  of  the  product  as  designed  against  the  costs  of  making  the \\nproduct  safer.”181  If  the  risks  can  be  reduced  by  a  significant  amount  at  a \\nrelatively low cost, a manufacturer that declines to do so is negligent. If the \\nrisks  can  be  reduced  only  by  a  small  amount  at  a  relatively  high  cost,  a \\nmanufacturer that declines to do so is not negligent. \\n\\nlikely  would  buy  competitors’  products \\n\\nTort liability creates important incentives for manufacturers to prevent \\nor  eliminate  design  defects.182  Imagine  a  company  that  makes  residential \\nfurnaces;  it  is  trying  to  decide  whether  to  remedy  a  design  defect  that \\nincreases the probability that the furnaces will explode. The company will \\ndo so if the expected benefits of reducing the risk of explosion exceed the \\nexpected  costs  of  making  the  fix.  Without  tort  liability,  the  benefit  of \\nmaking defect-free furnaces is lower than it otherwise would be. Furnaces \\nthat  occasionally  explode  would  damage  the  firm’s  reputation,  and  some \\ninstead.  The \\nconsumers \\nmanufacturer benefits to the extent it reduces these harms. But it does not \\nface the prospect of paying money damages to homeowners whose houses \\nburned  down.  The  cost–benefit  calculus  looks  very  different  once  a \\nproducts  liability  regime  is  in  place.  Tort  liability  increases  a  firm’s \\nexpected  benefit  of  remedying  design  defects—namely,  the  benefit  of \\nforegone money damages, discounted by the probability that they would be \\nawarded. It thus increases the number of circumstances in which firms will \\nfind  it  welfare  maximizing  to  improve  the  safety  of  their  products.  The \\nresult  is  that,  at  the  margin,  products  will  be  safer  than  they  otherwise \\nwould be. \\n\\nInternet-related  goods  and  services  sometimes  suffer  from  design \\ndefects that increase their vulnerability to cyber-attacks.183 Perhaps the best \\nknown  example  is  Microsoft  Windows.  The  operating  system  software, \\nwhich  accounts  for  more  than  90%  of  the  PC  market,184  is  notoriously \\nriddled  with  vulnerabilities.  These  flaws  stem  in  part  from  the  software’s \\nsize. In 2006, Microsoft projected that Windows Vista would feature some \\n50 million lines of code, compared to 35 million for Windows XP (released \\nin  2001)  and  just  15  million  for  Windows  95  (released  in  1995).185  It  is \\nmore  or  less  inevitable  that  the  programmers  who  write  these  millions  of \\nlines will  make mistakes,  and it can be quite difficult to detect and repair \\nthem.186 (Given that it probably would cost a great deal to eliminate all of \\nthese  vulnerabilities,  the  failure  to  do  so  may  not  be  negligent  under  the \\n\\n\\nRegulating Cyber-security \\n\\ntest.)187  Other  examples  abound.  Indeed,  many  of \\n\\nrisk–utility \\nthe \\nvulnerabilities described in Part I can be understood as the results of design \\ndefects.  Consider  the  decision  by  power  companies  to  connect  generators \\nand  other  elements  of  the  electrical  grid  to  the  Internet.  This  might  be \\ndescribed as a form of defective system design, in that Internet connectivity \\nexposes the nation’s power grid to potentially catastrophic cyber-attacks in \\nexchange  for  relatively  modest  benefits.188  The  same  can  be  said  of \\ncompanies  that  continue  to  protect  their  SCADA  systems  with  vendor-\\nsupplied  default  passwords189—a  defect,  incidentally,  that  could  be \\nremedied at a negligible cost. \\n\\nThe  incentives  to  cure  these  design  defects  are  fairly  weak  because \\npoor cyber-security generally does not trigger civil liability.190 One reason \\nfor  this  is  a  venerable  chestnut  of  tort  law  known  as  the  economic  loss \\ndoctrine. The economic loss doctrine provides that, while a defendant who \\ncauses physical injuries is also liable for any resulting economic harms, he \\ngenerally  is  not  liable  for  freestanding  economic  harms.191  Many  of  the \\nharms that would result from a cyber-attack on, say, the power grid or the \\nfinancial  sector  would  be  purely  economic  in  nature.  An  automobile \\nmanufacturer might be unable to run its assembly line because the power is \\nout,  or  a  consumer  might  default  on  a  loan  because  he  can’t  make  a \\npayment online. Few of these harms would derive from a physical injury, \\nand  they  therefore  would  not  be  actionable.  For  instance,  in  2009,  the \\nSupreme  Judicial  Court  of  Massachusetts  dismissed  a  lawsuit  brought  by \\ncredit  unions  against  a  retailer  after  hackers  accessed  the  retailer’s \\ncomputer systems and stole customer credit card data.192 The court agreed \\nwith the lower court’s conclusion that, because “the plaintiffs suffered only \\neconomic harm due to the theft of the credit card account information,” the \\n“economic  loss  doctrine  barred  recovery  on  their  negligence  claims.”193 \\n\\nCyber-attacks  that  cause  physical  injuries  would  remain  actionable,  as \\nwould  any  resulting  economic  harms.  So,  for  instance,  if  an  attacker \\nexploited  a  design  defect  in  a  dam’s  control  system  and  opened  the \\nfloodgates,194  the  dam  operator  might  be  held  liable  for  the  deaths  of  the \\ndownstream landowners and any corresponding economic losses. \\n\\nThe problem also can be understood in Coasean terms.195 Consider the \\nfamous  example  of  a  train  that  emits  sparks  that  burn  the  wheat  in \\nneighboring fields.196 Regardless of whether the legal entitlement is initially \\nassigned to the railroad (a right to emit sparks) or the farmers (a right to be \\nfree  from  incinerated  crops),  the  parties  will  bargain  to  reallocate  the \\nentitlement to its socially most efficient use, assuming that the transaction \\ncosts  are  sufficiently  small.  In  the  cyber-security  context,  the  absence  of \\ntort  liability  essentially  grants  firms  a  legal  right  to  refrain  from  taking \\nprecautions that would protect third parties from attacks on their systems or \\nproducts.  This  may  be  an  efficient  allocation  of  the  legal  entitlement  in \\nsome contexts, but not always. In these latter circumstances, companies and \\nthird parties theoretically should negotiate and establish a new legal right to \\nbe  free  from  harm  due  to  cyber-intrusions.  But  Coasean  bargaining  over \\ncyber-security  seems  unlikely \\nthe  staggering \\ntransaction costs. It would be prohibitively expensive, if not impossible, for \\ncompanies to bargain with everyone who conceivably could be injured by \\ncyber-attacks on their systems or products. \\n\\nto  occur  because  of \\n\\nBeyond  tort,  it  is  doubtful  that  other  sources  of  law  will  threaten \\ncyber-security  shirkers  with  liability.  Contract  law  does  not  seem  well \\nsuited to the task. Software manufacturers typically do not offer warranties \\nthat their products are secure.197 Indeed, some do not “sell” software at all. \\nThey  merely  grant  a  license,  and  users  cannot  install  the  software  unless \\nthey  click  a  button  to  accept  terms  and  conditions  that  usually  include  a \\nlimit on the manufacturer’s liability.198 Likewise, federal law extends broad \\nimmunity  to  ISPs.  Section  230  of  the  Communications  Decency  Act \\nprovides that an ISP will not “be treated as the publisher or speaker of any \\ninformation provided by another information content provider.”199 At least \\none federal appellate court has interpreted this statute to foreclose a lawsuit \\nalleging that an ISP negligently failed to prevent malware from being sent \\n\\nbar  recovery  for  economic  harms  resulting  from  a  cyber-intrusion);  Patco  Constr.  Co.  v.  People’s \\nUnited  Bank,  684  F.3d  197  (1st  Cir.  2012)  (upholding  liability  under  contract  governed  by  Uniform \\nCommercial Code for economic harms resulting from a cyber-intrusion). \\n\\n\\nRegulating Cyber-security \\n\\nover  its  network.200  From  the  standpoint  of  a  profit-maximizing  firm,  the \\nexpected  benefits  of  remedying  a  cyber-vulnerability  often  will  be  lower \\nthan  the  expected  costs.  Without  the  prospect  of  tort  liability,  firms  have \\nweaker  incentives  to  invest  in  measures  to  secure  their  systems  and \\nproducts against cyber-attacks. \\n\\nintercept[] . . . \\n\\nNot  only  do  liability  fears  fail  to  incentivize  firms  to  take  better \\nprecautions against cyber-attacks, they can actually discourage them from \\ndoing so. Companies sometimes are reluctant to better secure their systems \\nbecause  of  concerns  that  these  steps  could  expose  them  to  civil  liability. \\nFor  instance,  ISPs  typically  do  not  offer  assistance  if  they  discover  that \\ntheir customers’ PCs have been infected by malware. ISPs often are able to \\ntell,  through  routine  traffic  analysis,  that  a  particular  machine  on  the \\nnetwork is part of a botnet or has been infected by a worm.201 “[B]ut they \\ndon’t dare inform the customer (much less cut off access) out of fear that \\ncustomers  would . . .  try  to  sue  them  for  violating  their  privacy.”202  Doing \\nso  might  even  be  a  crime.  The  Federal  Wiretap  Act  makes  it  unlawful  to \\n“intentionally \\nelectronic \\ncommunication,”203 and some companies fear that filtering botnet traffic or \\nother  malware  might  fall  within  this  prohibition.204  And  while  federal  law \\nmakes an exception for ISPs that intercept communications to protect their \\nown  property,205  there  is  no  parallel  exception  for  intercepts  intended  to \\nprotect  the  property  of  subscribers.  Likewise,  some  ISPs  use  deep  packet \\ninspection  to  examine  the  data  streams  on  their  networks  for  malicious \\ncode.  This  is  probably  lawful  under  the  exception  mentioned  above,  or  a \\nseparate  exception  for  “mechanical  or  service  quality  control  checks.”206 \\nBut even when they uncover malware, ISPs “have been reluctant to ‘black \\nhole’ (or kill) malicious traffic because of the risk that they might be sued \\nby  customers  whose  service  is  interrupted.”207  Again,  as  in  the  antitrust \\ncontext, even if the applicable service contracts or state and federal laws do \\nnot clearly forbid these measures, the mere risk of liability may be enough \\nto dissuade firms from undertaking them.208 \\n\\nany  wire, \\n\\noral, \\n\\nor \\n\\nWhile  firms  with  poor  cyber-defenses  generally  do  not  face  the \\nprospect of civil lawsuits, there is one context in which a credible liability \\nthreat  exists.  The  Gramm–Leach–Bliley  Act  of  1999  (GLB  Act)  imposes \\n\\n\\n\\n \\n\\x0cN O R T H W E S T E R N  U N I V E R S I T Y  L A W  R E V I E W \\n\\nliability for data breaches in the financial services sector. The Act directs a \\ngroup  of  federal  agencies,  such  as  the  Federal  Trade  Commission  (FTC) \\nand  the  Federal  Deposit  Insurance  Corporation,  to  issue  data  security \\nregulations  for  financial  institutions.209  In  particular,  the  Act  mandates  the \\nadoption  of  “administrative,  technical,  and  physical  safeguards”  that  will, \\namong  other  things,  “insure  the  security  and  confidentiality  of  customer \\nrecords and information” and “protect against unauthorized access to or use \\nof  such  records.”210  The  sanctions  for  violating  these  data  security \\nrequirements  can  be  severe.  Gramm–Leach–Bliley  does  not  enumerate \\nspecific  penalties,  but  rather  directs  the  enforcing  agencies  to  apply  the \\nAct’s requirements according to their respective enabling statutes.211 Thus, \\nfor example, a bank subject to FTC jurisdiction would face a civil penalty \\nof  up  to  $16,000  for  each  violation.212  If  the  FTC  treated  every  customer \\naffected  by  a  cyber-intrusion  as  a  separate  violation,  the  penalties  could \\nvery quickly become staggering. \\n\\nPerhaps not coincidentally, financial institutions are widely believed to \\ndo  a  better  job  of  protecting  customer  data  than  members  of  other \\nindustries.213  Unlike  other  firms,  which  typically  spend  only  modest  sums \\non  cyber-security,  most  banks  devote  “between  6  and  7  percent  of  their \\nentire  information  technology  budgets.”214  Financial  institutions  also  are \\nmore likely to adopt specific security measures like intrusion-detection and \\n-prevention systems, antivirus software, smart cards, and biometrics.215 The \\nunique risk of liability that banks face may be responsible, at least in part, \\nfor  that  record.  The  GLB  Act  has  the  effect  of  increasing  the  expected \\nbenefit  of  cyber-security—namely,  avoiding  potentially  crippling  civil \\npenalties—and  thus  creates  strong  incentives  for  banks  to  invest  in \\ndefenses. (Another explanation is the risk of customer exit. Unlike, say, the \\ncustomers of public utilities, it is relatively easy for a depositor who fears \\ncyber-intrusions to switch banks, so the bank has an incentive to maintain \\ndata integrity.)216 \\n\\nOf course, the GLB Act’s emphasis on protecting consumer data might \\ndistort firms’ cyber-security investments. Rather than expending resources \\non  defenses  against  the  attacks  they  regard  as  the  most  dangerous,  or  the \\n\\n\\n \\n\\x0c107:1503 (2013) \\n\\nRegulating Cyber-security \\n\\nmost  likely  to  occur,  financial  institutions  will  tend  to  prioritize  defenses \\nagainst  the  one  form  of  intrusion  singled  out  by  their  regulators—the \\ncompromise of customer data.217 The effect may be to ensure that firms are \\nwell-defended  against  one  threat  at  the  expense  of  increased  exposure  to \\nmany other threats.218 Even so, Gramm–Leach–Bliley remains an example \\nof  how  the  risk  of  civil  liability  might  be  used  to  incentivize  firms  to \\nimprove at least some of their cyber-defenses. \\n\\nE.  . . . as a Public Health Problem \\n\\nAs  several  scholars  have  noted,  in  more  or  less  detail,  cyber-security \\ncan be thought of in terms of public health.219 A critically important goal for \\nany cyber-security regime is to keep attacks from happening and to contain \\ntheir  ill  effects.220  The  same  is  true  of  public  health,  the  ultimate  goal  of \\nwhich is prevention.221 Unlike medical practice, which typically has an ex \\npost orientation toward treating illnesses that have already occurred, public \\nhealth  is  primarily  oriented  toward  ex  ante  solutions—preventing  people \\nfrom contracting infectious diseases, preventing pathogens from spreading, \\nand  so  on.  Broadly  summarized,  public  health  law,  including  the  subset \\nknown  as  public  health  emergency  law,  involves  government  efforts  “to \\npersuade,  create  incentives,  or  even  compel  individuals  and  businesses  to \\nconform  to  health  and  safety  standards  for  the  collective  good.”222  Some \\nscholars  defend  these  interventions  on  controversial  paternalistic  grounds. \\nThe  notion  is  that  the  state  may  curtail  individuals’  freedoms  to  promote \\ntheir  own  physical  health  and  safety.223  The  more  common  justification  is \\nthe  risk  of  harm  to  others:  the  state  may  coerce  persons  who  have \\ncontracted an infectious disease or are at risk of doing so to prevent them \\nfrom transmitting the disease to, and thereby harming, others.224 Seen in this \\nlight,  a  principal  objective  of  public  health  law  is  to  internalize  negative \\n\\n\\nexternalities—in  particular,  the  costs  associated  with  spreading  infections \\nto others. \\n\\nPublic  health  law  contemplates  three  specific  measures  that  are \\nrelevant here: mandatory inoculations to reduce susceptibility to infectious \\ndiseases, biosurveillance to monitor for epidemics and other outbreaks, and \\nisolation and quarantine to treat those who have been infected and prevent \\nthem from spreading the pathogen.225 We will consider each in turn along \\nwith their potential relevance to cyber-security. \\n\\nInoculation, in which a healthy subject is exposed to a pathogen, helps \\nprevent disease both directly (a person who is inoculated against a disease \\nis thereby rendered immune) and indirectly (the person’s immunity reduces \\nthe  risk  that  he  will  transmit  the  disease  to  others).  Inoculation  mandates \\ncan take several forms. In the nineteenth and early twentieth centuries, state \\nand local governments sometimes opted for direct regulation—a firm legal \\nrequirement  that  citizens  must  receive  a  particular  vaccine,  backed  by  the \\nthreat of sanctions.226 In the 1905 case of Jacobson v. Massachusetts,227 the \\nSupreme  Court  upheld  such  a  requirement  against  a  lawsuit  invoking  the \\nFourteenth Amendment’s privileges or immunities, due process, and equal \\nprotection  clauses.  According  to  the  Court,  mandatory  inoculation  is  a \\npermissible  exercise  of  the  states’  police  powers.228  The  modern  approach \\nusually  involves  a  lighter  touch.  Now,  state  and  local  governments \\ntypically create incentives for citizens to undergo inoculation by making it \\na  condition  of  eligibility  for  certain  valuable  benefits.  The  best  known \\nexample is to deny children access to public schools unless they have been \\nvaccinated.229 The Supreme Court upheld such a scheme in 1922 in Zucht v. \\nKing.230 \\n\\nIt isn’t necessary to inoculate all members of a population to frustrate \\nthe transmission of a given disease. This is so because of “herd immunity.” \\nWhen  large  numbers  of  a  population  are  immune  to  a  given  contagious \\ndisease,  their  immunity  helps  prevent  the  disease  from  spreading,  even  to \\nthose who are not immune.231 The critical number is typically around 85% \\nof the population, but it can be as low as 75% for some diseases, such as \\nmumps, and as high as 95% for others, such as pertussis.232 Herd immunity \\nis  a  form  of  positive  externality—those  who  undergo  vaccination  provide \\n\\n\\nRegulating Cyber-security \\n\\nan uncompensated benefit to those who do not—which creates a potential \\nfree-rider  problem.233  Many  people  would  prefer  to  enjoy  the  benefits  of \\nherd immunity without themselves undergoing vaccination, which is costly \\nin terms of money, discomfort, and risk of reaction. This free-rider problem \\nweakens  each  person’s  incentive  to  undergo  vaccination,  and  overall \\nvaccinations may drop below the levels needed to support herd immunity. \\nState and local governments therefore sometimes use their coercive powers \\nto require inoculation. (Another approach would be to provide subsidies to \\nthose  who  have  been  inoculated.  Public  school  vaccination  requirements \\ncan  be  understood  in  these  terms;  the  government  is  subsidizing  the \\neducation of children who are inoculated.) \\n\\nEnsuring  widespread  immunity—not  to  disease,  but  to  malicious \\ncode—is  also  an  important  goal  of  cyber-security.  The  average  Internet-\\nconnected computer may be even more susceptible to infection by malware \\nthan  the  average  person  is  to  infection  by  a  pathogen,  because  malicious \\ncode  can  propagate  more  efficiently  than  disease.  Many  pathogens  are \\ntransmitted by person-to-person contact; you are unlikely to contract polio \\nunless  you  come  into  close  proximity  with  someone  who  is  already \\ninfected.  But  one  can  contract  malware  from  virtually  any  networked \\ncomputer  in  the  world.  The  Internet  effectively  brings  dispersed  systems \\ninto direct contact with one another. Alternatively, the Internet is a disease \\nvector that, like mosquitoes and malaria, can transmit a contagion between \\ndispersed  systems.  It  is  therefore  essential  for  the  elements  at  the  edge  of \\nthe network, such as the SCADA system that runs the local power plant, to \\nmaintain  effective  defenses  against  cyber-intrusions,  such  as  isolating  the \\npower  plant’s  controls  from  the  public  Internet.  And  there’s  the  rub.  As \\nwith  herd  immunity,  cyber-security  raises  free-rider  problems.234  A  user \\nwho takes steps to prevent his computer from being infected by a worm or \\nimpressed  into  a  botnet  thereby  makes  other  systems  more  secure;  if  the \\nuser’s machine is not infected, it cannot transmit the malware to others. But \\nthe user receives no compensation from those who receive this benefit; he \\ndoes  not  internalize  the  positive  externality.  He  therefore  has  weaker \\nincentives to secure his system, as he—like everyone else—would prefer to \\nfree ride on others’ investments. A critical challenge for any cyber-security \\nregime is to reverse these incentives. \\n\\nThe  second  key  element  of  public  health  law  is  biosurveillance. \\n“Biosurveillance  is  the  systematic  monitoring  of  a  wide  range  of  health \\ndata of potential value in detecting emerging health threats . . . .”235 Public \\nhealth  officials  collect  and  analyze  data  to  determine  a  given  disease’s \\n\\nincidence, or “the ‘rate at which new cases occur in a population during a \\nspecified  period,’”  as  well  as  its  prevalence,  or  “the  ‘proportion  of  a \\npopulation that are cases at a point in time.’”236 Effective biosurveillance is \\nin  managing  an  epidemic  or  other  outbreak.237 \\na  vital  first  step \\nBiosurveillance takes place through a partnership among the U.S. Centers \\nfor Disease Control and Prevention, the CDC’s state level counterparts, and \\nfront  line  health  care  providers,  such  as  hospitals,  clinics,  and  individual \\nmedical  practitioners.  Many,  if  not  all,  states  have  enacted  legislation \\nrequiring  specified  health  care  professionals  to  notify  state  authorities  if \\ntheir patients have contracted any number of infectious diseases,238 such as \\nsmallpox or polio.239 These reports typically include the patient’s name, the \\ntype  of  disease,  medical  history,  and  other  personal  information.240  State \\nauthorities then share the data with the CDC. These reports are not required \\nby  law,  but  most  states  appear  to  be  fairly  conscientious  about  them.241 \\nPublic health law thus uses a system of distributed surveillance. No central \\nregulator  is  responsible  for  collecting  all  the  data  needed  to  detect  and \\nrespond  to  infectious  disease  outbreaks.  Instead,  the  system  relies  on \\nindividual  nodes  within  a  far-flung  network—from  state  agencies  to \\nhospitals  to  individual  doctors—to  gather  the  necessary  information  and \\nroute it to the CDC’s central storehouse. The CDC then analyzes the data \\nand  issues  alerts  advising  state  agencies  and  medical  practitioners  about \\ndisease trends and offering recommendations about how to respond.242 \\n\\nThe  third  public  health  intervention  involves  containing  infectious \\ndiseases  once  an  outbreak  has  occurred,  and  preventing  them  from \\nspreading further.243 Two key measures are isolation and quarantine.244 The \\ngoal of each is to segregate from the population those who have contracted \\n\\nRegulating Cyber-security \\n\\nor  been  exposed  to  an  infectious  disease,  and  thus  prevent  them  from \\ntransmitting  it  to  those  who  are  well.245  Isolation  and  quarantine  are  often \\ncoupled  with  mandatory  treatment,  which  helps  reduce  the  risk  of  further \\ncontagion;  a  person  who  has  been  cured  of  an  infectious  disease  cannot \\ntransmit it to others.246 The rationale for these interventions is the familiar \\nharm principle—the risk that a person who has contracted or been exposed \\nto  a  pathogen  will  infect  others.247  Isolation  and  quarantine  thus  seek  to \\nreduce negative externalities. \\n\\nAt  the  federal  level,  isolation  and  quarantine  are  accomplished  under \\nthe Public Health Service Act of 1944. The Secretary of Health and Human \\nServices has authority under the Act “to make and enforce such regulations \\nas in his judgment are necessary to prevent the introduction, transmission, \\nor  spread  of  communicable  diseases”  into  or  within  the  United  States.248 \\nThe  law  further  provides  for  “the  apprehension,  detention,  or  conditional \\nrelease”  of  persons  who  may  have  been  exposed  to  any  one  of  several \\ncommunicable  diseases  that  the  President  has  specified  by  executive \\norder.249  The  list,  which  was  updated  most  recently  in  2005,250  includes \\ncholera, \\ntuberculosis,  plague,  smallpox,  SARS,  and  several  other \\ndiseases.251  Large-scale  isolation  and  quarantine  are  rarely  used;  the  most \\nrecent example is from the 1918 Spanish flu pandemic, which was carried \\nout  under  different  legal  authorities.252  However,  isolation  and  quarantine \\nare sometimes used for particular individuals. In May 2007, HHS issued an \\nisolation  order  for  an  American  with  multidrug-resistant  tuberculosis  who \\nflew from the Czech Republic to Canada and then crossed the land border \\ninto  the  United  States.253  Violations  of  the  quarantine  regulations  carry \\ncriminal penalties, including a fine of up to $1000 and incarceration for up \\nto a year.254 \\n\\nBoth  biosurveillance  and  isolation/quarantine  carry  important  lessons \\nfor cyber-security. Like the public health system, effective cyber-defenses \\n\\ndepend on information about the incidence and prevalence of various kinds \\nof  malware.  Users  need  to  know  what  new  forms  of  malicious  code  are \\ncirculating  on  the  Internet  in  order  to  secure  their  systems  against  them. \\nAnd  measures  resembling  isolation  and  quarantine  can  help  ensure  that \\nsystems infected with malicious code do not spread the contagion to other, \\nhealthy computers. \\n\\nThere is, of course, a significant difference between infectious diseases \\nand  malicious  computer  code:  diseases  typically  develop  and  spread  on \\ntheir  own,  whereas  malware  is  created  by  human  beings  and  sometimes \\nrequires human intervention to propagate. This is true as far as it goes, but \\nthe  differences  between  cyberspace  and  realspace  pathogens  can  be \\noverstated.  Infectious  diseases  can  be  engineered  (e.g.,  biological \\nweapons),  and  sometimes  malware  is  able  to  spread  on  its  own  (e.g.,  a \\nworm  that  is  programmed  to  search  for  other  computers  on  which  to \\nreplicate itself255). Another potential obstacle is the tension between antique \\npublic  health  legislation  and  contemporary  constitutional  law.  These \\nstatutes  often  restrict  civil  liberties  and  privacy  to  a  degree  rarely  seen \\ntoday,256  and  the  judicial  precedents  upholding  them  against  various \\nconstitutional  challenges  typically  antedate  the  Supreme  Court’s  modern \\ncivil  rights  and  liberties  jurisprudence.  It  is  not  clear  that  today’s  Court \\nwould uphold, say, mandatory vaccination of adults as readily as it did in \\n1905.257  Yet  even  if  public  health  law  fits  uneasily  with  modern \\nconstitutional  law,  it  can  still  be  a  useful  framework  for  cyber-security \\nbecause,  as  explained  below,  the  cyber  versions  of  public  health \\ninterventions  can  be  friendlier  to  civil  liberties  and  privacy  than  their \\nrealspace counterparts.258 \\n\\nIII.  REGULATORY PROBLEMS, REGULATORY SOLUTIONS \\n\\nThis  concluding  Part  examines  the  responses  of  environmental, \\nantitrust, products liability, and public health law to various challenges, and \\nit  considers  how  those  solutions  might be  adapted  for  cyber-security.  The \\npossible  responses  to  cyber-insecurity  are  determined  by  our  antecedent \\nchoice  of  how  to  describe  that  problem.  If  we  regard  cyber-security  from \\nthe standpoint of law enforcement and armed conflict, we will tend to favor \\nthe  responses  of  law  enforcement  and  armed  conflict—stronger  penalties \\nfor  cyber-intrusions,  retaliating  with  kinetic  attacks,  and  so  on.  Those  are \\nplausible frameworks and equally plausible solutions. But they are not the \\nonly ones. A wider angle lens is needed. \\n\\n\\nRegulating Cyber-security \\n\\nTaken together, the regulatory frameworks described in Part II suggest \\nthat  an  effective  cyber-security  regime  should  include  four  components: \\n(1) monitoring  and  surveillance  to  detect  malicious  code,  (2) hardening \\nvulnerable  targets  and  enabling  them  to  defeat  intrusions,  (3) building \\nresilient  systems  that  can  function  during  an  attack  and  recover  quickly, \\nand  (4) responding  in  the  aftermath  of  an  attack.259  There  are  two \\ncomplementary  objectives  here:  preventing  intrusions  from  happening  at \\nall,  and  enabling  firms  to  withstand  the  intrusions  that  do  take  place.260 \\nStronger defenses would provide an obvious, first-order level of protection: \\nbetter  defense  means  less  damage.  They  also  would  provide  an  important \\nsecond-order  level  of  protection:  stronger  defenses  can  help  achieve \\ndeterrence. By enabling victims to defeat, survive, and recover from cyber-\\nattacks,  these  measures  increase  the  expected  costs  of  an  intrusion  to  an \\nattacker and also decrease its expected benefits.261 And that means weaker \\nincentives to attack in the first place; why try to take down the power grid \\nif the effort is likely to fail? \\n\\nOf  course,  it  is  inevitable  that  some  attacks  will  succeed.  Some \\nintrusions  can  be  prevented  or  mitigated  but  others  cannot,  and  any \\ndefensive scheme is necessarily imperfect.262 This is so because offense is \\nmuch  less  costly  than  defense  in  cyberspace.  “Defending  a  modern \\ninformation  system”  is  like  “defending  a  large,  thinly-populated  territory \\nlike  the  nineteenth  century  Wild  West:  the  men  in  black  hats  can  strike \\nanywhere, while the men in white hats have to defend everywhere.”263 The \\ngoal  therefore  is  not  to  develop  impregnable  defenses.  Doing  so  may  be \\nimpossible from a technological standpoint and, even if such defenses were \\nfeasible,  they  may  be  inefficiently  costly.264  Instead,  the  goal  is  to  attain \\nefficient  levels  of  investment  in  defenses  that  are  better  at  protecting \\nsociety’s  critical  systems  than  current  defenses  are.265  Another  important \\npoint  is  that  cyber-defense  is  not  a  one-size-fits-all  proposition.  Security \\n\\nthreats, \\n\\ncombinations \\n\\nvulnerabilities, \\n\\nmeasures should be tailored to the unique risks faced by specific firms or \\nand \\nof \\nindustries—their \\nconsequences.266  The  strongest,  and  presumably  most  costly,  defenses \\nshould be reserved for the firms that are most vulnerable to cyber-attacks, \\nthat face the most severe threats (e.g., from foreign intelligence services as \\nopposed  to  recreational  hackers),  and  whose  compromise  would  have  the \\nmost devastating consequences for society. Strategically unimportant firms \\nmight  get  by  with  modest  defenses,  whereas  robust  defenses  may  be \\nneeded  for  critical  industries.267  Finally,  what  follows  is  by  no  means  an \\nexhaustive list of possible responses to cyber-insecurity. It is merely a list \\nof  responses  suggested  by  conceiving  of  cyber-security  in  environmental, \\nantitrust,  products  liability,  and  public  health  terms.  Other  solutions, \\nsuggested by other analytical frameworks, may be just as promising. \\n\\nA.  Monitoring and Surveillance \\n\\nEffective  cyber-security  depends  on  the  generation  and  exchange  of \\ninformation.268  An  ideal  system  would  create  and  distribute  vulnerability \\ndata (the holes intruders might exploit to gain access to computer systems), \\nthreat data (the types of malware circulating on the Internet and the types of \\nattacks  firms  have  suffered),  and  countermeasure  data  (steps  that  can  be \\ntaken  to  prevent  or  combat  infection  by  a  particular  piece  of  malicious \\ncode).269  Perhaps  the  best  way  to  collect  this  information  is  through  a \\ndistributed  surveillance  network  akin  to  the  biosurveillance  system  at  the \\nheart of public health law. Companies are unlikely to participate in this sort \\nof arrangement due to fears of liability under antitrust and other laws.270 A \\nsuite  of  measures  is  therefore  needed  to  help  foster  favorable  incentives, \\nincluding subsidies, threats of liability, and offers of immunity. These steps \\nwould  not  guarantee  that  firms  will  collect  and  share  cyber-security  data, \\nbut  they  would  make  such  arrangements  more  viable  than  they  are  at \\npresent. \\n\\nPublic  health  law’s  system  of  distributed  biosurveillance  seems  well \\nsuited to the challenge of gathering and disseminating cyber-security data. \\nLike  health  care  providers  who  diagnose  and  then  report  their  patients’ \\ninfectious diseases, firms could be tasked with monitoring their systems for \\nvulnerabilities  and  intrusions,  then  reporting  their  findings  and  the \\ncountermeasures they have implemented to designated recipients.271 Such a \\n\\n\\nRegulating Cyber-security \\n\\nthan  outsiders  about \\n\\nsystem  would  take  advantage  of  important  information  asymmetries. \\nthe \\nIndividual  companies  often  know  more \\nvulnerabilities in their systems and the types of intrusions they have faced; \\nthey have a comparative advantage in compiling this data.272 The principal \\nalternative—surveillance by a single, central regulator—is unlikely to be as \\neffective.  As  F.A.  Hayek  emphasized,  “the  knowledge  of  the  [economic] \\ncircumstances of which we must make use never exists in concentrated or \\nintegrated  form,  but  solely  as  the  dispersed  bits  of  incomplete  and \\nfrequently  contradictory  knowledge  which  all  the  separate  individuals \\npossess.”273  The  same  is  true  of  cyber-security  data.  A  central  regulator \\nlacks the capacity to examine each device that is connected to the Internet \\nto  determine  its  vulnerabilities,  and  cannot  inspect  every  data  packet \\ntransiting the Internet to determine whether it contains malicious code. And \\neven if the scope of the project was not prohibitively vast, the privacy costs \\nassociated  with  a  central  monitor—especially  a  government  monitor—\\nwould likely be intolerable.274 Instead, the better course would be to rely on \\nindividual firms to gather the relevant information.275 \\n\\nWhile  firms  would  be  responsible  for  the  lion’s  share  of  monitoring, \\nthe  government  still  has  an  important  role  to  play:  providing  especially \\nsensitive companies, such as power companies and ISPs, with information \\nabout  especially  sophisticated  forms  of  malware.  Here,  the  comparative \\nadvantage  is  reversed;  the  government’s  highly  resourceful  intelligence \\nagencies are simply better than the private sector at detecting intrusions by \\nsophisticated  adversaries \\nforeign  militaries  and  developing \\ncountermeasures.276  The  government  can  provide  these  firms  with  the \\nsignatures  of  malware  used  in  previous  attacks,  and  firms  can  use  the \\nsignature  files  to  detect  future  intrusions.  In  2010  the  National  Security \\nAgency began assisting Google in detecting intrusions into its systems. The \\npartnership  was  announced  in  the  wake  of  reports  that  sophisticated \\nhackers, most likely affiliated with China’s intelligence service, had broken \\ninto Google’s systems and collected data about users, including a number \\nof  human  rights  activists.277  The  NSA  reportedly  has  entered  a  similar \\npartnership with a number of large banks.278 \\n\\nlike \\nthe \\n\\nAt least two possibilities exist for how to structure the system used to \\nfirms.  Some \\ndisseminate \\ninformation  compiled  by  private \\ncommentators have called for a central repository of cyber-security data—a \\n“cyber-CDC,”279 as it were. Under such a system, an individual firm would \\nnotify the clearinghouse if it discovers a new vulnerability in its systems, or \\na  new  type  of  malicious  code,  or  a  particular  countermeasure  that  is \\neffective against a particular kind of threat. The repository would analyze \\nthe  information,  looking  for  broader  trends  in  vulnerabilities  and  threats, \\nthen  issue  alerts  and  recommendations  to  other  firms.  This  clearinghouse \\nmight be a government  entity, as in public health law, but it need not be. \\nAn  alternative  architecture  would  be  for  firms  to  exchange  cyber-security \\ninformation  with one another directly, on a peer-to-peer basis, rather than \\nfirst routing it through a central storehouse. One advantage of the peer-to-\\npeer approach is that it may be more resilient. A CDC-type clearinghouse \\nwould  be  an  attractive  target  for  cyber-adversaries,  and  the  entire  system \\nwould fail if it were compromised. \\n\\nDistributed  surveillance  may  be  an  even  better  fit  for  cyber-security \\nthan for public health, for several reasons. First, malicious computer code \\ncan  often  be  detected  more  quickly  than  biological  pathogens,280  which \\nmeans  that  countermeasures  can  be  developed  and  put  in  place  rapidly. \\nBiosurveillance  can  be  slow  because  the  incubation  period  for  certain \\ndiseases—the  amount  of  time  between  when  a  disease  is  contracted  and \\nwhen its symptoms first manifest—can be days or weeks. By contrast, it is \\npossible  to  detect  known  malware  in  real  time,  as  the  code  is  passing \\nthrough a company’s system. Of course, malware detection is imperfect.281 \\nDeep  packet  inspection  and  other  forms  of  network  monitoring  typically \\nwork by comparing streams of data against signatures of known malicious \\ncode.282 These systems are only as good as their underlying definitions files. \\nIf there is no signature for a particular type of malware, chances are it will \\nnot  be  detected.  As  a  result,  sophisticated  “zero-day”  attacks—so  called \\nbecause they occur before the first day on which security personnel become \\naware  of  them  and  begin  to  develop  countermeasures—may  well  go \\nunnoticed.283  Former  CIA  director  Jim  Woolsey  emphasizes  that  “[i]f  you \\ncan’t deal with a zero-day attack coming from a thumb drive . . . you have \\nnothing.”284  Of  course,  these  are  the  very  sorts  of  attacks  likely  to  be \\nlaunched  by  sophisticated  adversaries  like  foreign  intelligence  services. \\nPublic  health  law’s  biosurveillance  framework  thus  is  probably  better  at \\n\\n\\nRegulating Cyber-security \\n\\ndetecting intrusions of low to modest complexity than those undertaken by \\nforeign governments. \\n\\nSecond,  cyber-threat  monitoring  has  the  potential  to  raise  fewer \\nprivacy  concerns  than  biosurveillance.285  Health  care  providers  often  give \\nauthorities  sensitive  information  about  individual  patients,  such  as  their \\nidentifiable \\nnames,  Social  Security  numbers,  and  other  personally \\ninformation,  as  well  as  the  diseases  they  have  contracted.286  A  properly \\ndesigned  cyber-monitoring  system  need  not  compile  and  disseminate \\ninformation of the same sensitivity. Collection and sharing could be limited \\nto information about the incidence and prevalence of known malware. The \\nfact that the “ILoveYou” worm has infected a particular system exposes a \\ngreat  deal  less  personal  information,  and  thus  raises  weaker  privacy \\nconcerns, than the fact that a particular patient suffers from HIV or breast \\ncancer. \\n\\nThe challenge, then, is to provide firms with incentives to collect and \\ndisseminate  cyber-security  information.287  At  present  companies  have \\nstrong disincentives to do so, partly due to fears of legal liability,288 but also \\nbecause  of  concerns  about  compromising  trade  secrets,  losing  customer \\ngoodwill, and reputational harms.289 Public health law facilitates collection \\nand sharing through both direct regulation, such as state statutes requiring \\nhealth  care  providers  to  notify  authorities  about  patients  who  have \\ncontracted  various  infectious  diseases,  and  less  coercive  alternatives.290  A \\nsimilar  arrangement  might  be  adopted  for  cyberspace.  The  government \\ncould require firms to gather information about the vulnerabilities in their \\nsystems, the types of attacks they have suffered, and the countermeasures \\nthey  have  used  to  combat  malware,  and  then  to  disseminate  the  data  to \\ndesignated  recipients.291  Imposing  such  an  obligation  would  not  eliminate \\ncompanies’  incentives  to  withhold  cyber-security  data.  It  would  simply \\nmake it more costly for them to do so, where costs include the sanctions for \\nhoarding discounted by the probability of punishment. Firms will be more \\nlikely  to  collect  and  share  cyber-security  data,  but  some  will  still  find  it \\nadvantageous to hoard. \\n\\nThere is also a less coercive, and probably more effective, alternative. \\nCyber-security data is a sort of public good, and economic theory predicts \\n\\n\\nthat  it  will  be  underproduced.292  Firms  might  be  offered  subsidies  to \\nencourage them to compile and exchange the needed information.293 These \\nbounties  could  be  direct  payments  from  the  government,  tax  credits,  or \\ndeductions. They could also take the form of enhanced intellectual property \\nprotections  for  the  cyber-security  information  firms  generate.  If  the \\nsubsidies  are  large  enough,  firms  will  have  an  incentive  not  just  to  report \\nthe data they have already compiled, but to invest in discovering previously \\nunknown vulnerabilities, threats, and countermeasures.294 \\n\\nAntitrust law can also help recalibrate firms’ incentives.295 Antitrust is \\noften  skeptical  of  information  sharing  and  other  forms  of  cooperation \\namong  competitors.296  But  exchanges  of  cyber-security  data  can  enhance \\nconsumer  welfare  by  preventing  attacks  from  taking  place  or  at  least \\nmitigating their effects.297 One way to incentivize companies to cooperate is \\nto  alleviate  their  apparently  widespread  fears  of  antitrust  liability  through \\njudicial, administrative, or legislative action. Federal courts could expressly \\ndiscard the per se approach and substitute a rule of reason when reviewing \\nprivate sector agreements to share cyber-security data or to adopt common \\nsecurity  protocols.  Instead,  arrangements  would  be  judged  on  a  case-by-\\ncase  basis,  and  would  stand  or  fall  based  on  the  degree  to  which  they \\nactually advance or hinder consumer welfare. This would reduce the risk of \\nfalse  positives—the  danger  that  the  coarse-grained  per  se  rule  might \\ninvalidate  a  cyber-security  initiative  that  is  actually  welfare-enhancing. \\nWhile  this  approach  shows  promise,  it  also  carries  some  significant \\ndrawbacks.  A  judicial  response  may  not  sufficiently  remove  legal \\nuncertainty.  Companies  will  not  always  be  able  to  predict  whether \\nreviewing  courts  will  sustain  or  invalidate  a  proposed  cyber-security \\nventure, and the risk of liability will dissuade firms from forming them.298 \\nIn  short,  the  uncertain  prospects  of  ex  post  judicial  approval  may  not \\nprovide firms with enough assurance ex ante. \\n\\nA  more  promising  approach  would  be  for  administrative  agencies  to \\nsponsor  cyber-security  exchanges,  as  some  in  Congress  have  proposed.299 \\nAgencies with special expertise in cyber-security (such as the NSA and the \\nDepartment of Homeland Security) could partner with the agencies that are \\n\\nRegulating Cyber-security \\n\\nresponsible  for  enforcing  federal  antitrust  laws  (the  Federal  Trade \\nCommission  and  the  Justice  Department’s  antitrust  division)  to  establish \\nfora  in  which  companies  could  establish  common  security  standards  and \\nexchange information. The government’s participation in these fora would \\noffer assurances that they are being used for legitimate purposes and not as \\nvehicles  for  anticompetitive  conduct.  From  the  standpoint  of  participating \\nfirms,  this  approach  is  advantageous  because  it  offers  them  de  facto \\nantitrust immunity.300 It is unlikely that an agency such as the FTC or DOJ \\nthat sponsored a cooperative cyber-security arrangement later would go to \\ncourt to have it invalidated. And while the blessing of these agencies does \\nnot formally bind other potential plaintiffs, such as state attorneys general \\nor private parties, their determination that a proposed venture is permissible \\nunder  federal  antitrust  laws  probably  would  receive  a  healthy  dose  of \\njudicial  deference.  Government  sponsorship  has  another  advantage:  it  can \\nhelp  solve  the  coordination  and  free-rider  problems  associated  with \\ncollective  action.301  A  regulator  can  mitigate  these  tendencies  by  coercing \\nfirms into participating in the forum and complying with its requirements; \\nit also can withhold the forum’s benefits from firms that shirk. \\n\\nA  third  alternative  would  be  for  Congress  to  enact  a  cyber-security \\nexception  to  the  antitrust  laws.302  The  upside  of  a  legislative  carve-out  is \\nthat  it  would  eliminate  virtually  all  risk  of  liability  and  thus  remove  one \\npowerful  disincentive  for  companies  to  cooperate  on  cyber-security \\ninitiatives.  Ideally,  such  a  measure  would  be  narrowly  tailored  to  the \\nprecise  sort  of  interfirm  cooperation  that  is  desired—the  exchange  of \\nvulnerability, threat, and countermeasure information and the development \\nof  common  security  protocols.  In  other  words,  the  exemption  would  be \\npegged  to  specific  conduct,  and  would  not  immunize  entire  industries  (as \\nused  to  be  the  case  with  major  league  baseball303).  A  broader  exception \\nwould offer few additional cyber-security gains and could open the door to \\nanticompetitive conduct. \\n\\nWe  also  might  consult  products  liability  law  for  ideas  on  how  to \\nincentivize companies to exchange cyber-security data. Firms do not have \\nstrong incentives to search for vulnerabilities in their systems or products, \\nand  ISPs  are  reluctant  to  monitor  network  traffic  for  malicious  code.304 \\nLawmakers  might  use  a  combination  of  carrots  and  sticks  to  recalibrate \\nthese incentives. Offers of immunity would increase companies’ expected \\n\\n\\n \\n\\x0cN O R T H W E S T E R N  U N I V E R S I T Y  L A W  R E V I E W \\n\\nbenefits  of  compiling  and  sharing  cyber-security  data;  threats  of  liability \\nwould increase their expected costs of failing to do so.305 \\n\\nConsider  the  carrots  first.  Firms  could  be  offered  immunity  from \\nvarious  laws  that  presently  inhibit  them  from  collecting  and  exchanging \\ncertain  information  about  cyber-vulnerabilities  and  threats.  In  particular, \\nCongress  could  expand  the  service-provider  exception  to  the  Federal \\nWiretap  Act’s  general  ban  on  intercepting  electronic  communications.306 \\nAnd  the  exception  could  be  broadened  to  authorize  ISPs  to  monitor \\nnetwork traffic for malicious code that threatens their subscribers’ systems, \\nnot just their own. Congress could also authorize ISPs to notify customers \\nwhose  systems  are  found  to  be  infected  by  malware.307  It  further  could \\nexpressly preempt any state laws to the contrary. This would foreclose any \\nclaims that  monitoring for malware violates state  privacy law or breaches \\nthe  terms  of  service  between  an  ISP  and  its  subscribers.  In  all  cases, \\neligibility for these forms of immunity could be conditioned on information \\nsharing: a company would not be able to take advantage of the safe harbor \\nunless  it  shared  the  information  it  discovered  with  other  firms.  The  result \\nwould  be  to  foster  strong  incentives  to  exchange  data  about  threats  and \\nvulnerabilities. \\n\\nAs  for  the  sticks,  below  I  propose  modifying  tort  law’s  traditional \\neconomic  loss  doctrine  in  the  cyber-security  context.308  Firms  that \\nimplement  approved  security  standards  would  enjoy  immunity  from \\nlawsuits seeking redress for injuries sustained from an intrusion; companies \\nthat disregard the protocols would be subject to lawsuits for any resulting \\ndamages. Under such a scheme, a company that implemented the standards \\nmight  have  its  immunity  stripped  if  it  failed  to  share  information  about \\nknown weaknesses in its systems or products. As for firms that fail to adopt \\nthe security standards, the lack of information sharing could be treated as \\nan  aggravating  factor;  extra  damages  could  be  imposed  on  firms  that  are \\naware  of  vulnerabilities  or  threats  but  fail  to  share  that  information  with \\nother  companies.  This  series  of  tiered  penalties  would  produce  marginal \\ndeterrence;  firms  would  have  good  reason  not  only  to  implement  the \\napproved  security  standards,  but  also  to  exchange  the  threat  and \\nvulnerability information on which those protocols depend. \\n\\nB.  Hardening Targets \\n\\nA  second  objective  for  a  cyber-security  regime  is  to  harden  critical \\nsystems  against  attack  by  developing  effective  security  protocols.309  The \\n\\n\\nRegulating Cyber-security \\n\\ngoal  of  such  measures  is  to  prevent  cyber-intruders  from  harming  these \\nsystems at all, as opposed to limiting the amount of damage intrusions can \\ndo;  the  objective  is  to  increase  impregnability  as  opposed  to  their \\nsurvivability.310  Of  course,  some  cyber-attacks  inevitably  will  succeed,  so \\nenhancing survivability, as discussed below,311 is an essential goal as well. \\nThe  regulatory  disciplines  surveyed  above  suggest  various  techniques  for \\nencouraging companies to adequately secure their networks. Environmental \\nlaw  suggests  the  need  for  industry-wide  security  standards;  these  rules \\nshould be developed through collaborative partnerships between regulatory \\nagencies  and  private  firms,  rather  than  imposed  via  direct  regulation. \\nProducts liability law suggests that pairing threats of liability with offers of \\nimmunity  can  incentivize  firms  to  implement  the  security  standards.  And \\npublic  health  law’s  use  of  mandatory  vaccinations  might  be  adapted  by \\nincentivizing firms to take certain minimum steps to secure their systems. \\nAgain, different firms  and industries face different vulnerabilities, threats, \\nand consequences, so the resulting security standards should be calibrated \\nto the particular conditions in individual industries. \\n\\nRegulators  could  improve  critical  systems’  defenses  by  establishing \\nand  enforcing  new  cyber-security  protocols  akin  to  the  environmental \\nregulations  that  restrict,  say,  the  amount  of  sulfur  dioxide  a  given  source \\nmay emit into the atmosphere.312 Regulatory standards can help manage the \\nnegative externalities that result when a company suffers a cyber-intrusion. \\nIt should be emphasized at the outset that the specific content of any cyber-\\nsecurity standards is well beyond the scope of this Article.313 My focus here \\n\\n \\n\\x0cN O R T H W E S T E R N  U N I V E R S I T Y  L A W  R E V I E W \\n\\nto  use \\n\\nTurning \\n\\nis  not  on  the  technical  feasibility  or  policy  advantages  of  any  particular \\ndefensive  measure.  Instead,  the  focus  of  this  Article  is  establishing \\nregulatory mechanisms by which new cyber-security standards—whatever \\ntheir content—may be adopted. \\nto \\n\\nthat  question,  one  obvious  option  would  be  for \\ntraditional  “command  and  control” \\nadministrative  agencies \\nregulation—to issue a set of mandatory standards and incentivize firms to \\ncomply  with  them  by  threatening  civil  or  criminal  penalties.314  This  is  a \\nfairly  common  approach  in  environmental  law,315  and  some  scholars  have \\nurged  the  government  to  adopt  it  here.  Neal  Katyal  argues  that  “direct \\ngovernment  regulation”  of  cyber-security  “is  the  best  solution,”  and  calls \\nfor regulatory agencies to issue “the equivalent of building codes to require \\nproper  design  and  performance  standards  for  software.”316  Likewise,  a \\nprominent  think  tank  argues  that  “the  federal  government  bears  primary \\nresponsibility” for cyber-security and that “it is completely inadequate” to \\nleave the matter “to the private sector and the market.”317 Some have even \\ncalled  for  the  federal  government  to  take  over  certain  sectors  of  the \\neconomy in the name of cyber-security. According to an ABA task force, \\n“government  may  also  need  to  ‘semi-nationalize’  some  sectors  (like  the \\nelectricity  grid)  where  isolation  is  not  an  option  and  the  adverse \\nconsequences  of  certain  low  probability  events  are  likely  to  be  very \\nhigh.”318  It  isn’t  steel  mills,  but  Harry  Truman  would  have  admired  the \\nproposal.319 \\n\\nTraditional  command-and-control  regulation  seems  ill  suited  to  the \\ntask of securing the nation’s cyber-infrastructure. The better course would \\nbe  to  involve  the  firms  that  operate  these  assets  in  establishing  and \\nimplementing  new  security  protocols.  Private  sector  participation—an \\napproach  sometimes  seen  in  environmental  law—is  desirable  for  several \\nfamiliar  reasons.  First,  information  asymmetries:  companies  often  know \\nmore than regulators about the vulnerabilities in their systems, the types of \\n\\n96,  at  34,  or  moving  to  an  entirely  new  Internet  architecture  (such  as  IPv6)  in  which  anonymity  is \\nreduced and user activity is capable of being traced. BAKER, supra note 24, at 231–32; LESSIG, supra \\nnote 67, at 45, 54; POST, supra note 94, at 84; Bambauer, Conundrum, supra note 12, at 590, 601; Frye, \\nsupra note 153, at 354; Katyal, Digital Architecture, supra note 15, at 2269–70; Taipale, supra note 96, \\nat 31. \\n\\nRegulating Cyber-security \\n\\nintrusions  they  have  faced,  and  the  most  effective  countermeasures  for \\ndealing  with  those  threats.320  Second,  a  related  concern  is  that  regulators \\nprobably  lack  the  knowledge  necessary  to  determine  the  socially  optimal \\nlevel  of  cyber-breaches  and  set  the  security  standards  accordingly.321  The \\nmarket, through the price system, is capable of aggregating and processing \\nthis  information  in  a  way  that  central  planners  cannot.  Third,  rapid \\ntechnological change makes it difficult for regulators to formulate durable \\nsecurity  rules.322  Vulnerabilities,  threats,  and  countermeasures  are  in  a \\nconstant state of flux, and regulatory standards cannot keep pace with these \\ndevelopments. Notice-and-comment rulemaking rarely takes less than two \\nyears,  sometimes  much  longer,323  and  the  rules  likely  would  be  obsolete \\nbefore the ink in the Federal Register was dry. Fourth, there is a risk that \\ngovernment  protocols  will  stifle  innovation.324  If  regulatory  agencies \\npromulgate  a  set  of  mandatory  standards,  regulated  firms  will  have  less \\nreason  to  search  for  newer  and  more  efficient  countermeasures;  they  will \\nsimply implement the government’s directives. \\n\\nWhat  specific  role  should  private  firms  have  in  developing  and \\nimplementing  cyber-security  standards? At  least  two  possibilities  come  to \\nmind. First, regulators could practice a form of “delegated regulation”325 in \\nwhich  they  mandate  broad  security  goals  and  establish  the  penalties  for \\nfalling  short,  then  leave  it  up  to  companies  to  achieve  those  goals  in \\nwhatever manner they deem most effective.326 Regulation by delegation is \\nsaid  to  be  appropriate  where  administrative  agencies  have  the  capacity  to \\n“identify specific outcomes but cannot easily codify in generally-applicable \\nrules  the  means  for  achieving  them.”327  Environmental  law  sometimes \\nfollows  this  approach,  as  do  other  fields  such  as  food  safety328  and \\n\\n\\x0cN O R T H W E S T E R N  U N I V E R S I T Y  L A W  R E V I E W \\n\\nsecurities  regulation.329  For  instance,  the  EPA’s  acid  rain  program  affords \\ncompanies  a  measure  of  discretion  in  deciding  how  to  comply  with  their \\nobligation  under  the  Clean  Air  Act  to  reduce  various  emissions.  And  the \\nEPA’s “bubble” approach to the Clean Air Act allowed polluters to offset \\nincreased emissions from one source with decreased emissions from other \\nsources,  providing  them  with  an  incentive  to  experiment  with  new \\ntechnologies  that  could  reduce  emissions  at  lower  cost.330  (Note  that  both \\nprograms involve discretion in implementing numerical values rather than, \\nas  would  be  true  in  the  cyber  context,  substantive  standards.)  Delegated \\nregulation  seems  a  good  fit  for  cyber-security,  though  not  a  perfect  one. \\nGiving  companies  discretion  to  implement  the  government’s  security \\nstandards  achieves  three  of  the  four  benefits  of  private  action  mentioned \\nabove: it avoids some problems with information asymmetries,  allows for \\nflexibility  in  reacting  to  fast-changing  technologies,  and  promotes  rather \\nthan  stifles  private  sector  innovation.  However,  difficulties  would  remain \\nwith  formulating  the  standards.  Regulators  probably  lack  the  knowledge \\nneeded to determine the socially optimal level of cyber-breaches and set the \\nsecurity standards accordingly. \\n\\nAn  alternative  would  be  a  form  of  “enforced  self-regulation”331  in \\nwhich  private  companies  develop  new  cyber-security  protocols  in  tandem \\nwith the government.332 These requirements would not be handed down by \\nadministrative  agencies,  but  rather  would  be  developed  through  a \\ncollaborative partnership in which both regulators and regulated would play \\na  role.  In  particular,  firms  might  prepare  sets  of  industry-wide  security \\nstandards.  The  National  Industrial  Recovery  Act,  famously  invalidated  by \\nthe  Supreme  Court  in  1935  on  nondelegation  grounds,  contained  such  a \\nmechanism,333 and today the energy sector develops reliability standards in \\nthe  same  way.334  Or  agencies  could  sponsor  something  like  a  negotiated \\nrulemaking  in  which  regulators,  firms,  and  other  stakeholders  forge  a \\nconsensus on new security protocols.335 In either case, agencies would then \\nensure  compliance  through  standard  administrative  techniques  like  audits, \\ninvestigations, and enforcement actions.336 This approach would achieve all \\nfour  of  the  benefits  of  private  action  mentioned  above:  it  avoids  some \\n\\nRegulating Cyber-security \\n\\nproblems  with  information  asymmetries,  takes  advantage  of  distributed \\nprivate  sector  knowledge  about  vulnerabilities  and  threats,  accommodates \\nrapid  technological  change,  and  promotes  innovation.  On  the  other  hand, \\nallowing firms to help set the standards that will be enforced against them \\nmay increase the risk of regulatory capture—the danger that agencies will \\ncome to promote the interests of the companies they regulate instead of the \\npublic’s  interests.337  The  risk  of  capture  is  always  present  in  regulatory \\naction,  but  it  is  probably  even  more  acute  when  regulated  entities  are \\nexpressly invited to the decisionmaking table.338 \\n\\nProducts  liability  law  likewise  offers  several  strategies  for  hardening \\ncritical  infrastructure  against  cyber-attacks.  The  prospect  that  a  company \\nmight be required to pay money damages to those who have been injured \\nby  an  attack  on  their  systems  or  products  would  internalize  costs  that  are \\nnow  externalized  onto  others.  Liability  thus  would  incentivize  firms  to \\noffer  goods  (such  as  computer  software)  and  services  (such  as  online \\nbanking)  that  are  more  secure.339  Thanks  to  the  economic  loss  doctrine, \\ncompanies  presently  face  little  risk  of  liability  for  the  injuries  that  result \\nfrom their failure to prevent cyber-intrusions.340 Modifying this default rule \\nof de facto immunity could help foster incentives for firms to improve their \\ncyber-defenses. \\n\\nWhat could a recalibrated liability regime for cyber-security look like? \\nAgain, a combination of carrots and sticks could be used. Congress might \\nabolish  the  economic  loss  doctrine  for  injuries  that  result  from  a  given \\ncompany’s  wrongful  failure  to  prevent  a  cyber-attack.  In  its  place, \\nlawmakers  could  substitute  a  regime  that  imposes  liability  or  offers \\nimmunity based on what steps a company has taken to secure its products \\nor systems. As for the carrots, firms that implement the security standards \\nthat are developed in tandem with regulators, but nevertheless suffer cyber-\\n\\n \\n\\x0cN O R T H W E S T E R N  U N I V E R S I T Y  L A W  R E V I E W \\n\\nattacks,  could  be  offered  immunity  from  lawsuits  seeking  redress  for  the \\nresulting  damages.341  This  cyber  “safe  harbor”  could  extend  not  just  to \\npurely  economic  injuries  (for  which  firms  currently  enjoy  de  facto \\nimmunity) but also to physical injuries and the associated economic harms \\n(for which firms presently may be held liable). The scope of immunity thus \\nwould be broader than under current law, but it would only be available to \\ncompanies  that  take  the  desired  steps  to  improve  their  cyber-defenses. \\nLawmakers  might  use  the  Safety  Act  as  a  model.342  The  Support  Anti-\\nTerrorism  by  Fostering  Effective  Technologies  Act  of  2002  grants \\nimmunity to firms that sell certain antiterrorism goods and services, so long \\nas  they  comply  with  various  standards,  including  a  requirement  that  they \\ncarry liability insurance.343 \\n\\nAs  for  the  sticks,  firms  that  fail  to  implement  the  agreed  security \\nmeasures  and  then  suffer  cyber-attacks  could  be  held  liable  for  the  full \\nrange  of  injuries  that  result  from  the  intrusions.  The  severity  of  the \\ndamages  could  be  pegged  to  the  severity  of  their  misconduct,  thereby \\nachieving marginal deterrence. A company that fails to adopt the approved \\nsecurity standards might be made to pay compensatory damages or even a \\nsmaller  fixed  sum  set  by  statute,  but  a  company  whose  conduct  is  more \\negregious—one that fails to share information about known vulnerabilities \\nor  threats,  for  instance—might  be  eligible  for  exemplary  damages.  For \\ninspiration, lawmakers might look to the Gramm–Leach–Bliley Act, which \\nimposes liability on banks that fail to protect consumer data,344 contributing \\nto  the  financial  services  sector’s  relatively  robust  defenses  against  cyber-\\nintrusions.345 Such a liability regime would increase both a firm’s expected \\nbenefits  of  implementing  the  security  protocols,  as  well  as  the  expected \\ncosts of defying them. \\n\\nCivil  liability  would  also  help  promote  a  more  robust  market  for \\ncyber-security insurance. Insurers can have a profound effect on the steps \\nfirms  take  to  secure  their  systems  and  products  against  cyber-intrusions, \\nbecause  they  can  insist  that  companies  implement  various  security \\nmeasures  as  a  condition  of  coverage  or  charge  higher  premiums  to  those \\nthat  do  not.346  Insurance  companies  provide  a  sort  of  second-order \\nregulation, enforcing cyber-security standards by refusing to bear the losses \\nof  firms  with  poor  records  or  engaging  in  price  discrimination  against \\nthem.  The  result  is  to  provide  the  insured  with  financial  incentives  to \\nimplement the defenses their insurers are calling for. These incentives have \\n\\nRegulating Cyber-security \\n\\nalready  borne  fruit.  According  to  Bruce  Schneier,  “[f]irewalls  are \\nubiquitous because auditors started demanding firewalls. This changed the \\ncost equation for businesses. The cost of adding a firewall was expense and \\nuser  annoyance,  but  the  cost  of  not  having  a  firewall  was  failing  an \\naudit.”347  Enforcement  by  insurers  also  can  decrease  the  government’s \\nenforcement costs; there is less need for regulators to verify that firms are \\ncomplying  with  the  agreed  security  standards  if  insurers,  pursuing  their \\nown financial interests, are already doing so. \\n\\ninsurance \\n\\nAt  present, \\n\\nthe  market  for  cyber-security \\n\\nis  fairly \\nunderdeveloped  (though  some  insurance  companies  have  begun  to  offer \\ncoverage348), in part because firms currently face very little risk of liability \\nfor injuries resulting from cyber-attacks on their systems or products; why \\ninsure when one is effectively immune?349 The prospect of civil liability is a \\ncritical first step in creating a viable market for cyber-security insurance.350 \\nLawmakers might further stimulate the market by offering various kinds of \\nsubsidies. For instance, the government  might provide insurers with more \\ninformation \\nthe \\nincidence,  prevalence,  and  consequences  of  various  sorts  of  malicious \\ncode. Insurers could use this data to more accurately assess the probability \\nof  cyber-intrusions  and  their  potential  costs,  which  would  help  in  setting \\npremiums.351  Or  the  government  might  offer  tax  benefits  to  insurers  that \\noffer cyber-security policies. Or it might require certain companies, such as \\nstrategically  important  firms  like  public  utilities  or  companies  that  supply \\ngoods or services to the government, to carry cyber-security insurance. \\n\\n(including,  perhaps,  classified \\n\\ninformation)  about \\n\\nPublic  health  law  suggests  a  final  approach  to  hardening  critical \\ninfrastructure. Most states have enacted laws requiring schoolchildren to be \\nvaccinated  against  various  diseases,352  and  lawmakers  might  adopt  similar \\nmeasures  for  cyberspace.  In  both  contexts,  compulsory  inoculation  helps \\nreduce  negative  externalities  and  foster  positive  ones.  Just  as  an \\nunvaccinated  child  might  infect  classmates  with  a  pathogen,  a  computer \\nsystem that lacks  effective cyber-defenses  might be  commandeered into a \\nbotnet.  In  addition,  a  child  who  has  been  vaccinated  contributes  to  herd \\nimmunity  and  thereby  decreases  the  probability  that  other,  unvaccinated \\nstudents  will  contract  the  disease.  In  the  same  way,  companies  that  adopt \\n\\neffective cyber-defenses make it less likely that their systems will be used \\nto transmit malware to other users. \\n\\nWhat  would  mandatory  vaccination  look  like  in  cyberspace?  Several \\nvariants exist. The most coercive approaches involve direct regulation, akin \\nto  a  requirement  that  all  citizens  receive  a  particular  vaccine.  One  option \\nwould  be  for  lawmakers  to  mandate  that  every  computer  user  (or,  less \\ndramatically,  firms  in  particularly  sensitive  industries  such  as  the \\ntelecommunications  sector)  install  certain  security  products  on  their \\nsystems,  such  as  antivirus  software  or  firewalls.  Think  of  it  as  a  digital \\nequivalent of the Patient Protection and Affordable Care Act’s “individual \\nmandate”  to  purchase  health  insurance.353  An  alternative  would  be  for  the \\ngovernment  to  require  ISPs  to  provide  their  customers  with  a  specified \\nsecurity  software  package.354  ISPs  presumably  would  pass  on  the  costs  of \\nthe  software  to  their  subscribers,  so  the  effect  would  be  the  same  as  the \\nindividual mandate approach—users would be made to pay a premium for \\na  security  product \\nthe \\ngovernment could compensate the ISPs for the costs of making the security \\npackage  available  to  their  subscribers.  In  that  event,  the  scheme  would \\nrepresent  a  (likely  regressive)  wealth  transfer  from  taxpayers  who  do  not \\nuse computers to those who do. \\n\\nthey  previously  declined \\n\\nto  purchase.  Or, \\n\\nAnother  less  coercive  set  of  options  would  withhold  or  offer  certain \\nbenefits  to  incentivize  security  improvements;  they  are  the  equivalent  of \\nmaking vaccination a condition of eligibility to attend public schools. The \\nability to access the Internet, as opposed to local or proprietary networks, is \\na  valuable  benefit  of  the  service  one  receives  from  an  ISP—for  many \\nsubscribers  it  is  the  most  valuable  benefit  ISPs  offer—and  it  might  be \\nconditioned  on  a  subscriber  taking  steps  to  improve  cyber-security.  In \\nparticular, regulators could direct ISPs to refuse to route users’ traffic to the \\npublic  Internet  unless  they  are  able  to  verify  that  the  users  have  installed \\nspecified  security  software  on  their  systems.355  Alternatively,  government \\nweb sites could refuse any traffic sent from a system that has not adopted \\nspecified  security  measures.  Users  thus  would  be  unable  to,  for  example, \\npost comments in an online rulemaking docket or check the status of a tax \\nrefund  unless  they  adopted  the  security  measures.  This  sort  of  measure \\ndepends on the ability to authenticate the identity of the sender, as well as \\nthe presence of various cyber-defenses on its system. That capability does \\nnot  presently  exist,  because  the  TCP/IP  routing  protocol  is  unconcerned \\nwith the sender’s identity,356 though some scholars believe an authenticated \\nInternet  is  inevitable.357  Finally,  the  government  could  offer  tax  credits  or \\n\\n\\nRegulating Cyber-security \\n\\ndeductions  to  firms  or  individual  users  that  install  the  specified  security \\nsoftware on their systems—another (likely regressive) wealth transfer. \\n\\nC.  Survivability and Recovery \\n\\nThe  third  thing  an  ideal  cyber-security  regime  would  do  is  promote \\nresilience, thus limiting the amount of damage attackers can do to critical \\ninfrastructure.  Here, \\nthe  goals  are  survivability  and  recovery,  not \\nimpregnability.358  As  Derek  Bambauer  emphasizes,  “[m]itigation,  not \\nprevention,  is  the  key.”359  The  need  to  build  resilience  into  the  nation’s \\ncyber-defenses  is  a  concession  to  reality;  no  matter  how  good  one’s \\ndefenses are, some attackers will be able to breach them. As a result, it is \\nnot  enough  to  try  to  prevent  attacks  altogether.  It  is  also  necessary  to \\nminimize the amount of harm that the inevitably successful intrusions can \\ndo, and to restore victims to the status quo ante as quickly as possible. \\n\\nPublic health law offers several strategies for improving resilience. In \\nrealspace, quarantine and isolation aim at minimizing the harm a pathogen \\ncan do; once an outbreak is underway, we want to contain the disease and \\nlimit the number of people to whom it can spread. Quarantine and isolation \\nmight  be  adapted  for  cyberspace—where  the  goal  is  to  prevent  malicious \\ncode  from  infecting  more  machines—in  any  number  of  ways.  The  most \\nstraightforward approach would be for authorities, in the event of a cyber-\\nattack,  to  order  systems  that  are  known  or  suspected  to  be  infected  with \\nmalware to temporarily disconnect from the Internet. While in quarantine, \\nthe systems could be inspected to see if they are in fact carrying malicious \\ncode. If not, they could be reconnected; if so, they could be repaired. The \\nanalogy  to  public  health  law  is  fairly  exact:  separation  of  the  infected, \\nwhether physical or virtual, prevents them from spreading the contagion to \\nothers  and  presents  an  opportunity  for  treatment.  While  potentially \\neffective,  this  approach  has  a  significant  drawback—legitimate  users  will \\nbe  unable  to access  the  infected  system  while  it  is  offline.  Putting  a  bank \\ninto  cyber-quarantine  does  not  just  keep  hackers  from  stealing  money,  it \\nalso  keeps  a  customer  from  logging  on  to  pay  a  credit  card  bill.  A  less \\ndrastic way of preventing the spread of malware would be to isolate traffic \\nrather  than  systems.  Infected  systems  would  remain  connected  to  the \\nInternet,  but  authorities  could  use  or  require  firms  to  use  deep  packet \\ninspection  to  determine  if  the  data  the  systems  are  sending  and  receiving \\ncontain malware. If a given packet is found to be carrying malicious code, \\nit could be blocked; if not, it would be allowed to continue on its way. The \\npublic  health  analogy  is  allowing  a  man  infected  with  SARS  to  leave  an \\nisolation facility and go about his business while wearing a surgical mask \\nthat  intercepts  the  respiratory  droplets  through  which  the  virus  is  spread. \\nThe virtue of this finer-grained variant is that it allows legitimate users to \\n\\n\\x0cN O R T H W E S T E R N  U N I V E R S I T Y  L A W  R E V I E W \\n\\ncontinue to access an infected system even as attackers are prevented from \\nusing it for their malign purposes; the hackers are thwarted, but customers \\ncan  still  access  their  accounts,  although  perhaps  a  bit  more  slowly  than \\nusual. On the other hand, traffic quarantines will only be as effective as the \\npacket  sniffers  and  malware  signature  files  on  which  they  rely,  and \\nsophisticated adversaries might be able to defeat both. \\n\\nas \\n\\nthe \\n\\nsuch \\n\\ngrid, \\n\\npower \\n\\nfinancial \\n\\ninstitutions, \\n\\nAnother  more  controversial  set  of  options  involves  preventive \\nquarantine—separating  systems  that  have  not  been  infected  but  that  are \\nvulnerable. This approach would turn public health law on its head: rather \\nthan  isolating  the  sick,  authorities  would  isolate  the  healthy.  The  most \\naggressive variant would require a select group of strategically significant \\nfirms, \\nand \\ntelecommunications carriers, to temporarily disconnect from the Internet if \\na  cyber-attack  takes  place.360  Senator  Nelson  Rockefeller  introduced \\nlegislation  along  these  lines  in  2009,361  but  critics  denounced  it  as  an \\n“Internet Kill Switch.”362 Preventive quarantine would be a fairly effective \\nway  of  preventing  malware  from  spreading  to  critical  infrastructure \\nbecause  a  system  that  isn’t  on  the  Internet  can’t  contract  a  virus  that \\nspreads online. But it wouldn’t be infallible. Even “air gapped” systems—\\nthose  that  are  physically  separated  from  the  Internet363—are  vulnerable  to \\ninfection via USB devices and other removable  media.364 A disconnection \\nrequirement  could  also  prove  quite  costly:  the  affected  systems  would  be \\nunavailable to legitimate users for as long as the order remained in effect. \\nThere is also a risk that regulators might pull the disconnection trigger too \\nreadily.  As  an  alternative  to  a  strict  disconnection  requirement,  regulators \\nmight  direct  strategically  significant  firms \\nimplement  security \\ncountermeasures  of  their  own  devising  in  the  event  of  a  cyber-attack. \\nSenator  Joseph  Lieberman  introduced  legislation  along  these  lines  in \\n2010,365  and  it  likewise  was  denounced  as  a  kill  switch.366  Whatever  the \\ncontent of these security protocols—encrypting data to prevent its theft, for \\n\\nto \\n\\nRegulating Cyber-security \\n\\ninstance,  or  requiring  users  to  authenticate  themselves  before  gaining \\naccess to the system—they could be established through the collaborative \\nregulatory partnership described above.367 An even more modest version of \\npreventive  quarantine  would  be,  as  above,  to  segregate  traffic  rather  than \\nentire systems. In the event of a cyber-attack, packet sniffers might be used \\nto inspect all traffic that is sent to and from designated systems. This would \\nallow  the  systems  to  continue  to  operate  more  or  less  as  usual,  though \\nperhaps at a cost of less security. \\n\\nAnother  important  goal  is  to  ensure  that  critical  systems  are  able  to \\ncontinue functioning during a cyber-attack and recover quickly thereafter. \\nOne  way  to  achieve  this  is  to  build  systems  with  excess  capacity—to \\ninclude  more  capabilities  than  a  firm  needs  for  its  day-to-day  operations, \\nwhich  can  be  held  in  reserve  and  called  into  service  if  an  attack  takes \\nplace.368  In  particular,  regulators  might  require  certain  companies  to  build \\ntheir systems with excess bandwidth. A “strategic reserve of bandwidth” is \\nan especially useful countermeasure for defending against denial-of-service \\nattacks;369  if  a  company’s  servers  are  being  overwhelmed,  the  reserve \\nbandwidth can be brought into service to process the requests. Regulators \\nalso  might  require  certain  companies  to  maintain  redundant  data  storage \\ncapabilities. These firms might routinely back up their data to servers that \\nare  dispersed  both  geographically  and  in  network  terms.  If  a  cyber-attack \\ncorrupted their systems, it would be relatively easy to wipe them clean and \\nrestore  the  data  from  an  uncorrupted  backup.370  An  attacker  thus  might \\nsucceed  in  taking  down  one  site  “only  to  find  that  the  same  content \\ncontinues  to  appear  through  other  servers.  This  is  like  playing  electronic \\nWhac-A-Mole on a global scale . . . .”371 These sorts of measures are akin to \\nthe public health practice of stockpiling medicines and vaccines for use in a \\ncrisis. The CDC may not need 300 million doses of smallpox vaccine in its \\neveryday  operations,  but  they  would  prove  critical  in  the  event  of  an \\noutbreak. \\n\\nExcess capacity can be expensive; requiring firms to keep reserves of \\nlargely unused bandwidth costs money, and “[h]aving information located \\nin multiple places makes it more costly to maintain.”372 One way to pay for \\nthese  measures  would  be  for  companies  to  pass  their  costs  of  complying \\nwith resilience mandates to their customers in the form of price increases, \\nservice decreases, or both. A difficulty with this approach is that improving \\na  given  company’s  ability  to  withstand  an  attack  does  not  just  confer \\nbenefits  on  its  customers.  It  also  confers  benefits  on  third  parties;  if \\n\\n\\n \\n\\x0cN O R T H W E S T E R N  U N I V E R S I T Y  L A W  R E V I E W \\n\\nCitibank  can  continue  to  operate  notwithstanding  a  DDOS,  its  customers \\nwill still be able to pay their bills, and third-party vendors will still be able \\nto receive payments. Excess capacity thus creates positive externalities, and \\nthe  customers  who  pay  higher  prices  for  excess  capacity  are  effectively \\nsubsidizing  others.  Another  option  would  be  for  the  government  to  offer \\nvarious  subsidies  to  firms  that  are  subject  to  survivability  mandates.  This \\napproach  is  based  on  a  recognition  that  excess  capacity  is,  in  a  sense,  a \\npublic  good  that  the  market  will  tend  to  undersupply.373  In  part  because \\nexcess  capacity  requirements  can  be  costly,  regulators  would  only  apply \\nthem to selected firms of special strategic significance. \\n\\nD.  Responding to Cyber-attacks \\n\\nThe fourth and final component of an effective cyber-security regime \\nis responding to individuals, groups, and states that have committed cyber-\\nattacks.  This  topic  naturally  lends  itself  to  analysis  under  the  law \\nenforcement and armed conflict frameworks, and it is exhaustively covered \\nin  the  existing  literature.374  For  instance,  scholars  have  proposed  better \\ninternational  cooperation  on  cyber-crime  investigations,  increasing  the \\npenalties  for  certain  computer-related  offenses,  increasing  the  costs  that \\nperpetrators  must  bear  to  commit  cyber-crimes,  treating  intrusions  as \\n“armed  attacks”  that  trigger  the  right  to  self-defense  under  the  United \\nNations  Charter,  treating  cyber-attacks  as  acts  of  aggression  that  justify \\nretaliating with conventional military force, and so on.375 This Article does \\nnot  seek  to  add  to  this  already  voluminous  literature.  There  is,  however, \\none  type  of  response  that  deserves  brief  mention:  active  self-defense,  or \\n“hackbacks.” \\n\\nA  hackback  is  an  in-kind  response  to  a  cyber-attack.  The  victim \\nessentially mounts a counterattack against the assailant, “shutting down the \\nattack  before  it  can  do  further  harm  and/or  damaging  the  perpetrator’s \\nsystem  to  stop  it  from  launching  future  attacks.”376  This  might  be \\naccomplished in several ways. If a victim detects that it is experiencing a \\ncyber-attack, it might direct a flood of traffic to the servers through which \\nthe attack is being routed, temporarily overwhelming them and preventing \\nthem from continuing the intrusion.377 Or it might hack into the responsible \\nservers, taking control of them or damaging them.378 Some scholars believe \\n\\n \\n\\x0c107:1503 (2013) \\n\\nRegulating Cyber-security \\n\\nthat  hackbacks  are  the  most  effective  defense  against  cyber-attacks,379  in \\npart because active self-defense can avoid the attribution problem; a victim \\nfirm that is experiencing an intrusion could retaliate against any computer \\nthat  is  attacking  it  without  knowing  who  is  behind  the  incident  or  his \\npurposes.380  Needless  to  say,  active  self-defense  is  only  possible  if  the \\nvictim  is  aware  that  it  is  under  attack.  It  will  not  be  an  option  if,  as  is \\nsometimes the case, the intrusion goes undetected. \\n\\nActive  self-defense  fits  into  the  law  enforcement  framework  fairly \\ncomfortably. Although hackbacks are probably illegal under the Computer \\nFraud  and  Abuse  Act381—the  victims  are,  after  all,  perpetrating  cyber-\\nintrusions  of  their  own—fundamental  principles  of  criminal  law  can \\nexplain why they might be acceptable if we were writing on a blank slate. \\nThe  basic  idea  is  justification.  Conduct  that  ordinarily  is  condemned  can \\nbecome  permissible,  or  even  desirable,  in  certain  circumstances.382 \\nHomicide is typically illegal, but we are allowed to use deadly force against \\nthose who pose a threat to our lives or the lives of others. The same might \\nbe  said  of  hackbacks.  Society  ordinarily  condemns  those  who  break  into \\nothers’  computers,  but  one  might  be  justified  in  hacking  a  machine  to \\nfrustrate its attack on one’s own system.383 \\n\\nActive self-defense is controversial, but it offers one potential benefit \\nthat has been largely overlooked in the literature. Like the other regulatory \\nsolutions  discussed  in  this  Article,  hackbacks  can  incentivize  firms  to \\nimprove  the  security  of  their  systems.  Cyber-perpetrators  typically  do  not \\nlaunch attacks directly; to obscure their responsibility, they usually route an \\nattack through a chain of unsecured intermediary systems before reaching \\nthe ultimate target.384 If a victim responds to an intrusion with active self-\\n\\n\\ndefense,  it  is  likely  that  these  third-party  systems  will  be  harmed.385  The \\nrealspace  analog  is  a  driver  who  leaves  his  car  unlocked  with  the  keys  in \\nthe ignition; the car is then stolen by bank robbers and destroyed when the \\nthieves open fire and the bank’s security guards shoot back. Many scholars \\nregard this third-party problem as a sufficient reason to forbid hackbacks.386 \\nYet the prospect of damage to third parties may have beneficial effects. The \\nthreat of harm would incentivize third parties to prevent their systems from \\nbeing used as conduits for attacks on others. Suppose Citibank knows that, \\nif  attackers  gain  control  of  its  computers  and  use  them  to  conduct  DDOS \\nattacks,  the  victims  will  be  allowed  to  retaliate  against  Citibank’s \\nmachines.  Citibank  will  have  a  fairly  strong  incentive  to  ensure  that  its \\ncomputers  are  not  commandeered  into  botnets.  Damage  from  hackbacks \\nthus would internalize some of the costs that third parties impose on others \\nby maintaining insecure systems.387 (Likewise in realspace. If drivers know \\nthat  security  guards  are  allowed  to  damage  getaway  cars  even  if  they  are \\nstolen,  they  will  lock  their  doors.)  Active  self-defense  also  might  weaken \\nattackers’  incentives  to  commit  cyber-attacks.  If  assailants  know  that \\nvictims will be able to use hackbacks to render their attacks ineffective, or \\nless  effective,  they  will  have  less  reason  to  undertake  them  in  the  first \\nplace. By increasing the futility of intrusions, hackbacks can help achieve \\ndeterrence.388  Active  self-defense  thus  can  simultaneously  foster  favorable \\nincentives  to  improve  security  and  weaken  unfavorable  incentives  to \\ncommit attacks. \\n\\nAt  the  same  time,  active  self-defense  has  a  number  of  glaring \\ndownsides. It seems inequitable to force third parties whose systems have \\nbeen compromised to bear the costs of the ensuing hackbacks—especially \\nif  they  are  individual  users  rather  than  sophisticated  firms  capable  of \\ndevoting  meaningful  sums  to  cyber-defense.389  Moreover,  as  Orin  Kerr \\npoints  out,  active  self-defense  “would  create  an  obvious  incentive  for \\nattackers to be extra careful to disguise their location or use someone else’s \\ncomputer  to  launch  the  attack.”390  Permitting  hackbacks  also  would \\n\\n\\nRegulating Cyber-security \\n\\n“encourage foul play designed to harness the new privileges”; one example \\nis the “bankshot attack,” in which an assailant who wants a computer to be \\nattacked “can route attacks through that one computer towards a  series of \\nvictims, and then wait for the victims to attack back at that computer.”391 It \\ncannot be predicted a priori whether the harmful conduct produced by these \\nnegative  incentives  would  be  greater  or  lesser  than  the  beneficial  conduct \\nproduced  by  the  positive  incentives.  A  good  deal  more  study  is  needed \\nbefore an active self-defense regime could be put into place. \\n\\nCONCLUSION \\n\\nCyber-threats aren’t going away. As society increasingly comes to rely \\non  networked  critical  infrastructure  such  as  banks  and  the  power  grid, \\nadversaries  will  find  that  they  have  ever  more  to  gain  by  attacking  these \\ndigital assets. And we will find that we have ever more to lose. \\n\\nIt  therefore  becomes  essential  to  think  about  cyber-security  using  an \\nanalytical framework that is rich enough to account for the problem in all \\nits  complexity.  Cyber-security  is too  important,  and  too  intricate,  to  leave \\nto  the  criminal  law  and  the  law  of  armed  conflict.  Instead,  as  this  Article \\nhas proposed, an entirely new conceptual approach is needed—an approach \\nthat  can  account  for  the  systematic  tendency  of  many  private  firms  to \\nunderinvest  in  cyber-defense.  Companies  sometimes  fail  to  secure  their \\nsystems  against  attackers  because  they  do  not  bear  the  full  costs  of  the \\nresulting intrusions; the harms are partially externalized onto third parties. \\nFirms also tend to neglect cyber-security because by improving their own \\ndefenses they contribute to the security of others’ systems; the benefits are \\npartially  externalized,  which  creates  opportunities  for  free  riding.  If  these \\nproblems  sound  familiar,  that’s  because  they  are.  These  challenges  of \\nnegative  externalities,  positive  externalities,  and  free  riding  are  similar  to \\nchallenges that the modern administrative state encounters in a number of \\nother  settings,  such  as  environmental  law,  antitrust  law,  products  liability \\nlaw,  and  public  health  law.  Scholars  and  lawmakers  might  look  to  these \\nother fields for suggestions on how to incentivize private firms to improve \\ntheir  defenses;  conceiving  of  cyber-security  in  regulatory  terms  opens  the \\ndoor to regulatory solutions. \\n\\nOf  course,  “regulatory  solutions”  need  not  mean  “command-and-\\ncontrol solutions.” Often it will be possible to promote better cyber-security \\nby  appealing  to  firms’  self-interest—encouraging  them  to  improve  their \\ndefenses  by  immunizing  them  from  liability  or  offering  other  subsidies—\\ninstead  of  sanctioning  them  when  they  fail  to  do  so.  For  instance,  rather \\nthan  empowering  a  central  regulator  to  monitor  the  Internet  for  outbreaks \\nof  malicious  code,  companies  should  use  something  like  public  health \\nlaw’s  distributed  biosurveillance  network  to  collect  and  share  information \\n\\nabout cyber-threats. Similarly, the private sector should play an active role \\nin establishing industry-wide cyber-security standards, as it frequently does \\nin  environmental  law  and  other  regulatory  contexts.  Offers  of  immunity \\nand threats of liability then would be used to encourage companies to adopt \\nthe  agreed-upon  standards.  And  as  for  improving  the  ability  of  critical \\nsystems  to  survive  intrusions,  infected  computers  could  be  temporarily \\ndisconnected from the Internet to keep them from spreading the malware, \\nand  companies  should  be  encouraged  to  build  their  systems  with  excess \\ncapacity (such as reserve bandwidth and remote backups) that can be called \\ninto service during cyber-attacks. \\n\\nVirtually no one is happy with the state of America’s cyber-defenses, \\nand  scholars  have  felled  entire  forests  exploring  how  to  prosecute  cyber-\\ncriminals more effectively or retaliate against countries that launch cyber-\\nattacks.  Maybe  we’ve  been  asking  the  wrong  questions.  Maybe  what  we \\nneed  to  secure  cyberspace  isn’t  cops,  spies,  or  soldiers.  Maybe  what  we \\nneed is administrative law. \\n\\n \\n\\x0cReproduced with permission of the copyright owner. Further reproduction prohibited withoutpermission.\\x0c', 'Moving Beyond Defense-in-Depth to Strategic Resilience for Critical Control Systems \\n\\nHimanshu Khurana \\nHoneywell Automation and Control Solutions Laboratory \\nHimanshu.Khurana@Honeywell.com\\n\\nincreased \\n\\nCritical  control  systems  such  as  the  North  American \\nPower  Grid  are  undergoing  significant  modernization \\nand \\nof \\nuse \\ninvolving \\ncomputer \\ncommunication \\nthese  advances \\nsystems.  While \\npromise  better  capabilities,  for  example,  an  electric \\ngrid with increased reliability and efficiency, they also \\nincrease  the  risk  to  the  control  systems  from  cyber \\nattacks.  A  significant  effort \\nis  underway  by \\ngovernment,  industry,  national  labs  and  academia  to \\ndevelop  and  deploy  security  technologies  that  assess \\nand  mitigate  this  increased  risk.  This  effort  includes \\nselect  programs  funded  by  the  US  Departments  of \\nEnergy1 \\nand  Homeland  Security2, \\nthe  US \\nReinvestment and Recovery Act, the National Institute \\nled  Smart  Grid \\nof  Standards  and  Technologies \\nInteroperability  Panel3,  and  standard  development \\nbodies to name a few. The focus of this effort includes \\nelectric  grid  systems  ranging  from  smart  meters  and \\nSCADA  (Supervisory  Control  and  Data  Acquisition) \\nsystems \\nsynchrophasor  based  Wide  Area \\nMeasurement Systems4, oil and gas SCADA systems, \\nand  industrial  control  systems.  A  timely  challenge  in \\nthis  environment,  therefore,  is  to  explore  the  right \\ncyber security constructs and principles that can guide \\nthe  effort  and  ultimately  result  in  secure  critical \\ninfrastructure  for  the  nation.  It  is  our  contention  that \\ncommonly  employed  defense-in-depth  constructs \\ncentered on building layers of defense are insufficient \\nto  achieve  that  objective.  Instead,  there  is  a  need  to \\nexplore  strategic  resilience-based  approaches  that \\ninvolve  designing  the  systems  to  protect  critical \\ncomponents and functions, strive to provide service in \\nthe  face  of  cyber  attacks,  and  ensure  timely  response \\nand recovery if the attacks succeed. \\n\\nto \\n\\nDefense-in-depth  approaches  are  at  times  neither \\nfeasible nor sufficient for control system security. For \\n\\nexample,  in  the  recent  stuxnex  malware5  series  of \\nattacks a sophisticated adversary was able to penetrate \\nseveral layers of defense while when one looks at low-\\ncapability  platforms  such  as  smart  meters  defense-in-\\ndepth  approaches  are  not  feasible  to  deploy  and \\nmanage.  To  address  these  limitations,  we  believe  a \\nnew  strategic  resilience  approach  is  needed  that  is \\ngeared towards control systems. In control systems the \\npriorities tend to differ from traditional IT and Internet \\nsystems, for example, 1) availability tends to be more \\nimportant  than  confidentiality,  2)  the  safety  and \\nsecurity  of  underlying  physical  processes  is  more \\ncritical  than  that  of  the  cyber  systems  and  3) \\ntimeliness  requirements  of  underlying  operations  can \\npose  challenges  for  typical  cyber  security  solutions. \\nThere  are  also  some  unique  opportunities  in  control \\nsystems, \\nfor  example,  1)  networks  are  more \\nrestrictive, 2) protocols behaviors are easier to specify, \\n3)  critical  components  and  functions  are  easier  to \\nidentify  (e.g.,  this  is  a  key  component  of  current \\nNERC  Critical  Infrastructure  Protection  standards) \\nand  3)  auditing  and  monitoring  capabilities  are \\ntypically built into the environment for other purposes.  \\n\\nWith these criteria in mind we argue that an effective \\nstrategic  resilience-based  approach  should  emphasize \\nthe  following  aspects  that  take  into  account  cost \\neffectiveness  and  measurability.  First,  instead  of \\nassuming  that  the  protection,  detection  and  response \\nmeasures  can  be  completely  trusted  in  the  face  of \\ncyber  attacks,  for  all  identified  critical  components \\nand  functions  a  response  and  recovery  plan  be \\ndesigned and instituted that re-instates capabilities in a \\ntimely  manner.  This  plan  would  include  automated \\nactions  where  feasible  but  utilize  Computer  Security \\nIncident  Response  Teams \\n(CSIRTs)  as  a  key \\ncapability.  Second,  detection  capabilities  should  be \\nintegrated  with  existing  auditing  and  monitoring \\nfunctions  for  effective  detection  of  cyber  attacks, \\nespecially  those  that  target  critical  components  and \\nfunctions. Third, instead of trusting layers of security \\n\\n\\nAuthorized licensed use limited to: Ryerson University Library. Downloaded on May 04,2022 at 19:25:56 UTC from IEEE Xplore.  Restrictions apply. \\n\\n \\n \\n \\n \\n                                                           \\n \\n                                                           \\n\\x0cor  even  well  protected  attacks  paths,  strong  endpoint \\nsecurity  should  be  provisioned  at  each  critical \\ncomponent  and  function  leveraging  hardware-based \\nsecurity  capabilities  to  truly  mitigate  the  risk  of \\ncompromise. Fourth, for all other system components \\na comprehensive system-wide security maturity model \\nshould  be  developed  and  utilized  that  allows  system \\noperators \\nincreasing \\nto  assess  and  demonstrate \\nsecurity over time. Further, this maturity model should \\naddress  people,  technology  and  operations  (as  in \\ndefense-in-depth)  but  in  a  measurable  system-wide \\nmanner \\nlayers  of  unknown \\ncapabilities.  Analogies  for  such  maturity  models \\ninclude  the  CMMI  software  engineering  maturity \\nmodel6 with the recently proposed BSIMM7 (Building \\nSecurity  In  Maturity  Model)  an  interesting  example \\nfor consideration in the control systems context. \\n\\nthan  with \\n\\nrather \\n\\n\\nAuthorized licensed use limited to: Ryerson University Library. Downloaded on May 04,2022 at 19:25:56 UTC from IEEE Xplore.  Restrictions apply. \\n\\n \\n                                                           \\n\\x0c', 'On the Limits of EM Based Detection of Control\\nLogic Injection Attacks In Noisy Environments\\n\\nKurt Vedros⇤, Georgios Michail Makrakis⇤, Constantinos Kolias⇤, Min Xian⇤ Daniel Barbara† Craig Rieger‡\\n⇤Department of Computer Science, University of Idaho, Idaho Falls, Idaho 83402\\nEmail: kvedros@uidaho.edu, makr7178@vandals.uidaho.edu, kolias@uidaho.edu, mxian@uidaho.edu\\n†Department of Computer Science, George Mason University, Fairfax, Virginia 22030\\nEmail: dbarbara@gmu.edu\\n‡Idaho National Lab, Idaho Falls, Idaho 83402\\nEmail: craig.rieger@inl.gov\\n\\nAbstract—The difﬁculty in applying traditional security mech-\\nanisms in Industrial Control System (ICS) environments makes a\\nlarge portion of these mission-critical assets vulnerable to cyber\\nattacks. Therefore, there is a dire need for the development\\nof novel security mechanisms speciﬁcally designed to protect\\nsuch critical systems. Recently a lot of attention has been given\\nto mechanisms that exploit the EM emanations of devices for\\ndefense purposes. Such practices may lead to the development\\nof robust external and non-intrusive anomaly detection systems.\\nNevertheless, the majority of current work in the area neglects to\\nconsider the implications of real-life environments, particularly\\nenvironmental noise. In this work, we explore the limits of EM-\\nbased anomaly detection towards identifying injection attacks\\nin control\\nlogic software in noisy environments. Our study\\nconducted upon both synthetically generated and real signals\\nidentiﬁed that indeed environmental noise might signiﬁcantly\\ndegrade the accuracy of the anomaly detection process. Exper-\\niments done upon synthetic data indicated that assuming that\\nsignals are captured with high sampling rates, even minor code\\ninjections can be detected with above-90% accuracy in noisy\\nenvironments where SNR is up to -2dB. This is true even if\\nnaive detection methods are considered. Moreover, experiments\\ndone using a real-life testbed attest that even single-instruction\\ninjections can be detected with near-perfect accuracy in relatively\\nclean environments. Finally, noise-elimination techniques can\\ndrastically improve the reliability of the detection mechanism\\neven in noisy environments.\\n\\nIndex Terms—cyber resilience; anomaly detection;\\nchannel analysis; cybersecurity; industrial control systems.\\n\\nside-\\n\\nI. INTRODUCTION\\n\\nDevices that are the building blocks of Industrial Control\\nSystem (ICS) networks include Programmable Logic Con-\\ntrollers (PLC), Intelligent Electronic Devices (IEDs), Remote\\nTerminal Units (RTUs), and Industrial Internet of Things\\n(IIoT) smart-sensors. Such devices are designed to execute\\nsolely one speciﬁc task typically directly related to the physical\\nprocess. Also, they tend to be severely limited in terms of\\nresources which in turn leaves little-to-no room for supplemen-\\ntary security features. Previous work of the authors [1] focused\\non deﬁning a multi-tiered and dynamic framework for cyber\\nresilience in control systems. Towards this goal, implementing\\nexternal monitoring and protection mechanisms for maintain-\\ning a high level of proactive state of awareness is critical. It is\\nclear that mature security mechanisms, such as anti-malware\\n\\ntools and host-based intrusion detection systems (IDS), cannot\\nbe natively supported in the realm of ICS devices. Moreover,\\nfor the same reasons, the adoption of cryptographically secure\\ncommunication protocols is not extensive.\\n\\nA family of novel defense systems is based upon the\\nanalysis of side-channels that get emitted constantly and invol-\\nuntarily by various components [2], [3] of devices. Compared\\nto the traditional network intrusion detection systems (N-IDS),\\nsuch approaches may detect compromises and the execution\\nof malicious code, even if the malware never produces any\\nnetwork footprint or if it remains in an installed-but-dormant\\nstate. In the past, alternative types of side-channels have been\\nconsidered, including the power consumption patterns [4], [5],\\nthe thermal emission proﬁles [6] or acoustic signals [7] of de-\\nvices during their usual operational cycles. Nevertheless, elec-\\ntromagnetic (EM) based approaches [8], [9], [10], [11], [12]\\noffer a comparative advantage since the signals themselves\\ncan be captured and analyzed in a completely non-intrusive\\nfashion,\\ni.e., no installation of software in the monitored\\ndevice is assumed. In contrast to power consumption signals,\\nthe EM spectrum offers high bandwidth. In the same vein,\\nthe analysis of thermal output, e.g., via infrared cameras, is\\nconstrained by the slow sampling rates of the equipment used\\nfor the purpose. Nevertheless, near-ﬁeld probes and modern\\noscilloscopes employed for capturing EM signals can support\\nextremely high sampling rates. Both of these factors contribute\\nto the fast and ﬁne-grained analysis of EM signals.\\n\\nDespite its advantages, EM-based analysis has been proven\\nextremely sensitive to the placement of the monitoring equip-\\nment and external environmental conditions. Unfortunately,\\nthe majority of research works in the area have failed to\\nconsider the implications of real-life conditions that exist in\\nindustrial settings [13] and more speciﬁcally, the impact of\\nnoise which is omnipresent in such environments. In theory,\\nnoise may severally degrade the predictive accuracy of EM-\\nbased anomaly detection systems.\\n\\nTo the best of our knowledge, this work is the ﬁrst that\\nprovides an ample evaluation of EM-based anomaly detection\\ndefenses under the inﬂuence of noise. Our study focuses on\\nminute modiﬁcations in the control logic that are likely to go\\nunnoticed when relying on traditional detection approaches\\n\\nIEEE: 978-1-6654-2905-4/21/$31.00 ©2021 IEEE\\n\\nAuthorized licensed use limited to: Ryerson University Library. Downloaded on May 04,2022 at 19:33:55 UTC from IEEE Xplore.  Restrictions apply. \\n\\n.\\n\\n.\\n\\n5\\n0\\n8\\n1\\n1\\n6\\n9\\n1\\n2\\n0\\n2\\n6\\n8\\n6\\n2\\n5\\nS\\nW\\nR\\n/\\n9\\n0\\n1\\n1\\n0\\n1\\n:\\nI\\n\\n.\\n\\nO\\nD\\n|\\nE\\nE\\nE\\nI\\n\\n.\\n\\n1\\n2\\n0\\n2\\n©\\n0\\n0\\n1\\n3\\n$\\n/\\n1\\n2\\n/\\n4\\n-\\n5\\n0\\n9\\n2\\n-\\n4\\n5\\n6\\n6\\n-\\n1\\n-\\n8\\n7\\n9\\n|\\n)\\nS\\nW\\nR\\n(\\nk\\ne\\ne\\nW\\ne\\nc\\nn\\ne\\n\\ni\\nl\\ni\\ns\\ne\\nR\\n1\\n2\\n0\\n2\\n\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n\\x0cor even existing EM-based detection solutions. The primary\\npurpose of this work is to identify the limits of EM-based\\nanomaly detection. Additionally, we aim to quantify the impact\\nof several factors that may potentially inﬂuence the efﬁciency\\nof defense mechanisms that are based on the analysis of EM\\nsignals.\\n\\nOur experimental evaluation on synthetic data indicates\\nthat it is possible to detect minimal code-injection attacks,\\neven ones having a pollution rate of just 1%, with above\\n90% accuracy. This can be done despite the impact of strong\\nenvironmental noise, even one reaching SNR levels of -8dB. In\\nsuch cases, we identiﬁed that one of the most important factors\\ninﬂuencing the anomaly detection process is the sampling\\nrate. Our experimental results indicate that to achieve granular\\ndetection of such minute anomalies, the sampling rate should\\nbe at least eight times (x8) faster than the speed of the CPU\\nclock. Adopting sampling rates near the limits dictated by\\nthe Nyquist rate often results in poor performance, as the\\nsamples describing the anomalies are negligible in comparison\\nto all other samples. More importantly, experiments conducted\\nin a testbed show that even single-instruction injections can\\nbe detected with above 90% accuracy in relatively noise-\\nfree environments if the sampling rate is kept high. Finally,\\nwe identiﬁed that most standard noise elimination techniques\\nimprove detection accuracy. However, particularly the SVD-\\nbased method for noise reduction provides high accuracy for\\nthe detection of such detrimental attacks, even in extremely\\nnoisy environments (-5dB SNR).\\n\\nThe ability to accurately recognize cyber attacks in spite\\nof the negative effects of noise, allows not only to maintain\\nfull situational awareness (recon stage) but also for surgical\\nmitigation (resist and respond stage) of threats.\\n\\nThe rest of the paper is organized as follows: Section II\\nprovides the necessary technical background and outlines the\\nmain terms and deﬁnitions that are necessary for understanding\\nthe concepts discussed in the paper. The subsequent section\\ndescribes the anomaly detection method adopted as the basis\\nfor evaluating all experiments. Section IV and V provides a\\ndescription of all the experiments done using synthetically\\ngenerated data and data obtained from a real-life testbed\\nrespectively. Finally, the conclusions extracted from this study,\\nalong with directions for future research, are included in\\nsection VI.\\n\\nII. TECHNICAL BACKGROUND & DEFINITIONS\\n\\nThis section provides the necessary background information\\n\\nand terminology used in the rest of the paper.\\n\\nIndustrial devices such as smart-sensors and PLCs, which\\ntypically interact directly with physical processes have sig-\\nniﬁcant differences from mainstream high-end computers. For\\nexample, they have much lower hardware capabilities, includ-\\ning a CPU speed of just a few Mhz, and a limited amount of\\nmemory. They also tend to rely on real-time operating systems\\n(RTOS) or execute instructions directly at the hardware level\\n(“bare metal”). Typically,\\nthey operate continuously under\\nharsh environmental conditions, including high levels of noise\\n\\nand interference. Moreover, they are replaced only after years\\nof use, and they operate continuously with only seldom update\\ntheir lifetime. Finally, such devices are\\ncycles throughout\\nusually designed to perform simple and well-deﬁned tasks but\\nwith extremely high levels of reliability.\\n\\nThe software that runs in such systems is responsible for\\ngoverning and/or inspecting a physical process. This software\\nis known as control logic. This type of software typically runs\\nperpetually, in a loop. Although control logic can become com-\\nplex, the control ﬂow typically has a much simpler structure\\nin comparison to software seen in high-end IT systems.\\n\\nNumerous works [14] indicate that\\n\\nthe mechanisms re-\\nsponsible for the updating of the control logic are plagued\\nby weaknesses. These revolve around naive, passwords-based\\nauthentication, as well as poor design decisions regarding the\\nuse of cryptographic primitives. Alternatively, attackers may\\nexploit existing bugs in the control logic itself. The latter\\nis also known as control logic hijacking or a control logic\\ninjection attack. For example, Tychalas et al. [15] pointed out\\nthe applicability of buffer overﬂow methodologies in embed-\\nded systems. Regardless, the outcome of both methodologies\\nis the alteration in the sequence of the set of machine-level\\ninstructions of a speciﬁc execution path\\nCi with the intention\\nof affecting the physical process itself. The end result may\\nvary from harming equipment to a large-scale environmental\\ndamage which in turn may endanger human lives.\\n\\nEM-based anomaly detection capitalizes on the relationship\\nbetween instructions executed at the machine level and the\\nEM signals emitted involuntarily as the natural outcome of\\nthis process. Every time a new instruction is executed, slightly\\ndifferent amounts of current are drawn by the CPU. This\\nthe\\nresults in the formation of EM ﬁelds, and therefore,\\nemanation of EM signals. Theoretically, these signals can act\\nas indicators of the type of instructions executed by the CPU\\nat any given time. The work in [16] indicates the correlation\\nbetween the CPU activity, the current drawn, and the creation\\nof EM signals. Speciﬁcally, the CPU may act as a transmitter\\nthat performs amplitude modulation over a carrier, i.e., the\\nCPU clock.\\n\\nDeﬁnition 1: We deﬁne control logic injections in the dis-\\ncrete time-domain representation of the EM signal as follows:\\nAssume a signal Si\\nm of length m, which is normally obtained\\nby the execution of instructions in the execution path\\nCi.\\nAssume a signal \\nbeen identified to play a detrimental or amplificative role in\\nthe anomaly detection process including the extent of the\\nmodification denoted here as pollution rate, the levels of noise\\nhere described as signal-to-noise-ratio, and the sampling rate\\nat which the signal is obtained.\\nDefinition 2: Pollution Rate (PR), is a metric of the extent of\\nthe corruption inflicted to the original executional path. It is\\ncalculated by the Equation 2.\\nP R = |M|\\n|CM\\ni | (2)\\nMore specifically, PR is the ratio of maliciously injected (at\\nthe machine level) instructions |M|, to the total number of\\ninstructions that constitute the studied executional path. More\\nspecifically, |CM\\ni | is calculated as:\\n|CM\\ni | = |M| + |Ci| (3)\\nwhere |Ci| is the number of instructions comprising the orig\\x02inal path. Theoretically, the smaller the PR, the harder it is\\nto identify an anomaly by simply observing the EM spectrum\\nfrom a time-domain perspective.\\nDefinition 3: Signal-to-Noise-Ratio (SNR), is a measure of the\\nquality of the signal. SNR can be calculated as in Equation 4.\\nSNR = 10log10\\nPs\\nPn\\n(4)\\nwhere Ps is the power of the signal and Pn is the power of\\nnoise. SNR is measured in dB. Theoretically, the lower the\\nSNR, the harder it becomes to identify whether a series has\\nbeen subjected to alterations.\\nDefinition 4: Sampling Rate (SR) is the number of elements\\nin a discrete-time sequence describing an analog signal. Ac\\x02cording to the Nyquist theorem, the minimum SR should be\\nat least two times greater than the frequency of the signal\\nin order for the resulting sequence to be unaffected by the\\nnegative impacts of the aliasing phenomenon. Theoretically,\\nwith higher sampling rates, a given anomaly in a time series\\nwill be described by more data points.\\nIII. ANOMALY DETECTION METHOD\\nIn this work, we relied on a rudimentary anomaly detection\\nmethod that is based on the k-Nearest Neighbors (k-NN)\\nalgorithm, for evaluating purposes.\\nIn its most popular version, k-NN is a supervised ML al\\x02gorithm. This implies that instances (EM signals) of normal\\nand anomalous states must be given a priori. However, in this\\ncontext, it is not valid to assume knowledge of all anomalous\\ncases. For example, assuming that an attacker has identified\\na vulnerability in code, they can inject a single instruction to\\nalter the value of a potentially critical variable. In fact, any\\nof the numerous logical combinations of instructions that the\\nCPU architecture supports can potentially be injected. Indeed,\\nthe alternative ways to create anomalies are potentially infinite.\\nTherefore, providing labels for anomalous cases is impractical.\\nTowards this end, we relied on a semi-supervised version of\\nk-NN where knowledge of only the normal case is assumed.\\nThis is a realistic assumption as such signals can be captured\\nat an early stage, even before the deployment of the system.\\nAnother reason for this choice of algorithm is the fact that k\\x02NN performs lazy learning i.e., no model is created during the\\ntraining step, but rather the modeling process is delayed until\\nthe deployment phase. Indeed, in this work, our aim is not\\nto evaluate the generalization ability of a specific algorithm\\nacross different noise environments, but rather to quantify\\nthe effects of noise in distinguishing between normal and\\nanomalous signals.\\nTraining: As a first step, the algorithm is fed with a set\\nof normal (only) signals X. Then, an exhaustive process of\\ncomparing each signal xi with the rest in this set takes place to\\ninfer a distance score Di of xi. More specifically, the distance\\nscore Di is calculated by formula 5:\\nDi(X, xi) =\\nPmink{d(xj , xi)}8xj 6= xi 2 X\\nk (5)\\nwhere d is a distance metric such as Euclidean distance, and\\nmink are the k closest neighbors to xi. Finally, the values\\n{Dmin, Dmax} are the thresholds of normalcy. These thresh\\x02olds are inferred from the data, and they are not manually\\ndecided, but rather they are specific to each dataset. We\\nrecognize that the absolute minimum and maximum values\\nmay constitute too strict criteria for establishing thresholds,\\nespecially for non-trivial scenarios in real-life situations. By\\nadopting this method, our goal is to simply provide a baseline\\nfor purposes of comparison and not achieve the optimal\\naccuracy. Alternative methods like [17] \\n\\nM. We assume that n << m, because extensive alterations\\nin control logic tend to raise immediate suspicions. Then, the\\nsignal corresponding to a control logic injection is a version\\nof that signal that is obtained as in Equation 1:\\nSMm+n = S[1...k], \\n\\nData Generation: For the sake of simplicity, in our exper\\x02iments, the period T of normal signals is set to one second\\n(unrealistically long), and the corresponding frequency F of\\nthe CPU is set to 1000 (unrealistically slow). Each instruction\\nranges between amplitudes 3mV to 6mV. Since there is a finite\\nnumber of supported instructions by CPU architectures and\\nsince each instruction (or sequence of instructions) modulates\\nthe signal in a different way the resulting amplitude levels are\\nalso finite. The base dataset was created to consist of 1000\\nexamples of the same basic signal with random (but minor)\\nfluctuations of the amplitude ranging from -0.2mV to 0.2 mV\\nper example. To effectively conduct our study, we produced\\nseveral variations of this basic dataset, by altering specific\\ncharacteristics, namely, the SR, PR, and SNR. Different SR\\nlevels were considered, starting from x2 and increasing up to\\nreaching levels up to x32 the base frequency of the signal\\nwith an increment step of 2 (for example, x2, x4, . . . , x32).\\nThe anomalous signals are created by injecting an invalid,\\nnever-seen-before sequence exactly in the middle of all benign\\nsignals. Different PR were considered, ranging from 1% to\\n20% with an increment step of 2.5% (for example, 1%, 2.5%,\\n. . . , 20%). Finally, we considered variations after applying\\ndifferent levels of additive white Gaussian noise (AWGN), i.e.,\\nthe type of noise that mostly affects ICS settings. Noise levels\\nthat were taken into account in this study, range from -10dB\\n(i.e., the noise is 10 times stronger than the signal) to 10dB\\nwith an increment step of 2dB (for example, -10dB, -8dB, . . . ,\\n10dB).\\nEvaluation Method: For this set of experiments, the efficiency\\nwas measured based on the accuracy (ACC). We define ACC\\nas:\\nACC = T P + T N\\nT P + T N + F P + F N (6)\\nwhere T P is the total number of true positives, T N the\\nnumber of true negatives, F P the number of false positives,\\nand F N as the number of false negatives.\\nWe recognize that a metric such as ACC should not\\nbe considered for applications where the classes of signals\\n(normal, anomalous) are heavily imbalanced. For example,\\nin a protected network, successful device compromises are\\nexpected to be rare incidents in the benign (in its majority)\\noperational lifespan of each device. However, for this set\\nof experiments, we choose to adopt ACC because (a) the\\nconsidered test sets are balanced, and (b) for reasons of\\ndirect comparison with relevant bibliography [16]. Subsequent\\nexperiments based on real-life setup (such as ones included in\\nSection IV) additionally report F1 and AUC scores.\\nIn the first experiment, a ten-fold cross-validation strategy\\nis used for evaluation purposes. For every fold, the number\\nof signals used for training purposes was 90% of the entire\\nnormal dataset. The testing set was 10% of the normal dataset,\\nand an equal number of anomalous signals was added.\\nA total of 1000 thresholds was considered ranging from\\nthe minimum distance (0) to the maximum distance observed.\\nThe ACC reported for each fold is the maximum among all\\nthresholds considered. The ACC of the neighborhood is the\\nmean ACC for all folds. We considered neighborhoods of 3,\\n5, 10, 25, 50, 75, and 100 neighbors. The overall accuracy\\nreported is the best among all the neighborhoods.\\nEstimating the Impact of Pollution Rate: In the first round\\nof experiments, the main question posed was the following:\\nAssuming a high SR (i.e., x32), what is the impact of noise\\nconsidering various PR levels? The results indicate that a high\\nPR level, i.e., 20%, can be detected with high accuracy of\\nabove 0.9 even in extremely noisy environments, i.e., SNR\\n-10dB. Interestingly, the ACC is maintained at near-perfect\\nlevels (i.e., 0.963) even at SNR -6dB. PR of 10% can also\\nbe reliably detected with above 0.9 ACC for SNR greater\\nthan -4dB. Finally, the smallest considered PR, i.e., 1%, was\\ndetected effectively with above 90% for up to SNR -2dB.\\nIn this case, the ACC was constantly near-perfect 0.988 for\\nup to 0dB SNR. Nevertheless, the ACC rapidly degrades for\\nevery considered level below -2dB, by almost a -10% per noise\\nlevel. Figure 2 depicts the ACC achieved for various pollution\\n\\nse ratios when the sampling rate is kept\\nconstantly high at x32 the speed of the CPU.\\nFig. 2: Accuracy for various levels of pollution rates and\\nsignal-to-noise-ratios. The experiments considers a sampling\\nrate x32 faster than the CPU clock.\\nEstimating the Impact of Sampling Frequency: In the light\\nof the previous experiment, we wanted to answer the following\\nquestion: Focusing solely on the detection of injection attacks\\nof the smallest PR (1% PR), what is the impact of noise\\nfor various SR? The case SR of x32 was analyzed in the\\nprevious experiment. For lower SR levels of x16, the anomaly\\ndetection yields near-perfect accuracy of 0.958 or higher when\\nSNR levels are up to 0dB. In comparison to higher SR\\nlevels, one may notice that SR of x32, x24, and x16 yield\\nsimilar accuracy. Only when considering SR levels of x8 or\\nlower one may observe drastic changes in the accuracy levels.\\nFor example, at SNR -2dB and -4dB, the biggest change of\\napproximately 0.150 in the accuracy can be seen in comparison\\nto x16 SR. At the lowest SR tested (x2), injections cannot be\\ndetected with any certainty. The accuracy at every SNR level\\nwas approximately 0.500. Figure 3 presents the accuracy for\\nvarious levels of sampling rates and signal-to-noise-ratios (the\\npollution level is kept constant at a level of 1%).\\nFig. 3: Accuracy for various levels of sampling rates and\\nsignal-to-noise-ratios. The pollution rate is kept constant at\\n%1.\\nFigure 1 summarizes the ACC achieved across all PR, SR,\\nand SNR levels considered. The main conclusions drawn from\\nthese experiments are: (a) The higher the PR, the more robust\\nagainst the influence of noise the anomaly detection becomes,\\n(b) Injection attacks at any PR level (1%-20%) can be detected\\nwith near-perfect accuracy when the SNR is no less than\\n0dB. (c) Very small PR can effectively be detected even in\\nthe presence of high environmental noise. (d) SR must be\\nsignificantly higher than x2 the CPU speed to effectively detect\\nany injection code. (e) The higher the SR, the greater the\\nresistance to noise, especially for low SNR levels. Finally, (f)\\nSR higher than x16 may improve the ACC but only marginally.\\nV. EXPERIMENTS USING REAL-LIFE EQUIPMENT\\nExperimental Setup: For all experiments involving real\\x02life equipment, the target device is an Arduino Mega. The\\nArduino Mega is equipped with the 8-bit ATmega2560 AVR\\nmicrocontroller unit (MCU). This MCU is widely deployed\\nin real-time control applications. The Arduino device family\\nallows the developers to run code at the firmware level without\\nthe intervention of an OS or a runtime environment.\\nTo acquire EM signals, we make use of a near-field probe,\\nnamely an EMRSS RF Explorer H-Loop, which is placed atop\\nof the CPU. Due to the fact that emanations from the CPU\\nare transmitted unintentionally, the EM signals have a very\\nlow amplitude. For that reason, each signal captured is first\\namplified using a Beehive 150A EMC probe amplifier and\\nis then saved in a digital format using a PicoScope 3403D\\noscilloscope. The sampling rate is set to 250MS/sec, which\\ncorresponds to a sampling interval of 4ns. The CPU clock\\nof the ATmega2560 is 16Mhz which implies that the chosen\\nsampling rate is roughly 15 times higher. As identified by\\nthe previous experiments, this is roughly the SR threshold\\nlevels above which any increase contributes minimally to the\\nanomaly detection. The experimental setup can be seen in\\nFigure 4.\\nFig. 4: Experimental setup considered for the acquisition of\\nEM signals.\\nThe control logic coded in the Arduino is a basic tank\\x02filling system. The control logic was implemented in the\\nAVR assembly language. Compared to C, which is the typical\\nchoice for developing software in the Arduino platform, the\\nuse of assembly allows granular modifications analogous to\\nreal adversarial activity.\\nThe chosen adversarial cases include the injection of ADD,\\nand JMP instructions. In other words, all two malicious cases\\ninvolve the injection of a single instruction that consumes as\\nlittle as one (ADD), and three (JMP) cycles, respectively.\\nOne may claim that code injections of such small caliber are\\nnot meaningful from an adversarial point of view. However, we\\nargue that introducing a malicious ADD instruction could a\\n\\nse ratios when the sampling rate is kept\\nconstantly high at x32 the speed of the CPU.\\nFig. 2: Accuracy for various levels of pollution rates and\\nsignal-to-noise-ratios. The experiments considers a sampling\\nrate x32 faster than the CPU clock.\\nEstimating the Impact of Sampling Frequency: In the light\\nof the previous experiment, we wanted to answer the following\\nquestion: Focusing solely on the detection of injection attacks\\nof the smallest PR (1% PR), what is the impact of noise\\nfor various SR? The case SR of x32 was analyzed in the\\nprevious experiment. For lower SR levels of x16, the anomaly\\ndetection yields near-perfect accuracy of 0.958 or higher when\\nSNR levels are up to 0dB. In comparison to higher SR\\nlevels, one may notice that SR of x32, x24, and x16 yield\\nsimilar accuracy. Only when considering SR levels of x8 or\\nlower one may observe drastic changes in the accuracy levels.\\nFor example, at SNR -2dB and -4dB, the biggest change of\\napproximately 0.150 in the accuracy can be seen in comparison\\nto x16 SR. At the lowest SR tested (x2), injections cannot be\\ndetected with any certainty. The accuracy at every SNR level\\nwas approximately 0.500. Figure 3 presents the accuracy for\\nvarious levels of sampling rates and signal-to-noise-ratios (the\\npollution level is kept constant at a level of 1%).\\nFig. 3: Accuracy for various levels of sampling rates and\\nsignal-to-noise-ratios. The pollution rate is kept constant at\\n%1.\\nFigure 1 summarizes the ACC achieved across all PR, SR,\\nand SNR levels considered. The main conclusions drawn from\\nthese experiments are: (a) The higher the PR, the more robust\\nagainst the influence of noise the anomaly detection becomes,\\n(b) Injection attacks at any PR level (1%-20%) can be detected\\nwith near-perfect accuracy when the SNR is no less than\\n0dB. (c) Very small PR can effectively be detected even in\\nthe presence of high environmental noise. (d) SR must be\\nsignificantly higher than x2 the CPU speed to effectively detect\\nany injection code. (e) The higher the SR, the greater the\\nresistance to noise, especially for low SNR levels. Finally, (f)\\nSR higher than x16 may improve the ACC but only marginally.\\nV. EXPERIMENTS USING REAL-LIFE EQUIPMENT\\nExperimental Setup: For all experiments involving real\\x02life equipment, the target device is an Arduino Mega. The\\nArduino Mega is equipped with the 8-bit ATmega2560 AVR\\nmicrocontroller unit (MCU). This MCU is widely deployed\\nin real-time control applications. The Arduino device family\\nallows the developers to run code at the firmware level without\\nthe intervention of an OS or a runtime environment.\\nTo acquire EM signals, we make use of a near-field probe,\\nnamely an EMRSS RF Explorer H-Loop, which is placed atop\\nof the CPU. Due to the fact that emanations from the CPU\\nare transmitted unintentionally, the EM signals have a very\\nlow amplitude. For that reason, each signal captured is first\\namplified using a Beehive 150A EMC probe amplifier and\\nis then saved in a digital format using a PicoScope 3403D\\noscilloscope. The sampling rate is set to 250MS/sec, which\\ncorresponds to a sampling interval of 4ns. The CPU clock\\nof the ATmega2560 is 16Mhz which implies that the chosen\\nsampling rate is roughly 15 times higher. As identified by\\nthe previous experiments, this is roughly the SR threshold\\nlevels above which any increase contributes minimally to the\\nanomaly detection. The experimental setup can be seen in\\nFigure 4.\\nFig. 4: Experimental setup considered for the acquisition of\\nEM signals.\\nThe control logic coded in the Arduino is a basic tank\\x02filling system. The control logic was implemented in the\\nAVR assembly language. Compared to C, which is the typical\\nchoice for developing software in the Arduino platform, the\\nuse of assembly allows granular modifications analogous to\\nreal adversarial activity.\\nThe chosen adversarial cases include the injection of ADD,\\nand JMP instructions. In other words, all two malicious cases\\ninvolve the injection of a single instruction that consumes as\\nlittle as one (ADD), and three (JMP) cycles, respectively.\\nOne may claim that code injections of such small caliber are\\nnot meaningful from an adversarial point of view. However, we\\nargue that introducing a malicious ADD instruction could a\\n\\nI. CONCLUSION & FUTURE WORK\\nIn this work, we explored the limits of EM-based anomaly\\ndetection approaches towards detecting malicious code injec\\x02tion attacks in control logic software. The main conclusion\\nextracted from our study is that, while noise may severally\\ndegrade the accuracy of the anomaly detection, code injections\\nthat alter the execution path minimally to moderately can still\\nbe detected even under highly noisy environments, if the sam\\x02pling rate is high enough. Through experiments with real-life\\nequipment, we prove that even single-instruction injections can\\nbe identified with high accuracy in clean or moderately noisy\\n(0dB) environments. Standard noise elimination techniques\\nmay drastically improve the accuracy of the anomaly detection\\ntask even in sub 0dB environments.\\nOur future research efforts will be focused on investigating\\nthe transferability of ML-based anomaly detection models\\namong environments of different levels of noise. Towards this\\ngoal, we aim to improve existing domain adaptation techniques\\nthat may prove beneficial for this application', 'Hitachi Review Vol. 63 (2014), No. 5      218\\n\\nTechnotalk\\n\\nPeople and Systems Working in Harmony to Make \\nSocial Infrastructure More Resilient\\n\\nMakoto Takahashi, Ph.D \\nShuji Senoo \\n\\nProfessor, Management of Science & Technology Department, Graduate School of Engineering, Tohoku University\\n\\nSenior  Director,  Advanced  Security Technology  Operations,  Services  Creation  Division,  Information  & \\n\\nTelecommunication Systems Company, Hitachi, Ltd.\\n\\nMasahiro Mimura, Ph.D. \\nDepartment Manager, Enterprise Systems Research Department, Yokohama Research Laboratory, Hitachi, Ltd.\\nToshihiko Nakano, Ph.D.  General Manager, Control System Security Center, Omika Works, Infrastructure Systems Company, Hitachi, Ltd.\\nToshiaki Arai, Ph.D. \\n\\nCTO, Defense Systems Company, Hitachi, Ltd.\\n\\nCyber-attacks and other threats to information security have been growing in recent years. Meanwhile, rising \\nconcerns about natural disasters and terrorism have made the provision of comprehensive countermeasures \\nagainst events such as these an issue for society. Along with putting measures in place to counter growing \\nthreats,  maintaining  the  safety  of  social  infrastructure  systems  also  requires  appropriate  measures  for \\nminimizing  damage.  Hitachi  has  built  up  a  portfolio  of  security  technologies  in  fields  ranging  from  social \\ninfrastructure  to  physical  security. Through  total  security  solutions  that  utilize  these  technologies,  Hitachi \\nintends to help create a society that is safer and more secure.\\n\\nDefense in Depth to Deal with the \\nUnexpected\\n\\nArai: Along with the growth in threats to the safety and \\nsecurity of society, concern about the security of social \\ninfrastructure is also growing. Professor Takahashi \\ncurrently heads the Tohoku Tagajo Headquarter of \\nthe Control System Security Center, of which Hitachi \\nis a member. Can you please explain which aspects \\nof social infrastructure security you are looking at in \\nparticular?\\nTakahashi: My main research topic is the security of \\n\\nlarge systems such as nuclear power plants or air traffic \\ncontrol systems that, if disrupted, have a major impact \\non society. I am looking in particular at how to improve \\nthe overall security of systems, including human factors. \\nThe idea of the “unexpected” was a key legacy of the \\nGreat East Japan Earthquake. However much you \\nallow for various different situations, it will not prevent \\nthe unexpected from happening. Whatever capabilities \\nyou build into your systems, there will always remain \\nsome aspects where you must rely on the adaptability \\nand fl exibility of people to deal with the unexpected. My \\nresearch looks at how these human factors can make \\n\\nMakoto Takahashi, Ph.D\\n\\nShuji Senoo\\n\\nProfessor, Management of \\nScience & Technology \\nDepartment, Graduate \\nSchool of Engineering, \\nTohoku University\\n\\nGraduated in 1986 with a degree in nuclear \\nengineering from the School of Engineering, \\nTohoku University, and earned a doctoral \\ndegree in nuclear engineering from the \\nGraduate School of Engineering, Tohoku \\nUniversity in 1991. After appointments that \\nincluded assistant professor at the Graduate \\nSchool of Engineering, Tohoku University in \\n2000, he took up his current position in 2011. \\nHe is also currently the head of the Tohoku \\nTagajo Headquarter of the Control System \\nSecurity Center. He is a director of the Atomic \\nEnergy Society of Japan and of the Human \\nInterface Society. He specializes in cognitive \\nengineering, system engineering, and human \\nerror analysis.\\n\\n- 9 -\\n\\nSenior Director, Advanced \\nSecurity Technology \\nOperations, Services \\nCreation Division, \\nInformation & \\nTelecommunication \\nSystems Company, \\nHitachi, Ltd.\\n\\nJoined Hitachi, Ltd. in 1984. After \\nworking as a system engineer in the \\npublic sector division of Hitachi that \\ndevelops systems for local government \\nand other government agencies, he \\ncommenced his current security-related \\nwork in 2002.\\n\\n\\x0c219      Technotalk\\n\\noverall systems safer.\\nSenoo: In the case of cyber-security where new viruses \\nand other forms of malware are continually emerging, \\nthere is no hope of being able to anticipate all risks \\nin advance. Taking the unexpected as a given, it is \\nimportant to focus on damage limitation, which means \\nlooking at how to reduce the unexpected and how to \\nminimize damage when it does occur.\\nMimura: Targeted attacks have recently become a \\nproblem for cyber-security. These are attacks that target \\nspecifi c devices by exploiting little-known vulnerabilities. \\nBecause the tendency in the past was to spread \\nviruses far and wide, vulnerabilities could be identifi ed \\nand patched quickly. Targeted attacks on the other \\nhand, because they are directed at a limited number \\nof targets, are difficult to spot and are capable of doing \\nlarge amounts of damage before being detected. Along \\nwith the elimination of vulnerabilities, “risk hedging” \\ntechniques that minimize damage also have an \\nimportant role in dealing with this new type of threat.\\nTakahashi: In this sense, I also believe that a “defense \\nin depth” approach is important. This is a fundamental \\nconcept in the military realm. Rather than erecting \\nprotective measures in duplicate or triplicate, what it \\nmeans is ensuring that if one line of defense fails, other \\nlines will continue to function. By adopting this practical \\napproach as the basis of our planning, I believe that \\nwe can minimize the ultimate damage.\\n\\nExtending Range of Regular Exercises, \\nand Use of Information during \\nEmergencies\\n\\nArai: Conducting command and control system \\ntraining exercises is also important for reducing risks \\n\\ncaused by human factors. Especially in the case of \\nthe emergencies that arise during a large disaster, \\na change in attitude is also crucial because of the \\ndifferent operations that are required compared to \\nnormal situations, such as working diligently through \\nthe observe, orient, decide, and act (OODA) loop.\\nTakahashi: In the case of large systems, simulators \\nare used to perform exercises under near-real-world \\nconditions. While these can include one-in-tens-of-\\nmillion situations with multiple simultaneous incidents, \\ntheir value depends on the details of the exercise \\nitself. As scenario-based exercises are ineffective at \\ndelivering the unexpected, a worthwhile approach is to \\nconduct planned exercises in which the scenario after \\na certain point is left undisclosed. Also, however many \\nexercises are conducted, because the availability of \\ninformation during an actual disaster can be a matter \\nof life or death, it is also important to put measures in \\nplace for utilizing information during an emergency.\\nSenoo: The USA is proceeding with the adoption of \\na standard model for information sharing called the \\nNational Information Exchange Model (NIEM) so \\nthat preexisting infrastructure for sharing information \\nbetween government, agencies, municipalities, \\nand other participants will be available during an \\nemergency such as a disaster or terrorist attack, and \\nto establish the mechanisms for the smooth fl ow of \\ninformation between the various systems involved. \\nJapan is also looking at open data practices that \\nencourage the availability and use of public information \\ncollected and held by government agencies. However, \\nnumerous issues still remain. Together with the use of \\ntechnologies such as those for preventing tampering, I \\nbelieve that making public data available in a form that \\nfacilitates secondary use is essential to conducting \\n\\nMasahiro Mimura, Ph.D.\\n\\nToshihiko Nakano, Ph.D.\\n\\nGeneral Manager, Control \\nSystem Security Center, \\nOmika Works, Infrastructure \\nSystems Company, \\nHitachi, Ltd.\\n\\nJoined Hitachi, Ltd. in 1980. He is \\ncurrently engaged in the development of \\nsecurity for social infrastructure systems. \\nDr. Nakano is a member of The Institute \\nof Electrical Engineers of Japan (IEEJ).\\n\\nDepartment Manager, \\nEnterprise Systems \\nResearch Department, \\nYokohama Research \\nLaboratory, Hitachi, Ltd.\\n\\nJoined Hitachi, Ltd. in 1997. After \\nworking on the research and \\ndevelopment of financial systems and of \\nbiometric and other security technologies \\nand systems, he commenced work in \\n2012 on the research and development \\nof financial and public sector solutions \\ntogether with software productivity \\ntechniques used by these solutions, and \\nof system security technology. \\nDr. Mimura is a member of the \\nInformation Processing Society of Japan \\n(IPSJ).\\n\\n- 10 -\\n\\n\\x0cHitachi Review Vol. 63 (2014), No. 5      220\\n\\nthe amount of human intervention required, and the \\nuse of information technology (IT) for automation and \\nto support administrators.\\nTakahashi: An important factor when an actual \\ncyber-attack occurs is to be able to determine quickly \\nwhether it is in fact a cyber-attack rather than simply an \\noperational problem caused by a fault in the system. \\nWhile one system-based technique is to use predefi ned \\nsignatures to detect attacks automatically, another \\nimportant approach is to have countermeasures \\nthat provide a common operational picture (COP) \\nand other appropriate information to the people who \\nadminister the system, and to support them in situation \\nassessment, decision making, and other related tasks.\\nSenoo: Because security is a new fi eld in the case of \\ncontrol systems in particular, there is no way of knowing \\nwhat unexpected threats may arise. Accordingly, we \\nare focusing on ways of issuing warnings as quickly \\nas possible and providing assistance to administrators. \\nOne example is a solution we have developed that \\nuses decoy servers in a system to detect virus \\nintrusion and infection at an early stage, and that alerts \\nadministrators accordingly to prevent the infection \\nfrom spreading. In the social infrastructure sector, \\nin particular, where system availability is critical, the \\nsystem is being built to operate continuously over long \\nperiods.\\nNakano: Compliance with the IEC 62443 international \\nstandard for security is starting to become more \\ncommon in the control system sector. I believe we \\nneed to contribute to this standardization process \\nwith a view to standardizing highly reliable techniques \\nbuilt up over time, with the aim of ensuring security \\neverywhere from individual components up to entire \\nsystems, operations, and society.\\n\\noperations appropriately during a disaster or other \\nemergency.\\n\\nSecurity Risks for Control Systems\\n\\nArai: Another human consideration is that, while \\nprogress has been made on information security \\nmanagement systems (ISMSs) and other measures for \\npreventing information leaks and other unauthorized \\ntampering with corporate information systems, there is \\na need for rethinking attitudes to the security of control \\nsystems.\\nNakano: Whereas control systems in the past were \\nclosed systems and not seen as under threat from \\ncyber-attacks, factors such as the use of general-\\npurpose platforms, networking, and portable storage \\nmedia mean that risks are growing. I believe we have \\nan obligation to help raise general knowledge of \\nsecurity and risk awareness in the control systems \\nfi eld.\\nSenoo: Security requires more than just experts with \\nspecialist knowledge. The problem is that protection \\nfunctions will only work if the staff responsible for \\nday-to-day activities have a basic understanding of \\nsecurity. Otherwise, their naivety will leave them prone \\nto opening fi les attached to targeted e-mail attacks, \\nfor example. The challenge for businesses, I believe, \\nis to ensure that security knowledge is spread widely, \\nnot just among system engineers (SE) and other non-\\ntechnical personnel.\\nMimura: The idea that security involves work \\nand cost is also deep-rooted, I believe. Along with \\nemphasizing the importance of security, other areas \\nI think we should be working on include adopting \\ncountermeasures against cyber-attacks that minimize \\n\\nToshiaki Arai, Ph.D.\\n\\nCTO, Defense Systems \\nCompany, Hitachi, Ltd.\\n\\nJoined Hitachi, Ltd. in 1978. Prior to taking up \\nhis current position, Dr. Arai worked on \\ninformation system research and development \\nat the then Systems Development Laboratory.\\n\\n- 11 -\\n\\n\\x0cbiometric authentication techniques such as fi nger \\nvein recognition. There have also been moves in \\nrecent times to analyze information such as people’s \\nmovements (“pedestrian fl ow”) or position information \\nfrom mobile phones, and to use this for security or to \\nimprove services. If Japan as a nation can clarify its \\npolicies on privacy and information use, it will make it \\neasier for us to develop the technologies for this use.\\nMimura: Hitachi sees adaptability, readiness, and \\nharmony as being the three key concepts needed for \\nsocial infrastructure security. Adaptability means the \\nidea of implementing security measures at all layers \\nwithin a system, from the individual components \\nup to the middleware that ties them together \\nand the applications that run on this middleware. \\nMeanwhile, because there is still a risk of these being \\ncompromised due to infection by a virus, the concept \\nof readiness means being able to respond promptly \\nto any situation. Likewise, harmony means taking \\nsteps to share information obtained about viruses \\nor other vulnerabilities as quickly as possible with \\nthe rest of the community, including the Information-\\ntechnology Promotion Agency, Japan (IPA) and \\nthe Japan Computer Emergency Response Team \\n(JPCERT). While this already happens, I believe we \\nshould go even further and establish mechanisms for \\nmore pooling and sharing of the information needed \\nto improve security right across society, not just for IT \\nsystems and physical security, but also for the control \\nsystems that underpin social infrastructure. I see these \\nkey concepts as also being important for security in \\nother areas.\\nArai: Hitachi supplies total security solutions based \\non technologies that support security in a wide range \\nof fi elds, from IT and control systems to physical \\nsecurity. Drawing on our discussion today, I hope we \\ncan contribute to enhancing the safety and security of \\nsociety. Thank you for your time today.\\n\\n221      Technotalk\\n\\nUtilizing Human Factors to Enhance \\nResilience\\n\\nTakahashi: A recent interest of mine has been \\nthe fi eld of resilience engineering. While resilience \\nnormally refers to a system’s ability to withstand or \\nrecover from a shock, the concept is also becoming \\nimportant for security. Past security measures have \\nsought to identify the cause when an incident occurs \\nso that measures can be adopted to prevent it from \\nhappening again. While I certainly do not want to \\ndiscredit that approach, there are also cases when, \\nrather than focusing on rare examples of failure, it is \\nbetter to analyze why practices work successfully in an \\never-changing environment, and to implement them \\naccordingly. Also essential to the progress of security \\ntechnology, I believe, is an approach that focuses \\non why practices work and establishes processes \\nfor preventing incidents by enhancing resilience \\nthrough human factors, such as people’s ability to \\nmake accurate predictions, to respond, and to act with \\nfl exibility.\\nNakano: In the event of a major disaster or other \\nincident of a sort that happens only once in a lifetime, \\nthere is always a potential for panic, even among \\npeople who have been through numerous training \\nexercises. What is needed to deal with such situations, \\nI suspect, is to study past examples of success and \\nfailure, and to have systems that can supply the best \\npossible information in a timely manner to assist \\npeople in decision making.\\nTakahashi: Getting people and systems to work \\nin harmony will be increasingly important in the \\nfuture. One example might be for machines and \\nother systems to leave decisions to people during \\nnormal situations, but also to read their state of mind \\nfrom biometric or other data and provide them with \\nassistance in situations where they appear to be \\nreaching the limit of their capabilities, the point where \\nthey are potentially becoming unreliable. If systems like \\nthis become possible, that would be the ideal. We have \\nembarked on research into the basic technology for \\nsuch systems, which we call adaptive interfaces.\\nArai: Having people and machines working \\nharmoniously together will also be critical for physical \\nsecurity within Japan, which will become increasingly \\nimportant as we approach the Tokyo Olympics in \\n2020. Hitachi has strengths in IT and is hoping to use \\nthese skills to contribute to better physical security, \\nby combining surveillance cameras and image \\nrecognition, for example.\\nSenoo: There will also be uses, I believe, for \\n\\n- 12 -\\n\\n\\x0c', 'Serial Network Security with Device Routers \\nLinton, Howard . Control Engineering, suppl. Cyber Security ; Barrington \\xa0Vol.\\xa054,\\xa0Iss.\\xa011,\\xa0 (Nov 2007): 6.\\n\\nProQuest document link\\n\\nFULL TEXT\\n\\nProviding cyber security for legacy serial networks can be simpler using a new family of serial device routers.\\n\\nThese devices bridge the gap between Ethernet and serial protocols while providing protection. \\n\\nAs security continues to be in the forefront of the challenges facing designers of industrial networks, legacy\\n\\nsystems, using serial intelligent electronic devices (IEDs) and other serial network components that have been\\n\\noperating faithfully for years, have become a significant concern. Typically separate from newer Ethernet\\n\\ndeployments, they fall outside any automated security strategy, yet their splendid isolation can make them a target\\n\\nfor attack. \\n\\nThis decades-long accumulation of industrial devices that utilize asynchronous, serial protocols for operational\\n\\napplications, such as supervisory control and data acquisition (SCADA) and for industrial device console\\n\\ninterfaces, can have its serial communications requirements met via separate networks distinct from Internet\\n\\nprotocol (IP)/Ethernet infrastructure. But there is no way to implement managed remote cyber security for\\n\\ntraditional serial applications. For an effective communications-system-wide security program, as well as overall\\n\\nnetwork efficiency, it would be better to integrate serial devices on the edge of industrial networks with the central\\n\\nIP/Ethernet network for ease of management and to extend IP-based cyber security features to the serial edge of\\n\\nthe network. \\n\\nHolistic architectures are coming on the market that allow the serial edge to be an integral part of an automated,\\n\\nsecure network system. An emerging class of products called serial device routers supports architecture that\\n\\nallows managers to design and control integrated industrial networks that provide monitoring, management, and\\n\\nsecurity for the entire network, including legacy systems. \\n\\nIntegrating industrial networks  \\n\\nA holistic view of the emerging industrial network uses Ethernet switches as a universal connectivity medium at\\n\\nthe core of the network, and then surrounds this core with edge and access layers for Ethernet devices, serial\\n\\ndevices and wide area network connections. See graphic. \\n\\nAt the Ethernet edge of this architecture, IP-ready industrial devices connect directly to the core network, or via\\n\\nEthernet edge switches that are deployed near distributed industrial devices. The wide area network (WAN) access\\n\\nelement of the architecture enables remote systems or personnel to access industrial devices in the local network.\\n\\nIn addition to physical layer interfaces to WAN facilities, WAN access requires IP routing for interconnection of\\n\\ndifferent Ethernet networks and perimeter-security capabilities, such as an IP firewall. \\n\\nThe serial edge has historically been implemented as a separate network. While the Ethernet and serial domains\\n\\nmay share a common WAN access element, it has been difficult to share a local Ethernet infrastructure. \\n\\n \\n \\n \\n \\n \\n  \\n \\n \\n  \\n  \\n  \\n  \\n  \\n  \\n  \\n\\x0cRelatively static, dedicated networks have been developed for connecting serial devices and interfaces to central\\n\\ndata collectors and/or to basic remote access facilities. Devices may be connected to dedicated modem\\n\\nconnections for remote access, or some limited shared WAN access may be provided by a local data concentrator\\n\\nfor both an operational data interface, such as SCADA, and a separate interface for serial console access. A major\\n\\ndrawback is that static serial edge networks rely on dedicated connections for each application. Thus, adding new\\n\\nindustrial devices (ID) or new systems means adding new dedicated connections. Console access to devices is\\n\\nalso highly restricted, inhibiting efficient access by remote technical personnel. Connections are hard-wired with\\n\\nno resiliency against faults and no remote management of network elements. \\n\\nSerial device routers are a class of devices that offer intelligent serial-IP networking, leverage the Ethernet\\n\\ninfrastructure to take advantage of the ubiquity, performance, security and resiliency offered by the emerging\\n\\nEthernet core architecture. A new dynamic serial edge is created by their deployment adjacent to distributed\\n\\nindustrial serial devices to provide serial-IP/Ethernet connectivity into the common local core network. Because\\n\\nthey are specially designed for industrial applications, these devices can be widely distributed within even the\\n\\nharshest environments. In addition, multiple serial connections may be attached to the same industrial device. For\\n\\nexample, both an operational data interface, such as SCADA, and serial console access can share a serial device\\n\\nrouter. \\n\\nA fieldbus example \\n\\nSecurity often has not been a concern of fieldbuses because they are typically closed systems. However, when IP-\\n\\nbased devices enter the picture, security with fieldbus systems becomes a concern. Serial device routers have the\\n\\ndata manipulation capability and the intelligence to address cyber security concerns.  \\n\\nThere are numerous serial devices in industrial control system environments. Many systems have standardized on\\n\\nserial-mode DNP (distributed network protocol) and Modbus protocols. Modbus fieldbus technology allows for\\n\\nserial communications among many devices connected to the same network. For example, Modbus is often used\\n\\nto connect a supervisory computer with a remote terminal unit (RTU) in serial SCADA systems.  \\n\\nBecause Modbus is an important and widely deployed serial technology, the ability of a serial device router to\\n\\nintegrate Modbus/RTU and Modbus/ASCII serial devices with newer TCP/IP network devices is particularly\\n\\nimportant. Utilizing Modbus/TCP, an extension of Modbus/RTU, it is possible to encode Modbus messages within\\n\\nand transport over TCP/IP-based networks to support client (master) and server (slave) modes of operation. This\\n\\napproach can integrate Modbus devices into an Ethernet-core integrated industrial network to extend Ethernet-\\n\\nbased management and cyber security functionality to Modbus devices in an industrial facility. \\n\\nOther serial approaches \\n\\nLike a serial device router, traditional terminal servers, serial device servers, or console servers provide the basic\\n\\nfunction of serial-to-TCP/IP protocol encapsulation and connectivity to an Ethernet network. Serial device routers,\\n\\nhowever, integrate the multiple functions of a terminal server, an Ethernet switch and an IP router and firewall,\\n\\nwhich can enhance management, resiliency and security capabilities for serial devices. Traditional terminal servers\\n\\nand other serial server devices have no intelligence, and therefore no security capability. This may not be a\\n\\nproblem if the connected serial devices are in a secure area and access is restricted to trusted employees. For\\n\\nexample, use of security techniques such as per-port virtual local area networks (VLANs), are not possible with\\n\\nterminal servers. Todayâ[euro](TM)s emphasis on security preparedness rather than trust, however, suggests that\\n\\ncommunications management should include a unified security system that is vigilant toward not only external\\n\\nattack, but also unauthorized use by personnel or systems within the installation. An SDR has the flexibility to play\\n\\nmany roles in industrial networks, including acting as a perimeter security appliance (such as firewalls and VLANs)\\n\\n  \\n  \\n  \\n  \\n  \\n\\x0cfor remote locations, as a watchdog for activity on a serial port, or as a layer-3 (IP protocol) gateway among\\n\\nEthernet network domains. \\n\\nThe serial device router is also designed for industrial environments with hardening to withstand extreme\\n\\ntemperatures, electrical surges, EMI, and corrosive, high particulate, or high humidity environments. These\\n\\nhardened devices enable reliable deployment in applications where terminal servers, typically available only in\\n\\ncommercial grade, will not operate. \\n\\nNew industrial routers incorporate SDR capabilities to provide WAN connectivity to integrated networks supporting\\n\\nboth dynamic Ethernet and dynamic serial edges. \\n\\nCyber security features  \\n\\nCyber security becomes more urgent when remote access is enabled, and remote access is critical for efficient\\n\\nsupport of many industrial functions. In some industries, such as electric power transmission, implementing\\n\\nremote access brings regulatory obligations for cyber security protection of critical infrastructure. In addition to\\n\\nperimeter security via a WAN-access firewall function, full cyber protection requires rigorous port security for\\n\\nindustrial devices including authentication and encryption of serial connections by remote systems and personnel\\n\\non an end-to-end basis, extending locally to the serial port itself. Serial device routers have IP capability, allowing\\n\\nthem to support secure socket layer (SSL) sessions from remote systems and PC-based remote personnel with\\n\\nauthentication that is specific to individual serial ports, in addition to high-performance, hardware-assisted\\n\\nencryption of traffic all the way to the edge of the local network. Serial device routers also have the capability for\\n\\nassociating serial ports into closed communities of interest using capabilities such as Ethernet 802.1Q VLAN\\n\\ntechnology, which allows per-port assignment of serial ports within the network to different VLANs.  \\n\\nBusiness objectives \\n\\nA serial device router enables the creation of a dynamic serial edge that meets many critical business objectives of\\n\\nindustrial network designers and planners. In addition to extending cyber security to the edge of the industrial\\n\\nnetwork for serial devices, and facilitating compliance with cyber security standards, serial device routers can\\n\\nimprove network reliability and thus associated operational system and process reliability. The result is improved\\n\\nSCADA system reliability, achieved by increased security and resiliency of local network connections. \\n\\nSerial device routers protect existing investment in industrial equipment by network-enabling serial devices for\\n\\naccess by remote systems and personnel. Deployment of additional industrial devices and systems is made more\\n\\ncost-effective by leveraging the Ethernet core network in industrial environments, including cyber security, and by\\n\\nbuilding for long-term project life cycles with open standards technology. \\n\\nNew and evolving application requirements, such as comprehensive cyber security mandates and heightened\\n\\nconcerns for overall system reliability, require new views of industrial network architecture. Serial devices within\\n\\nthe network add security challenges because they do not easily fit within IP-enabled security systems. Moreover,\\n\\neach application requires its own individual uplink, adding complexity to new deployments. With an integrated\\n\\napproach to the design and planning of multi-protocol industrial networks now available, network planners and\\n\\ndesigners can use the emerging product class of serial device routers to facilitate an integrated, secure and\\n\\nreliable industrial network. \\n\\nFor more information, visit: \\n\\nwww.garrettcom.com  \\n\\n  \\n  \\n  \\n  \\n  \\n  \\n  \\n  \\n\\x0cAuthorAffiliation \\n\\n Howard Linton, is director of application engineering, GarrettCom Inc. Reach him at hlinton@garrettcom.com.  \\n\\nDETAILS\\n\\nBusiness indexing term:\\n\\nSubject: Infrastructure Automation; Industry: 56162 : Security Systems Services\\n\\nSubject:\\n\\nInfrastructure; Automation; Wide area networks; Distributed network protocols;\\n\\nRemote searching; Network security; Security management; Computer security;\\n\\nElectricity distribution; Internet Protocol; Integrated approach; Connectivity;\\n\\nEthernet; Legacy systems; Firewalls; Servers; Security systems; Interfaces;\\n\\nDesigners\\n\\nPublication title:\\n\\nControl Engineering; Barrington\\n\\nVolume:\\n\\nIssue:\\n\\n54\\n\\n11\\n\\nSupplement:\\n\\nCyber Security\\n\\nFirst page:\\n\\nNumber of pages:\\n\\n6\\n\\n1\\n\\nPublication year:\\n\\n2007\\n\\nPublication date:\\n\\nNov 2007\\n\\nPublisher:\\n\\nCFE Media\\n\\nPlace of publication:\\n\\nBarrington\\n\\nCountry of publication:\\n\\nUnited States, Barrington\\n\\nPublication subject:\\n\\nComputers--Automation, Engineering\\n\\nISSN:\\n\\ne-ISSN:\\n\\nCODEN:\\n\\n00108049\\n\\n21634076\\n\\nCENGAX\\n\\nSource type:\\n\\nTrade Journal\\n\\nLanguage of publication:\\n\\nEnglish\\n\\nDocument type:\\n\\nPERIODICAL\\n\\nProQuest document ID:\\n\\n200374931\\n\\n \\n \\n \\n\\x0cDocument URL:\\n\\nhttp://ezproxy.lib.ryerson.ca/login?url=https://www.proquest.com/trade-\\n\\njournals/serial-network-security-with-device-routers/docview/200374931/se-\\n\\n2?accountid=13631\\n\\nCopyright:\\n\\nCopyright Reed Business Information, a division of Reed Elsevier, Inc. Nov 2007\\n\\nLast updated:\\n\\n2021-09-10\\n\\nDatabase:\\n\\nProQuest One Business,SciTech Premium Collection\\n\\nLINKS\\nLinking Service\\n\\nDatabase copyright (cid:211) 2022 ProQuest LLC. All rights reserved.\\n\\nTerms and Conditions   Contact ProQuest\\n\\n \\n  \\n \\n \\n\\x0c', 'DATE DOWNLOADED: Fri May  6 11:59:12 2022\\nSOURCE: Content Downloaded from  HeinOnline\\n\\nABSTRACT\\n\\nThe  current  cybersecurity  landscape  is  unsustainable.  Companies  are  increasingly  relying  on\\nthird parties for  conducting  services, yet these third-parties  continue to be targets of attack due to\\ntheir weak  cybersecurity  measures.  The problem  stems back  to  the responsibility  of contracting\\ncompanies  to  ensure  the  adequate  cybersecurity  of third  parties.  This  oversight  mechanism  has\\nproven  to  be  inadequate,  and  third  parties  remain  untrustable  as  the  weakest  link.  Moreover,\\nthe  Federal  Trade  Commission\\'s  (FTC)  inconsistent  enforcement  of  reasonable  cybersecurity\\nmeasures  continues  this  vicious  cycle.  Until  now,  the  FTC  has  brought  enforcement  actions\\nonly  against  larger  companies  who  contract  out  services  to  third  parties,  even  in  instances\\nwhere  the  third  party  was  breached  due  to  their  own  inadequate  security.  As  a  result,  third\\nparties  lack  the  major  incentive  to  maintain  reasonable  cybersecurity  measures  created  by\\nFTC  enforcement  actions  and  they  operate  in  a  de  facto  unenforced  cybersecurity  realm.\\n\\nBlockchain  technology  should  be  implemented  as  part  of  a  large  company\\'s  comprehensive\\ncybersecurity  plan.  The  technology  offers  a  myriad  of  cybersecurity  benefits  as  it  ensures\\nconfidentiality, integrity,  availability,  and resilience.  Moreover,  the technology,  even  in its current\\nnascent  state,  comports  with the  FTC\\'s  cybersecurity  guidelines-found  in their  2015  guidebook\\ntitled  \"Start with Security.\"  Recognizing  that the  FTC\\'s reasonableness  analysis is done on  a  case-\\nby-case  basis,  the  absence  of blockchain-based  data  storage by  a  large  company-with  adequate\\nmeans  and who  collects  sensitive  information  from  many people-can  be deemed  unreasonable.\\nDoing  so will  limit  cybersecurity  risk  and  legal  risk.  The  trust that  the  blockchain  offers,  along\\nwith  the  cybersecurity  benefits,  makes this  technology  a  unique  and  unparalleled  solution  to  the\\nthird-party data breach problem.  Large companies  handling sensitive and confidential  data should\\nstart  with  trust  and  include  blockchain  technology  as  part  of their  comprehensive  cybersecurity\\nplan.\\n\\nAUTHOR\\n\\nJ.D.,  UCLA  School  of Law,  2019;  B.A.,  University  of California,  Los  Angeles,  2015.  The  opinions\\nexpressed in this Comment  reflect the author\\'s personal views  only.  A  special thank you to Professor\\nKristen Eichensehr  for her guidance,  insight,  and pushback and the entire  UCLA  Law Review board\\nand staff for their  tireless work and thoughtful  edits.\\n\\n66 UCLA L.  REV.  1242  (2019)\\n\\n\\x0cTABLE OF  CONTENTS\\n\\nINTRODUCTION................................................................................................................................................ \\n1.  CURRENT  CYBERSECURITY  LANDSCAPE  ................................................................................................. \\n\\nA.  W hat  is Cybersecurity?.................................................................................................................... \\nB.  Breadth and Scope of the Problem ................................................................................................. \\n\\n1244\\n1246\\n1246\\n1249\\n\\nII.  CYBERSECURITY  ENFORCEMENT  IN  THE  UNITED  STATES..................................................................1255\\n\\nA.  W hat  is \"Unreasonable\\'?................................................................................................................. \\n\\n1257\\n1.  Failing to Adopt Readily  Available  Technology................................................................... \\n1259\\n2.  Leaving  Gaps in Encryption/Security  in the Storage-Transmission  Chain ....................  1260\\n3.  Responding  and  Recovering Too  Slowly  From  Breaches...................................................1261\\n4.  Inadequately Policing  the Security  of Third-Party  Service Providers..............................1261\\nB.  Cybersecurity of Third Parties  and  Inconsistent Enforcem ent.................................................1262\\n\\nIII.  W HAT  IS  BLOCKCHAIN?  .......................................................................................................................... \\n\\nA.  Blockchain Technology...................................................................................................................1263\\nB.  Public, Consortium , and Private Blockchains.............................................................................. \\nC.  Applications....................................................................................................................................... \\n\\n1263\\n\\n1267\\n1269\\n\\nIV.  BLOCKCHAIN  AND  CYBERSECURITY...................................................................................................... \\n\\n1273\\n1273\\nA.  H ow Blockchain  Can Enhance  Cybersecurity  ............................................................................ \\n1275\\n1.  Confidentiality........................................................................................................................... \\n1277\\n2.  Integrity ...................................................................................................................................... \\n1278\\n3.  Availability.................................................................................................................................. \\n1278\\n4.  Resilience.................................................................................................................................... \\n1279\\nB.  Absence  of Blockchain  as Unreasonable  in the Data Storage  Context .................................... \\n1280\\n1.  Adopting  Readily Available  Technology............................................................................... \\n2.  Filling Gaps  in Encryption/Security  in the Storage-Transmission  Chain.......................  1282\\n3.  Responding  and  Recovering  Quickly From  Breaches ........................................................ \\n1284\\n4.  Ensuring the Security  of Third-Parties:  The Trust M achine..............................................1284\\nC.  Concerns About Market Adoption,  Job Killing,  and the \"Right to be Forgotten\".................1286\\n\\nCONCLUSION....................................................................................................................................................1288\\n\\n1243\\n\\n\\x0c1244\\n\\n66 UCLA  L.  REV.  1242  (2019)\\n\\nINTRODUCTION\\n\\nData breaches  have  been  the  topic  of headlines  more  often  than not in\\nrecent  memory.  With  breaches  ranging  from  Sony,\\'  to  the  Democratic\\nNational  Committee  (DNC), 2  to  the  U.S.  Navy and  its industry partners,3  to\\nEquifax,\\'  no industry  or sector remains  impervious  to  cyberattacks.  And this\\ntrend will likely  get worse.  In fact, there was a record high of 1,579  breaches in\\n2017-a 45 percent  increase from 2016.5  What is  even more frightening is that\\nin  516  of the  584  reported  company  breaches,  the  number  of total  records\\ncompromised  is unknown.6  This data might make someone  reconsider  his or\\nher nomenclature.  Is this cybersecurity  or cyberinsecurity?\\n\\nYet the so-called third-party problem, which arises from large companies\\'\\nuse  of smaller  third-party  companies  to  store  sensitive  data,  is  even  more\\nshocking.  In 2017,  56 percent  of companies  had  a third-party breach.  That\\nnumber is projected to rise because companies are increasingly relying on third\\nparties,  yet they often  do not know exactly what  information  the third party\\ncarries.  Moreover,  the  current  cybersecurity  enforcement  regime  forces\\ncompanies to conduct their own oversight of third parties-as evinced through\\nthe  Federal  Trade  Commission\\'s  (FTC)  2015  guidebook  titled  \"Start  with\\nSecurity\"-which  has proven inadequate.\\'  This is because  the FTC continues\\nto bring  cybersecurity  enforcement  actions  against the larger companies  even\\n\\nJ. \\n\\n\\x0cStart  With Trust\\n\\n1245\\n\\nwhen it was the third party that was breached.9  These third parties often handle\\nthe same  highly sensitive  and confidential information  as the larger company,\\nbut  escape  FTC  enforcement,  and  therefore \\nin  a  realm  outside\\ncybersecurity  enforcement.  Under  the  current  structure,  these  so-called\\ntrusted third parties are  often  practically untrustable  and  continue  to  remain\\nthe weakest link in a landscape plagued with cyber-insecurity.\\n\\nlive \\n\\nThis  Comment  argues  that  utilizing  blockchain-based  data  storage\\ninstead of third-party storage providers will not only reduce  cybersecurity risk\\nbut  will  also  reduce  legal  risk  in  the  eyes  of the  FTC.  The  FTC  brings\\nenforcement  actions  against  companies\\'  unfair  practices,  and  has  defined\\nunfair  practices  to  include  reasonable  cybersecurity  protocols.\"  Large\\ncompanies  can  ensure  their  protocols  are  reasonable  only  by  somehow\\nestablishing trust in  third-party service providers  that have up until now been\\ninsecure  and  untrustable.  When  it  comes  to  third-party  service  providers,\\nlarge companies should start with trust by using blockchain  technology as part\\nof their comprehensive  cybersecurity  plan.  The  absence of this \"technological\\ngenie  [that]  has  been  unleashed  from  its  bottle\"\"  might  well  be  deemed\\nunreasonable  by the FTC.\\n\\nPart I  reviews what  cybersecurity  is  and what it attempts  to  accomplish,\\nparticularly  its  four dimensions  of confidentiality,  integrity,  availability,  and\\nresilience.  It also gives  an overview of the  current cybersecurity  landscape  by\\nexamining  the breadth  and scope  of attacks  in general  and on third parties in\\nparticular.\\n\\nPart  II  examines  the  cybersecurity  enforcement  regime  in  the  United\\nStates  and explores  some  guidelines  that  would be  relevant  to  incorporating\\nblockchain  into  the  FTC\\'s  understanding  of  reasonableness.  These  FTC\\nguidelines  include  (1)  using  readily available  technology,  (2)  protecting  data\\nduring  storage  and  transmission,  (3)  responding  and recovering  from  cyber\\nattacks,  and (4)  ensuring  the security  of third parties.  An analysis  of why the\\ncurrent enforcement  regime is  inadequate  to address the  third-party problem\\nfollows.\\n\\nPart  III  dissects  blockchain  technology  and  its  components  and  lists\\nvarious  potential  and  actual  applications.  While  a  relatively  new  concept,\\nblockchain\\'s  genius  lies  in  its  unique  combination  of two breakthroughs  in\\n\\nSee  infra notes  147-148  and accompanying text.\\nSee  infra Part II.A.\\n\\n66 UCLA  L.  REV.  1242  (2019)\\n\\ncomputer science-both of which, standing alone,  are widely used throughout\\nmany industries to strengthen the security of networks.\\n\\nFinally,  Part  IV analyzes  how blockchain  can  enhance  cybersecurity  by\\nlooking at  its effects  on cybersecurity\\'s  four  dimensions.  It  then looks  at how\\nblockchain  fits  into  the  current cybersecurity  guidelines  discussed in Part  II.\\nPart IV also addresses  some concerns that may come up in trying to implement\\nblockchain  technology to enhance  cybersecurity.\\n\\nI. \\n\\nCURRENT  CYBERSECURITY  LANDSCAPE\\n\\nA.  What is Cybersecurity?\\n\\nCybersecurity is  \"[t]he  process  of protecting information by preventing,\\ndetecting,  and  responding  to  attacks.\"l2  An  old joke  in  the  security industry\\nabout the best way to keep  a computer secure  is to  \"[j]ust  unplug it.\"\"  But the\\nevolving  \"Information  Age\"l 4 has rendered this punch line solution more and\\nmore  impractical.  Moreover, the increasing  connectivity of electronic  devices\\nto the internet  and to  other devices,  as embodied in the \"Internet  of Things,\"\"\\ncreates  nearly  infinite  potential  vulnerabilities  for  these  devices  and  their\\nconnections.  As a result, there is now an unprecedented  need for information\\nsecurity. 16\\n\\n\\nINST.  OF \\n\\nSTANDARDS  &  TECH.,  FRAMEWORK  FOR \\n\\nIMPROVING  CRITICAL\\nINFRASTRUCTURE  CYBERSECURITY  45  (2018),  https://nvlpubs.nist.gov/nistpubs/CSWP\\n/NIST.CSWP.04162018.pdf  [https://perma.cc/6NSZ-89B6].\\nP.W.  SINGER  & ALLAN  FRIEDMAN,  CYBERSECURITY  AND  CYBERWAR:  WHAT  EVERYONE\\nNEEDS  TO  KNow 34  (2014).\\nSee,  e.g.,  MANUEL  CASTELLS,  THE  INFORMATION  AGE:  ECONOMY,  SOCIETY  AND  CULTURE,\\nVOLUME  III: END  OF  MILLENNIUM  (Wiley-Blackwell 2d ed.  2010).\\n\\n\\x0cStart  With Trust\\n\\n1247\\n\\nA system\\'s  ability to protect its information\" from \"unauthorized access,\\nis assessed through\\nuse,  disclosure,  disruption, modification,  or destruction\" \\nthe  three properties,  or goals,  of cybersecurity:  confidentiality,  integrity,  and\\navailability-also  known as the \"CIA triad\". 19\\n\\nConfidentiality  is  the  idea  of \"keeping  data  private.\"20 \\n\\nIt  is  defined  as\\n\"[p]reserving  authorized  restrictions  on  information  access  and  disclosure,\\nfor  protecting  personal  privacy  and  proprietary\\nincluding  means \\ninformation.\"21 \\nConfidentiality  aims  to  ensure  that  only  authorized\\nindividuals or entities have access to  a certain  computer,  system, or network.\\nIntegrity  is  the  idea  that  \"the  system  and  the  data  in  it  have  not been\\nimproperly  altered  or  changed  without  authorization.\"22 \\nIt  assures  that\\nsensitive  data  is  consistent,  accurate,  and  trustworthy  throughout  its  life\\ncycle.23  There  are  two  types  of integrity:  data  integrity  and system  integrity.\\nData  integrity  is  \"[tihe  property  that  data  has  not  been  altered  in  an\\nunauthorized  manner\"  and it \"covers  data  in  storage,  during processing,  and\\nwhile in  transit.\"24  System integrity is  \"[t]  he quality that a system has when  it\\nperforms \\nin  an  unimpaired  manner,  free  from\\nunauthorized  manipulation  of the  system.\"25  Integrity is the  most important\\npart  of the  CIA triad because  unauthorized  alteration can  be more subtle than\\noutright  theft  or  deletion  of data,  and  thus  is  often  the  target  of the  most\\nsophisticated  attackers.26\\n\\nits  intended  function \\n\\n\\n66 UCLA  L.  REV.  1242  (2019)\\n\\nAvailability is the idea of \"being able to use the system as anticipated.\" 2 7  It\\nto  and  use  of  information.\" 28\\nensures  the  \"timely  and  reliable  access \\nAvailability applies to both data, such as the availability of data in a system, and\\na system itself, such  as the ability of an administrator to access the system more\\ngenerally.\\n\\nAlong  with  the  CIA  triad,  experts  also  refer  to  a  fourth  property  of\\ncybersecurity:  resilience. 29  Resilience  \"allows  a  system  to  endure  security\\nthreats  instead  of critically  failing.\"30 \\nIt  includes  the  ability  to  operate  and\\nmaintain  essential  capabilities  while  under  attack,  as  well  as  the  ability  to\\nultimately recover and restore  normal operations.\"  This property stems from\\nthe idea that cyber attacks  are  inevitable and therefore  it is vital  to  ensure that\\nsystems are  resilient in the face  of such attacks.32\\n\\nCybersecurity concerns can  arise when there are vulnerabilities  or threats\\nto these properties.  A vulnerability is  a weakness  in a  system and is akin to  an\\nunlocked  door.  The  proverbial unlocked  door is  not a threat  unless  someone\\nwants to enter.  An actor that tries  to access, use, or alter a system or data in a\\nsystem  without authorization  is  a threat. 34  Because  an actor can exploit  these\\nweaknesses,  a  vulnerability  increases  the  likelihood  that  a  threat  will  be\\nsuccessful. 35  Moreover,  a breach  is  \"an incident  in which  an individual  name\\nplus  a  Social  Security  Number,  driver\\'s  license  number,  medical  record  or\\nfinancial record  (credit/debit cards included)  is potentially put at risk.\" 36\\n\\n\\x0cStart  With Trust\\n\\n1249\\n\\nB.  Breadth and Scope  of the Problem\\n\\nData breaches  occur almost every  day in nearly every industry,  and in too\\nmany  places  across  the  country  and  globe  to  keep  a  precise  count.  The\\nfollowing  examples  are  intended  to  illustrate  the  breadth  and  scope  of data\\nbreaches  and cyber attacks.  This is by no means a comprehensive  list.\\n\\nThe  account  information  of three billion Yahoo!  users was compromised\\nafter the  company suffered  a data breach in 2013.\"  A  cyber  attack suffered  by\\neBay  in  2014  exposed  the names,  addresses,  dates  of birth,  and passwords  of\\n145  million users.\"  The personal information of 412  million people, including\\nexposed  when\\ncustomer \\ntwenty  years  of  historical \\nAdultFriendFinder was hacked in 2016.39  A  data breach at Equifax,  one  of the\\nlargest  credit bureaus  in the  United States,  exposed the personal  information\\nof 145.5 million people, including Social  Security numbers,  dates  of birth, and\\nin  some  cases drivers\\'  license  numbers  and credit  card  data.4 0  Moreover,  in a\\nstudy conducted  in  the  United  Kingdom,  nearly half of the  businesses  in the\\nnation reported cybersecurity breaches  within a twelve-month  period.4 1\\n\\ndata,  was \\n\\nBut  cybersecurity  breaches  are  not  limited  to  the  private  sector.  The\\nFederal  Reserve  Bank  of Cleveland  was  the  victim  of a  cyberhack  in  2010.42\\nPersonal  information,  including  Social  Security  numbers,  of  22.1  million\\npeople  was  stolen  when  the  Office  of Personnel  Management  was  hacked  in\\n2015.43  In the same year, the European Union Central Bank\\'s database-which\\n\\n\\nincludes \\ninformation  such  as  email  addresses,  phone  numbers,  and\\naddresses-was  hacked, affecting 20,000 people.44  In 2016, the corporate filing\\nsystem  of the  Securities  and  Exchange  Commission  was  breached,  and  it  is\\nbelieved that the private information could have been  exploited for trading.45\\nState  actors  also  conduct  cyber  attacks,  for  various  reasons.  The  2016\\nbreach  of the  Federal  Reserve  Bank  of New York,  in  which  $81  million  was\\nstolen,  has been linked to  the  North Korean  government.4 6  North Korea has\\nalso  been  blamed  for  the  2017  \"WannaCry\"  ransomware  cyberattack,4 7  and\\nwas said to be  \"centrally involved\" in the  2014 Sony Pictures  hack.48  The 2016\\nhack  of DNC  emails,  phone  calls,  and  more,  has  been  attributed,  in  part, to\\nRussia and has led to the DNC\\'s filing of a lawsuit  against the country of Russia,\\namong  other defendants.4 9\\n\\nIt  is  estimated  that  there  were  1,765  data  breach  incidents  in  2017,  in\\nwhich  2.6  billion  records  were  stolen,  lost,  or  exposed-an  increase  of 88\\npercent  from 2016.50  A  Kaspersky Lab  study found that the  impact  of a  data\\nbreach in North America now amounts to  an average  of $1.3  million  for large\\nbusinesses  and  $117,000  per  incident  for  small  and  midsize  businesses.\\nAccording to a studyby the Ponemon Institute in 2017, the average size of data\\n\\ngovernment-personnel-data-hack-idUSKCNOPJ2M420150709\\n[https://perma.cc/ZLM8-ER3J].\\n\\n\\x0cStart  With Trust\\n\\n1251\\n\\nbreaches  around the world increased  in 2017 to more than 24,000  records per\\nbreach,  with the  United  States  standing  at  an  average  of  more  than  28,000\\nrecords  per breach.52  This study also estimated  \"an average  probability of 27.7\\npercent that organizations  in this study will have a material  data breach in the\\nnext 24 months.\"\"\\n\\nWhile  security  appears  to  be  receiving  a  larger  percentage  of  large\\ncompanies\\'  overall  Information  Technology  (IT)  budget,  the  budget itself is\\ngetting  smaller.5 4  The  average  IT budget  for  large  businesses  dropped from\\n$25.5  million  in  2016  to  $13.7  million  in  2017.\\'\"  This  is  troubling  because,\\naccording  to  experts, \"[t]hings  are bad and they\\'re going  to get worse.\" 56  This\\nis  not  only because  hackers  are  exploiting  sophisticated government  hacking\\ntools, 5 7  but also because companies  and government  agencies  frequently fail to\\npatch holes in their systems in a timely manner.\\n\\n\\n66 UCLA  L.  REV.  1242  (2019)\\n\\nMore importantly,  the future of cybersecurity breaches  seems bleak if the\\nincreasing  reliance  on  third\\nstatus  quo  remains  because  of  companies\\' \\nparties.5 9   Companies  often  outsource \\ntasks  to  a  third  party  such  as\\ntransporting  and  distributing  goods,  processing  orders  and  collecting\\npayments,  managing  inventory,  and  managing  stored  data.60   These  third\\nparties  market  themselves  as  being  able  to  leverage  their  global  partnerships\\nand  established  infrastructure  in  order  to  deliver  flexible  service  options,\\nallowing  a  business  to  focus  on  its  own  core  competencies  to  drive  down\\ncosts. 61\\n\\nA  study  conducted  by  Armstrong  &  Associates,  a  supply  chain\\nmanagement  consultancy,  found that  90  percent  of Fortune  500  companies\\noperating  within  the  United  States  have  sought assistance  from  one  or more\\nthird  parties. 62  The report also  predicted  a  continued increase  in third-party\\nusage.63\\n\\nSo why  is  this  consequential  to  cybersecurity  breaches?  The  Ponemon\\nInstitute  study found that 56 percent  of businesses have had a third-party  data\\nbreach-an  increase from  2016-and 57 percent  lack an inventory  of all third\\nparties  with which they share sensitive information.6 4  Meanwhile,  the average\\nnumber  of third parties  with  access  to  confidential  or  sensitive  information\\nincreased  from  2016.65  Moreover,  less than  half of the  respondents  said that\\nmanaging outsourced  relationship  risks is  a priority in their  organization,  and\\nonly  17  percent  of  respondents  rated  their  companies\\'  effectiveness  in\\nmitigating third-party  risk as  \"highly effective.\" 6 6  Importantly,  data breaches\\n\\n\\x0cStart  With Trust\\n\\n1253\\n\\ninvolving  third  parties  are \\nincidents.67\\n\\nthe  most  expensive \\n\\ntype  of  cybsersecurity\\n\\nA third-party attack occurs when someone \"infiltrates  [a]  system through\\nsystems and data.\"68  Because\\nan outside partner  or provider with  access to  ... \\nmany companies  have vast supplier and partner networks  that are made  up of\\nmany  smaller partners,  these third parties are  easier  targets for attackers.69  In\\nfact,  \"[t]he  larger  the  company,  the  more  likely  it  will  have  at  least  one\\nrelationship  with  a  [third  party].\"\"  Thus,  \"most financial  institutions  have\\ntens  of thousands  of supplier  relationships.\"\"  The  former  superintendent  of\\nthe  New York State  Department  of Financial  Services,  Benjamin  M.  Lawsky,\\nastutely  noted  that  \"[iun  many  ways,  a  company\\'s  cyber  security  is  only  as\\nstrong  as the  cyber security of its third-party vendors.\"72\\n\\nSmaller  companies  contracting  with  Fortune  500  or  other  large\\ncompanies  often  do not have  the same  level  of security measures  as the larger\\ncompany,  even  though they carry much of the larger company\\'s  sensitive and\\nconfidential  information.\"  This is often the case because the larger company\\'s\\nfocus is  \"always on the  [third party\\'s]  service being rendered,  and making sure\\nthe service is of the highest quality, performance,  and uptime,\" 7 4  rather than on\\nthe  third  party\\'s  security  measures-indeed,  a  third  party\\'s  quick  response,\\ncheaper  service  costs, and high quality are  sometimes  achieved  at the  expense\\n\\n\\n66 UCLA  L.  REV.  1242  (2019)\\n\\nof security.\"  Thus  a  hacker can  attack the weakest  link in the  chain and gain\\naccess  to a larger and more secured company\\'s data.7 6\\n\\nA  third  party  was  the  attack  vector\"  in  the  2013-2014  Target  data\\nbreach.\"  Fazio  Mechanical  Services,  a  ventilation  and  air  conditioning\\n(HVAC)  subcontractor,  worked  at  a  number  of Target  locations  and  had\\nexternal  network access.7 9  It is  common for large retail operations  to give this\\ntype  of access  to their HVAC  servicers because these  \"vendors need to be  able\\nto  remote  into the system  in order to  do maintenance  (updates,  patches,  etc.)\\nor  to  troubleshoot  glitches  and  connectivity  issues  with  the  software.\"80\\nHackers  stole  Fazio\\'s  network  credentials  and  gained  access  to  Target\\'s\\nsystems,  uploading credit-card stealing software  to a number of cash  registers\\nwithin  Target  stores.\"  This breach  exposed  forty million  Target  credit  and\\ndebit  card numbers  as  well  as  sixty  million  personal  information  records  of\\ncustomers.82\\n\\nA  third party was also  the  weakest  link in the  2015  cyberattack  on CVS\\nPhoto, in which hackers  breached the servers of PNI Digital Media, a company\\nthat  handled  the  credit  card  transactions  for  the  photo-uploading  site.\"\\nSimilarly,  in  2014  Goodwill  Industries  was  breached  through  C&K  Systems\\nInc., their third-party payment  vendor.84  Many other large organizations  have\\nhad their servers breached because  of poor third-party security:  Philips  (2012),\\nCogent Healthcare  (2013),  Lowe\\'s (2014), Dairy Queen  and TacoTime  (2014),\\nHome  Depot  (2014),  Department  of Veterans  Affairs  (2014),  Zoup  (2015),\\n\\nAT&T Services,  Inc.  (2015),  Harbortouch  (2015), Clif Family Wineries  (2015),\\nLouisville  Metro  Government  (2015),  Detroit  Zoo  (2015),  California  State\\nUniversity  (2015), Jimmy John\\'s  (2015), Netflix (2015),  Sonic Drive-In  (2017),\\nand Whole  Foods (2017).\\n\\nA  company  is  responsible  for  ensuring  that  third-party  contractors\\nimplement  reasonable  security  measures.8 6  This  is  problematic  because\\nbuilding trust between  a company and a third party can be  difficult,17  and third\\nparties  often evade FTC enforcement  actions.\"\\n\\nBreaches  of third-party  service  providers  are  not  limited to  the  private\\nsector.  More  recently,  in  2018  the  Secretary  of  the  Navy  released  a\\n\"Cybersecurity  Review\"  that directed, among other things, a \"[r]  eview  [of]  the\\nappropriateness  of the Navy\\'s organizational  culture and that of its supporting\\ncontractors.\"8 9  This Review came in light  of an \"increase[]  in both the severity\\nand sophistication\"  of \"attempts  to steal  critical information\"  that resulted in\\n\"several  significant  compromises  of classified  information.\"9 0  Additionally,\\nhackers  gained  access  to the personal  information and credit card numbers  of\\nDepartment  of Defense  personnel  through  a  system  maintained  by  a  third-\\nparty contractor.91\\n\\nII. \\n\\nCYBERSECURITY  ENFORCEMENT IN THE UNITED  STATES\\n\\nDespite the growing threat  and cost  of cybersecurity breaches,  there is no\\nconsensus  on  how  best  to  address  the  issue.  Congress  has  yet  to  pass  a\\ncomprehensive  law,  and  has instead  decided to  target individual  industries.9 2\\nA  partnership between  the private and public sectors may be  one solution, but\\ndrawing  proper  lines of authority  and responsibility  between  the  two sectors\\n\\n85. \\n\\nSee,  e.g.,  PROSKAUER,  PRIVACY  AND  DATA  SECURITY,  RECENT  DATA  SECURITY  BREACHES\\nINVOLVING  THIRD-PARTY  VENDORS  (2017),  https://www.privacyand  securityforum.com\\n/wp-content/uploads/2015/10/25092-Privacy-and-Data-Security-Breach.pdf\\n[https://perma.cc/4UFQ-W4UW];  Bond, supra note 82.\\nSee  infra Part II.A.4.\\nSee  infra notes  144-146  and accompanying text.\\nSee  infra Part II.B.\\n\\nresponsible \\n\\ncan  pose  a  challenge. 93  Recommendations  for  international  coordination  to\\nharmonize  cybersecurity  policies  and  practices  have  also  been  made. 94\\nHowever,  there is often tension  within the government  regarding who  should\\nthere  are\\nbe \\ndisagreements  about  whether  cybersecurity  should  be  regulated  through\\npolicy,  standards,  guidelines,  or  a  combination  thereof.9 6   This  gap  in\\nenforcement  has  been  filled  by  the  FTC,  which  has  redefined  the  \"unfair\\npractices\"  in its purview to include inadequate cybersecurity.\\n\\nfor  enforcing  cybersecurity. 95   Moreover, \\n\\nSince  2002,  the  FTC  has  extended  its  oversight  of  reasonable  security\\nmeasures  over  all companies  operating  in the  United  States  by  assuming  the\\nrole  of \"cybersecurity  police.\"  Section  5  of the  FTC Act prohibits  \"unfair or\\ndeceptive business practices  in or affecting commerce.\"9 7  Even though the Act,\\nwhich  dates  back to  1914,  does  not mention  cybersecurity,  the  FTC has  long\\nmaintained  that  Congress  intended  the  word  \"unfair\"  to  be  interpreted\\nbroadly  and flexibly \"to allow the agency  to  protect  consumers  as technology\\nchanges.\"9 8  The  FTC  has  brought  over  sixty  enforcement  actions  \"against\\ncompanies  that  have  engaged  in  unfair  or  deceptive  practices  that  failed to\\nadequately  protect  consumers\\'  personal  data.\" 99  From  2002  to  2012,  all\\ncybersecurity  enforcement  actions  brought  under  the  FTC  resulted  in\\nnegotiated  settlements  and no company tested the FTC\\'s  authority to regulate\\n\\n\\n1257\\n\\ncybersecurity.\\'  That  changed  when  the  FTC  sued  Wyndham  Worldwide\\nCorp. in 2012.\\n\\nIn 2012, the FTC sued Wyndham Worldwide Corp. for engaging in unfair\\ncybersecurity  practices  that  \"unreasonably  and  unnecessarily  exposed\\nconsumers\\'  personal data to unauthorized access  and theft\" after the company\\nsuffered  three breaches between 2008  and 2009.101  Wyndham argued that the\\nFTC did not have the authority to regulate cybersecurity under the Act and that\\nthere was no  \"fair notice  of the  specific cybersecurity  standards  the  company\\nwas required to follow.\"102  The Third Circuit rejected both of these arguments\\nand held  for the  first time  that the  FTC had authority  to regulate  companies\\'\\ncybersecurity  standards  and  that  these  companies  are  on  notice.\"\\'  FTC\\nChairwoman  Edith Ramirez welcomed the  decision and stated that \"[i]  t is not\\nonly  appropriate,  but  critical,  that the  FTC  has  the  ability to  take  action  on\\nbehalf of consumers  when  companies  fail  to  take  reasonable  steps  to  secure\\nsensitive  consumer information.\" 10 4\\n\\nA.  What is \"Unreasonable\"?\\n\\nThe  FTC brings enforcement  actions against companies whose security is\\nlegal  ambiguity  is  appropriate  for\\n\\nThis  intentional \\n\\n\"unreasonable.\"os \\n\\n\\n66 UCLA  L.  REV.  1242  (2019)\\n\\ncybersecurity  procedures because  it gives  regulators flexibility to  update their\\ninterpretation  as technology changes. 10 6\\n\\nIn  2015  the  FTC  released  a  guidebook  on  cybersecurity  best  practices,\\ntitled \"Start with Security: A Guide for Business,\" to clarify some of the \"lessons\\nIt  is  worth  noting  that  the  published  FTC\\nlearned  from  FTC  cases.\"\"o\\' \\nenforcement  actions  \"are  settlements-no  findings  have  been  made  by  a\\ncourt-and the specifics  of the orders apply just to those companies.\"\\'  Along\\nwith the  FTC guidelines,  the  National  Institute  of Technology  and  Standards\\n(NIST)  has  also  published  guidelines  to  help  companies  understand what  is\\nand  is  not  reasonable.10 9  According  to  the  FTC,  \"NIST\\'s  Cybersecurity\\nFramework  is  consistent  with  the  process-based  approach  that  the  FTC has\\nfollowed.\"no  These guidelines  are important because  they allow companies to\\ngauge  when  the  absence  of  a  certain  technology  would  be  considered\\nunreasonable  and thus merit an enforcement  action by the FTC.\\n\\nthat  contains  \"technical  ... \\n\\nSince  the  settlement  with Microsoft  in  2002,  the  FTC  has  made  it  clear\\nthat  companies  handling  consumer information  must implement  a  security\\nprogram \\n[the\\ncompany\\'s]  size and complexity, the nature and scope of [its] activities, and the\\nsensitivity of the personal information collected from or about consumers.\"\\nThe  NIST  Framework  also  recommends  that  a  company  look  at  the  costs,\\nbenefits,  and risks, and the company\\'s  ability to fund and implement  a certain\\nprocedure  or technology.1 1 2  The FTC requires that data security procedures be\\n\\nsafeguards  appropriate \\n\\nto \\n\\n1259\\n\\n\"reasonably  designed to protect the  security, confidentiality,  and integrity\"  of\\ninformation.\"\\'  The  following  are  some  guidelines  that would  be  relevant  to\\nthe  incorporation  of blockchain  technology  into the  FTC\\'s  understanding  of\\nreasonableness.  By  applying  these  guidelines,  the  FTC  can  find  that  it  is\\nunreasonable  for certain  companies to not incorporate blockchain  technology\\nas part of their comprehensive  cybersecurity  plan.\\n\\n1. \\n\\nFailing to Adopt Readily Available  Technology\\n\\nA  company  should  keep  their  security  \"current\"1 4  and  employ  readily\\navailable  technology,\"  including  \"protective  technologies\"  that  \"ensure  the\\nsecurity  and  resilience  of  systems  and  assets.\" 1 6  Specifically,  companies\\nshould  \"incorporat[e]  advanced  cybersecurity  technologies\"  to  ensure  that\\nthey  \"actively  adapt[]  to  a  changing  threat  and  technology  landscape  and\\nin  a  timely  and  effective  manner  to  evolving,  sophisticated\\nrespond[] \\nthreats.\"\"\\'  A  software  system that is  generally  accepted  by the  industry \"can\\nbe  considered  reasonable  even if it is  imperfect.\"\"  Conversely,  operating  on\\noutdated  software \\nleaves  systems  especially  vulnerable  can  be\\nunreasonable.11 9  In the matter of HTC America Inc., the  FTC alleged that the\\ncompany  failed  to  implement  \"readily  available\"  measures  to  address\\nvulnerabilities  in  its  systems  and  thus  \"plac[ed]  sensitive  information  at\\nrisk.\" 20  According  to the FTC, HTC America could have \"add[ed]  a few lines\\n\\nthat \\n\\n\\x0c1260\\n\\n66 UCLA  L.  REV.  1242  (2019)\\n\\nof...  code\"  to  implement  \"secure  communications  mechanisms\"  to  address\\nthese vulnerabilities. 121\\n\\nA  study of past  enforcement  actions  found that  the  FTC is  increasingly\\nshifting their  focus  to companies\\'  handling  of information and improvement\\nof  security  procedures. 12 2   Specifically,  the  FTC  has  increasingly  brought\\nenforcement  actions  against  companies  with  \"vulnerabilities  that  target\\nspecific  technological  failures  with  known  solutions.\" 2 3 \\nIt  is  important  for\\ncompanies  to follow this trend because  as technology changes,  so too does the\\nmeaning  of \"known solutions.\"  As  a result,  the reasonableness  of a company\\'s\\ncybersecurity  technology constantly evolves.\\n\\n2.  Leaving  Gaps in Encryption/Security in the Storage-\\n\\nTransmission Chain\\n\\nIn  order  to  protect  information,  technology  and  procedures  must  be\\nimplemented  to enable  a company  to  \"[s]  tore  sensitive personal  information\\nsecurely  and protect  it  during transmission.\"l24  Procedures  that increase the\\nrisk  of breach  from  a  compromise  of  an  employee  or  third-party  service\\nprovider\\'s  credentials  can  be  unreasonable. 1 25   Additionally,  transporting\\ninformation in a manner that makes it susceptible  to theft or misappropriation\\ncan be  unreasonable. 12 6\\n\\nThe  FTC enforcement  action against Superior Mortgage  Corp. illustrates\\nthe principle that storing and transmitting sensitive information must be  done\\nsecurely,  even when done by a third-party service provider.  Superior Mortgage\\nCorp.  hired  a  third  party  to  supply  maintenance  to  the  servers  that  stored\\nsensitive  personal information. 127  The FTC alleged  that the  sensitive personal\\ninformation  on the servers was originally  encrypted, but was decrypted by the\\nthird-party  service  provider  before  being sent  to  Superior  Mortgage  Corp. 128\\n\\n\\n1261\\n\\nThe FTC made it clear that this risk could have been prevented by ensuring that\\nthe  data  was  secure  throughout  its  lifecycle.129  Security  procedures  and\\ntechnology must protect the  confidentiality,  integrity,  and availability  of data\\nwhile it is in storage and in transit.\"o\\n\\n3.  Responding and Recovering  Too Slowly  From Breaches\\n\\nAccording to the FTC, not adequately responding to and recovering from\\nan incident can be  unreasonable.\"\\'  Companies  should implement procedures\\nand  technologies  that  allow  them  to  successfully  respond  to  attempted  and\\nsuccessful  cyber  attacks.132  This  includes  containing  and  mitigating  these\\nincidents.\"  Moreover,  procedures  and technologies  should allow a company\\nto  maintain  resilience  and  restore  the  capabilities  or  services  that  were\\nimpaired  due  to  an incident.134  Companies  must be  able  to  \"move  quickly to\\nfix\" the problem and ensure  timely recovery to normal operations.\"\\'\\n\\n4. \\n\\nInadequately Policing  the Security of Third-Party Service  Providers\\n\\nA  company  is  responsible  for  ensuring  that  its  third-party  service\\nproviders implement  reasonable  security measures, 136  and failure to  do so can\\n\\n\\x0c1262\\n\\n66 UCLA  L.  REV.  1242  (2019)\\n\\nbe  unreasonable.\"\\'  This  includes  not  only  \"determining\"  the  adequate\\ncybersecurity  requirements  of  third-party  services  providers,  but  also\\n\"verifying\"  that the requirements  are met.\"\\'  Allowing a third party to  operate\\non  outdated  software  poses  a  security  risk  and thus  can  be  unreasonable.13 9\\nFailing  to  adequately  reduce  the  risk  posed  by  a  third  party  can  also  be\\nunreasonable.140  In the  case  of Dave  & Buster\\'s,  the FTC  alleged  that hackers\\nexploited  the  security  weaknesses  in  the  third-party  credit  card  processing\\ncompany\\'s  system and  intercepted  personal information.141  Dave  & Buster\\'s\\nactions  were  unreasonable  because  they  could  have  reduced  the  risk  and\\nbreadth of data compromise by better monitoring of the third party.142\\n\\nB.  Cybersecurity of Third Parties and Inconsistent Enforcement\\n\\nThe  current structure  of enforcing  reasonable  security measures of third\\nparties is problematic because the company outsourcing the service is expected\\nto  ensure  that  the  third  party  has  adequate  security  (i.e.,  the  third party  is\\n\"trusted\").143  Building trust can be  challenging because  getting a third party to\\nfocus  on security  and finding the  right  people  who can  provide that  security\\ncan be  difficult,  time consuming,  and expensive.144  Moreover,  \"the problem is\\nmade  more  challenging  due  to  a  lack  of  standard  security  practices  for\\nevaluating  particular  scenarios.\" 45  The oversight programs that are  currently\\nin place have been found to be \"insufficient  to manage third-party risks.\"14 6\\n\\nThis is an important issue because  companies are  increasingly relying on\\n\"trusted\"  third parties, 147  yet the  FTC brings  enforcement  actions  against the\\ncompany  contracting  out  services  (the larger  company),  instead  of the  party\\n\\n\\nthat was  initially  breached  (the third  party).  For example,  in the  matters  of\\nCardSystems  Solutions,  Dave  & Buster\\'s,  GMR Transcription  Services,  and\\nAshley  Madison,  the  FTC  brought  enforcement  actions  against  the  named\\nparties  instead  of the  third  parties  that  had their  networks  breached  due  to\\ninadequacies  in their own  security measures.14 \\nIn essence,  a third party that\\nhandles  the  same  confidential  and  sensitive  information  as  the  larger\\ncontracting  company  escapes  FTC enforcement  and  thus  is  not  required to\\nhave  reasonable  security  measures.  The  FTC\\'s  enforcement  of reasonable\\nsecurity measures  against the big fish does not deter third parties from having\\nunreasonable  security  measures.  This  leaves  the  regulation  of third-party\\nsecurity solely in the hands  of a contracting  company.  Under this framework,\\nthird parties will  continue  to  pose  security risks and will  remain  the  weakest\\nlink, unless the contracting companies  know how to assess  their cybersecurity.\\n\\nIII.  WHAT IS BLOCKCHAIN?\\n\\nA.  Blockchain  Technology\\n\\nAs  a  relatively  new  technology  that  employs  a  sophisticated  system  of\\ncryptographic  mathematics,  blockchain  has  been  defined  in  many  different\\nways,  and  there  is  not  much  consensus  on  the  proper  definition.149  Some\\ncommentators  refer  to  blockchain  by  analogy  and  describe  it  as  a  massive,\\nimmutable,  and  distributed  Google  Spreadsheet.\\'  Others  describe  it  in\\nsimple terms  as a system that allows you to \"validate, with absolute certainty,  a\\nsource  and destination for any transaction\"\"\\'  and \"manufacture trust through\\nclever code.\"152\\n\\nPerhaps the  best definition  describes blockchain  by its central  elements:\\nan  electronic  transaction ledger that is  decentralized,  immutable,  consensus-\\n\\n\\n66 UCLA  L.  REV.  1242  (2019)\\n\\nspecific  elements \\n\\ndriven,  and secured by cryptographic verification.\"\\'  But just as important  as\\nits \\ntechnological\\nbreakthrough-which  is to establish trust between two parties without the use\\nof a trusted third party.\\n\\nis  blockchain\\'s  goal-and  chief \\n\\nMost simply, blockchain is a ledger.154  A ledger is a database that can store\\nall  sorts  of information,\"\\'  for  example,  a  complete  record  of all  transactions\\nover the life of a company. 15 6  The ledger maintained by a blockchain tracks the\\ntransfer  of information  from  the  transferor  to  the  transferee.5  However,\\nunlike  a  traditional  ledger,  \"a  blockchain  ledger  is  considered  decentralized\\nbecause transactions  are  stored on (several thousand) computers  connected to\\na  common network via the  Internet.\"158  The  computers,  called nodes,  are  the\\n\\n2-4 \\n\\nARS \\n\\nTECHNICA \\n\\nrecordkeepers  who update the ledger.  This peer-to-peer platform ensures that\\n\"only information upon which the network reaches  consensus will be included\\nin the blockchain.\\n\\n66 UCLA  L.  REV.  1242  (2019)\\n\\nIn order to validate  a transaction, 164  a node must trace the history of all  of\\nthe transactions  on a particular  blockchain.  It does so by looking  at the most\\nrecent block. 165  Blocks are  groups of transactions  that have been  validated and\\nstored on the blockchain  around the  same time. 1 6 6  Blocks  are  linked together\\nin  a chronologically  ordered  chain, giving rise to  the name blockchain.  Each\\nblock  contains  a  unique  reference  point  that  represents  the  contents  of the\\nblock (i.e., the transactions  or information in the block). 1 67  The nodes must use\\nthe unique reference  point of the previous block in order to  solve the complex\\ncryptographic  function presented by the  transaction at hand. 168\\n\\nHowever,  before  a transaction can be  added to  the blockchain,  the  other\\nnodes  must  come  to  a  consensus  on  the  correct  answer  to  the  complex\\ncryptographic  function  by also  using the  previous  block\\'s  reference  point. 169\\nBecause  all of the nodes\\'  ledgers are in sync,  and thus all nodes  are aware  of the\\nvalid reference  points,o if one  malicious  node  tries  to alter  a previous block,\\nthe  other  nodes  would  recognize  that  the  malicious  node\\'s  attempted\\nalteration  did not use  the valid  reference  point and  the network  would reject\\nthat  transaction.  \"[T]he  information  in a  particular block  cannot  be  altered\\nwithout changing all subsequent blocks in the chain and creating  a discrepancy\\nthat  other  record-keepers  in  the  network  would  immediately  notice.\"7 1\\nRequiring  the  use of a common  reference  point  and decentralized  consensus\\nensures  immutability  and  \"eliminates  the  dangers  that come  with data being\\nkept in a central location.\" 72\\n\\nTo simplify, say each block is numbered with a letter.  If someone tried to\\nalter  block D  (a  combination  of blocks  A  + B  + C) by  attempting  to  change\\nblock A into \"A + 1\", block D would still be  read as A + B + C by all of the other\\n\\n\\nnodes in the network.  The malicious  actor\\'s attempts to  create block D as A +\\n1  +  B  + C  would  not be  verified  by the  other  nodes  on  the  network.  The\\nresulting disagreement  between the  nodes regarding the order of transactions\\nwould  prevent  consensus  in  the network  and  that  invalid transaction  would\\nnot  be  added  to  the  blockchain.  Thus  it  would  prevent  the  type  of fraud\\ndescribed  above.\\n\\nB.  Public, Consortium, and Private Blockchains\\n\\nLike many other  databases,  blockchains  can be  public,  private,  or some\\ncombination thereof.  All  of these versions have important similarities: they are\\nall  decentralized  peer-to-peer  networks  where  each  participant  maintains  a\\nreplica  of the  ledger;  they all  operate  under the  consensus  model  of verifying\\ntransactions  that  are  added  to  the  blockchain;  they  all  provide  certain\\nguarantees  of immutability  of the  ledger  even  when  some  participants  act\\nmaliciously;  and the  decentralized  nature  of all of these  versions ensures  that\\nnone of them has a single point of failure.\"\\'\\n\\nThe most well-known blockchain  network, Bitcoin, is public (also known\\nas  \"permission-less\"  or  \"fully decentralized\")  because  anyone  can  operate  a\\nnode  on  this network if they  have  the  appropriate  software.174  Under public\\nblockchains,  \"the number  of participants  on the network is  unlimited, and no\\none needs  to get permission from another user in order to take part.\"\"\\'  Public\\nblockchains  provide  a  \"robust network that  ensures  efficacy in  the  system\"17 6\\nbecause  open access ensures  distribution of nodes  and prevents any one single\\nentity  or  power  from  possessing  majority  control  over  the  network.\"\\nHowever,  public  blockchains  require  substantial  amounts  of computational\\npower  to  maintain  the  distributed  ledger  because  a  larger  number  of nodes\\nmust verify a transaction  before it is  added to the blockchain.\"\\'\\n\\n\\x0cStart  With Trust\\n\\n1269\\n\\nthat  aims  to  service \\nthe  needs  of  a  permissioned  group  of  financial\\ninstitutions.190  Separately,  Ford,  Renault,  General  Motors,  BMW,  and  IBM\\nrecently announced that they founded the Mobility Open Blockchain Initiative\\nconsortium  with  the  aim  of \"foster[ing]  an  ecosystem  where  businesses  and\\nconsumers  have security and sovereignty over their driving data, manage ride-\\nshare  and  car-share  transactions,  and  store  vehicle  identity  and  usage\\ninformation.\" 91\\n\\nC.  Applications\\n\\nBitcoin is the first and most popular use of blockchain and is one of many\\n\"cryptocurrencies.\"l 92  Cryptocurrencies  are  built  on  public blockchains  and\\ncan  be  bought  and  sold on various  online  exchanges  that operate  much like\\ntraditional financial exchanges.  The term \"cryptocurrency\"  is frequently used\\nto  describe  all  sorts  of public  blockchains,  but this  can  be  very  misleading.\\nWhile  it  conveys  attributes  that  define  some  blockchains,  like  a  means  of\\nstoring  value  and  exchanging  wealth,  it  fails  to  capture  the  nuances  and\\ncapabilities  of others.\\n\\nAs of early April 2019, there are over 2,000 public blockchains.1 93  A public\\nblockchain  can be  used to  verify a  source  and destination  of a  transaction  of\\nassets  (i.e.,  cryptocurrencies).  But  not all  public  blockchains  have  currency\\napplications. \\nIt is  important  to  understand  that  currency  was  just  the  first\\napplication  of blockchain  and is  by no means  the  only or  best  use.1 94  Utility\\n\\n66 UCLA  L.  REV.  1242  (2019)\\n\\nblockchains are  another type of application and are explored in Subpart IV.B.2.\\n(in  particular,  data  storage).  Other  blockchains  have  a  platform  function.\\nPlatform  blockchains  create  an  infrastructure  on  which  more  specific\\napplications  can be built.  Ethereum,  for example, is an open software platform\\nbased  on blockchain  technology  that allows  developers  to  build  and  deploy\\ndecentralized  applications.195  Decentralized  applications  that are  created  on\\ntop  of this platform  do not need  to  create  their own  blockchain,  but instead\\nwork  off  of  the  existing  Ethereum  blockchain.  The  \"IBM  Blockchain\\nPlatform\"l96  is an example  of a \"private Ethereum,\"  where businesses can build\\nand  use  applications  on  top  of IBM\\'s  blockchain.  Unlike  Ethereum\\'s  fully\\ndecentralized  and public model, IBM controls the nodes.\\n\\nThe potential  ofblockchain technology as a whole is largely untapped and\\nthe exploration  of private blockchains  is in especially nascent stages, but things\\nare  picking  up.  Both the  private  sector and the  public  sector have  started to\\nlook closely at  the potential  of private blockchain  technology.\\n\\nThe  most  significant  use of private blockchains  in  the private  sector has\\nbeen  for platform blockchains  such  as  IBM\\'s  Blockchain  Platform.197  Unlike\\nEthereum\\'s  public  platform,  these  private  blockchain  platforms  are  more\\nsuitable  for  corporate  usersl98  because  transactions  are  made  efficient  and\\nconfidential  by the  limited  and selective  nature  of the  participants.199  These\\ntypes of private platform blockchains  can be thought of as \"blockchain for hire\"\\nor  \"blockchain  as  a  service,\"  where  users  leverage  and  use  the  blockchain\\n\\n\\nplatform created by a  company that has the  resources  and expertise to  design,\\ncreate,  and service a private blockchain.  For example, Helzberg Diamonds and\\njewelry manufacturer  Richline  Group  are  already  working with  IBM to  track\\nand  authenticate  diamonds  and  precious  metals  on  IBM\\'s  blockchain.200\\nWalmart and Sam\\'s Club sent a letter to its suppliers of fresh leafy greens asking\\nthem  to  track their products  on Walmart\\'s  IBM-powered  blockchain.201  But\\nnew and unestablished players  are also entering the market.  Coin Sciences Ltd.\\nallows  users to utilize  their blockchain  infrastructure for various  uses,  such  as\\nmessaging,  decentralized  exchanges,  database  synchronization,  currency\\nsettlement,  bond  issuance,  and  consumer  reward  schemes.202 \\nIn  2017,  the\\nblockchain company Chain struck a deal with Nasdaq and Citi where these two\\ncompanies  would  use  Chain\\'s  platform  to  create  \"a  new integrated  payment\\nsolution  that  enables  straight  through  payment  processing  and  automates\\nreconciliation  by using  a distributed  ledger  to  record and  transmit  payment\\ninstructions.\"203\\n\\nThe  public  sector  has  started  to  look  into  a  different  type  of private\\nblockchains.  These  private  blockchains  would  be  created  for  one  entity\\'s\\nexclusive  use,  as  opposed  to  many  different  companies  using  the  same\\nplatform.  Private  companies  could also  create  this  type  of blockchain,  but it\\nmay be  more  expensive  and  resource  intensive  to  invest  in  this  technology\\nfrom the ground up rather than using a preexisting blockchain.204  Thus far, the\\nU.S.  government\\'s  interest  has  largely  been  in  how blockchain  can  bolster\\nnational defense.  In September 2016,  the Defense Advanced  Research Projects\\nAgency  (DARPA)  awarded  a  $1.8  million  contract  to  two  companies  to\\n\"advance  the  state  of  formal  verification  tools  and  all  blockchain-based\\n\\n\\n66 UCLA  L.  REV.  1242  (2019)\\n\\nintegrity monitoring  systems.\"2 05  In May 2017,  ITAMCO,  a developer  of the\\nadvanced  privacy  application  called  \"Crypto-Chat,\"  was  awarded  a  Phase  1\\ngrant  from  DARPA  to  \"develop  a  secure,  non-hackable  messaging  and\\ntransaction  platform for the U.S.  military.\"2 0 6  Joel Neidig, Director of Research\\nand  Development  at  ITAMCO,  stated  that  they  aim \"to  develop  the  latest in\\nmilitary-grade  encryption software using blockchain  technology.\"2 0 7  The uses\\nof this new messaging  platform include \"the communication  of troops  on the\\nground with HQ, or sending information between  intelligence  officers and the\\nPentagon.\"2 0 8  A  $700  billion  defense  bill  passed  by  the  U.S.  Senate  in  2017\\nincluded an amendment that would require \"a report on the potential offensive\\ntechnology  and  other\\nand  defensive  cyber  applications  of  blockchain \\ndistributed  database  technologies  and  an  assessment  of  efforts  by  foreign\\npowers,  extremist  organizations,  and  criminal  networks  to  utilize  these\\ntechnologies.\"2 0 9  The  U.S.  Treasury  also  hired  a  contractor  \"to  develop  a\\nprototype  using  blockchain,  or  distributed  ledger  technology,  to  track  and\\nmanage  physical  assets.\"2 1 0  In  2018,  a hearing  was held  by the  U.S.  House  of\\nRepresentatives  Committee on Science,  Space, and Technology  titled \"Beyond\\nBitcoin:  Emerging  Applications  for  Blockchain  Technology\"  with the  aim  of\\naddressing  how  blockchain  technology  could  \"potentially  bolster  private\\ncompanies\\'  and the federal government\\'s  cybersecurity  weaknesses.\"2 1 1\\n\\nBLOCKCHAIN  AND  CYBERSECURITY\\n\\nA.  How Blockchain  Can Enhance  Cybersecurity\\n\\nBlockchain  technology  has  the  potential  to  tremendously  improve\\ncybersecurity2 12  and  many  industries  and  enterprises  are \\nincreasingly\\nconsidering  its use.2 13  The Executive  Director of the European Union Agency\\nfor  Network  and  Information  Security  agrees  that  \"cyber  security  should  be\\nconsidered  as  a  key  element  in  the  Blockchain  implementation.\"2 1 4  The\\ntechnology has already been deployed  in Estonia to protect the confidentiality,\\nintegrity,  and  availability of marriage  registrations,  health records,  and other\\nsensitive  information.2 1 5 \\nIBM  has  applied  for  a  patent  that  would  use\\nblockchain  to  increase the  security and privacy of storing  and managing  data\\nassociated  with unmanned  aerial vehicles.2 1 6  The National  Aeronautics  and\\nSpace  Administration  (NASA)  also  proposed  the  use  of  a  permissioned\\n\\n\\n\\x0c1274\\n\\n66 UCLA  L.  REV.  1242  (2019)\\n\\nblockchain \\nto  boost  cybersecurity  by  \"enabl[ing]  aircraft  privacy  and\\nanonymity while providing a secure  and efficient  method for communication\\nauthorized entities.\"217  Dozens of central banks  around the world are\\nwith  ... \\nalso  experimenting  with  blockchain  technology  with  the  aim  of addressing\\ncybersecurity  concerns, among other things.218  The Department  of Homeland\\nSecurity is getting ready to use blockchain  technology to secure  the storage and\\ntransmission of data collected by security cameras, sensors,  and other internal\\ndatabases.21 9  Additionally,  the  Colorado  Senate  recently  passed  a  bill  that\\nwould  require state  departments  to  \"annually assess  the  data systems  of each\\npublic  agency  for the benefits  and costs  of adopting and applying\"  blockchain\\ntechnology.220\\n\\nBlockchain\\'s  breakthrough  is  in  its  \"culmination  of decades  of research\\nand breakthroughs  in cryptography and security.\"221  This combination makes\\nblockchain  secure  to  the  point  where  \"no  one  has  yet  managed  to  break\\nthe  ...  decentrali[zled  architecture\"  of  it.222   Even  the  National  Security\\nAgency  and Federal Bureau of Investigation  lack the ability to circumvent the\\ntechnology behind blockchain.223  Contrast  this impenetrable  nature with the\\ncurrent state of cyber-insecurity,  where even  the largest  companies get hacked\\nregularly,  no  matter  how  much  money  they  spend  on  their  own  security\\n\\n\\n1275\\n\\ninfrastructure.2 2 4  Moreover,  the security offered by blockchain  is needed now\\nmore  than ever in order  to heed  cybersecurity  experts\\' warning  that \"the new\\nparadigm  has  to  stop the  hacker[s]  getting  in\"  before  they can  do damage.2 2 5\\nThe  key  to  solving  the  current  \"systemic\"  cybersecurity  crisis  lies  in\\nblockchain\\'s  ability \\nto  maximize  decentralization  and  distribution  of\\ncomputers,  and thus  create more fault-tolerant  and unhackable networks.226\\n\\nAlthough  not  a panacea, 2 27  incorporating  blockchain  into  a  company\\'s\\ncomprehensive  cybersecurity  plan can  increase  the  confidentiality,  integrity,\\nand availability of data, and better ensure the resilience  of networks.\\n\\n1.  Confidentiality\\n\\nEncryption  methods  and  access  controls,  when  combined  with\\nblockchain,  can ensure confidentiality of data.2 28  While public blockchains  do\\nnot  provide  confidentiality  of data,  on  a  private blockchain,  a  company  can\\ndecide  to  encrypt  information  end-to-end before  storing  it. 22 9  Thus  a hacker\\nwho gains  access  to a node on a private blockchain\\'s  network could not  access\\nthe information so long as the hacker does not possess  the encryption key.23 0\\n\\n\\nMoreover,  a  private  blockchain  can  be  designed  to  implement  access\\ncontrols and thus ensure that data is restricted to authorized personnel.  Access\\ncontrols  can  determine who can  read  the  data, who  can  submit transactions,\\nand who can validate  them.231  The cryptographic  validation  process can  even\\nbe  spread out among multiple  computers,232  where  each party only has partial\\naccess  to  the  information,  and  thus  \"[tihe  parties  are  trusted  as  a  whole,\\ndecentralized  unit, but not individually.\" 2 3 3  This is similar to the idea of a data\\nstorage  blockchain  splitting  up  data  into  shards  where  one  piece  of\\ninformation  is split into many different pieces  and distributed  throughout the\\nnetwork.234\\n\\nAccess  to  data on  a private blockchain  can  even  be limited  to  as little  as\\ntwo  parties.  IBM\\'s  private  blockchain 235  allows  the  sharing  of data  through\\nchannels  with only those  organizations  that need to  have  access  to  it. 2 3 6  For\\nexample,  in  a  medical information  context,  all  organizations  in  the  network\\ncan  see  that an  individual has health insurance,  but only those in a particular\\nchannel can see the coverage  details.237\\n\\nEmploying  encryption  and  access  controls  in  a  blockchain  ensures  the\\nconfidentiality of data even when computers on the network are compromised.\\nCompanies  must  assess  their  own  risk  tolerance  in  deciding  what  type  of\\nblockchain  to  implement.  Larger blockchain  networks  (with,  for  example,\\nmore  participants)  make  it more difficult for  a hacker to  know exactly which\\nparticipant  has access to the data that they are  looking for.  Smaller blockchain\\nnetworks  allow  for  more  confidentiality  because  only  a  small  number  of\\n\\npractices  to  manage  their  encryption  keys.  See,  e.g.,  VIRTRU,  THE  SIMPLE  GUIDE  TO\\nENCRYPTION  KEY  MANAGEMENT,  https://www.virtru.com/wp-content/themes/virtru\\n/files/pdf/The%20Simple%20Guide%20to%20Encryption%2OKey%20Management.pdf\\n[https://perma.cc/8K8Q-CMDG].\\n\\n1277\\n\\nparticipants  are  privy to  data, but are  more likely  to be  breached  because  they\\nare  less centralized.\\n\\n2. \\n\\nIntegrity\\n\\nBlockchain\\'s  innate characteristics  of immutability and  decentralization\\nensure  data integrity.  Once  data is inputted on a blockchain it is  \"usually there\\nforever.\" 23 8  It is so immutable  that it has been  dubbed a \"digital tattoo.\" 239\\n\\nThe  cryptographic  validation  mechanism,  consensus  model,  and\\ndecentralized  nature make it very challenging for any party to tamper with the\\ndata  stored  on  a blockchain.  Data  can  only be  added  on  the  blockchain  if a\\nmajority  of nodes  agree  that  the  data  should be  added.  Once  added  on the\\nblockchain,  that data becomes  a reference point which ensures that before  any\\nnew  data  can  be  added,  the  nodes  must  agree  that  the  reference  point  (i.e.,\\nexisting  data)  has  not  been  altered.  This  structure  ensures  that  once\\ninformation  is  on  a  blockchain,  it  will  remain  unaltered.  Moreover,\\nmechanisms  similar  to  those  applied  in  data  storage  blockchains  can\\nperiodically verify the integrity of information.240\\n\\nIt should be  noted that if hackers  were to  gain  access  to a majority of the\\ncomputers  on ablockchain\\'s network, they would potentiallybe  able to tamper\\nwith the  data.241  But  a hacker\\'s  successful control  of a majority  of computers\\n24 2  Rather,  \"an  attacker  would  only  be  able  to\\ndoes  not  guarantee  success.\\nmodify transactions  within the past few blocks\" because  \" [t] he farther back in\\nthe blockchain  transactions  are, the more secured they are  against this kind of\\nattack.\" 243   Moreover,  it  is  significantly  more  difficult  for  hackers  to  gain\\ncontrol of an entire network where computers  are  distributed than for them to\\ngain  control  over  a  network  that  is  centralized,  which  is  often  the  model  in\\ntoday\\'s  cybersecurity landscape.244  In a manner parallel to  confidentiality,  the\\nlarger  the  blockchain  network,  the  more  difficult  it  will  be  to  corrupt  the\\n\\n\\n66 UCLA  L.  REV.  1242  (2019)\\n\\nintegrity  of the  data.  Private blockchains  operating  with  a lower  number  of\\nnodes  should  ensure  that  their  network  is  sufficiently  distributed  with  no\\nsingle  points of attack.\\n\\nBlockchain\\'s  ability  to  ensure  the  immutability  of  data  is  especially\\nimportant  for cybersecurity  because  the  subtlety  of altering  data,  rather than\\nstealing  it or  deleting  it,  makes  this  a particularly  insidious  form  of attack.245\\nImplementing  blockchain as part of a company\\'s comprehensive  cybersecurity\\nplan can ensure the integrity of data far better than other methods.\\n\\n3.  Availability\\n\\nDecentralization  and  immutability  ensure  that  the  data  stored  on  a\\nblockchain  and the  system itself will remain  available  in the  face  of an  attack.\\nThe  decentralized nature ofblockchain  guarantees that there is no single point\\nof failure.246  This  means  that  if a  node is  taken  down,  data is  still  accessible\\nthrough other nodes since  all  of them maintain a full copy of the data-unless\\naccess  controls  are  set  in  place  that  would  limit  a  certain  node\\'s  access.\\nMoreover,  compromised  nodes  can  be  dropped  from  the  blockchain\\nnetwork.247  Even  if  a  part  of  the  network  is  compromised,  distribution\\nguarantees  that  the  blockchain  network  will  be  operational  through  the\\nremaining  nodes.  Immutability  of information  added  on  a blockchain  also\\nensures  that  a  hacker  cannot  erase  the  data  even  if part  of the  network  is\\ncompromised.\\nAlthough \\n\\nthat  risk\\nproportionally  decreases  with  greater  distribution  of  nodes.  As  with\\nmaintaining  integrity,  smaller  private  blockchains  must  ensure  that  their\\nnetwork is sufficiently distributed so that there can be no single point of failure.\\nSimilarly,  proper  access  controls  should  be  implemented  as  part  of  a\\ncomprehensive  cybersecurity  plan  to  ensure  that  blockchain\\'s  potential  to\\nensure  availability can be  realized.\\n\\nthe  risk  of  a  networkwide  breach  remains, \\n\\n4.  Resilience\\n\\nThe  most common type  of cyberattack that would  affect the resilience  of\\na  network  is  the  distributed  denial  of service  (DDoS).  DDoS  attacks  flood a\\nserver  with  superfluous  requests  in  an  attempt  to  overload  the  system  and\\n\\n1279\\n\\nprevent  legitimate  use  of a  system.248  These  requests  often  originate  from\\nthousands of sources, which makes them effectively impossible to stop.2 4 9 They\\nhave  been  successful  thus  far  because  of  the  pervasive  use  of  centralized\\nservers.25 0  DDoS  attacks  have  been  taking  place  for  twenty  years  and  are\\ngrowing  more  prevalent  and  stronger.2 5 1  Recently,  Twitter,  SoundCloud,\\nSpotify, and Shopify were the targets of DDoS attacks that caused their websites\\nto  go  offline  temporarily.25 2  On  the  other  hand,  the  Bitcoin  blockchain  has\\nremained  operational in the  face  of regular and \"massive\"  DDoS  attacks since\\nits inception  over ten years ago.25 3\\n\\nBlockchain  offers  resilience  against  these  types  of  attacks  and  others\\nthrough  its  decentralized  structure.  Even  if  a  major  part  of  a  blockchain\\nnetwork  is  under  attack  or  compromised,  it  will  remain  fully  operational\\nthrough the  other nodes.  Ensuring that nodes  are  sufficiently  distributed will\\nincrease  the resilience  of a network.  As  above, this  may be  more challenging\\nwith  smaller  private  blockchains  because  of  the  smaller  number  of nodes.\\nTherefore,  blockchain  technology  should always  be  implemented  as part  of a\\nlarger cybersecurity plan.\\n\\nB.  Absence  of Blockchain  as Unreasonable in the Data Storage  Context\\n\\nCompanies  handling  consumer information  must  implement  a security\\nprogram  that  contains  technical  safeguards  that  are  appropriate  to  the\\norganization\\'s  size,  complexity,  and  activities,  and  to  the  sensitivity  of the\\n\\n248.  Security  Tip  ST04-015:  Understanding Denial-of-Service Attacks,  US-CERT  (Nov.  4,\\n2009),  https://www.us-cert.gov/ncas/tips/STO4-015  [https://perma.cc/GGY3-7587].\\n\\n249.  Id.\\n250.  See  Jon  Buck,  Why  Blockchain  Technology  Is  Perfect for  Fighting DDoS  Attacks,\\n(Sept.  30,  2017),  https://cointelegraph.com/news/why-blockchain-\\n\\n\\npersonal information that the organization  collects from users.254  They should\\nalso  look at  a technology\\'s  costs, benefits,  and risks,  and their  ability to fund\\nand  implement  it.255  Understanding  that  the  analysis  of  cybersecurity\\nreasonableness  is  always  done case-by-case,  this Subpart applies  the  FTC and\\nNIST cybersecurity  guidelines  to blockchain  and argues that the FTC ought to\\nview failure to  use blockchain  as unreasonable.  As a  reminder, the  guidelines\\nthat would be  relevant  to incorporating blockchain  technology into the FTC\\'s\\nunderstanding  of reasonable  cybersecurity  measures  are  (1)  using  readily\\navailable  technology,  (2)  protecting data during storage  and transmission,  (3)\\nresponding and recovering from cyber attacks, and (4) ensuring the security of\\nthird parties.\\n\\n1.  Adopting  Readily Available  Technology\\n\\nBlockchain is  a  current  and state-of-the  art technology  that was  created\\nabout ten years ago.256  But importantly, new technology can still be considered\\nreadily  available  in  the  FTC\\'s  eyes.  Readily  available  is  understood  to  mean\\nadopted  by the  relevant  industry,  with allowance  for imperfection  in  cases  of\\nsoftware.257  In fact,  much of the  technology  behind blockchain  is  already in\\nwidespread use, 2 5 8  most  importantly the Turing Award-winning  technologies\\nof  asymmetric  cryptography  and  distributed \\nAsymmetric\\ncryptography was first conceived of in 1970 by a British cryptographer working\\nfor  the  United  Kingdom\\'s  Government  Communications  Headquarters  and\\nlater made public in 1976.259  Since then it has been in wide use in the financial\\nand telecommunications  industries among others.260  It is even  required by the\\nNIST  for use  in the  U.S.  Federal  Government. 2 61  The FTC also  recommends\\n\\nsystems. \\n\\nthat  companies  \"[ulse  strong  cryptography  to  secure  confidential  material\\nduring  storage and transmission.\"26  Moreover,  the  entire  architecture  of the\\ncurrent  World  Wide  Web  is  based  on  the  distributed  systems  model.263\\nits  combination  of  existing\\nEssentially,  blockchain\\'s \\ntechnologies.264\\n\\ninnovation  was \\n\\nAdditionally,  blockchain  technology  is  open-source  code  that  can  be\\ndownloaded  and  run  by  anyone  for  free.265  The  barriers  of  entry  are\\nexceedingly  low  and  should  not  inhibit  a  company  from  adopting  this\\ntechnology.  In fact, there are already a number of fully-functional  and market-\\nready  blockchain-based  data  storage  applications.266  Moreover,  there  are  a\\nnumber  companies  that  offer  blockchain  services  that  are  directly  aimed  at\\nenhancing  cybersecurity 267  and  some  companies  are  already  adopting  the\\ntechnology  for  this  purpose. 268  Also,  across  nearly  every  sector,  billions  of\\ndollars  are  being spent  on blockchain  funding 269  and  Fortune  500 companies\\nhave  filed  hundreds of blockchain  patents. 270  A large company with adequate\\n\\nMECHANISMS \\n\\n66 UCLA  L.  REV.  1242  (2019)\\n\\ncapital  that  collects  sensitive  information  from  numerous  individuals would\\nbe remiss to not adopt this technology because its cybersecuritybenefits  greatly\\noutweigh its costs.  From the perspective  of a reasonable company, blockchain\\nin  the  cybersecurity  and  data  storage  context  is  a  known  solution271  to  data\\nbreaches  and  thus  its  absence  will  lead  to  FTC  enforcement  actions  sooner\\nrather than  later.  Not  using blockchain  is akin  to  running outdated  software,\\nwhere adding  a few lines of code can address critical vulnerabilities.272\\n\\n2. \\n\\nFilling Gaps in Encryption/Security in the Storage-\\nTransmission Chain\\n\\nCompanies  must  implement  technology  that  protects  data  during  its\\nstorage  and transmission.273  Blockchain technology is capable of achieving this\\nexact  result throughout the lifecycle  of the stored data.\\n\\nBlockchain  can  ensure  confidentiality  of  data  with  the  addition  of\\nencryption  and  access  control  mechanisms. 274   This  is  similar  to  other\\ntechnologies  that  the  absence  of which  would  be  considered  unreasonable.\\nAnd  blockchain\\'s  immutability  and  decentralization  ensure  data  integrity,\\ndata and network availability, and network  resilience.275\\n\\nThe  potential  of blockchain  to  protect data while  stored and in transit is\\nalready  being  realized \\nthrough  various  blockchain-based  data  storage\\nnetworks.  Filecoin 276  Siacoin 277  and  STORJ 278  are  examples  of blockchains\\nthat aim to revolutionize  data storage by creating  a platform for  decentralized\\ncloud storage.  Instead  of renting storage from  a centralized  provider, such as\\nDropbox, 2 79  with  one  or  a  few  points  of  attack,280  these  blockchain-based\\n\\nnews/articles/2018-01-16/bofa-tops-ibm-and-payments-firms-with-most-blockchain-\\n\\npatents.\\n\\n66 UCLA  L.  REV.  1242  (2019)\\n\\n(\"X/Y/Z\")  and  duplicate  it,  creating  multiple  copies  of X,  Y,  and  Z.  The\\nmultiple  copies  of  X,  Y,  and  Z  are  then  sent  to  various  servers  across  the\\nnetwork  (where,  for example:  hosts  1,  2, 3,  would  each  have  X; 4,  5,  6,  would\\neach have Y;  and 7, 8,  9, would each have Z).  This model of data storage creates\\nhigher  levels  of  data  security  by  increasing  confidentiality  (end-to-end\\nencryption,  splitting  of  data,  and  distributing  across  network),  integrity\\n(blockchain\\'s inherent  element of immutability and periodic verification of the\\nintegrity  of  the  data),  availability  (duplicating  the  encrypted  data  shards,\\ndistributing them across the  network,  and requiring periodic  verification  and\\navailability  of that  data),  and  resilience  (distributed  networks  are  more  fault-\\ntolerant  because  they  are  not  easily  susceptible  to  networkwide  crashes  or\\nhacks).\\n\\n3.  Responding and Recovering  Quickly From Breaches\\n\\nA  comprehensive  cybersecurity  plan  must  ensure  that  a  company  can\\nadequately  respond to  and recover from  an incident;  a plan  that fails  to do so\\nmay  be  considered  unreasonable.2 8 9  When \\nincluded  as  part  of  a\\ncomprehensive  cybersecurity plan, blockchain  technology  offers  unparalleled\\nopportunities  for companies  to contain and mitigate incidents.\\n\\nAny attempted alteration  of data on the blockchain  creates a discrepancy\\nthat other recordkeepers  in the network immediately notice.2 90  This allows the\\nnetwork  to  quickly  respond  by  shutting  down  the  compromised  node  and\\nremoving  it from the network.  Blockchain  technology also  allows  a company\\nto  recover  from  an  incident  because  of its  decentralized  structure.  Even  if a\\nmajor  part  of  a  blockchain  network  is  under  attack  or  compromised,  the\\nnetwork  will continue  to  be  fully  operational  through  the  other nodes.  The\\nresilience  of  blockchain \\nis  evinced  through  the  technology\\'s  ability  to\\nwithstand numerous DDoS attacks.2 91\\n\\n4.  Ensuring the Security of Third-Parties: The Trust Machine\\n\\nAccording  to the FTC and NIST, companies  are  responsible  for ensuring\\nthat  third-party  contractors  implement  reasonable  security  measures.292\\nCompanies  must determine what  requirements  are  necessary and must verify\\n\\n\\x0cStart  With Trust\\n\\n1285\\n\\nthat they are met by the third party.293  Blockchain provides the opportunity for\\ncompanies  to streamline this  effort of building trust.\\n\\nBlockchain has been dubbed \"the trust machine\" because it allows parties\\nwho have no particular confidence in each other to collaborate without having\\nto go through a neutral party.294  This technology can \"be applied in any context\\nin which trust is essential.\"295\\n\\nAlthough it may seem like an insurmountable  task to  replace for example\\ntraditional  third-party  storage  services  with  blockchain-based  storage,  the\\ncurrent  system is  unsustainable  and change  is  necessary.  Companies,  and in\\nparticular  large  companies  that  collect  tremendous  amounts  of  consumer\\ninformation,  overwhelmingly  rely  on third parties  for data  storage.296  Third\\nparties  have  increasingly  been  the  targets  of  cyber  attacks,  which  are\\nconsidered  to  be  the  most  expensive  type  of incident.297  Yet  the  amount  of\\nsensitive  and  confidential  information  that  these  third  parties  possess\\ncontinues  to  grow.298  The  current  cybersecurity  landscape  is  problematic\\nbecause  the  contracting  party is  expected  to  ensure  the  security of the  third\\nparty\\'s  networks299  and  this  oversight  has  been  found  to  be  insufficient.300\\nMoreover,  the FTC continues to target the \"big fish\"  companies even when  the\\nthird-party  service  provider  lacked  reasonable  security measures and was the\\none who was breached.30 \\'  Under the status  quo, third parties will continue  to\\npose  security  risks  and  will  remain  the  \"weakest  link.\" \\nIncorporating\\nblockchain  technology can resolve this problem.\\n\\nReplacing traditional third-party data storage providers with data storage\\nproviders  operating  on the  blockchain  has  tremendous benefits.  Companies\\nwould have  a guaranteed way of ensuring  the security  of the  service provider\\nbecause  data center standards  can  be  codified into the  blockchain302  and thus\\n\\n293.  See  NAT\\'L INST.  OF  STANDARDS  & TECH.,  supra note  12,  at  16.\\n294.  See  The  Trust Machine, ECONOMIST  (Oct.  31,  2015),  https://www.economist.com/news\\n\\n/leaders/21677198-technology-behind-bitcoin-could-transform-how-economy-works-\\ntrust-machine  [https://perma.cc/54QG-7XHQ].\\n\\n\\n66 UCLA  L.  REV.  1242  (2019)\\n\\ntrust can be regulated through code (i.e.,  \"code is law\").\"\\'  This would solve the\\ncurrent problem  of \"insufficient\"  oversight.304  Moreover,  a blockchain-based\\ndecentralized  storage  network  offers  more  security  than  traditional  cloud\\nstorage.  This  would  minimize  a  company\\'s  risk  of facing  an  enforcement\\naction by \"reducing the risk posed by a third-party.\"  Blockchain could remove\\nthe \"weakest link\" third party but still retain the  service provider.  This can also\\nbe  more  cost-efficient  than the  traditional  third-party  data  storage  structure\\nbecause storage on the blockchain  is up to ninety percent  cheaper than storage\\non traditional servers.\"\\n\\nC.  Concerns About Market Adoption, Job Killing, and the \"Right\\n\\nto be Forgotten\"\\n\\nSome  commentators  argue  that blockchain  technology  is \"not ready  for\\nmainstream deployment\"30 6 and that companies  should consider switching to\\nblockchain-based  service  providers  only  several  years  from  now, when  \"the\\ntechnology\\'s  full  potential  becomes  clear.\"\"  These  commentators  compare\\nblockchain\\'s  adoption to \"patterns  of technology adoption\"  in the past.\"\\n\\nBut the  rate  of technology  adoption is speeding  up across  the board and\\ninnovations  introduced more recently  are being adopted more  quickly.30 9 For\\nexample,  it  took  decades  for  the  telephone  to  reach  fifty  percent  of U.S.\\nhouseholds  but only took five  years for the cellphone  to  accomplish the  same\\npenetration.o  Companies  who  move  faster  to  capture  opportunities  that\\npresent  themselves  have  a  competitive  advantage.  Moreover,  \"[c]hange\\nhappens  at  the  enterprise  level  when  new  technology  solves  an  A  list\\nchallenge,\"  and \"cybersecurity  is  an A  list challenge.\"\"  The combination  of\\n\\n1287\\n\\nmarket  incentives  and  cybersecurity  benefits  that blockchain  offers  ensures\\nthat its adoption will happen sooner rather than later.\\n\\nOthers argue that blockchain technology is a \"job killer.\"312  They contend\\nthat  if companies  switch from traditional  third-party  storage  to  blockchain-\\nbased  storage  providers,  traditional workers  would be  displaced.  But this  is  a\\ntrend  that has  been  seen  before.  And  each  time,  embracing  the  benefits  of\\ntechnology  has  won  out  in  spite  of its job-killing  effect.  New  technologies\\ndisrupt  the  labor  market  temporarily,  but  ultimately  generate  new  and\\nincrementally  more  jobs.\"\\'  Lost  jobs  are  reincarnated  in  new  form.  Why\\nshould blockchain be  any different?\\n\\nLastly,  there  are  those  that  argue  that  blockchain\\'s  immutable  nature\\nconflicts  with the  European  Union\\'s  \"right  to  be  forgotten\"  laws314  and  the\\nFTC\\'s  recommendation  of disposing  of information  once  a  company  no\\nlonger  has  any  legitimate  business  need  for  it.\"  Two  solutions  have  been\\noffered  to  solve this  problem.  First, prototype  blockchains  have already been\\ndeveloped  in line with the  needs  of large banks.316  But the  ability to edit  data\\non a blockchain while maintaining  their authenticity requires  the nomination\\nof  trustworthy  administrators  who  are  authorized  to  alter  the  ledger.\"\\nTherefore, some  of the essential characteristics  of a decentralized database  may\\nnot be  retained.  Second,  some  commentators  suggest  that instead  of having\\nthe ability to erase the data off of a blockchain, it should be sufficient to destroy\\nthe decryption  keys and thus render the data unreadable.1  However,  the data\\nis technically still on the blockchain.  It is worth noting that a company running\\na private blockchain can also easily,  if desired,  revert transactions.319\\n\\n\\nWhile these problems make blockchain  an imperfect  substitute for third-\\nparty  data  storage  providers,  the  existence  of  potential  solutions  to  these\\nproblems, coupled with the blockchain\\'s significant cybersecurity benefits-so\\nthat  blockchain\\'s\\ndesperately  needed  in  an  insecure  landscape-ensure \\nadoption  will  come  sooner  than  anticipated.  As  noted  above,  software  like\\nblockchain  can  be  considered  a reasonable  security measure  by the  FTC even\\nif it is imperfect.320\\n\\nCONCLUSION\\n\\nThe  current  cybersecurity  landscape  is  unsustainable.  Companies  are\\nincreasingly  relying  on  third parties  for  conducting  services,  yet these  third\\nparties  continue  to  be  targets  of  attack  due  to  their  weak  cybersecurity\\nmeasures.  The  problem  arises  because  contracting  companies  bear  the\\nresponsibility of ensuring the adequate  cybersecurity  of third parties:  the FTC\\nonly goes  after  the  \"big fish\" companies  for unreasonable  security  measures,\\neven  when  the  third party was  the  one  who was  breached  due  to  their  own\\ninadequate  security.  Enforcement  actions  thus  have no  direct  effect on third\\nparties,  and  they operate  outside  cybersecurity  enforcement.  This  oversight\\nmechanism  has  proven  to  be  inadequate,  and  third  parties  remain  the\\nuntrustable  \"weakest link.\"\\n\\nBlockchain technology ensures confidentiality,  integrity, availability, and\\nresilience-the  core  components  of  good  cybersecurity.  Moreover,  the\\ntechnology,  even  in  its  current  nascent  state,  comports  with  the  FTC\\'s\\ncybersecurity  guidelines  on reasonableness.  The absence of blockchain-based\\ndata  storage  by  a  large  company-with  adequate  means  and  who  collects\\nsensitive  information  from  many  people-can  thus  be  unreasonable.  The\\nmyriad  cybersecurity  benefits  that blockchain  offers  make  this  technology  a\\nunique  and  unparalleled  solution  to  the  third-party  data  breach  problem.\\nLarge  companies  handling  sensitive  and  confidential  data  should  start  with\\ntrust  and  include  blockchain  technology  as  part  of  their  comprehensive\\ncybersecurity  plan.\\n\\n\\n\\x0c\\x0c', 'computer law & security review 34 (2018) 924–927 \\n\\nAvailable online at www.sciencedirect.com \\n\\njournal homepage: www.elsevier.com/locate/CLSR \\n\\nSingapore’s cybersecurity strategy \\n\\nKah Leng TER \\n\\nNUS Business School, National University of Singapore, Singapore \\n\\na r t i c l e \\n\\ni n f o \\n\\na b s t r a c t \\n\\nArticle history: \\n\\nKeywords: \\nCybersecurity \\nLegislation \\n\\nImminent cybersecurity threats of a massive global scale have led countries to review and \\nstrengthen their national cybersecurity strategies and to enact new and bolder legislation \\nthat is both comprehensive and far-reaching. This paper discusses how Singapore’s enact- \\nment of the Cybersecurity Act 2018 is one such attempt to foster a secure and resilient \\nnational infocomm environment against cyberattacks. \\n\\n© 2018 Kah Leng TER. Published by Elsevier Ltd. All rights reserved. \\n\\nRapid digitisation and increased cyber connectivity has led \\nto a surge in sophisticated cybersecurity threats. Singapore, \\nthe most globally connected country in the world,1 \\nand rated \\nthe top in the world on cybersecurity strategy,2 \\nhas responded \\nby formulating infocomm security master plans since 2003 \\nand a high-level National Cyber Security Strategy in October \\n2016. The Strategy sets out Singapore’s vision, goals and prior- \\nities for cybersecurity. It aims to: (1) strengthen the resilience \\nof critical information infrastructures by taking a coordinated \\nnational approach to ensure the continuity of essential ser- \\nvices in the face of cyberattacks; (2) develop a vibrant cyberse- \\ncurity ecosystem comprising a skilled workforce; (3) work with \\nlocal industry and the community to promote a strong aware- \\nness of the importance of cybersecurity and (4) forge strong \\ninternational partnerships in dealing with transnational cy- \\nber threats and cooperate with computer emergency response \\nteams internationally on cybersecurity incidents. \\n\\nSingapore’s commitment to cybersecurity is reinforced in \\nthe latest five-year National Cybersecurity Masterplan 2018 \\nwhich will provide strategic directions in securing the info- \\ncomm environment not only in the government and critical \\ninformation infrastructure, but also in the business and peo- \\nple sectors. At the same time, a balanced approach will be \\n\\ntaken between security requirements and the ease of con- \\nducting business and daily activities. The vision of Masterplan \\n2018 is for Singapore to be a “Trusted and Robust Infocomm \\nHub” by 2018. It focusses on three key areas: (1) enhancing \\nthe security and resilience of critical information infrastruc- \\nture; (2) increasing efforts to raise infocomm security aware- \\nness and adopting security measures among businesses and \\nusers; and (4) growing Singapore’s pool of infocomm security \\nexperts. The allocation of at least 8% of the government’s in- \\nfocomm technology budget to developing cybersecurity tal- \\nent and the cyber security ecosystem underscores Singapore’s \\ncommitment to engender a secure and resilient infocomm en- \\nvironment and a vibrant cyber security ecosystem. \\n\\nThe objectives, policies and strategies laid down in the Cy- \\nbersecurity Masterplan 2018 and the Cybersecurity Strategy \\nare reflected in the provisions of the Cybersecurity Act, en- \\nacted on 5 February 2018 and expected to come into force in \\nthe second half of the year. \\n\\nThe Cybersecurity Act has generally won the support of \\nindustry respondents and cybersecurity professionals. In re- \\nsponse  to  feedback  received  from  the  public  consultation \\nwhich was open from 10 July to 24 August 2017, a few but sig- \\nnificant amendments were introduced. The Act sets out three \\n\\nE-mail address: bizterkl@nus.edu.sg \\nAccording to the McKinsey Global Institute Report 2016. \\nSurvey by the UN International Telecommunication Union (ITU) based on Singapore’s legal, technical and organizational institutions, \\n\\n1 \\n2 \\n\\neducational and research capabilities and cooperation in information-sharing networks. \\n\\nhttps://doi.org/10.1016/j.clsr.2018.05.001 \\n0267-3649/© 2018 Kah Leng TER. Published by Elsevier Ltd. All rights reserved. \\n\\n\\x0ccomputer law & security review 34 (2018) 924–927 \\n\\n925 \\n\\ncore objectives: (1) to provide the Cyber Security Agency of \\nSingapore (“CSA”) with powers to manage and respond to cy- \\nbersecurity threats and incidents; (2) to provide a framework \\nfor the regulation of critical information infrastructure (“CII”); \\nand (3) to establish a framework for the sharing of cyberse- \\ncurity information with and by the CSA and the protection \\nof such information. The fourth objective to establish a light- \\ntouch licensing scheme for cybersecurity service providers \\nhas been narrowed down, following industry concerns raised \\nin the public consultation. \\n\\nThe Cyber Security Agency: Commissioner \\n\\n1. \\nfor Cybersecurity \\n\\nThe CSA was set up in April 2015 to oversee and coordinate \\nSingapore’s cybersecurity strategy. Under the Cybersecurity \\nAct, the Commissioner of Cybersecurity, appointed by the rel- \\nevant Minister, will have extensive supervisory, regulatory and \\nenforcement powers. He is to identify and designate as critical \\ninformation infrastructure any computer or computer system \\nwhich is necessary for the continuous delivery of essential ser- \\nvices. In order to determine whether it is a CII, the Commis- \\nsioner may require by notice certain information in advance \\nfrom the person operating the computer or computer system. \\nFailure to comply with the notice, without reasonable excuse, \\nis a criminal offence carrying a fine of up to $100,000 and or \\nimprisonment for up to 2 years. However, any person to whom \\nthe notice is issued is not obliged to do so if the information is \\nsubject to any right, privilege or immunity conferred by or un- \\nder any law, contract or rules of professional conduct (referred \\nto as “protected information”) in relation to the disclosure of \\nsuch information. Hence, this will protect a person’s right to \\nlegal professional privilege. \\n\\nThe Commissioner is to coordinate national efforts and \\nmonitor cybersecurity threats to Singapore’s national security, \\ndefence, economy, foreign relations, public health, public or- \\nder and safety or essential services, whether such cybersecu- \\nrity threats occur in or outside Singapore. In investigating a \\ncybersecurity threat, he may examine anyone relevant to the \\ninvestigation, take statements and require relevant informa- \\ntion to be furnished. The power to obtain information when \\nresponding to cyber breach incidents raised concerns during \\nthe public consultation and the CSA has clarified that it in- \\ntends to focus on technical information, not personal data. \\nFurthermore, the person affected is not obliged to provide the \\ninformation if it is “protected information”. \\n\\nThe Commissioner’s powers are more intrusive in cases of \\nserious cybersecurity threats and incidents. These are threats \\nwhich  create  a  real  risk  of  significant  harm  to  a  CII;  dis- \\nrupt the delivery of an essential service; or are a real threat \\nto the national security, defence, foreign relations, economy, \\npublic health, public safety or public order of Singapore. In \\nfurtherance of his duties, the Commissioner may direct per- \\nsons to carry out remedial measures, for example cleaning \\nup malware-infected computers; installing software updates \\nto address cybersecurity vulnerabilities and temporarily dis- \\nconnecting infected computers from the network until the \\nfirst two measures have been carried out; and the redirection \\nof malicious data traffic to designated computer servers. The \\n\\nCommissioner may also require CII owners to assist with in- \\nvestigations, which may include monitoring, scanning or pre- \\nserving the state of the computer, and allowing investigating \\nofficers to install software on it; entering premises where rel- \\nevant computers are located; and taking possession of com- \\nputers to carry out further examination or analysis with the \\nconsent of the owner or if other conditions are met. \\n\\nIn the case of emergency cybersecurity events, the Minister \\neffectively has the power to take any measures necessary to \\nprevent, detect or counter any threat. \\n\\nWhile the powers conferred on the Commissioner appear \\nto be wide and sweeping, the Consultation Paper to the Cyber- \\nsecurity Bill gives the assurance that there will be an internal \\ngovernance process within the CSA to ensure that all its pow- \\ners are exercised responsibly and in accordance with the Act, \\nand only by qualified persons. \\n\\nConcerns were also raised during the public consultation \\nover the broad powers of the CSA, with some respondents \\ncalling for safeguards. In response, the CSA emphasised that \\nthe powers of investigation are calibrated depending on the \\nseverity of the cyber threat. CSA does not have broad pow- \\ners to oversee every computer in Singapore and the statutory \\npowers of the CSA are only exercisable in the event of a cyber- \\nsecurity incident. Furthermore, there are checks and balances \\nto prevent the misuse of disclosed information and CSA offi- \\ncers may be prosecuted if they misuse any information that is \\nobtained. \\n\\n2. \\n\\nCritical information infrastructure \\n\\nThe vulnerability of CII has been exposed by the WannaCry \\nand NotPetya ransomware attacks affecting critical infrastruc- \\nture such as energy and power supply. Singapore was not af- \\nfected but is vulnerable. In 2017, hackers broke into the net- \\nworks of the National University and the Nanyang Technolog- \\nical University to steal government-related data, both univer- \\nsities being involved in government-linked projects for the de- \\nfence, foreign affairs and transport sectors. In a separate inci- \\ndent, the personal data belonging to 850 national servicemen \\nand defence ministry staff were hacked. \\n\\nThe Cybersecurity Act therefore seeks to strengthen Singa- \\npore’s CII that provide essential services by identifying eleven \\ncritical sectors: government, security and emergency services, \\nhealthcare, into-communications, banking and finance, en- \\nergy, water, media, land transport, aviation and maritime. A \\nCII means a computer or a computer system which has been \\ndesignated by the Commissioner as a CII. The Commissioner \\nmay do so by notice if satisfied that the computer or computer \\nsystem is necessary for the continuous delivery of an essen- \\ntial service and its loss or compromise will have a debilitat- \\ning effect on the availability of the essential service in Singa- \\npore; and the computer or computer system is located wholly \\nor partly in Singapore. The CII owner is then required to per- \\nform certain duties which will increase the entity’s account- \\nability for protecting the CII and to ensure its cybersecurity. \\nThe owner of a CII is defined as the legal owner of the CII and \\nevery joint owner where the CII is jointly owned by more than \\none person. \\n\\n\\x0c926 \\n\\ncomputer law & security review 34 (2018) 924–927 \\n\\nThis narrow definition of “owner” is welcome in the light of \\nindustry concerns that while a CII can be “owned” by a person \\nwho has effective control over the operations of the CII and the \\nability to carry out changes to the CII, the same CII can also be \\n“owned” by a person responsible for ensuring the continuous \\nfunction of the CII. It is now clear that suppliers and third party \\nvendors helping with the operations of a CII will not fall within \\nthe definition of “owner” in relation to the CII. \\n\\nThe six key duties of a CII owner are to: (a) provide informa- \\ntion on the CII’s technical architecture; (b) comply with codes \\nof practice, standards of performance or directions issued by \\nthe Commissioner; (c) notify the Commissioner of cybersecu- \\nrity incidents in respect of CII, or computers under their con- \\ntrol that are interconnected with or that communicate with \\nthe CII; (d) conduct regular audits of the compliance of the \\nCII with the Act, codes and standards; (e) conduct regular risk \\nassessments of the CII; and (f) participate in cybersecurity ex- \\nercises. \\n\\nAn example of (f) is the cybersecurity exercise conducted \\nby the CSA on 18 July 2017 involving participants such as the \\nLand Transport Authority, Public Utilities Board, Monetary Au- \\nthority of Singapore, Singapore Airlines and others. The exer- \\ncise simulated different types of cyberattacks targeting essen- \\ntial services—such as ransomware attacks, distributed denial \\nof service (DDoS) attacks, and malware infections. Failure to \\ncomply with a direction to participate in cybersecurity exer- \\ncises is a criminal offence carrying a fine of up to $100,000 and \\nor imprisonment for up to 2 years. \\n\\nThe mandatory reporting by CII owners of cybersecurity in- \\ncidents such as security breaches and attacks have been in \\nplace in the US, Europe, Japan, Australia and South Korea for \\nyears.3 \\nThe risk of cybersecurity breaches is increasingly se- \\nrious as Singapore aspires to be a smart nation. Due to the \\nnational security implications of non-compliance, a failure to \\nreport a cybersecurity incident is a criminal offence carry- \\ning a fine of up to $100,000 and or imprisonment for up to 2 \\nyears. The reporting of cybersecurity breaches is nothing new \\nto financial institutions in Singapore. They are required to re- \\nport critical system failures arising from technology and cy- \\nbersecurity incidents under the Technology Risk Management \\nGuidelines introduced in 2013. \\n\\nCII owners are also required to report to the Commissioner \\non any change of ownership of the CII or “material changes” to \\nthe “design, configuration, security or operation” of the CII. In \\naddition, they must establish mechanisms and processes for \\nthe purpose of detecting cybersecurity threats and incidents \\nin respect of the CII as set out in the applicable code of prac- \\ntice and conduct audits at least once every two years and risk \\nassessments at least once a year. \\n\\n3. \\n\\nInformation sharing \\n\\nIn recognition of the fact that information sharing between \\nthe various stakeholders is vital if any cybersecurity threat or \\nincident is to be detected and prevented, the Commissioner \\nmay share such information with the stakeholders in exercise \\n\\nof his function in promoting cybersecurity in Singapore. Cy- \\nbersecurity information sharing among financial institutions \\nin the Asia Pacific (APAC) region is nothing new. There is ex- \\nisting collaboration between the Monetary Authority of Singa- \\npore and the Financial Services Information Sharing and Anal- \\nysis Centre. \\n\\nHowever, it appears that Singapore companies are reluc- \\ntant to share information on cyber threats. A regional study 4 \\nof \\n500 professionals in the Asia-Pacific covering Australia, China, \\nHong Kong, India and Singapore markets, has revealed that \\nonly a third of the Singapore companies surveyed have shared \\ninformation on cyber threat incidents with their peers in the \\nindustry, lower than the average of 44% in the Asia–Pacific and \\nhalf of the proportion in China. The reason for this is a fear of \\nbeing seen as a victim of data breaches and the negative im- \\npact on the organisation’s reputation. The study also revealed \\nthat despite dedicated financial and human resources, almost \\nhalf of the respondents in Singapore acknowledged “their in- \\nability to keep up with evolving cybersecurity solutions as a \\nprimary barrier to ensuring cybersecurity in their organisa- \\ntions”. \\n\\n4. \\n\\nRegulating cybersecurity service providers \\n\\nThe original proposal was to regulate cybersecurity providers. \\nThis was considered necessary in view of increased cyberse- \\ncurity risks and the fact that such providers are given signif- \\nicant access to clients’ computers and networks and may get \\nto know the system’s vulnerabilities. It would also help client \\norganisations make informed choices when selecting credible \\nservice providers. However, industry players anticipated that \\nthe licensing requirement would hamper the growth of a vi- \\nbrant cybersecurity ecosystem in Singapore and prevent help \\nbeing obtained from global cybersecurity providers at short \\nnotice. In response, the licencing framework has been nar- \\nrowed down and the Act only requires providers of managed \\nsecurity operations centre (SOC) monitoring services and/or \\npenetration testing services to be licenced. The provider may \\nbe an individual or business entity, including resellers of such \\nservices. \\n\\nIn order to raise the quality of cybersecurity services, CSA \\nhas indicated that it will work with industry to establish vol- \\nuntary accreditation regimes to raise the quality of cyberse- \\ncurity services. This is likely to leverage on industry best prac- \\ntices and global standards that will allow a more current and \\nflexible approach to cybersecurity and facilitate the Commis- \\nsioner in discharging his functions of developing and promot- \\ning the cybersecurity services industry in Singapore and de- \\nveloping competencies, expertise and professional standards \\nin the cybersecurity community. \\n\\n5. \\n\\nPenalties \\n\\nNon-compliance  with  the  Cybersecurity  Act  is  a  criminal \\noffence, generally carrying stiff penalties or fines of up to \\n\\n3 \\n\\nThe Straits Times, Nov 17, 2017. \\n\\n4 \\n\\nToday, 20 July 2017. \\n\\n\\x0ccomputer law & security review 34 (2018) 924–927 \\n\\n927 \\n\\nS$100,000 and or imprisonment for up to 10 years. The Amer- \\nican Chamber of Commerce in Singapore expressed the view \\nthat the proposed criminal liability “penalises the wrong ac- \\ntors”, namely CII owners and not the perpetrators of attacks. \\nSuch penalties will also “create a significant disincentive for \\ninvestment in Singapore. Regulatory agencies should rely on \\nspecific directions to CII owners, with fines or injunctive relief \\nas a means to promote compliance”. However, the Consulta- \\ntion Paper noted that the provisions on offences and penalties \\nare to ensure statutory compliance rather than punish those \\nthat suffer from cyberattacks. It is submitted that without pro- \\nviding for criminal enforcement provisions in cybersecurity \\nlegislation, the Cybersecurity Act will be a dead duck. \\n\\n6. \\n\\nConclusion \\n\\nIn the light of recent, massive global cyberattacks, the Cyber- \\nsecurity Act has been welcomed by industry players as “bold, \\ndecisive, timely  and  forward-looking, covering  both  public \\nand private sectors”. The provisions are specific, comprehen- \\nsive and far-reaching. However, concerns have been expressed \\nabout the cost of compliance and whether it would be passed \\ndown  to  consumers  and  whether  cybersecurity  legislation \\nwould affect economic competitiveness and foreign invest- \\nment. It is apparent that while compliance costs will increase, \\nthe far-reaching provisions are in keeping with the general \\nglobal trend and a strong cybersecurity ecosystem may well \\nbe attractive to foreign investment in Singapore as a “Trusted \\nand Robust Inforcommunication Hub”. By taking a pro-active \\napproach towards pre-empting cybersecurity threats and pre- \\nventing the financial and reputational risks of cyberattacks, \\nthe Cybersecurity Act promotes Singapore’s strategy to be- \\ncome a smart nation and financial centre with a resilient and \\nstrong cybersecurity ecosystem. \\n\\nWith  the  enactment  of  the  Cybersecurity  Act,  indus- \\ntry  players  anticipate  that  businesses  and  entities  which \\nare  potential  CII  owners  should  take  steps  to  become \\n\\ncompliance-ready. They should strengthen their cybersecu- \\nrity; prepare for the additional responsibilities and liabilities \\nof a CII owner; undertake risk assessment measures and em- \\nployee education on cybersecurity risks; monitor the effective- \\nness of policies and take the necessary cyber-insurance to mit- \\nigate losses. However, a report by insurance market specialist \\nLloyd’s and risk modelling platform Cyence 5 \\nhas revealed that \\nAsia continues to be under-insured and economically vulner- \\nable to cyberattacks. On the other hand, industry stakehold- \\ners feel that the mandatory reporting of cyber incidents by \\nCII owners would enable insurers to better price the risk, offer \\nprotection and drive demand for cyber insurance. \\n\\nHaving in place a comprehensive and far-reaching cyber- \\nsecurity legislation is vital to fostering a secure and resilient \\nnational infocomm environment. But while it embodies the \\nspirit of Singapore’s Master Plans and National Cybersecurity \\nStrategy, legislation cannot single-handedly give effect to the \\nvision, goals, priorities and policies that have been set out. \\nThe strategy that Singapore has developed is therefore multi- \\npronged, involving participation by experts, the public, private \\nand people sectors. For example, efforts have been stepped \\nup to raise awareness of infocomm security and the adoption \\nof security measures among businesses and users through \\noutreach programmes on online and social media platforms, \\nseminars, educational talks, road shows and printed adverto- \\nrials. The shortage of cybersecurity professionals locally and \\nthe need to grow Singapore’s pool of infocomm security ex- \\nperts is intended to be addressed by working with institutes \\nof higher learning to incorporate cybersecurity into the cur- \\nriculum or running a specialist track in current programmes. \\nCyber training facilities will also be developed for testing and \\ntraining cybersecurity professionals and there are plans to de- \\nvelop R&D to attract and cultivate more cybersecurity experts. \\nAs the cybersecurity landscape changes, amendments to \\nthe Cybersecurity Act are to be expected as the law seeks to \\nstay relevant and dynamic and provide the legal clarity and \\ncertainty that is so crucial in the face of rapid technological \\nadvancements. \\n\\n5 \\n\\nBusiness Times, 17 July 2017. \\n\\n\\x0c', 'Internet Governance and the \\nDomain Name System: \\nIssues for Congress \\n\\nLennard G. Kruger \\nSpecialist in Science and Technology Policy \\n\\nMarch 23, 2016 \\n\\nCongressional Research Service \\n\\n7-5700 \\nwww.crs.gov \\n\\nR42351 \\n\\n \\n \\n\\x0cInternet Governance and the Domain Name System: Issues for Congress \\n\\nSummary \\nThe Internet is often described as a “network of networks” because it is not a single physical \\nentity, but hundreds of thousands of interconnected networks linking hundreds of millions of \\ncomputers around the world. As such, the Internet is international, decentralized, and comprised \\nof networks and infrastructure largely owned and operated by private sector entities. As the \\nInternet grows and becomes more pervasive in all aspects of modern society, the question of how \\nit should be governed becomes more pressing. \\n\\nCurrently, an important aspect of the Internet is governed by a private sector, international \\norganization called the Internet Corporation for Assigned Names and Numbers (ICANN), which \\nmanages and oversees some of the critical technical underpinnings of the Internet such as the \\ndomain name system and Internet Protocol (IP) addressing. ICANN makes its policy decisions \\nusing a multistakeholder model of governance, in which a “bottom-up” collaborative process is \\nopen to all constituencies of Internet stakeholders.  \\n\\nNational governments have recognized an increasing stake in ICANN policy decisions, especially \\nin cases where Internet policy intersects with national laws addressing such issues as intellectual \\nproperty, privacy, law enforcement, and cybersecurity. Some governments around the world are \\nadvocating increased intergovernmental influence over the way the Internet is governed. For \\nexample, specific proposals have been advanced that would create an Internet governance entity \\nwithin the United Nations (U.N.). Other governments (including the United States), as well as \\nmany other Internet stakeholders, oppose these proposals and argue that ICANN’s \\nmultistakeholder model is the most appropriate way to govern the Internet. \\n\\nCurrently, the U.S. government, through the National Telecommunications and Information \\nAdministration (NTIA) at the Department of Commerce, holds a “stewardship” role over the \\ndomain name system by virtue of a contractual relationship with ICANN. On March 14, 2014, \\nNTIA announced its intention to transition its stewardship role and procedural authority over key \\ndomain name functions to the global Internet multistakeholder community. If a satisfactory \\ntransition can be achieved, NTIA stated that it would let its contract with ICANN expire as early \\nas September 30, 2015. On August 17, 2015, NTIA announced that the Internet Assigned \\nNumbers Authority (IANA) contract will be extended for one year until September 30, 2016. \\nNTIA has also stated that it will not accept any transition proposal that would replace the NTIA \\nrole with a government-led or an intergovernmental organization solution. On March 10, 2016, \\nthe ICANN Board formally accepted the multistakeholder community’s transition plan and \\ntransmitted that plan to NTIA for approval. \\nIn the 114th Congress, H.R. 805/S. 1551 (the DOTCOM Act of 2015) would prohibit NTIA from \\nrelinquishing its authority until 30 legislative days after NTIA submits a report to Congress in \\nwhich NTIA certifies that the transition proposal meets certain criteria. The DOTCOM Act was \\npassed by the House, but has not been passed by the Senate. Meanwhile, the Consolidated \\nAppropriations Act, 2016 (P.L. 114-113) prevents NTIA from relinquishing its contractual control \\nover IANA in FY2016.  \\nThe 114th Congress is likely to closely examine NTIA’s proposed transition of its authority. As the \\ntransition plan is implemented by the Internet community and evaluated by NTIA, Congress will \\nlikely monitor and evaluate that plan, and seek assurances that an Internet and domain name \\nsystem free of U.S. government stewardship will remain stable, secure, resilient, and open. \\nCongress will likely continue assessing to what extent ongoing and future intergovernmental \\ntelecommunications conferences constitute an opportunity for some nations to increase \\nintergovernmental control over the Internet, and how effectively the Administration is working to \\ncounteract that threat.  \\n\\nCongressional Research Service \\n\\n \\n\\x0cInternet Governance and the Domain Name System: Issues for Congress \\n\\nContents \\n\\nWhat Is Internet Governance? ......................................................................................................... 1 \\nHow Is the Internet Currently Governed? ....................................................................................... 1 \\nRole of U.S. Government ................................................................................................................ 3 \\nAffirmation of Commitments .................................................................................................... 4 \\nDOC Contract and Cooperative Agreement With ICANN and VeriSign .................................. 5 \\nNTIA Intent to Transition Stewardship of the DNS .................................................................. 6 \\nMultistakeholder Process to Develop a Transition Proposal .............................................. 7 \\nLegislative Activities in the 113th Congress ........................................................................ 8 \\nLegislative Activities in the 114th Congress ...................................................................... 10 \\nOther Activities ................................................................................................................. 12 \\nDebate over Future Model of Internet Governance ....................................................................... 13 \\n2005 World Summit on the Information Society (WSIS) ....................................................... 14 \\nCreation of the .xxx Domain and New gTLDs ....................................................................... 14 \\n.xxx ................................................................................................................................... 15 \\ngTLD Expansion ............................................................................................................... 16 \\nProposed Models for Internet Governance .............................................................................. 20 \\nWorld Conference on International Telecommunications (WCIT) ......................................... 23 \\nMontevideo Statement on the Future of Internet Cooperation ................................................ 25 \\nNETmundial ............................................................................................................................ 25 \\nNETmundial Initiative ............................................................................................................ 26 \\n2014 Plenipotentiary Conference in Busan ............................................................................. 26 \\nWSIS+10 ................................................................................................................................. 26 \\nInternet Governance and Terrorism ......................................................................................... 27 \\nIssues for Congress ........................................................................................................................ 28 \\n\\nFigures \\n\\nFigure A-1. Organizational Structure of ICANN .......................................................................... 30 \\n\\nAppendixes \\n\\nAppendix. ICANN Basics ............................................................................................................. 29 \\n\\nContacts \\n\\nAuthor Contact Information .......................................................................................................... 30 \\n\\nCongressional Research Service \\n\\n \\n \\n \\n  \\n \\n \\n\\x0cInternet Governance and the Domain Name System: Issues for Congress \\n\\nWhat Is Internet Governance? \\nThere is no universally agreed-upon definition of “Internet governance.” A more limited \\ndefinition would encompass the management and coordination of the technical underpinnings of \\nthe Internet—such as domain names, addresses, standards, and protocols that enable the Internet \\nto function. A broader definition would include the many factors that shape a variety of Internet \\npolicy-related issues, such as such as intellectual property, privacy, Internet freedom, e-\\ncommerce, and cybersecurity.  \\n\\nOne working definition was developed at the World Summit on the Information Society (WSIS) \\nin 2005:  \\n\\nInternet  governance  is  the  development  and  application  by  governments,  the  private \\nsector  and  civil  society,  in  their  respective  roles,  of  shared  principles,  norms,  rules, \\ndecision-making  procedures,  and  programmes  that  shape  the  evolution  and  use  of  the \\nInternet.1 \\n\\nAnother definition developed by the Internet Governance Project (IGP)2 delineates three aspects \\nof the Internet that may require some level of governing: technical standardization, which \\ninvolves arriving at and agreeing upon technical standards and protocols; resource allocation and \\nassignment, which includes domain names and Internet Protocol (IP) addresses; and human \\nconduct on the Internet, encompassing the regulations, rules, and policies affecting areas such as \\nspam, cybercrime, copyright and trademark disputes, consumer protection issues, and public and \\nprivate security. With these three categories in mind, the IGP definition is: \\n\\nInternet  governance  is  collective  decisionmaking  by  owners,  operators,  developers,  and \\nusers  of  the  networks  connected  by  Internet  protocols  to  establish  policies,  rules,  and \\ndispute resolution procedures about technical standards, resource allocations, and/or the \\nconduct of people engaged in global internetworking activities.3 \\n\\nHow Is the Internet Currently Governed? \\nThe nature of the Internet, with its decentralized architecture and structure, makes the practice of \\ngoverning a complex proposition. First, the Internet is inherently international and cannot in its \\ntotality be governed by national governments whose authority ends at national borders. Second, \\nthe Internet’s successful functioning depends on the willing cooperation and participation by \\nmostly private sector stakeholders around the world. These stakeholders include owners and \\noperators of servers and networks around the world, domain name registrars and registries, \\nregional IP address allocation organizations, standards organizations, Internet service providers, \\nand Internet users.  \\n\\nGiven the multiplicity and diversity of Internet stakeholders, a number of organizations and \\nentities play varying roles. It is important to note that all of the Internet stakeholders cited above \\nparticipate in various ways within the various fora, organizations, and frameworks addressing \\nInternet governance and policy.  \\n\\n1 \\n\\n \\n                                                 \\n\\x0cInternet Governance and the Domain Name System: Issues for Congress \\n\\nKey organizations in the private sector include the following: \\n\\nInternet Corporation for Assigned Names and Numbers (ICANN)—ICANN was created in 1998 \\nthrough a Memorandum of Understanding with the Department of Commerce (see the following \\nsection of this report, “Role of U.S. Government”). Directed by an internationally constituted \\nBoard of Directors, ICANN is a private, not-for-profit organization based in Los Angeles, CA, \\nwhich manages and oversees the critical technical underpinnings of the Internet such as the \\ndomain name system (DNS) and IP addressing (see the Appendix for more background \\ninformation on ICANN). ICANN implements and enforces many of its policies and rules through \\ncontracts with registries (companies and organizations who operate and administer the master \\ndatabase of all domain names registered in each top level domain, such as .com and .org) and \\naccredited registrars (the hundreds of companies and organizations with which consumers \\nregister domain names). Policies are developed by Supporting Organizations and Committees in a \\nconsensus-based “bottom-up” process open to various constituencies and stakeholders of the \\nInternet. As such, ICANN is often pointed to as emblematic of the “multistakeholder model” of \\nInternet governance. \\n\\nInternet standards organizations—As the Internet has evolved, groups of engineers, researchers, \\nusers, and other interested parties have coalesced to develop technical standards and protocols \\nnecessary to enable the Internet to function smoothly. These organizations conduct standards \\ndevelopment processes that are open to participants and volunteers from around the world. \\nInternet standards organizations include the Internet Engineering Task Force (IETF), the Internet \\nArchitecture Board (IAB), the Internet Society (ISOC), and the World Wide Web Consortium \\n(W3C).  \\n\\nGovernmental entities involved in Internet governance include the following: \\n\\nGovernmental Advisory Committee (GAC)—As part of ICANN’s multistakeholder process, the \\nGAC provides advice to the ICANN Board on matters of public policy, especially in cases where \\nICANN activities and policies may interact with national laws or international agreements related \\nto issues such as intellectual property, law enforcement, and privacy. GAC advice is developed \\nthrough consensus among member nations. Although the ICANN Board is required to consider \\nGAC advice and recommendations, it is not obligated to follow those recommendations. \\nMembership in the GAC is open to all national governments who wish to participate. Currently, \\nthere are 146 members. The GAC Chair is currently held by Switzerland, with Vice Chairs held \\nby Argentina, Spain, Namibia, Turkey, and Thailand.  \\n\\nInternet Governance Forum (IGF)—The IGF was established in 2006 by the United Nations’ \\nWorld Summit on the Information Society (WSIS). The purpose of the IGF is to provide a \\nmultistakeholder forum which provides an open discussion (in yearly meetings) on public policies \\nrelated to the Internet. Open to all stakeholders and interested parties (governments, industry, \\nacademia, civil society), the IGF serves as an open discussion forum and does not have negotiated \\noutcomes, nor does it make formal recommendations to the U.N. In December 2010, the U.N. \\nGeneral Assembly renewed the IGF through 2015 and tasked the U.N.’s Commission on Science \\nand Technology for Development (CSTD) to develop a report and recommendations on how the \\nIGF might be improved. A Working Group on Improvements to the Internet Governance Forum \\nwas formed by the U.N., which includes 22 governments (including the United States) and the \\nparticipation of Internet stakeholder groups. In December 2015, the General Assembly renewed \\nthe IGF through 2025. \\n\\nOther International Organizations—Other existing international organizations address Internet \\npolicy issues in various ways. The International Telecommunications Union (ITU) is the United \\nNations’ specialized agency for communications and information technology. The World \\n\\nCongressional Research Service \\n\\n2 \\n\\n \\n\\x0cInternet Governance and the Domain Name System: Issues for Congress \\n\\nIntellectual Property Organization (WIPO) is another specialized agency of the U.N., which \\naddresses a wide range of intellectual property issues, including those related to Internet policy. \\nThe Organisation for Economic Co-operation and Development (OECD) provides a forum for \\ngovernments to work together to address economic issues, including the recent development of \\nInternet policymaking principles. While none of these organizations have direct control or \\nauthority over the Internet, their activities can have influence over future directions of global \\nInternet policy.  \\n\\nNational governments—National governments have acted to address various Internet policy \\nissues within their own borders. Many of the national laws and regulations pertain to user \\nbehavior on the Internet. For example, in the United States, laws have been passed addressing \\nsuch issues as cybersecurity and cybercrime, Internet gambling, Internet privacy, and protection \\nof intellectual property on the Internet. Governments have also established internal Internet policy \\ncoordinating bodies (e.g., the National Telecommunications and Information Administration’s \\nInternet Policy Task Force and the European Commission’s Information Society).  \\n\\nRole of U.S. Government \\nThe U.S. government has no statutory authority over ICANN or the domain name system. \\nHowever, because the Internet evolved from a network infrastructure created by the Department \\nof Defense, the U.S. government originally owned and operated (primarily through private \\ncontractors) many of the key components of network architecture that enabled the domain name \\nsystem to function. In the early 1990s, the National Science Foundation (NSF) was given a lead \\nrole in overseeing domain names used in the civilian portion of the Internet (which at that time \\nwas largely comprised of research universities). By the late 1990s, ICANN was created, the \\nInternet had expanded into the commercial world, and the National Telecommunications and \\nInformation Administration (NTIA) of the Department of Commerce (DOC) assumed the lead \\nrole.  \\n\\nA 1998 Memorandum of Understanding between ICANN and the DOC initiated a process \\nintended to transition technical DNS coordination and management functions to a private-sector \\nnot-for-profit entity. While the DOC plays no role in the internal governance or day-to-day \\noperations of ICANN, the U.S. government, through the DOC/NTIA, retains a role with respect \\nto the DNS via three separate contractual agreements. These are \\n\\n\\uf0b7 \\n\\uf0b7 \\n\\n\\uf0b7 \\n\\na 2009 Affirmation of Commitments (AoC) between DOC and ICANN;4 \\na contract between ICANN and DOC to perform various technical functions such \\nas allocating IP address blocks, editing the root zone file, and coordinating the \\nassignment of unique protocol numbers; and \\na cooperative agreement between DOC and VeriSign to manage and maintain the \\nofficial DNS root zone file. \\n\\nBy virtue of those three contractual agreements, the U.S. government—through DOC/NTIA—\\nexerts a legacy authority and stewardship over ICANN, and arguably has more influence over \\nICANN and the DNS than other national governments.  \\n\\n4 For more information on the Affirmation of Commitments, including the precursor agreements between DOC and \\nICANN such as the Joint Project Agreement and the Memorandum of Understanding, see CRS Report 97-868, Internet \\nDomain Names: Background and Policy Issues, by Lennard G. Kruger. \\n\\nCongressional Research Service \\n\\n3 \\n\\n \\n                                                 \\n\\x0cInternet Governance and the Domain Name System: Issues for Congress \\n\\nWhile NTIA is the lead agency overseeing domain name issues, other federal agencies maintain a \\nspecific interest in the DNS that may affect their particular missions. For example, the Federal \\nTrade Commission (FTC) seeks to protect consumer privacy on the Internet, the Department of \\nJustice (DOJ) addresses Internet crime and intellectual property issues, and the Department of \\nDefense and Department of Homeland Security address cybersecurity issues. However, none of \\nthese agencies has legal authority over ICANN or the running of the DNS. \\n\\nAffirmation of Commitments \\n\\nOn September 30, 2009, DOC and ICANN announced agreement on an Affirmation of \\nCommitments (AoC) to “institutionalize and memorialize” the technical coordination of the DNS \\nglobally and by a private-sector-led organization.5 The AoC replaced the previous Memorandum \\nof Understanding and subsequent Joint Project Agreement between DOC and ICANN. It has no \\nexpiration date and would conclude only if one of the two parties decided to terminate the \\nagreement.  \\n\\nUnder the AoC, ICANN committed to remain a not-for-profit corporation “headquartered in the \\nUnited States of America with offices around the world to meet the needs of a global \\ncommunity.” According to the AoC, “ICANN is a private organization and nothing in this \\nAffirmation should be construed as control by any one entity.” Specifically, the AoC called for the \\nestablishment of review panels which will periodically make recommendations to the ICANN \\nBoard in four areas: ensuring accountability, transparency, and the interests of global Internet \\nusers (panel includes the Administrator of NTIA); preserving security, stability, and resiliency; \\nimpact of new generic top level domains (gTLDs); and WHOIS policy.6  \\n\\nOn December 31, 2010, the Accountability and Transparency Review Team (ATRT) released its \\nrecommendations to the Board for improving ICANN’s transparency and accountability with \\nrespect to Board governance and performance, the role and effectiveness of the GAC and its \\ninteraction with the Board, public input and policy development processes, and review \\nmechanisms for Board decisions.7 At the June 2011 meeting in Singapore, the Board adopted all \\n27 ATRT recommendations. According to NTIA, “the focus turns to ICANN management and \\nstaff, who must take up the challenge of implementing these recommendations as rapidly as \\npossible and in a manner that leads to meaningful and lasting reform.”8  \\n\\n\\n \\n                                                 \\n\\x0cInternet Governance and the Domain Name System: Issues for Congress \\n\\nDOC Contract and Cooperative Agreement With ICANN \\nand VeriSign \\nA contract between DOC and ICANN—specifically referred to as the “IANA9 functions \\ncontract”—authorizes ICANN to manage the technical underpinnings of the DNS. Specifically, \\nthe contract allows ICANN to perform various critical technical functions such as allocating IP \\naddress blocks, editing the root zone file, and coordinating the assignment of unique protocol \\nnumbers. Additionally, and intertwined with the IANA functions, a cooperative agreement \\nbetween DOC and VeriSign (the company that operates the .com and .net registries) authorizes \\nVeriSign to manage and maintain the official root zone file that is contained in the Internet’s root \\nservers that underlie the functioning of the DNS.10 By virtue of these legal agreements, the DOC \\napproves changes or modifications made to the root zone file (changes, for example, such as \\nadding a new top level domain).11  \\n\\nOn July 2, 2012, NTIA announced the award of the most recent (and current) IANA contract to \\nICANN through September 30, 2015 (with an option to extend the contract through September \\n2019). The IANA contract continues to specify that the contractor must be a wholly U.S. owned \\nand operated firm or a U.S. university or college; that all primary operations and systems shall \\nremain within the United States; and that the U.S. government reserves the right to inspect the \\npremises, systems, and processes of all facilities and components used for the performance of the \\ncontract. \\n\\n\\n \\n                                                 \\n\\x0cInternet Governance and the Domain Name System: Issues for Congress \\n\\nNTIA Intent to Transition Stewardship of the DNS12 \\n\\nThe IANA functions contract with ICANN and the cooperative agreement with Verisign give \\nNTIA the authority to maintain a stewardship and oversight role with respect to ICANN and the \\ndomain name system. On March 14, 2014, NTIA announced its intention to transition its \\nstewardship role and procedural authority over key domain name functions to the global Internet \\nmultistakeholder community.13 NTIA’s stated intention was that it would let its IANA functions \\ncontract with ICANN expire on September 30, 2015, if a satisfactory transition could be \\nachieved. With NTIA having the option of extending the contract for up to two two-year periods \\nthrough September 30, 2019, NTIA announced on August 17, 2015, that it will extend the IANA \\nfunctions contract through September 30, 2016. \\n\\nNTIA asked ICANN to convene interested global Internet stakeholders (both from the private \\nsector and governments) to develop a proposal to achieve the transition. Specifically, NTIA \\nexpects ICANN to work collaboratively with parties directly affected by the IANA contract, \\nincluding the Internet Engineering Task Force (IETF), the Internet Architecture Board (IAB), the \\nInternet Society (ISOC), the Regional Internet Registries (RIRs), top level domain name \\noperators, Verisign, and other interested global stakeholders. In October 2013, many of these \\ngroups—specifically, the Internet technical organizations responsible for coordination of the \\nInternet infrastructure—had called for “accelerating the globalization of ICANN and IANA \\nfunctions, towards an environment in which all stakeholders, including all governments, \\nparticipate on an equal footing.”14  \\n\\nNTIA has stated that it will not accept any transition proposal that would replace the NTIA role \\nwith a government-led or an intergovernmental organization solution. \\n\\nIn addition, NTIA told ICANN that the transition proposal must have broad community support \\nand address the following four principles: \\n\\nsupport and enhance the multistakeholder model; \\n\\n\\uf0b7 \\n\\uf0b7  maintain the security, stability, and resilience of the Internet DNS; \\n\\uf0b7  meet the needs and expectation of the global customers and partners of the IANA \\n\\nservices; and \\n\\n\\uf0b7  maintain the openness of the Internet. \\n\\nSupporters of the transition15 argue that by transferring its remaining authority over ICANN and \\nthe DNS to the global Internet community, the U.S. government will bolster its continuing \\nsupport for the multistakeholder model of Internet governance, and that this will enable the \\nUnited States to more effectively argue and work against proposals for intergovernmental control \\nover the Internet. Supporters also point out that the U.S. government and Internet stakeholders \\nhave, from the inception of ICANN, envisioned that U.S. authority over IANA functions would \\n\\n \\n                                                 \\n\\x0cInternet Governance and the Domain Name System: Issues for Congress \\n\\nbe temporary, and that the DNS would eventually be completely privatized.16 According to NTIA, \\nthis transition is now possible, given that “ICANN as an organization has matured and taken steps \\nin recent years to improve its accountability and transparency and its technical competence.”17  \\nThose opposed, skeptical, or highly cautious about the transition18 point out that NTIA’s role has \\nserved as a necessary “backstop” which has given Internet stakeholders confidence that the \\nintegrity and stability of the DNS is being sufficiently overseen. Critics assert that in the wake of \\nthe Edward Snowden NSA revelations, foreign governments might gain more support \\ninternationally in their continuing attempts to exert intergovernmental control over the Internet, \\nand that any added intergovernmental influence over the Internet and the DNS would be that \\nmuch more detrimental to the interests of the United States if NTIA’s authority over ICANN and \\nthe DNS were to no longer exist. Another concern regards the development of the transition plan \\nand a new international multistakeholder entity that would provide some level of stewardship \\nover the domain name system. Critics are concerned about the risks of foreign governments—\\nparticularly those favoring censorship of the Internet—gaining influence over the DNS through \\nthe transition to a new Internet governance mechanism that no longer is subject to U.S. \\ngovernment oversight. \\n\\nMultistakeholder Process to Develop a Transition Proposal \\n\\nICANN convened a process through which the multistakeholder community came to consensus \\non a transition proposal. The process was divided into two separate but related parallel tracks: (1) \\nIANA Stewardship Transition and (2) Enhancing ICANN Accountability. On March 10, 2016, the \\nICANN Board formally accepted the IANA Stewardship Transition proposal19 and the Enhancing \\nICANN Accountability report.20 The Board formally transmitted the transition and accountability \\nplans to NTIA for approval. On March 11, 2016, NTIA stated that it “will now begin the process \\nof reviewing the proposal, hopefully within 90 days, to determine whether it meets the criteria we \\noutlined when we announced the transition.”21 For a full discussion of the status and results of the \\nmultistakeholder process to develop a transition proposal, see CRS Report R44022, The Future of \\nInternet Governance: Should the United States Relinquish Its Authority over ICANN?, by \\nLennard G. Kruger. \\n\\n\\n \\n                                                 \\n\\x0cInternet Governance and the Domain Name System: Issues for Congress \\n\\nLegislative Activities in the 113th Congress \\n\\nOn March 27, 2014, Representative Shimkus introduced H.R. 4342, the Domain Openness \\nThrough Continued Oversight Matters (DOTCOM) Act. H.R. 4342 would have prohibited the \\nNTIA from relinquishing responsibility over the Internet domain name system until GAO submits \\nto Congress a report on the role of the NTIA with respect to such system. The report would have \\nincluded a discussion and analysis of the advantages and disadvantages of the change and address \\nthe national security concerns raised by relinquishing U.S. oversight. It would also have required \\nGAO to provide a definition of the term “multistakeholder model” as used by NTIA with respect \\nto Internet policymaking and governance. H.R. 4342 was referred to the House Energy and \\nCommerce Committee. On April 2, 2014, the Subcommittee on Communications and Technology \\nheld a hearing on the DOTCOM Act.22 H.R. 4342 was approved by the House Energy and \\nCommerce Committee on May 8, 2014. Subsequently on June 5, 2014, the House Energy and \\nCommerce Committee requested that the GAO examine the Administration’s proposal to \\ntransition NTIA’s current authority over IANA to the multistakeholder Internet community.23 \\n\\nOn May 22, 2014, the text of the DOTCOM Act was offered by Representative Shimkus as an \\namendment to H.R. 4435, the National Defense Authorization Act for FY2015. During House \\nconsideration of H.R. 4435, the amendment was agreed to by a vote of 245-177. H.R. 4435 was \\npassed by the House on May 22, 2014. The House Armed Services bill report accompanying H.R. \\n4435 (H.Rept. 113-446) stated the committee’s belief that any new Internet governance structure \\nshould include protections for the Department of Defense-controlled .mil generic top level \\ndomain and its associated Internet protocol numbers. The committee also supported maintaining \\nseparation between the policymaking and technical operation of root-zone management functions. \\n\\nOn June 2, 2014, the Senate Armed Services Committee reported S. 2410, its version of the \\nFY2015 National Defense Authorization Act. Section 1646 of S. 2410 (“Sense of Congress on the \\nFuture of the Internet and the .mil Top-Level Domain”) stated that it is the sense of Congress that \\nthe Secretary of Defense should  \\n\\nadvise the President to transfer the remaining role of the United States Government in the \\nfunctions  of  the  Internet  Assigned  Numbers  Authority  to  a  global  multi-stakeholder \\ncommunity  only  if  the  President  is  confident  that  the  ‘.MIL’  top-level  domain  and  the \\nInternet  Protocol  address  numbers  used  exclusively  by  the  Department  of  Defense  for \\nnational security will remain exclusively used by the Department of Defense. \\n\\nSection 1646 also directed DOD to take “all necessary steps to sustain the successful stewardship \\nand good standing of the Internet root zone servers managed by components of the Department of \\nDefense.” In the report accompanying S. 2410 (S.Rept. 113-176), the committee urged DOD to \\n\\nseek an agreement through the IANA transition process, or in parallel to it, between the \\nUnited States and the Internet Corporation for Assigned Names and Numbers and the rest \\nof the global Internet stakeholders that the .mil domain will continue to be afforded the \\nsame generic top level domain status after the transition that it has always enjoyed, on a \\npar with all other country-specific domains. \\n\\nThe Carl Levin and Howard P. “Buck” McKeon National Defense Authorization Act for Fiscal \\nYear 2015 was signed by the President on December 16, 2014 (P.L. 113-235). The enacted law \\n\\n \\n                                                 \\n\\x0cInternet Governance and the Domain Name System: Issues for Congress \\n\\ndoes not contain the DOTCOM Act provision contained in the House-passed version. Section \\n1639 of P.L. 113-235 (“Sense of Congress on the Future of the Internet and the .mil Top-Level \\nDomain”) states it is the sense of Congress that the Secretary of Defense should support the \\nIANA transfer  \\n\\nonly if assurances are provided for the protection of the current status of legacy top-level \\ndomain  names  and  Internet  Protocol  address  numbers,  particularly  those  used  by  the \\nDepartment of Defense and the components of the U.S. Government for national security \\npurposes;  mechanisms  are  institutionalized  to  uphold  and  protect  consensus-based \\ndecision  making in the  multi-stakeholder approach; and existing stress-testing scenarios \\nof the accountability process of the multi-stakeholder model can be confidently shown to \\nwork  transparently,  securely,  and  efficiently  to  maintain  a  free,  open,  and  resilient \\nInternet. \\n\\nIt is also the sense of Congress that the Secretary of Defense should “take all necessary steps to \\nsustain the successful stewardship and good standing of the Internet root zone servers managed \\nby components of the Department of Defense, including active participation, review, and analysis \\nfor transition planning documents and accountability stress testing.” \\n\\nOn May 8, 2014, the House Appropriations Committee approved H.R. 4660, the FY2015 \\nCommerce, Justice, Science (CJS) Appropriations Act, which appropriates funds for DOC and \\nNTIA. The bill report (H.Rept. 113-448) stated that in order that the transition be more fully \\nconsidered by Congress, the committee’s recommendation for NTIA does not include any funds \\nto carry out the transition and that the committee expects that NTIA will maintain the existing no-\\ncost contract with ICANN throughout FY2015. During House consideration of H.R. 4660, an \\namendment offered by Representative Duffy was adopted on May 30, 2014 (by recorded vote, \\n229-178), which stated that (Section 562) “[n]one of the funds made available by this Act may be \\nused to relinquish the responsibility of the National Telecommunications and Information \\nAdministration with respect to Internet domain name system functions, including responsibility \\nwith respect to the authoritative root zone file and the Internet Assigned Numbers Authority \\nfunctions.” H.R. 4660 was subsequently passed by the House on May 30, 2014. \\n\\nOn June 5, 2014, the Senate Appropriations Committee reported its version of the FY2015 \\nCommerce, Justice, Science, and Related Agencies Appropriations Act (S. 2437). In the bill report \\n(S.Rept. 113-181) the committee directed NTIA to conduct a thorough review and analysis of any \\nproposed transition of the IANA contract in order to ensure that ICANN has in place an NTIA \\napproved multi-stakeholder oversight plan that is insulated from foreign government and \\nintergovernmental control. Further, the committee directed NTIA to report quarterly to the \\ncommittee on all aspects of the privatization process and further directed NTIA to inform the \\ncommittee, as well as the Committee on Commerce, Science, and Transportation, not less than \\nseven days in advance of any decision with respect to a successor contract. The committee also \\nexpressed its concern that NTIA has not been a strong advocate for U.S. businesses and \\nconsumers through its participation in ICANN’s Governmental Advisory Committee (GAC), and \\nstated that it awaits “the past due report on NTIA’s plans for greater involvement in the GAC and \\nthe efforts it is undertaking to protect U.S. consumers, companies, and intellectual property.” \\n\\nThe Consolidated and Further Continuing Appropriations Act, 2015 (P.L. 113-235) was signed by \\nthe President on December 16, 2014. Section 540 provides that during FY2015, NTIA may not \\nuse any appropriated funds to relinquish its responsibility with respect to Internet domain name \\nsystem functions, including its responsibility with respect to the authoritative root zone file and \\nthe IANA functions. The prohibition on funding for NTIA’s IANA transition activities expires on \\nSeptember 30, 2015. Additionally, the Explanatory Statement accompanying P.L. 113-235 \\nreiterates House and Senate language regarding ICANN and IANA matters and modifies the \\n\\nCongressional Research Service \\n\\n9 \\n\\n \\n\\x0cInternet Governance and the Domain Name System: Issues for Congress \\n\\nSenate language by directing NTIA “to inform appropriate Congressional committees not less \\nthan 45 days in advance of any such proposed successor contract or any other decision related to \\nchanging NTIA’s role with respect to ICANN or IANA activities.” The Explanatory Statement \\nalso directs NTIA to submit a report to the House and Senate Committees on Appropriations \\nwithin 45 days of enactment of P.L. 113-235 regarding “any recourse that would be available to \\nthe United States if the decision is made to transition to a new contract and any subsequent \\ndecisions made following such transfer of Internet governance are deleterious to the United \\nStates.” \\n\\nOther legislation addressing the proposed transition included the following: \\n\\n\\uf0b7  H.R. 4367 (Internet Stewardship Act of 2014, introduced by Representative Mike \\nKelly on April 2, 2014), which would have prohibited NTIA from relinquishing \\nits DNS responsibilities unless permitted by statute;  \\n\\n\\uf0b7  H.R. 4398 (Global Internet Freedom Act of 2014, introduced by Representative \\nDuffy on April 4, 2014), which would have prohibited NTIA from relinquishing \\nits authority over the IANA functions; and \\n\\n\\uf0b7  H.R. 5737 (Defending Internet Freedom Act of 2014, introduced by \\n\\nRepresentative Mike Kelly on November 19, 2014), which would have \\nprohibited NTIA from relinquishing its responsibilities over domain name \\nfunctions unless it certifies that the transition proposal meets certain specified \\ncriteria. \\n\\nH.R. 4367, H.R. 4398, and H.R. 5737 were referred to the Committee on Energy and Commerce. \\nMeanwhile, the House Judiciary Committee, Subcommittee on Courts, Intellectual Property, and \\nthe Internet, held a hearing on April 10, 2014, that examined the proposed transition. \\n\\nLegislative Activities in the 114th Congress \\n\\nHouse Legislation \\nThe DOTCOM Act of the 113th Congress was reintroduced into the 114th Congress by \\nRepresentative Shimkus as H.R. 805 on February 5, 2015. As introduced, the DOTCOM Act of \\n2015 would have prohibited NTIA from relinquishing responsibility over the Internet domain \\nname system until GAO submitted a report to Congress examining the implications of the \\nproposed transfer. H.R. 805 would have directed GAO to issue the report no later than one year \\nafter NTIA received a transition proposal. On June 17, 2015, the House Committee on Energy \\nand Commerce approved an amended DOTCOM Act. The amended version of H.R. 805 reflected \\na bipartisan agreement and was approved unanimously by voice vote. On June 23, 2015, H.R. 805 \\nwas passed by the House (378-25) under suspension of the rules. \\n\\nH.R. 805, as passed by the House, does not permit NTIA’s authority over the IANA function “to \\nterminate, lapse, be cancelled, or otherwise cease to be in effect” until 30 legislative days after \\nNTIA submits a report to Congress on the final IANA transition proposal. Specifically, the report \\nmust contain the final transition proposal and a certification by NTIA that the proposal \\n\\n\\uf0b7 \\nsupports and enhances the multistakeholder model of Internet governance; \\n\\uf0b7  maintains the security, stability, and resiliency of the Internet domain name \\n\\nsystem; \\n\\n\\uf0b7  meets the needs and expectations of the global customers and partners of IANA \\n\\nservices; \\n\\nCongressional Research Service \\n\\n10 \\n\\n \\n\\x0cInternet Governance and the Domain Name System: Issues for Congress \\n\\n\\uf0b7  maintains the openness of the Internet; and \\n\\uf0b7  does not replace the role of NTIA with a government-led or intergovernmental \\n\\norganization solution. \\n\\nH.R. 805 also requires NTIA to certify that the required changes to ICANN’s bylaws contained in \\nthe transition proposal have been adopted by ICANN. \\n\\nMeanwhile, on June 3, 2015, the House passed H.R. 2578, the FY2016 Commerce, Justice, \\nScience (CJS) Appropriations Act, which appropriates funds for DOC and NTIA. Section 536 of \\nH.R. 2578 states that “[n]one of the funds made available by this Act may be used to relinquish \\nthe responsibility of the National Telecommunications and Information Administration with \\nrespect to Internet domain name system functions, including responsibility with respect to the \\nauthoritative root zone file and the Internet Assigned Numbers Authority functions.” \\n\\nOther House-introduced legislation that addresses the proposed IANA transition includes: \\n\\n\\uf0b7  H.R. 355 (Global Internet Freedom Act of 2015, introduced by Representative \\nDuffy on January 14, 2015), which would prohibit NTIA from relinquishing its \\nauthority over the IANA functions. \\n\\n\\uf0b7  H.R. 2251 (Defending Internet Freedom Act of 2015, introduced by \\n\\nRepresentative Mike Kelly on May 15, 2015), which would prohibit NTIA from \\nrelinquishing its responsibilities over domain name functions and the IANA \\nfunction unless it certifies that the transition proposal meets certain specified \\ncriteria.  \\n\\nSenate Legislation \\n\\nS. 1551, the Senate companion version of the DOTCOM Act of 2015, was introduced on June 11, \\n2015, by Senator Thune. The language of S. 1551 is virtually identical to H.R. 805 as approved \\nby the House Committee on Energy and Commerce. S. 1551 was referred to the Senate \\nCommittee on Commerce, Science, and Transportation and was ordered to be reported by the \\ncommittee on June 25, 2015. \\n\\nOn June 16, 2015, the Senate Appropriations Committee reported its version of the FY2016 \\nCommerce, Justice, Science, and Related Agencies Appropriations Act. In the bill report (S.Rept. \\n114-66) the committee directed NTIA to  \\n\\ncontinue quarterly reports to the Committee on all aspects of the transition process, and \\nfurther directs NTIA to inform the Committee and the Senate Committee on Commerce, \\nScience and Transportation, not less than 45 days in advance of any decision with respect \\nto  a  successor  contract.”  The  committee  also  stated  that  it  “continues  to  be  concerned \\nabout this process and supports the continued stewardship role of the United States over \\nthe domain name system in order to ensure the security of the .gov and .mil domains and \\nto protect the freedom of speech and expression internationally. \\n\\nAlso in the Senate, S.Res. 71—designating the week of February 8 through February 14, 2015, as \\n“Internet Governance Awareness Week”—was introduced by Senator Hatch on February 5, 2015. \\nS.Res. 71 seeks to increase public awareness regarding NTIA’s proposed transition, encourage \\npublic education about the importance of the transition process; and call the attention of the \\nparticipants at the ICANN meeting in Singapore to the importance of designing accountability \\nand governance reforms to best prepare ICANN for executing the responsibilities that it may \\nreceive under any transition of the stewardship of the IANA functions. S.Res. 71 was passed by \\nthe Senate on February 5, 2015.  \\n\\nCongressional Research Service \\n\\n11 \\n\\n \\n\\x0cInternet Governance and the Domain Name System: Issues for Congress \\n\\nEnacted Legislation \\n\\nThe Consolidated Appropriations Act, 2016 (P.L. 114-113) prevents NTIA from relinquishing its \\ncontractual control over IANA in FY2016. Section 539 of P.L. 114-113 states the following: \\n\\n(a)  None  of  the  funds  made  available  by  this  Act  may  be  used  to  relinquish  the \\nresponsibility  of  the  National  Telecommunications  and  Information  Administration, \\nduring fiscal year 2016, with respect to Internet domain name system functions, including \\nresponsibility  with  respect  to  the  authoritative  root  zone  file  and  the  Internet  Assigned \\nNumbers Authority functions.  \\n\\n(b) Not withstanding any other law, subsection (a) of this section shall not apply in fiscal \\nyear 2017. \\n\\nCongressional Hearings \\n\\nAs part of its continuing oversight over NTIA and the domain name system, Congress has held \\nhearings on the proposed IANA transition and on ICANN’s management of the domain name \\nsystem: \\n\\n\\uf0b7  On February 25, 2015, the Senate Committee on Commerce, Science, and \\n\\nTransportation held a hearing entitled, “Preserving the Multistakeholder Model \\nof Internet Governance.”24  \\n\\n\\uf0b7  On May 13, 2015, the House Committee on Energy and Commerce, \\n\\nSubcommittee on Communications and Technology, held a hearing entitled, \\n“Stakeholder Perspectives on the IANA Transition.”25 \\n\\n\\uf0b7  On May 13, 2015, the House Committee on the Judiciary, Subcommittee on \\n\\nCourts, Intellectual Property and the Internet, held a hearing entitled, \\n“Stakeholder Perspectives on ICANN: the .Sucks Domain and Essential Steps to \\nGuarantee Trust and Accountability in the Internet’s Operation.”26 \\n\\n\\uf0b7  On July 8, 2015, the House Committee on Energy and Commerce, Subcommittee \\n\\non Communications and Technology, held a hearing entitled, “Internet \\nGovernance Progress After ICANN 53.”27 \\n\\n\\uf0b7  On March 17, 2016, the House Committee on Energy and Commerce, \\n\\nSubcommittee on Communications and Technology, held a hearing entitled, \\n“Privatizing the Internet Assigned Number Authority.”28 \\n\\nOther Activities \\n\\nOn September 22, 2015, the Chairmen of the House and Senate Judiciary Committees \\n(Representatives Goodlatte and Senator Grassley), Senator Cruz, and Representative Issa sent a \\nletter to GAO expressing concern that the IANA transition and the relinquishing of U.S. \\ngovernment control over the root zone file may constitute a transfer of government property that \\n\\n24 Testimony available at http://www.commerce.senate.gov/public/index.cfm?p=Hearings. \\n25 Testimony available at http://energycommerce.house.gov/hearing/stakeholder-perspectives-iana-transition. \\n26 Testimony available at http://judiciary.house.gov/index.cfm/hearings?ID=7E5AF16E-B1F8-45B8-803B-\\n9E389A9B745E. \\n27 Testimony available at http://energycommerce.house.gov/hearing/internet-governance-progress-after-icann-53. \\n28 Testimony available at https://energycommerce.house.gov/hearings-and-votes/hearings/privatizing-internet-assigned-\\nnumber-authority. \\n\\nCongressional Research Service \\n\\n12 \\n\\n \\n                                                 \\n\\x0cInternet Governance and the Domain Name System: Issues for Congress \\n\\nmay only be authorized by an act of Congress.29 Specifically, the letter asked GAO to examine \\nthree questions: would the termination of NTIA’s contract with ICANN cause government \\nproperty of any kind to be transferred to ICANN; is the root zone file or other related or similar \\nmaterials or information U.S. government property; and if so, does NTIA have the authority to \\ntransfer the root zone file or other related materials or information to a nonfederal entity? \\n\\nOn October 15, 2015, the Chairman of the Senate Committee on Commerce, Science, and \\nTransportation and the Ranking Member of the Subcommittee on Communications, Technology, \\nInnovation, and the Internet (Senator Thune and Senator Schatz) sent a letter30 to ICANN calling \\nfor robust accountability reforms which may lessen the Board’s power and authority if those \\nreforms conform with the multistakeholder community’s accountability proposal. The Senators \\nfurther stated that no arbitrary deadlines should be used as a way to deter the community from \\nsecuring the reforms it must have to sufficiently replace the role currently played by NTIA. \\nOn February 4, 2016, Senators Cruz, Lee, and Lankford sent a letter31 to ICANN’s CEO Fadi \\nChehadé, questioning the propriety of his participation in the World Internet Conference \\norganized by the Chinese government. On March 3, 2016, a subsequent letter32 was sent to the \\nChairman of the ICANN Board questioning various ICANN activities in relation to China.  \\n\\nDebate over Future Model of Internet Governance \\nGiven its complexity, diversity, and international nature, how should the Internet be governed? \\nSome assert that a multistakeholder model of governance is appropriate, where all stakeholders \\n(both public and private sectors) arrive at consensus through a transparent bottom-up process. \\nOthers argue that a greater role for national governments is necessary, either through increased \\ninfluence through the multistakeholder model, or under the auspices of an international body \\nexerting intergovernmental control.  \\n\\nTo date, ICANN and the governance of the domain name system has been the focal point of this \\ndebate. While ICANN’s mandate is to manage portions of the technical infrastructure of the \\nInternet (domain names and IP addresses), many of the decisions ICANN makes affect other \\naspects of Internet policy, including areas such as intellectual property, privacy, and cybersecurity. \\nThese are areas which many national governments have addressed for their own citizens and \\nconstituencies through domestic legislation, as well as through international treaties.  \\n\\nAs part of the debate over an appropriate model of Internet governance, criticisms of ICANN \\nhave arisen on two fronts. One criticism reflects the tension between national governments and \\nthe current performance and governance processes of ICANN, whereby governments feel they \\nlack adequate influence over ICANN decisions that affect a range of Internet policy issues. The \\nother criticism is fueled by concerns of many nations that the U.S. government holds undue \\nlegacy influence and control over ICANN and the domain name system.  \\n\\nThe debate over multistakeholderism vs. intergovernmental control initially manifested itself in \\n2005 at the World Summit on the Information Society (WSIS), which was a conference organized \\nby the United Nations. More recently, this debate has been rekindled in various international fora, \\n\\n \\n                                                 \\n\\x0cInternet Governance and the Domain Name System: Issues for Congress \\n\\npartially sparked by two ICANN actions in 2011: the approval of the .xxx top-level domain and \\nthe approval of a process to allow an indefinite number of new generic top level domains \\n(gTLDs). \\n\\n2005 World Summit on the Information Society (WSIS) \\n\\nFollowing the creation of ICANN in 1998, many in the international community, including \\nforeign governments, argued that it was inappropriate for the U.S. government to maintain its \\nlegacy authority over ICANN and the DNS. They suggested that management of the DNS should \\nbe accountable to a higher intergovernmental body. The United Nations, at the first phase of the \\nWSIS in December 2003, debated and agreed to study the issue of how to achieve greater \\ninternational involvement in the governance of the Internet, and the domain name system in \\nparticular. The study was conducted by the U.N.’s Working Group on Internet Governance \\n(WGIG). On July 14, 2005, the WGIG released its report,33 stating that no single government \\nshould have a preeminent role in relation to international Internet governance. The report called \\nfor further internationalization of Internet governance, and proposed the creation of a new global \\nforum for Internet stakeholders. Four possible models were put forth, including two involving the \\ncreation of new Internet governance bodies linked to the U.N. Under three of the four models, \\nICANN would either be supplanted or made accountable to a higher intergovernmental body. The \\nreport’s conclusions were scheduled to be considered during the second phase of the WSIS held \\nin Tunis in November 2005. U.S. officials stated their opposition to transferring control and \\nadministration of the domain name system from ICANN to any international body. Similarly, the \\n109th Congress expressed its support for maintaining existing U.S. control over ICANN and the \\nDNS (H.Con.Res. 268 and S.Res. 323).34 \\n\\nThe European Union (EU) initially supported the U.S. position. However, during the September \\n2005 preparatory meetings, the EU seemingly shifted its support towards an approach which \\nfavored an enhanced international role in governing the Internet. Conflict at the WSIS Tunis \\nSummit over control of the domain name system was averted by the announcement, on \\nNovember 15, 2005, of an Internet governance agreement between the United States, the EU, and \\nover 100 other nations. Under this agreement, ICANN and the United States maintained their \\nroles with respect to the domain name system. A new international group under the auspices of \\nthe U.N. was formed—the Internet Governance Forum (IGF)—which would provide an ongoing \\nforum for all stakeholders (both governments and nongovernmental groups) to discuss and debate \\nInternet policy issues.  \\n\\nCreation of the .xxx Domain and New gTLDs \\n\\nStarting in 2010 and 2011, controversies surrounding the roll-out of new generic top level \\ndomains (gTLDs) and the addition of the .xxx TLD led some governments to argue for increased \\ngovernment influence on the ICANN policy development process.35  \\n\\n\\n \\n                                                 \\n\\x0cInternet Governance and the Domain Name System: Issues for Congress \\n\\n.xxx \\n\\nSince 2000, ICANN has repeatedly considered whether to allow the establishment of a gTLD for \\nadult content. On June 1, 2005, ICANN announced that it had entered into commercial and \\ntechnical negotiations with a registry company (ICM Registry) to operate a new “.xxx” domain, \\nwhich would be designated for use by adult websites. With the ICANN Board scheduled to \\nconsider final approval of the .xxx domain on August 16, 2005, the Department of Commerce \\nsent a letter to ICANN requesting that adequate additional time be provided to allow ICANN to \\naddress the objections of individuals expressing concerns about the impact of pornography on \\nfamilies and children and opposing the creation of a new top level domain devoted to adult \\ncontent. ICANN’s Governmental Advisory Committee (GAC) also requested more time before \\nthe final decision.  \\n\\nOn March 30, 2007, the ICANN Board voted 9-5 to deny the .xxx domain. ICM Registry \\nsubsequently challenged ICANN’s decision before an Independent Review Panel (IRP), claiming \\nthat ICANN’s rejection of ICM’s application for a .xxx gTLD was not consistent with ICANN’s \\nArticles of Incorporation and Bylaws. On February 19, 2010, a three-person Independent Review \\nPanel ruled primarily in favor of ICM Registry, finding that its application for the .xxx TLD had \\nmet the required criteria.  \\n\\nSubsequently, on June 25, 2010, at the ICANN meeting in Brussels, the Board of Directors voted \\nto allow ICM’s .xxx application to move forward, and at the December 2010 ICANN meeting, the \\nICANN Board passed a resolution stating that while “it intends to enter into a registry agreement \\nwith ICM Registry for the .xxx TLD,” the Board would enter into a formal consultation with the \\nGovernmental Advisory Committee on areas where the Board’s decision was in conflict with \\nGAC advice relating to the ICM application.36 \\n\\nWhile not officially or formally in opposition to the approval of .xxx, the GAC advised ICANN \\nthat “there is no active support of the GAC for the introduction of a .xxx TLD” and that “while \\nthere are members, which neither endorse nor oppose the introduction of a .xxx TLD, others are \\nemphatically opposed from a public policy perspective to the introduction of an .xxx TLD.”37 The \\nGAC listed a number of specific issues and objections that it wished ICANN to resolve. \\n\\nA February 2011 letter from ICANN to the GAC acknowledged and responded to areas where \\napproving the .xxx registry agreement with ICM would conflict with GAC advice received by \\nICANN.38 The Board acknowledged that ICANN and the GAC were not able to reach a mutually \\nacceptable solution, and ultimately, on March 18, 2011, the Board approved a resolution giving \\nthe CEO or General Counsel of ICANN the authority to execute the registry agreement with ICM \\nto establish a .xxx TLD. The vote was nine in favor, three opposed, and four abstentions. \\nThe decision to create a .xxx TLD was not viewed favorably by many governments.39 In an April \\n6, 2011, letter to the Department of Commerce, the European Commissioner for the Digital \\n\\n \\n                                                 \\n\\x0cInternet Governance and the Domain Name System: Issues for Congress \\n\\nAgenda asked that the introduction of .xxx be delayed.40 In its response, NTIA said it “share[s] \\nyour disappointment that ICANN ignored the clear advice of governments worldwide, including \\nthe United States, by approving the new .xxx domain.”41 However, NTIA stated why it would not \\n(and did not) interfere with the addition of .xxx: \\n\\nWhile  the  Obama  Administration  does  not  support  ICANN’s  decision,  we  respect  the \\nmulti-stakeholder Internet governance process and do not think that it is in the long-term \\nbest interest of the United States or the global Internet community for us unilaterally to \\nreverse  the  decision.  Our  goal  is  to  preserve  the  global  Internet,  which  is  a  force  for \\ninnovation, economic growth, and the free flow of information. I agree with you that the \\nBoard  took  its  action  without  the  full  support  of  the  community  and  accordingly,  I  am \\ndedicated  to  improving  the  responsiveness  of  ICANN  to  all  stakeholders,  including \\ngovernments worldwide.42 \\n\\ngTLD Expansion \\n\\nTop Level Domains (TLDs) are the suffixes that appear at the end of an address (after the “dot”). \\nPrior to ICANN’s establishment in 1998, the Internet had eight generic top level domains \\n(gTLDs), including .com, .org, .net, and .gov. In 2000 and 2004, ICANN held application rounds \\nfor a limited number of new gTLDs—currently there are 22. Some are reserved or restricted to \\nparticular types of organizations (e.g., .museum, .gov, .travel) and others are open for registration \\nby anyone (.com, .org, .info). Applicants for new gTLDs are typically commercial entities and \\nnonprofit organizations who seek to become ICANN-recognized registries that will establish and \\noperate name servers for their TLD registry, as well as implement a domain name registration \\nprocess for that particular TLD. \\n\\nThe growth of the Internet and the accompanying growth in demand for domain names have \\nfocused the debate on whether and how to further expand the number of gTLDs. Beginning in \\n2005, ICANN embarked on a long consultative process to develop rules and procedures for \\nintroducing and adopting an indefinite number of new gTLDs into the domain name system. A \\nnew gTLD can be any word or string of characters that is applied for and approved by ICANN. \\nBetween 2008 and 2011, ICANN released seven iterations of its gTLD Applicant Guidebook \\n(essentially the rulebook for how the new gTLD program will be implemented). On June 20, \\n2011, the ICANN Board of Directors voted to approve the launch of the new gTLD program, \\nunder which potentially hundreds of new gTLDs could ultimately be approved by ICANN and \\nintroduced into the DNS. Applications for new gTLDs were to be accepted from January 12 \\nthrough April 12, 2012. \\n\\nThe rollout of new gTLDs was controversial. Advocates (including the domain name industry) \\nargued that a gTLD expansion will provide opportunities for Internet innovation and competition. \\nOn the other hand, many trademark holders pointed to possible higher costs and greater \\ndifficulties in protecting their trademarks across hundreds of new gTLDs. Similarly, governments \\n\\n(...continued) \\nIndia and Saudi Arabia have stated their intention to block the .xxx domain. See “xxx addresses open for business,” The \\nTimes of India, April 19, 2011, available at http://articles.timesofindia.indiatimes.com/2011-04-19/computing/\\n29446429_1_icann-suffix-websites. \\n\\n\\n \\n                                                                 \\n\\x0cInternet Governance and the Domain Name System: Issues for Congress \\n\\nexpressed concern over intellectual property protections, and along with law enforcement entities, \\nalso cited concerns over the added burden of combating various cybercrimes (such as phishing \\nand identity theft) across hundreds of new gTLDs. Throughout ICANN’s policy development \\nprocess, governments, through the Governmental Advisory Committee, advocated for additional \\nintellectual property protections in the new gTLD process. The GAC also argued for more \\nstringent rules that would allow for better law enforcement in the new domain space to better \\nprotect consumers. Although changes were made, strong opposition from many trademark \\nholders43 led to opposition from some parts of the U.S. government towards the end of 2011. For \\nexample:  \\n\\n\\uf0b7  On December 8, 2011, the Senate Committee on Commerce, Science and \\n\\nTransportation held a hearing on the ICANN’s expansion of TLDs. Subsequently, \\non December 28, 2011, a letter from Senator John Rockefeller, chairman of the \\nSenate Committee on Commerce, Science and Transportation, to the Secretary of \\nCommerce and the Administrator of NTIA, stated his concern that “this \\nexpansion of gTLDs, if it proceeds as planned, will have adverse consequences \\nfor the millions of American consumers, companies, and non-profit organizations \\nthat use the Internet on a daily basis” and that at the hearing, “witnesses speaking \\non behalf of more than a hundred companies and non-profit organizations \\nexplained that ICANN’s current plan for gTLD expansion will likely cause \\nmillions of dollars in increased costs related to combating cybersquatting.” In the \\nletter, Senator Rockefeller requested that NTIA “should consider asking ICANN \\nto either delay the opening of the application period or to drastically limit the \\nnumber of new gTLDs it approves next year.”44 A subsequent December 22, \\n2011, letter to ICANN from Senators Klobuchar and Ayotte also registered \\nconcern over the TLD expansion and asked ICANN to further address law \\nenforcement, trademark, and consumer concerns before launching the program.45 \\n\\n\\uf0b7  On December 14, 2011, the House Committee on Energy and Commerce, \\n\\nSubcommittee on Communications and Technology, held a hearing on ICANN’s \\ntop level domain program. Subsequently on December 21, 2011, a bipartisan \\ngroup of committee members sent a letter to ICANN requesting that the \\nexpansion of the gTLDs be delayed, noting that “many stakeholders are not \\nconvinced that ICANN’s process has resulted in an acceptable level of \\nprotection.”46 The Energy and Commerce Committee members argued that “a \\nshort delay will allow interested parties to work with ICANN and offer changes \\nto alleviate many of them, specifically concerns over law enforcement, cost and \\ntransparency that were discussed in recent Congressional hearings.”47 \\n\\n \\n                                                 \\n\\x0cInternet Governance and the Domain Name System: Issues for Congress \\n\\n\\uf0b7  A December 16, 2011, letter to the Secretary of Commerce from Representative \\n\\nBob Goodlatte, chairman of the House Subcommittee on Intellectual Property, \\nCompetition, and the Internet, and Representative Howard Berman, ranking \\nMember of the House Committee on Foreign Affairs, urged DOC to take all steps \\nnecessary to encourage ICANN to undertake further evaluation and review \\nbefore the gTLD expansion is permitted to occur. The letter asked DOC to \\ndetermine whether the benefits of the expansion outweigh the costs and risks to \\nconsumers, businesses, and the Internet, and that if the program proceeds, that \\nICANN should initially limit the expansion to a small pilot project which can be \\nevaluated.48 Previously, the Subcommittee on Intellectual Property, Competition, \\nand the Internet had held a May 4, 2011, hearing on oversight of the gTLD \\nprogram. \\n\\n\\uf0b7  A December 16, 2011, letter from the Federal Trade Commission (FTC) to \\n\\nICANN argued that a “rapid, exponential expansion of gTLDs has the potential \\nto magnify both the abuse of the domain name system and the corresponding \\nchallenges we encounter in tracking down Internet fraudsters.” The FTC urged \\nICANN to implement the new gTLD program as a pilot program and \\nsubstantially reduce the number of gTLDs that are introduced in the first \\napplication round, strengthen ICANN’s contractual compliance program, develop \\na new ongoing program to monitor consumer issues that arise during the first \\nround of implementing the new gTLD program, conduct an assessment of each \\nnew proposed gTLD’s risk of consumer harm as part of the evaluation and \\napproval process, and improve the accuracy of WHOIS data, including by \\nimposing a registrant verification requirement. The FTC added that “ICANN \\nshould address these issues before it approves any new gTLD applications. If \\nICANN fails to address these issues responsibly, the introduction of new gTLDs \\ncould pose a significant threat to consumers and undermine consumer confidence \\nin the Internet.”49  \\n\\n\\uf0b7  A December 27, 2011, letter to ICANN from the Senate and House Judiciary \\n\\nCommittees expressed concerns over the new gTLD program and urged ICANN \\nto “strengthen protections for consumers and trademark holders who risk being \\nharmed by the proliferation of domain names on the web.” The letter also urged \\nICANN to work closely with the law enforcement community “to ensure that the \\nprogram’s rollout does not adversely impact their efforts to fight fraud and abuse \\non the Internet.”50 \\n\\nAt the December 2011 House and Senate hearings, ICANN stated its intention to proceed with \\nthe gTLD expansion as planned. ICANN defended its gTLD program, arguing that the new \\ngTLDs will offer more protections for consumers and trademark holders than current gTLDs; that \\nnew gTLDs will provide needed competition, choice, and innovation to the domain name system; \\nand that critics have already had ample opportunity to contribute input during a seven-year \\n\\n \\n                                                 \\n\\x0cInternet Governance and the Domain Name System: Issues for Congress \\n\\ndeliberative policy development process.51 Ultimately, ICANN did not delay the initiation of the \\nnew gTLD program, and the application window was opened on January 12, 2012, as planned.  \\n\\nMuch of the pressure on ICANN to delay the new gTLD program was directed at NTIA, given \\nNTIA’s unique relationship with ICANN. At both the December 2011 Senate and House hearings, \\nNTIA expressed support for ICANN’s planned rollout of the TLD expansion program, arguing \\nthat national governments have been able to address intellectual property, law enforcement, and \\nconsumer concerns through the Governmental Advisory Committee (GAC): \\n\\nNTIA  believes  that  ICANN  improved  the  new  gTLD  program  by  incorporating  a \\nsignificant number of proposals from the GAC. ICANN’s new gTLD program also now \\nprovides  law  enforcement  and  consumer  protection  authorities  with  significantly  more \\ntools than those available in existing gTLDs to address malicious conduct. The fact that \\nnot  all  of  the  GAC’s  proposals  were  adopted  as  originally  offered  does  not  represent  a \\nfailure of the process or a setback to governments; rather, it reflects the reality of a multi-\\nstakeholder model.52 \\n\\nWhile NTIA stated that it would continue to monitor progress and push for necessary changes to \\nICANN’s TLD expansion program, a key aspect of NTIA’s argument for supporting ICANN’s \\nplanned rollout was to preserve the integrity of the multistakeholder Internet governance process: \\n\\nNTIA is dedicated to maintaining an open, global Internet that remains a valuable tool for \\neconomic  growth,  innovation,  and  the  free  flow  of  information,  goods,  and  services \\nonline. We believe the best way to achieve this goal is to continue to actively support and \\nparticipate in multi-stakeholder Internet governance processes such as ICANN. This is in \\nstark contrast to some countries that are  actively seeking to move Internet policy to the \\nUnited  Nations.  If  we  are  to  combat  the  proposals  put  forward  by  others,  we  need  to \\nensure  that  our  multi-stakeholder  institutions  have  provided  a  meaningful  role  for \\ngovernments  as  stakeholders.  NTIA  believes  that  the  strength  of  the  multi-stakeholder \\napproach  to  Internet  policy-making  is  that  it  allows  for  speed,  flexibility,  and \\ndecentralized problem-solving and stands in stark contrast to a more traditional, top-down \\nregulatory model characterized by rigid processes, political capture by incumbents, and in \\nso many cases, impasse or stalemate.53  \\n\\nOn January 3, 2012, NTIA sent ICANN a letter concerning implementation of the new gTLD \\nprogram.54 While NTIA recognized that the program “is the product of a six-year international \\nmultistakeholder process” and that NTIA does “not seek to interfere with the decisions and \\ncompromises reached during that process,” NTIA urged ICANN to consider implementing \\nmeasures to address many of the criticisms raised. Such measures would address concerns of \\ntrademark holders, law enforcement, and consumer protection. NTIA also asked ICANN to assess \\n(after the initial application window closes and the list of prospective new gTLDs is known) \\n\\n\\n \\n                                                 \\n\\x0cInternet Governance and the Domain Name System: Issues for Congress \\n\\nwhether there is a need to phase in the introduction of new gTLDs, and whether additional \\ntrademark protection measures need to be taken. \\n\\nNTIA concluded its letter as follows: \\n\\nHow  ICANN  handles  the  new  gTLD  program  will,  for  many,  be  a  litmus  test  of  the \\nviability of this approach. For its part, NTIA is committed to continuing to be an active \\nmember  of  the  GAC  and  working  with  stakeholders  to  mitigate  any  unintended \\nconsequences of the new gTLD program.55 \\n\\nAs the new gTLDs go “live,” many stakeholders are concerned that various forms of domain \\nname abuse (e.g., trademark infringement, consumer fraud, malicious behavior, etc.) could \\nmanifest itself within the hundreds of new gTLD domain spaces. Thus, the effectiveness of \\nICANN’s approach to addressing such issues as intellectual property protection of second level \\ndomain names and mitigating unlawful behavior in the domain name space will be of interest as \\nthe new gTLD program goes forward. \\n\\nWith respect to the new gTLD program, the GAC provided advice to the ICANN Board on any \\nfirst round applications the GAC considered problematic. GAC advice can take three forms: \\n\\nI.  The  GAC  advises  ICANN  that  it  is  the  consensus  of  the  GAC  that  a  particular \\napplication  should  not  proceed.  This  will  create  a  strong  presumption  for  the  ICANN \\nBoard that the application should not be approved.  \\n\\nII. The GAC advises ICANN that there are concerns about a particular application “dot-\\nexample.”  The  ICANN  Board  is  expected  to  enter  into  dialogue  with  the  GAC  to \\nunderstand  the  scope  of  concerns.  The  ICANN  Board  is  also  expected  to  provide  a \\nrationale for its decision. \\n\\nIII. The GAC advises ICANN that an application should not proceed unless remediated. \\nThis will raise a strong presumption for the Board that the application should not proceed \\nunless  there  is  a  remediation  method  available  in  the  Guidebook  (such  as  securing  the \\napproval of one or more governments), that is implemented by the applicant.56 \\n\\nThe GAC also issued Early Warnings to the ICANN Board in the event that any GAC member \\nfound an application problematic for any reason. An Early Warning was an indication that a \\nformal GAC objection was possible (either through the GAC advice process or through the \\nformal objection process). Applicants were notified of an Early Warning against their application \\nand given the opportunity to address the concerns or to withdraw the application (thereby \\nqualifying for a partial refund of the application fee).  \\n\\nProposed Models for Internet Governance \\n\\nAs discussed above, ICANN is a working example of a multistakeholder model of Internet \\ngovernance, whereby a bottom-up collaborative process is used to provide Internet stakeholders \\nwith access to the policymaking process. Support for the multistakeholder model of Internet \\ngovernance is reflected in international organizations such as the Organisation for Economic Co-\\noperation and Development (OECD) and the Group of Eight (G8). For example, the OECD’s \\nCommuniqué on Principles for Internet Policy-Making cites multistakeholderism as a central \\ntenet of Internet governance: \\n\\n\\n \\n                                                 \\n\\x0cInternet Governance and the Domain Name System: Issues for Congress \\n\\nIn particular, continued support is needed for the  multi-stakeholder environment,  which \\nhas  underpinned  the  process  of  Internet  governance  and  the  management  of  critical \\nInternet  resources  (such  as  naming  and  numbering  resources)  and  these  various \\nstakeholders should continue to fully play a role in this framework. Governments should \\nalso work in multi-stakeholder environments to achieve international public policy goals \\nand strengthen international co-operation in Internet governance.57 \\n\\nSimilarly, at the G8 Summit of Deauville on May 26-27, 2011, the G8 issued a declaration on its \\nrenewed commitment for freedom and democracy that contained a new section on the Internet. \\nSupport for a multistakeholder model for Internet governance with a significant national \\ngovernment role was made explicit:  \\n\\nAs  we  support  the  multi-stakeholder  model  of  Internet  governance,  we  call  upon  all \\nstakeholders to contribute to  enhanced cooperation  within  and between all international \\nfora  dealing  with  the  governance  of  the  Internet.  In  this  regard,  flexibility  and \\ntransparency have to be maintained in order to adapt to the fast pace of technological and \\nbusiness developments and uses. Governments have a key role to play in this model.58 \\n\\nAs discussed above, in 2005, the World Summit on the Information Society (WSIS) considered \\nfour models of Internet governance, of which three would have involved an intergovernmental \\nbody to oversee the Internet and the domain name system. While the WSIS ultimately decided not \\nto pursue an intergovernmental model in 2005, some nations have again advocated an \\nintergovernmental approach for Internet governance. For example: \\n\\n\\uf0b7 \\n\\n\\uf0b7 \\n\\nIndia, Brazil, and South Africa (referred to as IBSA) proposed that “an \\nappropriate body is urgently required in the U.N. system to coordinate and evolve \\ncoherent and integrated global public policies pertaining to the Internet.” The \\nIBSA proposed body would “integrate and oversee the bodies responsible for \\ntechnical and operational functioning of the Internet, including global standards \\nsetting.”59 \\nIn order to implement the major aspects of the IBSA proposal, the government of \\nIndia proposed (in the U.N. General Assembly) the establishment of a new \\ninstitutional mechanism in the United Nations for global Internet-related policies, \\nto be called the United Nations Committee for Internet-Related Policies (CIRP). \\nCIRP would be comprised of 50 member states chosen on the basis of equitable \\ngeographical representation. The Internet Governance Forum (IGF) and four \\nadvisory stakeholder groups would provide input to CIRP, which would report \\ndirectly to the General Assembly and present recommendations for consideration, \\nadoption, and dissemination among all relevant intergovernmental bodies and \\ninternational organizations.60 \\n\\n \\n                                                 \\n\\x0cInternet Governance and the Domain Name System: Issues for Congress \\n\\n\\uf0b7  Another group of nations, including China and the Russian Federation, proposed \\na voluntary “International Code of Conduct for Information Security,” for further \\ndiscussion in the U.N. General Assembly. The Code includes language that \\npromotes the establishment of a multilateral, transparent, and democratic \\ninternational management system to ensure an equitable distribution of resources, \\nfacilitate access for all, and ensure a stable and secure functioning of the \\nInternet.61  \\n\\n\\uf0b7  On January 13, 2015, the same group of nations released a revised International \\n\\nCode of Conduct for Information Security which states that  \\n\\nall States must play the same role in, and carry equal responsibility for, international \\ngovernance of the Internet, its security, continuity and stability of operation, and its \\ndevelopment in a way which promotes the establishment of multilateral, transparent \\nand  democratic  international  Internet  governance  mechanisms  which  ensure  an \\nequitable distribution of resources, facilitate access for all and ensure the stable and \\nsecure functioning of the Internet.62 \\n\\nThus, governments such as the United States and the European Union support ICANN’s \\nmultistakeholder model, while at the same time advocating increased governmental influence \\nwithin that model.63 By contrast, other nations support an expanded role for an intergovernmental \\nmodel of Internet governance. The debate has been summarized by NTIA as follows:  \\n\\nBy  engaging  all  interested  parties,  multistakeholder  processes  encourage  broader  and \\nmore  creative  problem  solving,  which  is  essential  when  markets  and  technology  are \\nchanging as rapidly as they are. They promote speedier,  more flexible decision  making \\nthan is common under traditional, top-down regulatory models which can too easily fall \\nprey to rigid procedures, bureaucracy, and stalemate. But there is a challenge emerging to \\nthis model in parts of the world.... Some nations appear to prefer an Internet managed and \\ncontrolled  by  nation-states.  In  December  2012,  the  U.S.  will  participate  in  the  ITU’s \\nWorld Conference on International Telecommunications (WCIT). This treaty negotiation \\nwill  conduct  a  review  of  the  International  Telecommunication  Regulations  (ITRs),  the \\ngeneral  principles  which  relate  to  traditional  international  voice  telecommunication \\nservices.  We  expect  that  some  states  will  attempt  to  rewrite  the  regulation  in  a  manner \\nthat  would  exclude  the  contributions  of  multi-stakeholder  organizations  and  instead \\nprovide for heavy-handed governmental control of the Internet, including provisions for \\ncybersecurity  and  granular  operational  and  technical  requirements  for  private  industry. \\nWe do not support any of these elements. It is critical that we work with the private sector \\non  outreach  to  countries  to  promote  the  multi-stakeholder  model  as  a  credible \\nalternative.64 \\n\\n\\n \\n                                                 \\n\\x0cInternet Governance and the Domain Name System: Issues for Congress \\n\\nWorld Conference on International Telecommunications (WCIT) \\n\\nThe World Conference on International Telecommunications (WCIT) was held in Dubai on \\nDecember 3-14, 2012. Convened by the International Telecommunications Union (the ITU, an \\nagency within the United Nations), the WCIT was a formal meeting of the world’s national \\ngovernments held in order to revise the International Telecommunications Regulations (ITRs). \\nThe ITRs, previously revised in 1988, serve as a global treaty outlining the principles which \\ngovern the way international telecommunications traffic is handled. \\n\\nBecause the existing 24-year-old ITRs predated the Internet, one of the key policy questions in \\nthe WCIT was how and to what extent the updated ITRs should address Internet traffic and \\nInternet governance. The Administration and Congress took the position that the new ITRs should \\ncontinue to address only traditional international telecommunications traffic, that a \\nmultistakeholder model of Internet governance (such as ICANN) should continue, and that the \\nITU should not take any action that could extend its jurisdiction or authority over the Internet.  \\nAs the WCIT approached, concerns heightened in the 112th Congress that the WCIT might \\npotentially provide a forum leading to an increased level of intergovernmental control over the \\nInternet. On May 31, 2012, the House Committee on Energy and Commerce, Subcommittee on \\nCommunications and Technology, held a hearing entitled, “International Proposals to Regulate \\nthe Internet.”65 To accompany the hearing, H.Con.Res. 127 was introduced by Representative \\nBono Mack expressing the sense of Congress regarding actions to preserve and advance the \\nmultistakeholder governance model. Specifically, H.Con.Res. 127 expressed the sense of \\nCongress that the Administration “should continue working to implement the position of the \\nUnited States on Internet governance that clearly articulates the consistent and unequivocal policy \\nof the United States to promote a global Internet free from government control and preserve and \\nadvance the successful multistakeholder model that governs the Internet today.” H.Con.Res. 127 \\nwas passed unanimously by the House (414-0) on August 2, 2012.  \\n\\nA similar resolution, S.Con.Res. 50, was introduced into the Senate by Senator Rubio on June 27, \\n2012, and referred to the Committee on Foreign Relations. The Senate resolution expressed the \\nsense of Congress “that the Secretary of State, in consultation with the Secretary of Commerce, \\nshould continue working to implement the position of the United States on Internet governance \\nthat clearly articulates the consistent and unequivocal policy of the United States to promote a \\nglobal Internet free from government control and preserve and advance the successful \\nmultistakeholder model that governs the Internet today.” S.Con.Res. 50 was passed by the Senate \\nby unanimous consent on September 22, 2012. On December 5, 2012—shortly after the WCIT \\nhad begun in Dubai—the House unanimously passed S.Con.Res. 50 by a vote of 397-0. \\n\\nDuring the WCIT, a revision to the ITRs was proposed and supported by Russia, China, Saudi \\nArabia, Algeria, and Sudan that sought to explicitly extend ITR jurisdiction over Internet traffic, \\ninfrastructure, and governance. Specifically, the proposal stated that “Member States shall have \\nthe sovereign right to establish and implement public policy, including international policy, on \\n\\n                                                                 \\n\\x0cInternet Governance and the Domain Name System: Issues for Congress \\n\\nmatters of Internet governance.”66 The proposal also included an article establishing the right of \\nMember States to manage Internet numbering, naming, addressing, and identification resources.  \\n\\nThe proposal was subsequently withdrawn. However, as an intended compromise, the ITU \\nadopted a nonbinding resolution (Resolution 3, attached to the final ITR text) entitled, “To Foster \\nan enabling environment for the greater growth of the Internet.” Resolution 3 included language \\nstating “all governments should have an equal role and responsibility for international Internet \\ngovernance” and invited Member States to “elaborate on their respective positions on \\ninternational Internet-related technical, development and public policy issues within the mandate \\nof ITU at various ITU forums.”67 \\n\\nBecause of the inclusion of Resolution 3, along with other features of the final ITR text (such as \\nnew ITU articles related to spam and cybersecurity), the United States declined to sign the treaty. \\nThe leader of the U.S. delegation stated the following: \\n\\nThe Internet has given the world unimaginable economic and social benefits during these \\npast 24 years—all without UN regulation. We candidly cannot support an ITU treaty that \\nis  inconsistent  with  a  multi-stakeholder  model  of  Internet  governance.  As  the  ITU  has \\nstated,  this  conference  was  never  meant  to  focus  on  internet  issues;  however,  today  we \\nare in a situation where we still have text and resolutions that cover issues on spam and \\nalso provisions on internet governance. These past two weeks, we have of course made \\ngood progress and shown a willingness to negotiate on a variety of telecommunications \\npolicy  issues,  such  as  roaming  and  settlement  rates,  but  the  United  States  continues  to \\nbelieve that internet policy must be multi-stakeholder driven. Internet policy should not \\nbe determined by member states but by citizens, communities, and broader society, and \\nsuch  consultation  from  the  private  sector  and  civil  society  is  paramount.  This  has  not \\nhappened here.68 \\n\\nOf the 144 eligible members of the ITU, 89 nations signed the treaty, while 55 either chose not to \\nsign (such as the United States) or remain undecided.69  \\n\\nWhile the WCIT in Dubai is concluded, the international debate over Internet governance is \\nexpected to continue in future intergovernmental telecommunications meetings and conferences. \\nThe 113th Congress oversaw and supported the U.S. government’s continuing efforts to resist \\ninternational attempts to exert control over Internet governance. On February 5, 2013, the House \\nCommittee on Energy and Commerce, Subcommittee on Communications and Technology, held a \\nhearing entitled “Fighting for Internet Freedom: Dubai and Beyond.” The hearing was held \\njointly with the House Committee on Foreign Affairs, Subcommittee on Terrorism, \\nNonproliferation, and Trade and the Subcommittee on Africa, Global Health, Global Human \\nRights, and International Organizations.  \\n\\nOn April 16, 2013, H.R. 1580, a bill “To Affirm the Policy of the United States Regarding \\nInternet Governance,” was introduced by Representative Walden. Using language similar to the \\nWCIT-related congressional resolutions passed by the 112th Congress (S.Con.Res. 50 and \\n\\n \\n                                                 \\n\\x0cInternet Governance and the Domain Name System: Issues for Congress \\n\\nH.Con.Res. 127), H.R. 1580 stated that “It is the policy of the United States to preserve and \\nadvance the successful multistakeholder model that governs the Internet.” On May 14, 2013, H.R. \\n1580 was passed unanimously (413-0) by the House of Representatives.  \\n\\nMontevideo Statement on the Future of Internet Cooperation \\n\\nIn October 2013, the President of ICANN and the leaders of other major organizations \\nresponsible for globally coordinating Internet technical infrastructure70 met in Montevideo, \\nUruguay, and released a statement calling for strengthening the current mechanisms for global \\nmultistakeholder Internet cooperation. Their recommendations included the following: \\n\\n\\uf0b7  They reinforced the importance of globally coherent Internet operations, and \\n\\nwarned against Internet fragmentation at a national level. They expressed strong \\nconcern over the undermining of the trust and confidence of Internet users \\nglobally due to recent revelations of pervasive monitoring and surveillance. \\n\\uf0b7  They identified the need for ongoing effort to address Internet Governance \\n\\nchallenges, and agreed to catalyze community-wide efforts towards the evolution \\nof global multistakeholder Internet cooperation. \\n\\n\\uf0b7  They called for accelerating the globalization of ICANN and IANA functions, \\ntowards an environment in which all stakeholders, including all governments, \\nparticipate on an equal footing.71 \\n\\nNETmundial \\n\\nThe day after the Montevideo Statement was released, the President of ICANN met with the \\nPresident of Brazil, who announced plans to hold an international Internet governance summit in \\nApril 2014 that would include representatives from government, industry, civil society, and \\nacademia. NETmundial, which was described as a “global multistakeholder meeting on the future \\nof Internet governance,” was held on April 23-24, 2014, in Sao Paulo, Brazil.72 The meeting was \\nopen to all interested stakeholders, and was intended to “focus on crafting Internet governance \\nprinciples and proposing a roadmap for the further evolution of the Internet governance \\necosystem.”73  \\n\\nThe outcome of NETmundial produced a nonbinding “NETmundial Multistakeholder \\nStatement”74 that set forth general Internet governance principles and identified issues to be \\ndiscussed at future meetings on the future evolution of Internet governance. According to the U.S. \\ngovernment delegation at NETmundial, the meeting outcome reaffirmed the multistakeholder \\nmodel of Internet governance, endorsed the transition of the U.S. government’s stewardship role \\nof IANA functions to the global multistakeholder community, emphasized the importance of \\nstrengthening and expanding upon the mandate of the Internet Governance Forum, and \\nunderscored the importance of human rights in the implementation of a free and open Internet.75  \\n\\n \\n                                                 \\n\\x0cInternet Governance and the Domain Name System: Issues for Congress \\n\\nNETmundial Initiative \\n\\nOn August 28, 2014, the creation of a NETmundial Initiative for Internet Governance \\nCooperation and Development was announced by the World Economic Forum in partnership with \\nICANN and other governmental, industry, academic, and civil society stakeholders. While having \\nno formal relationship with the April 2014 NETmundial summit held in Brazil, the purpose of the \\nNETmundial Initiative is “to apply the NETmundial Principles to solve issues in concrete ways to \\nenable an effective and distributed approach to Internet cooperation and governance.”76  \\n\\n2014 Plenipotentiary Conference in Busan \\n\\nThe ITU’s three-week Plenipotentiary Conference in Busan, Republic of Korea, concluded on \\nNovember 7, 2014. The purpose of the conference, which meets every four years, is to set ITU \\ngeneral policies, adopt four-year strategic and financial plans, and elect ITU officials. Prior to the \\nconference, the U.S. delegation (headed by the State Department) had concerns that some ITU \\nmembers would attempt to expand ITU’s role in Internet governance. In the view of the State \\nDepartment, the conference concluded successfully, with “the member states decid[ing] not to \\nexpand the ITU’s role in Internet governance or cybersecurity issues, accepting that many of \\nthose issues are outside of the mandate of the ITU.”77  \\n\\nWSIS+10 \\n\\nOn December 15-16, 2015, the United Nations General Assembly held a high-level meeting in \\nNew York to review the implementation of outcomes of the World Summit on the Information \\nSociety (WSIS). The meeting was preceded by an intergovernmental process that took into \\naccount inputs from all relevant WSIS stakeholders.78 During this process, some nations argued \\nfor an enhanced role for national governments in Internet governance and the internationalization \\nof ICANN and the domain name system.79 The WSIS+10 outcome document supported “the need \\nto promote greater participation and engagement in Internet governance discussions that should \\ninvolve governments, the private sector, civil society, international organizations, the technical \\nand academic communities, and all other relevant stakeholders.”80 The outcome document also \\nsupported the role of the Internet Governance Forum (IGF) and the General Assembly extended \\nthe IGF mandate for another 10 years. The U.S. government supported the WSIS+10 outcome, \\nstating that it “establishes a strong foundation for the next ten years, based on multi-stakeholder \\n\\n\\n \\n                                                                 \\n\\x0cInternet Governance and the Domain Name System: Issues for Congress \\n\\ncollaboration.”81 The United States further stated that “greater governmental control could allow \\nrepressive regimes to advance policies for censorship or content controls on the web – which is \\nanathema to what the Internet should be about.”82 \\n\\nInternet Governance and Terrorism \\n\\nIn the wake of recent terrorist attacks in Europe, and with ongoing concern over the use of the \\nInternet by terrorist organizations, the question has arisen whether Internet governance \\nmechanisms could be used to combat the use of the Internet by terrorist entities. Traditionally, \\nnation-states can govern the use and content of the Internet within their national boundaries and \\nmany have the authority, pursuant to their respective national laws, to monitor, block, and/or shut \\ndown websites within their borders.83 In some instances, these powers and actions have been \\ncontroversial when, for example, antiterrorism concerns may be used to justify censorship or the \\nsuppression of free speech on the Internet.84 \\n\\nOn an international level, governance of the Internet with respect to its content and use is \\nproblematic. As discussed earlier in this report, the Internet is decentralized and its functioning \\nrelies on the cooperation and participation by mostly private sector stakeholders around the \\nworld. As such, there is no international governance entity that currently has authority to remove \\nglobal Internet content used to promote terrorism. While there have been proposals to establish \\nsome level of authority over the Internet by the United Nations, these proposals have originated, \\nfor the most part, from regimes such as China, Russia, and Iran, and have been consistently \\nopposed by the United States and other Western nations who fear that increased United Nations \\nauthority over the Internet would ultimately support censorship and suppression of free speech.85 \\n\\nCould ICANN—a functioning model of nongovernmental multistakeholder Internet \\ngovernance—be deployed to restrict or limit the use of the global Internet by terrorist groups? \\nCurrently, ICANN administers the technological infrastructure of the Internet (domain names, \\nInternet protocol numbers and standards) and explicitly does not regulate Internet content. Any \\nattempt to change ICANN policy towards regulating Internet content would likely be strongly \\nopposed by most of the Internet stakeholders who administer and set policy for ICANN through a \\nconsensus process. \\n\\n \\n                                                 \\n\\x0cInternet Governance and the Domain Name System: Issues for Congress \\n\\nIssues for Congress \\nCongress plays an important role overseeing NTIA’s stewardship of the domain name system and \\nICANN. The House Committee on Energy and Commerce and the Senate Committee on \\nCommerce, Science, and Transportation have held numerous oversight hearings exploring \\nICANN’s performance in general, as well as specific DNS issues that arise (e.g., the proposed \\ngTLD expansion). Additionally, other committees, such as the House and Senate Judiciary \\nCommittees, maintain an interest in the DNS as it affects Internet policy issues such as \\nintellectual property, privacy, and cybercrime. Since 1997, congressional committees have held \\n40 hearings on the DNS and ICANN.86 \\nThe 114th Congress is likely to closely examine NTIA’s March 14, 2014, proposed transitioning \\nof its authority over ICANN and the DNS to a wholly multistakeholder-driven entity. Congress \\nwill consider whether the proposed transition is in the best interest of the United States and in the \\nbest interest of the Internet. As the transition plan is implemented by the Internet community and \\nevaluated by NTIA, Congress will likely monitor and evaluate that plan, and seek assurances that \\na DNS free of U.S. government stewardship will remain stable, secure, resilient, and open. As \\npart of its examination, Congress will likely continue assessing to what extent ongoing and future \\nintergovernmental telecommunications conferences constitute an opportunity for some nations to \\nincrease intergovernmental control over the Internet, and how effectively NTIA and other \\ngovernment agencies (such as the State Department) are working to counteract that threat.  \\n\\nFinally, the ongoing debate over Internet governance will likely have a significant impact on how \\nother aspects of the Internet may be governed in the future, especially in such areas as intellectual \\nproperty, privacy, law enforcement, Internet free speech, and cybersecurity. Looking forward, the \\ninstitutional nature of Internet governance could have far-reaching implications on important \\npolicy decisions that will likely shape the future evolution of the Internet.  \\n\\n \\n                                                 \\n\\x0cInternet Governance and the Domain Name System: Issues for Congress \\n\\nAppendix. ICANN Basics \\nICANN is a not-for-profit public benefit corporation headquartered in Los Angeles, CA, and \\nincorporated under the laws of the state of California. ICANN is organized under the California \\nNonprofit Public Benefit Law for charitable and public purposes, and as such, is subject to legal \\noversight by the California attorney general. ICANN has been granted tax-exempt status by the \\nfederal government and the state of California.87 \\n\\nICANN’s organizational structure consists of a Board of Directors (BOD) advised by a network \\nof supporting organizations and advisory committees that represent various Internet \\nconstituencies and interests (see Figure A-1). Policies are developed and issues are researched by \\nthese subgroups, who in turn advise the Board of Directors, which is responsible for making all \\nfinal policy and operational decisions. The Board of Directors consists of 16 international and \\ngeographically diverse members, composed of one president, eight members selected by a \\nNominating Committee, two selected by the Generic Names Supporting Organization, two \\nselected by the Address Supporting Organization, two selected by the Country-Code Names \\nSupporting Organization, and one selected by the At-Large Advisory Committee. Additionally, \\nthere are five nonvoting liaisons representing other advisory committees. \\n\\nThe explosive growth of the Internet and domain name registration, increasing responsibilities in \\nmanaging and operating the DNS, and the rollout of the new gTLD program has led to marked \\ngrowth of the ICANN budget, from revenues of about $6 million and a staff of 14 in 2000, to \\ntotal support and revenue of $162.9 million and a headcount of 382 budgeted for 2016.88 ICANN \\nhas been traditionally funded primarily through fees paid to ICANN by registrars and registry \\noperators. Registrars are companies (e.g., GoDaddy, Google, Network Solutions) with which \\nconsumers register domain names.89 Registry operators are companies and organizations that \\noperate and administer the master database of all domain names registered in each top level \\ndomain (for example VeriSign, Inc. operates .com and .net, Public Interest Registry operates .org, \\nand Neustar, Inc. operates .biz).90 ICANN also collects significant revenue from new gTLD \\napplication fees (an estimated $49.5 million in 2016). \\n\\n\\n \\n \\n   \\n \\n\\x0c', '6G Networks: Is This an Evolution or a Revolution?\\n\\nThe  lessons  learned  from  the  third \\n\\nindustrial  revolution  taught  us \\nthat the transformation from mechani-\\ncal  and  analog  technology  to  digital \\nelectronics  have  changed  the  world \\nonce  and  forever.  While  computers \\nand  communication  networks  have \\nbecome  the  new  oil  that  defines  the \\nwealth  of  countries,  research  and \\nindustrial  communities  have  been \\nthe  driving  forces  that  have  made \\nthis transition possible. In the future, \\nthe  same  communities  and  stake-\\nholders  are  required  to  enable  the \\ntransition to net-zero communication \\nnetworks.  With  reference  to  mobile \\ncommunications,  5G  is  an  evolution \\nfrom  all  previous  networks  with  the \\nadoption of new radio access technolo-\\ngies,  multisliced  architecture,  cloud-\\nnative and automation, and so on. By \\ndefinition, 5G is a network that adapts \\nto user needs and dynamic changes in \\ntraffic, designed to serve a new class of \\nusers:  “machines.”  Therefore,  latency \\nhas  become  a  critical  metric  in  5G. \\nLooking forward, 6G shall employ cell-\\nless  access  networks,  integrated  non-\\nterrestrial  networks, joint sensing and \\ncommunications,  new  spectrums \\nsuch as terahertz (THz) communica-\\ntions,  switching  from  traditional \\nchannel-based  design  paradigms  to \\ndesigning  channels  through  novel \\ntechnologies  such  as  intelligent \\nreconfigurable  surfaces,  open  inter-\\nfaces  that  interconnect  all  network \\n\\nDigital Object Identifier 10.1109/MVT.2021.3116995\\n\\nDate of current version: 2 December 2021\\n\\nfunctions,  end-to-end  orchestrators, \\nand,  most  noticeably,  artificial  intelli-\\ngence  (AI)  machines  that  govern  all \\nfunctional  modules  and  operational \\nservices.  The  various  network  func-\\ntions  generate  traces  of  various \\noperations  that  are  ingested  into \\ndatabases;  then  AI  will  leverage  this \\ndata  for  optimized  decisions  that  are \\nreflected  into  network  status  transi-\\ntions,  resource  utilization,  service \\nenhancement,  and  ultimately  lead  to \\nself-synthesizing networks. Built upon \\ncommercial  clouds,  6G  will  have  the \\nflexibility to scale and restructure for \\nmore resilient response to traffic fluc-\\ntuations  and  user  requirements.  To \\nthis  end,  cybersecurity  features  will \\nbecome an embedded part of network \\nfunctions  to  shield  the  network  ser-\\nvices  not  only  from  external  threats \\nbut  also  from  hosting  domains.  From \\nan  air  interface  perspective,  6G  will \\nintegrate  nonterrestrial  (space,  air, \\ndrone,  and  ocean)  communications \\ntechnologies  to  connect  and  route \\nnew users such as drones and coastal \\ntrading  vessels.  Furthermore,  future \\nwireless  networks  need  to  make  use \\nof  a  spectrum  that  extends  into  the \\noptical  spectrum  and  includes  the \\nTHz  range.  The  channel  becomes  a \\ncritical component due to the impact \\nof blockages and random orientations \\nat  these  frequencies.  Active  and  pas-\\nsive  intelligent  reflecting  surfaces \\n(IRSs) will become a new wireless sys-\\ntem  element  that  will  help  overcome \\nnew  challenges  related  to  coverage \\nand the propagation channel.\\n\\nThe evolution of mobile networks \\ncould  be  defined  by  the  continu-\\nous  improvement  and  integration \\nof  new  services  or  users.  However, \\nif  6G  became  an  intelligent  network \\nthat identified requirements, adapted \\nto  situations,  and  applied  self-con-\\nfiguration  for  sophisticated  actions \\nwithout  human  intervention,  would \\nthis be considered an evolution of new \\nnetwork infrastructure? In fact, this is \\na  revolution!  The  question  that  we \\nshould ask is, “Is such a network vi-\\nsion achievable in five to 10\\xa0years from \\nnow?”  The  answer  is  simple:  “It  is \\npossible.” Considering the massive in-\\nvestment and attention to AI, the mi-\\ngration of networks to the cloud, the \\nadoption of new service and integral \\ncomponents,  and  most  important-\\nly the  new  visions  for  a  network-\\nover-the-cloud, all of those enablers \\nwill allow a new network generation \\nthat connect humans through smart \\nmachines to be built. A smart 6G net-\\nwork will open the space for ground-\\nbreaking advancements in technology \\nand service management. 6G will \\nprovide  connectivity  to  new  verti-\\ncals and management to life-sup-\\nporting facilities at reduced power \\nconsumption  rates.  Therefore,  it  is \\nthe  time  to  think  about  standards \\nfor such networks, composed ele-\\nments,  key-performance  indicators, \\nand changes that may be brought \\nto  social  and  economic  domains. \\nIt  seems that this is not the time to \\nthink  about  evolution;  it  is  time  to \\nbe  bold  and  consider  revolutionary \\n\\n14 |||   \\n\\nIEEE VEHICULAR TECHNOLOGY MAGAZINE  |  DECEMBER 2021\\n\\nFrom the Guest editorsKlaus David, Anwer Al-Dulaimi, Harald Haas, and Rose Qingyang Hu \\n\\x0csteps to adapt to the rapidly chang-\\ning user demands.\\n\\nThis is the fourth special issue of \\nIEEE  Vehicular  Technology  Magazine \\ndedicated  to  6G  technologies,  and \\nthe third issue in the 6G series with \\nthe IEEE Future Networks Initiative. \\nThe  special  issues  will  cover  differ-\\nent technical areas to help research \\nand  industrial  communities  have  a \\nbetter understanding of the state of \\nthe art for 6G communications. This \\nspecial  issue  has  six  articles  that \\naddress  various  network  segments \\nand technologies.\\n\\nThe first article, “Slicing-Based \\nArtificial  Intelligence  Service  Provi-\\nsioning  on  the  Network  Edge,”  by  Li \\net al., addresses the AI service provi-\\nsioning  to  support  6G  edge  network \\nintelligence. The authors specify the \\nfeatures  and  requirements  for  AI  as \\nwell as the customized slicing for such \\nservices. The article also provides  a \\ntrace-driven  case  study  to  demon-\\nstrate  the  AI  service  performance \\nrequirements  via  flexibly  choosing \\nresource pooling policies.\\n\\nIn  the  second  article,  “Key  Tech-\\nnologies  in  6G  Terahertz  Wireless \\nCommunication  Systems:  A  Survey,” \\nWang et al. study the interesting THz \\ntechnologies and their potential in \\nfuture  6G  wireless  communication \\nsystems.  The  authors  conducted  a \\nsurvey for key technologies in 6G THz \\nwireless communication systems, \\nfocusing  on  THz  channel  modeling, \\nTHz multibeam antenna design, THz \\nfront-end chip design, THz baseband \\nsignal processing, and THz resource \\nmanagement.  The  article  presents \\nvarious performance analyses.\\n\\nIn the third article, “Cooperative \\nMultiterminal  Radar  and  Communi-\\ncation:  A  New  Paradigm  for  6G  Mo-\\nbile Networks,” Leyva et al. explore \\nthe new hitherto separate radar and \\ncommunication systems toward their \\namalgam known as a joint radar and \\ncommunication  system.  The  article \\nproposes  to  integrate  a  radio  sensing \\ncomponent  into  6G  considering  an \\nultradense  network  scenario.  The  au-\\nthors show that building such a system \\n\\nis  feasible  with  current  technologies \\nand will support high-resolution appli-\\ncations for next-generation networks.\\n\\nIn the fourth article, “Intelligent Re-\\nflecting  Surface-Aided  Vehicular  Net-\\nworks  Toward  6G:  Vision,  Proposal, \\nand Future Directions,” Zhu et al. an-\\nalyze  IRS,  considering the significant \\nimprovement in the power of needed \\nsignals at the receivers, especially that \\nIRS  has  no  energy  cost  and  easy  de-\\nployment. The authors show how the \\nIRS  can  improve  the  signal  transmis-\\nsions  between  vehicles  and  roadside \\nunits. The article provides interesting \\nanalysis and also open the discussion \\nfor more complex scenarios that could \\nbe  studied  in  the  future,  such  as  the \\nutilization of IRS resource in vehicular \\ncommunication systems.\\n\\nIn the fifth article, “Multicarrier- \\nDivision Duplex: A Duplexing Technique \\nfor the Shift to 6G Wireless Communi-\\ncations,” Li et al. show the advantages \\nof  multicarrier-division  duplex  (MDD) \\nover  the  in-band  full-duplex  (IBFD) \\nmode and the conventional half-duplex \\nmodes  of  frequency-division  duplex \\nand  time-division  duplex  from  several \\nessential  aspects,  including  self-inter-\\nference cancellation (SIC) techniques \\ncapability,  resource  integration,  and \\nthe support for high-mobility commu-\\nnications. This article provides many \\nnumerical  results  that  show  that \\nMDD  outperforms  IBFD  in  terms  of \\nenergy efficiency and SIC. The article \\nalso discusses some implementation \\nchallenges for MDD systems.\\n\\nThe  last  article,  “Directional \\nTerahertz  Communication  Systems \\nfor  6G:  Fact  Check:  A  Quantitative \\nLook,”  by  Boulogeorgos  et  al.,  de-\\nrives realistic values for the nee ded \\ndirectivity  to  establish  ultrabroad-\\nband  communication  links  at  THz \\nfrequencies  both  in  backhaul  and \\nfronthaul  scenarios.  The  authors \\nalso  study  the  impact  of  misalign-\\nment  on  practical  link  distances, \\nincorporating  reconfigurable  intel-\\nligent surfaces as a solution to over-\\ncome  blockage,  and  explored  the \\nimplications  on  the  physical  layer \\nsecurity of THz networks. The find-\\n\\nings of this article are supported by \\na detailed analysis for performance.\\n\\nAuthor Information\\nKlaus  David  (david@uni-kassel.de) \\nis  a  full  professor  and  head  of  com-\\nmunication technology at Kassel Uni-\\nversity,  Kassel,  34121,  Germany.  His \\nresearch  interests  include  mobile \\nnetworks,  applications,  context \\nawareness, and artificial intelligence. \\nHe  has  12  years  of  industrial  experi-\\nence at companies including HP, Bell \\nNorthern  Research,  IMEC,  T-Mobile, \\nand IHP, with five years of experience \\nin  the United  Kingdom,  Belgium,  the \\nUnited States, and Japan.\\n\\nAnwer  Al-Dulaimi  (anwer.al-dulai \\nmi@exfo.com)  is  a  technical  product \\nowner  in  the  Center  of  Excellence  at \\nEXFO, Montréal, QC H4S 0A4, Canada. \\nHe  received  his  Ph.D.  degree  in  elec-\\ntronic and computer engineering from \\nBrunel  University,  London,  in  2012 \\nafter receiving B.Sc. and M.Sc. honors \\ndegrees  in  communication  engineer-\\ning.  His  research  interests  include  5G \\nand  6G  networks,  cloud  computing, \\nvehicle-to-everything  technology,  and \\nthe Internet of Things.\\n\\nHarald  Haas  (harald.haas@ieee \\n.org)  is  a  distinguished  professor  at \\nthe University of Strathclyde, Glasgow, \\nG1 1XW, United Kingdom. His research \\ninterests include optical wireless com-\\nmunications  and  spatial  modulation, \\nwhich he introduced in 2006. He is the \\ninitiator  and  a  cofounder  of  pureLiFi \\nand  director  of  the  Light  Fidelity \\nResearch and Development Center.\\n\\nRose  Qingyang  Hu  (rose.hu@usu \\n.edu) is a full professor in the Depart-\\nment of Electrical and Computer Engi-\\nneering  at  Utah  State  University, \\nLogan, Utah, 84322, USA, where she is \\nthe associate dean of research for the \\nCollege  of  Engineering.  She  received \\nher Ph.D. degree in electrical engineer-\\ning  from  the  University  of  Kansas, \\nLawrence. She has more than 10 years \\nof R&D experience with Nortel, Black-\\nberry, and Intel as a technical manag-\\ner,  senior  research  scientist,  and \\nsenior wireless system architect.\\n\\nDECEMBER 2021  |  IEEE VEHICULAR TECHNOLOGY MAGAZINE \\n\\n||| 15 \\n\\n \\n \\n\\x0c', '2019 IEEE/ACM 2nd International Workshop on Establishing the Community-Wide Infrastructure for Architecture-Based\\nSoftware Engineering (ECASE)\\n\\nA Multidisciplinary Approach to Developing\\nCommunity-based Research Infrastructure\\n\\nBetty H.C. Cheng\\nDepartment of Computer Science and Engineering\\nMichigan State University\\nEast Lansing, Michigan, USA\\nchengb@cse.msu.edu\\n\\ndustry. Her collaborators include Ford, General Motors, ZF,\\nBAE, Motorola, and Siemens. Previously, she was awarded\\na NASA/JPL Faculty Fellowship to investigate the use of\\nnew software engineering techniques for a portion of the\\nNASA space shuttle software. She has recently launched\\nnew projects in the areas of model-driven approaches to\\nsustainability, cyber security for automotive systems, and\\nfeature interaction detection and mitigation for autonomic\\nsystems, all in the context of operating under uncertainty\\nwhile maintaining assurance objectives. Her research has\\nbeen funded by several federal funding agencies, including\\nNSF, AFRL, ONR, DARPA, NASA, ARO, and numerous\\nindustrial organizations. She serves on the journal editorial\\nboards for Requirements Engineering and Software and\\nSystems Modeling; she is Co-Associate Editor-in-Chief for\\nIEEE Transactions for Software Engineering, where she\\npreviously served twice as an Associate Editor. She was\\nthe Technical Program Co-Chair for IEEE International\\nConference on Software Engineering (ICSE-2013).\\n\\nShe received her Bachelor of Science degree from North-\\nwestern University, and her MS and PhD from the University\\nof Illinois-Urbana Champaign, all in computer science.\\n\\nACKNOWLEDGMENTS\\n\\nWe are extremely grateful to the numerous undergraduate\\nand graduate students, academic and industrial collaborators,\\nas well as federal funding agencies who have all contributed\\nto the successful efforts described in the presentation. The\\nwork described in this work has been supported in part by\\ngrants from NSF (CNS-1305358 and DBI-0939454), NASA,\\nUSDA, AFRL, ONR, and numerous industrial collaborators.\\nThe views and conclusions contained herein are those of\\nthe author and should not be interpreted as necessarily\\nrepresenting the ofﬁcial policies or endorsements, either\\nexpressed or implied, of Air Force Research Laboratory\\n(AFRL), the U.S. Government, NSF, NASA, USDA, ONR,\\nMichigan State University, or other research sponsors.\\n\\nAbstract—Increasingly, computing-based technology appears\\nto transcend major aspects of our daily lives, from providing\\nconveniences (e.g., in-vehicle navigation services) to life-critical\\nservices (e.g., medical diagnostics and treatment). As computing\\ninfrastructure moves from supporting specialized computing\\nneeds and users, such as an electrical engineer designing a\\nspeciﬁc electronic circuit versus a policy analyst determining\\nhow to prepare costing and resource management models for a\\nsmart grid system, the range of supporting expertise broadens\\nand cross-cuts multiple disciplines. This talk will overview\\npersonal experiences for three community-based research in-\\nfrastructure development efforts that span almost three decades\\nof activities, each involving hundreds of participants, multiple\\norganizations and stakeholder communities, and multidisci-\\nplinary collaborations. We highlight common qualities that\\nmotivated a multidisciplinary approach to all three efforts. We\\ndiscuss lessons learned and highlight challenges to be overcome\\nas future community-based research infrastructures will neces-\\nsarily need to support increasingly broader stakeholder needs,\\nmuch of which will demand resilience and trust, even in the\\nface of uncertainty and cybersecurity threats.\\n\\nKeywords-community-based research infrastructure, multi-\\ndisciplinary collaborations, stakeholders, resilience, uncertainty\\n\\nBIOGRAPHICAL SKETCH\\n\\nBetty H.C. Cheng is a professor in the Department\\nof Computer Science and Engineering at Michigan State\\nUniversity. She is also the Industrial Relations Manager\\nand senior researcher for BEACON, the National Science\\nFoundation Science and Technology Center in the area of\\nEvolution in Action. Her research interests include self-\\nadaptive autonomous systems, requirements engineering,\\nmodel-driven engineering, automated software engineering,\\nand harnessing evolutionary computation and search-based\\ntechniques to address software engineering problems. These\\nresearch areas are used to support the development of high-\\nassurance adaptive systems that must continuously deliver\\nacceptable behavior, even in the face of environmental and\\nsystem uncertainty. Example applications include intelligent\\ntransportation and vehicle systems. She collaborates exten-\\nsively with industrial partners in her research projects in\\norder to ensure real-world relevance of her research and\\nto facilitate technology exchange between academia and in-\\n\\n978-1-7281-2241-0/19/$31.00 ©2019 IEEE\\nDOI 10.1109/ECASE.2019.00008\\n\\n1\\n\\nAuthorized licensed use limited to: Ryerson University Library. Downloaded on May 06,2022 at 16:20:53 UTC from IEEE Xplore.  Restrictions apply. \\n\\n\\x0c', 'EDPACS\\nThe EDP Audit, Control, and Security Newsletter\\n\\nISSN: 0736-6981 (Print) 1936-1009 (Online) Journal homepage: https://www.tandfonline.com/loi/uedp20\\n\\nArming Organizations to Detect and Respond to\\nStealthy APTS\\n\\nRobin “Montana“ Williams\\n\\nTo cite this article: Robin “Montana“ Williams (2016) Arming Organizations to Detect and Respond\\nto Stealthy APTS, EDPACS, 53:5, 7-13, DOI: 10.1080/07366981.2016.1160716\\n\\nTo link to this article:  https://doi.org/10.1080/07366981.2016.1160716\\n\\nPublished online: 11 May 2016.\\n\\nSubmit your article to this journal \\n\\nArticle views: 91\\n\\nView related articles \\n\\nView Crossmark data\\n\\nFull Terms & Conditions of access and use can be found at\\nhttps://www.tandfonline.com/action/journalInformation?journalCode=uedp20\\n\\n\\x0c2016\\n\\nE D P A C S\\n\\nARMING ORGANIZATIONS\\nTO DETECT AND RESPOND TO\\nSTEALTHY APTS\\n\\nROBIN “MONTANA“ WILLIAMS\\n\\nAbstract. In today’s digital dependent world, organizations struggle to mitigate\\na stealthy, well-resourced, and tenacious advanced persistent threat (APT)\\nattacks by nefarious actors, organizations, and even nation-states with intent\\non gaining a foothold into an organization’s IT infrastructure. This onslaught of\\nadvanced attacks requires far more than baseline security practices. While most\\nsecurity professionals are APT-aware, many lack the experience, requisite\\nskills, and the ability to integrate technology to counter APT attacks. The\\nproblem is exacerbated by a widening cybersecurity skills gap. Recent research\\nby ISACA, the world’s largest information security professional association,\\nreported more than 60% of applicants for entry level cybersecurity positions\\nlack the skill and ability to perform the tasks associated with their potential new\\nroles. Success against the APT is predicated on insight into APT attack stages and\\nthe integration of technology to enable organizational resilience; however, this is\\nnot possible in organizations do not have the workforce with the requisite\\nknowledge, skills, and abilities to perform the technical tasks related to their\\nfunctional roles. This article addresses a customized response strategy executed\\nby a skilled workforce that mitigates and even counters attacks. The strategy\\nrecommends that a coordinated response based on organization risk\\nmanagement policies be implemented. In addition, it requires organizational\\ninsight into their information assets, control of administrator privileges,\\nimplementation of sound network segregation architecture, and a commitment\\nto a balanced vulnerability management program. It is critical that a further\\ndiscussion occur to outline skills acquisition based on skills-based training and\\nperformance-based assessments.\\n\\nMitigating a sophisticated advanced persistent threat (APT)\\n\\nattack by a stealthy, well-resourced, well-researched and dogged\\nadversary intent on gaining a foothold into your organization’s IT\\ninfrastructure requires far more than baseline security practices.\\nIt demands specialist security skills, state-of-the-art security tech-\\nnology, intelligence-led risk assessments, skills-based education\\nof staff, vigilant, round-the-clock network monitoring, and cut-\\nting-edge forensic analysis skills.\\n\\nMost security professionals are familiar with many of these but\\ngenerally lack the experience, skill and technology needed to\\ncounter an APT attack. That is because APTs are not ordinary\\nattacks. Attackers use multiple attack vectors, including cyber,\\nphysical and deception, to establish and extend IT infrastructure\\nfootholds to exfiltrate information, undermine or impede critical\\naspects of a mission, program or organization; or position them-\\nselves to carry out these objectives in the future.\\n\\nULTIMATE CYBER THREATS\\n\\nOften concealed within an enterprise’s network traffic, APT\\nattackers interact just enough to achieve their goals. Able to hide\\n\\nª Copyright 2016 Taylor & Francis—All rights reserved.\\n\\n\\x0cE D P A C S\\n\\n2016\\n\\nand morph when needed, APTs can cripple security professionals’\\nattempts to identify or stop them.\\n\\nBefore launching an APT, an attacker thoroughly researches the\\nmarketplace to determine precisely which companies, government\\ndepartments, suppliers or institutions are of most\\ninterest.\\nProfessional APT attacks are rarely opportunistic or random. They\\nare designed to steal identified intellectual assets for the purposes of\\ndata theft, extortion, commercial advantage or even cyberwarfare.\\nUnlike traditional attackers, APT attackers tenaciously pursue\\nobjectives over an extended period of time, adapt to defenders’\\nefforts to resist, and are determined to maintain the level of inter-\\naction needed to execute their objectives. They keep at it until they\\nsucceed—or until the attacks are mitigated and removed.\\n\\nTHREATS EVOLVING WITH SECURITY\\n\\nMany preventive controls have emerged to make it more difficult\\nfor attackers to penetrate networks. Detective controls help iden-\\ntify breaches more quickly. Still, some attacks are difficult to\\nspot, presenting major questions to chief security officers,\\nincluding:\\n\\n● How can one tell if an attack has taken place?\\n● How does one assess the damage of a long-running intrusion?\\n● What evidence can be gathered if audit trails have been\\n\\nchanged?\\n\\n● How does one know when an infection has been completely\\n\\neradicated?\\n\\nThe questions are hard to answer and require a holistic approach\\nto APTs.\\n\\nAs technology changes and information security tools evolve, so\\ntoo do the tactics, techniques and procedures of threat actors. Social\\nengineering remains a key APT ploy for gaining footholds into\\ninformation systems. Early efforts began with phishing, evolved\\nto spear phishing, and then to whaling, which often includes an\\nattachment or a link that contains malware or an exploit.\\n\\nToday, more security professionals are aware of APTs and are\\nmaking positive changes to defend against them, according to a\\nrecent survey by global IT and cybersecurity association ISACA.\\nCybersecurity professionals seem to be practicing good security\\nmanagement by using a risk-based approach to managing APTs\\nwithin their enterprises. However, a gap in the understanding of\\nwhat APTs are and how to defend against\\nthem remains.\\nEnterprises have not changed how they protect against APTs.\\nThe technical controls they use to combat APTs—firewalls, access\\nlists within routers, anti-malware and antivirus—are helpful\\nagainst traditional attacks, but not against APTs.\\n\\nIn recent years APTs have moved to the Internet as the main\\nattack vector (e.g., web sites, social media and mobile applica-\\ntions). Watering hole (fake web site) attacks have increased and\\noften use a browser-based, zero-day attack.\\nIn fact, recent\\nreports by leading cybersecurity experts have found that web-\\nbased attacks outnumber email-based attacks nearly five to one.\\n\\n8\\n\\nª Copyright 2016 Taylor & Francis—All rights reserved.\\n\\n\\x0c2016\\n\\nE D P A C S\\n\\nWeb applications and point-of-sale systems are leading hacker\\ntargets.\\n\\nCYBERSECURITY SKILLS GAP HINDERS FIGHT\\n\\nEfforts to stay ahead of cybercriminals and APTs are hurt by a\\nskills gap in the information security workforce. Current practi-\\ntioners often lack the requisite skills to leverage the technology;\\nunderstand the threat; and integrate cybersecurity risk manage-\\nment strategies, tools and policies to defend against an APT.\\nAwareness of the existing skills gap is highlighted in the 2016\\nState of Cybersecurity Survey conducted by ISACA and RSA\\nConference—60 percent of all respondents do not believe their\\ninformation security staff can handle anything more than simple\\ncybersecurity incidents. Incident handling is slowed by the exist-\\ning skills shortage. Organizations struggle to find qualified per-\\nsonnel with the requisite skills to perform cybersecurity\\nfunctional roles, with 59 percent of respondents reporting that\\nfewer than half of the job candidates their organizations reviewed\\nwere considered “qualified upon hire.” This demands a paradigm\\nshift; the skills gap can only be closed by changing the training\\nand certification process for cybersecurity professionals around\\nthe world. Such a shift is possible through the development of\\npractitioners with the requisite skills to perform low-density,\\nhigh-demand technical\\ncybersecurity practitioner roles. To\\ndevelop and evolve these perishable hands-on skills, training\\nmust move from a solely knowledge-based foundation to a skills\\n(experiential) training and performance-based certification pro-\\ncess. Programs such as ISACA’s Cybersecurity Nexus (CSX) pro-\\nvide the environment for the development and measurement of\\nrequisite skills that can address APT-related incidents.\\n\\nDETECTING, COUNTERING APT ATTACKS\\n\\nA full spectrum of security controls is required to prevent, detect\\nand respond effectively to APT attacks. Additional measures are\\nneeded to eradicate the infection. Mature enterprises have many\\nnecessary controls already in place but some new controls and\\nprocesses may be needed. Many existing controls and processes\\nalso will need to be extended or strengthened to effectively miti-\\ngate the risk.\\n\\nNo single countermeasure can guarantee successful prevention,\\ndetection or eradication of an APT infection. The solution lies in\\ncombining tighter physical, technical, educational and operational\\nmeasures with a coordinated security management system.\\n\\nKey capabilities needed to better detect an APT attack include:\\n\\n● Understand what to look for.\\n● Know where and when to look.\\n● Differentiate APT activity from normal behavior.\\n● Have access to the skills and tools needed to detect and isolate\\n\\nAPT malware.\\n\\nª Copyright 2016 Taylor & Francis—All rights reserved.\\n\\n9\\n\\n\\x0cE D P A C S\\n\\n2016\\n\\nA CUSTOMIZED RESPONSE\\n\\nCombating APTs requires specialist skills because attacks are\\noften tailored to exploit the victim’s perceived weaknesses.\\nAttacks cannot be matched by general policies, baseline controls\\nand off-the-shelf products. A customized response is needed, sup-\\nported by a high degree of creativity and improvisation. This\\nrequires the development or recruitment of specialist skills,\\nsourced from within or through an external support service.\\n\\nAPT victims typically exhibit numerous security weaknesses, but\\nAPT attackers have weaknesses, too. No attack is perfect or com-\\npletely invisible. However sophisticated in their ability to hide\\nthrough disguise, code obfuscation or use of different attack vectors,\\nAPTs will still have recognizable signs and occasional weaknesses.\\nAn experienced security analyst with a good set of tools will even-\\ntually detect, deflect and eradicate even the most sophisticated\\nintrusion.\\n\\nAPT SECURITY PRINCIPLES/MEASURES\\n\\nPreventing and detecting APT attacks requires the use of many\\nindividual security principles/measures, including:\\n\\nCoordinated Risk Assessment and Response: Coordinating\\nactions across multiple business units, service functions, informa-\\ntion systems, infrastructure and supply chains poses a major\\nchallenge for managing APT risk response. The solution is to\\nassign specific responsibilities for assessing risk and coordinating\\nthe response. This requires executive board approval to cut\\nacross management reporting lines.\\n\\nAsset Management: Hardware/software assets need to be\\nidentified, recorded and managed for accounting and security\\npurposes, and to detail ownership/configuration status. This is\\nessential for developing an infrastructure free of vulnerabilities\\nand understanding the security posture of platforms and devices.\\nAdministrator Privileges: It is especially important to mini-\\nmize the number of users with administrator rights to critical\\napplications, servers and client devices. APT attackers seek\\nadministrator access to gain full control of platforms and applica-\\ntions and bury malware inside operating system kernels. Client\\ndevices can still be compromised, for example, through a drive-by\\ndownload, but it will be more difficult to hide malware and\\nbroaden the attack scope.\\n\\nNetwork Segregation: The easier it is to establish relationships\\nand access remote resources, the simpler it is for an intruder to\\nsteal information and sabotage services. Networks containing\\nsensitive, valuable or business-critical data must be segregated.\\nLarge enterprise networks should be divided into separate logical\\nnetwork domains, each protected by a defined security perimeter.\\nPolice boundaries between network domains with secure gate-\\nways, such as firewalls, to filter and direct traffic.\\n\\nEnsure that servers with highly sensitive or critical data cannot\\nfreely conduct data transfers to external locations to prevent a\\nTrojan horse from exporting data to a remote attacker. External\\ntransfers should be subject to strict rules and controls. Network\\nsegregation is the one control, above all, that will help mitigate\\n\\n10\\n\\nª Copyright 2016 Taylor & Francis—All rights reserved.\\n\\n\\x0c2016\\n\\nE D P A C S\\n\\nAPT attacks. Many enterprise networks, however, have insuffi-\\ncient segregation to safeguard critical data and processes.\\n\\nVulnerability Management: The process of identifying, prior-\\nitizing and mitigating known security weaknesses in information\\nsystems and platforms. At its simplest, it involves staying up to\\ndate with critical security patches to software systems and anti-\\nvirus definitions. This is crucial for platforms running critical\\nproduction systems that need to be available 24/7.\\n\\nAlthough APT attacks can incorporate zero-day exploits, many\\nrely on known vulnerabilities to infect systems, so it is vital that\\nall platforms are patched quickly. Many enterprises take too long\\nto implement critical patches, often days, weeks or even months.\\nSystems containing known vulnerabilities need to be shielded\\n(e.g., by a firewall) from the risk of external connections.\\n\\nUser Education: Most enterprises offer some security educa-\\ntion and awareness training for IT users but it is typically insuffi-\\ncient to mitigate well-researched social engineering attacks. The\\nscope, intensity and sophistication of education programs must be\\nexpanded, focusing on managers and other likely targets.\\n\\nATTACK STAGES: TIPS TO PREVENT AND MITIGATE\\nAPTS\\n\\nDifferent attack stages call for different methods of preventing\\nand mitigating APTs. Here is a quick rundown of the APT attack\\nstages and corresponding prevention/mitigation tips:\\n\\nTarget Selection and Research Stage: Avoid unnecessary pub-\\nlicity for secret research, product developments or contract nego-\\ntiations. Avoid publication of personal contact details for key staff\\nlikely to be targeted by APT actors. Train staff to report suspi-\\ncious or abnormal inquiries. Brief staff on conducting web analy-\\ntics for signs of attack research.\\n\\nTarget Penetration Stage: Train staff to be alert to suspicious\\nemail. Continuously scan Internet-facing platforms for vulnerabil-\\nities. Install an intrusion prevention system (IPS). Use sandbox\\nsimulation to identify incoming malicious programs. Maintain up-\\nto-date anti-malware and intrusion detection systems (IDSs).\\n\\nCommand and Control Stage: Ensure that critical network\\nareas have adequate segregation. Log and inspect domain name\\nserver (DNS) traffic. Scan incoming network traffic for known\\ncommand and control protocols and application program interface\\n(API) patterns. Block identified command and control protocols\\nand all outgoing traffic at the perimeter, except traffic explicitly\\nrequired to support the business.\\n\\nTarget Discovery Stage: Implement strict network security poli-\\ncies to limit access to critical servers. Examine audit logs for evidence\\nof suspicious scans and browsing. Establish an internal network\\nsurveillance capability (e.g., an internal IDS system). Set up a honey-\\npot to attract the attacker. Tighten network security controls (e.g.,\\nclose unused ports). Review audit logs to establish extent of intrusion.\\nData Exfiltration Stage: Configure network to prevent data\\nexfiltration from critical servers. Investigate suspicious data\\ntransfers (e.g., outside of regular hours). Install a data leak\\n\\nª Copyright 2016 Taylor & Francis—All rights reserved.\\n\\n11\\n\\n\\x0cE D P A C S\\n\\n2016\\n\\nprevention (DLP) system. Block unauthorized data transfers to\\nunknown locations.\\n\\nIntelligence Dissemination and Exploitation Stage: Ensure\\nthat trade secrets have legal protection. Look for signs of exploi-\\ntation, such as unexpected failures to win contracts or announce-\\nments of rival products with similarities to company designs.\\nConsult national security agencies.\\n\\nTECHNOLOGY TO MITIGATE APT ATTACKS\\n\\nNumerous security technologies have been developed over the last\\ntwo decades to prevent or detect malicious intrusions. Many scan,\\nfilter or block incoming or outgoing communications. Over the\\nyears, technologies have become more intelligent and sophisti-\\ncated, digging deeper into packet content, assembling them into\\nstreams of activity, understanding malicious behavior patterns\\nand executing any attached code in safe sandbox areas.\\n\\nThere are many scanning and filtering tools available, operating\\nat different levels in the communications protocol stack with an\\narray of detection techniques. No single security technology can\\nprevent or detect all APTs. A defense-in-depth approach, exploiting\\nas many inspection layers as can be afforded and managed, will\\nhelp mitigate risk. Combined with procedural and personal con-\\ntrols, the approach can reduce APT risk to an acceptable level.\\n\\nMany security appliances combine several technologies in a\\nsingle device. Enterprises can buy a multifunctional product,\\nselect separate ”best of breed” devices, or purchase a range of\\ncompatible technologies from a single vendor.\\n\\nThese technologies include:\\n\\n● Advanced\\n\\n● Basic Security Technology Measures: Antivirus, intrusion\\ndetection, firewalls, penetration testing, strong authentication\\nIntrusion\\nprevention, data leak prevention, vulnerability scanning,\\nsandbox simulation, database activity monitoring, and\\napplication security test\\n\\nTechnology Measures:\\n\\nSecurity\\n\\n● Specific APT Countermeasures: Deep packet\\n\\ninspection,\\ncommunications pattern matching, file integrity monitoring,\\nsecurity configuration management, security information and\\nevent management\\n\\n● Best Available Security Technology Practices: Trusted\\ninspections, application whitelisting,\\n\\ncomputing,\\nhoneypots, systems development life cycle\\n\\nforensic\\n\\nAPTs and the attackers who attempt to launch them are by far the\\nmost difficult for cybersecurity professionals to counter. Their\\nlevel of sophistication and persistence, as well as their stealth,\\nmake them much more dangerous than your run of the mill threat.\\nOrganizations need to dramatically expand the skills of their infor-\\nmation security teams to begin dealing with APTs effectively.\\n\\nRobin “Montana” Williams, MA-IOP, CWDP,\\nis ISACA’s Senior Manager,\\nCybersecurity Practices, Public Sector Business Development Executive, &\\nCyber Evangelist. He executes an intradepartmental cross functioning\\n\\n12\\n\\nª Copyright 2016 Taylor & Francis—All rights reserved.\\n\\n\\x0c2016\\n\\nE D P A C S\\n\\ncybersecurity and risk management strategy to focus delivery of information\\nsecurity products globally, to include ISACA’s Cybersecurity Nexus program–\\nthe industry’s first performance-based certification and professional develop-\\nment program. In addition, he was recalled by the White House staff to co-chair\\nthe Training and Certification Sub-Working Group for the National Initiative for\\nCybersecurity Education (NICE). Finally, he currently serves as an adjunct\\nprofessor at California State University-San Bernardino. Prior, Mr. Williams\\nserved as Chief, Cybersecurity Education & Awareness Branch at the\\nDepartment of Homeland Security & senior strategic advisor to the White\\nHouse on the National Initiative for Cybersecurity Education (NICE), his team\\ncreated the National Cybersecurity Workforce Framework, built the Federal\\nVirtual Training Environment, developed the National\\nInitiative for\\nCybersecurity Careers and Studies Portal, & led National Cybersecurity\\nAwareness Month. He has over 25 years’ experience in military operations,\\nintelligence, cybersecurity, & workforce development, including commanding\\nthe USAF Cyber Red Team. Currently a doctoral candidate in Industrial-\\nOrganizational Psychologist & Certified Workforce Development Professional,\\nhe is a globally recognized expert in cyber resiliency & human factors related to\\ncybersecurity incidents. He can be reached at mwilliams@isaca.org.\\n\\nª Copyright 2016 Taylor & Francis—All rights reserved.\\n\\n13\\n\\n\\x0c', 'computer law & security review 41 (2021) 105502 \\n\\nAvailable online at www.sciencedirect.com \\n\\njournal homepage: www.elsevier.com/locate/CLSR \\n\\nComment \\n\\nThe regulatory framework for the protection of \\ncritical infrastructures against cyberthreats: \\nIdentifying shortcomings and addressing future \\nchallenges: The case of the health sector in \\nparticular \\n\\nDimitra Markopoulou \\n\\n∗, Vagelis Papakonstantinou \\n\\nFaculty of Law & Criminology, Vrije Universiteit Brussel (LSTS), Pleinlaan 2, 1050 Brussels, Belgium \\n\\na b s t r a c t \\n\\nThe concept of “Critical Infrastructures” is constantly evolving in order to reflect current concerns and to respond to new challenges, es- \\npecially in terms of (cyber)security and resilience. Protection of critical infrastructures against numerous threats has therefore developed \\ninto a high priority at national and EU level. During the last two decades a new type of threat has prevailed in the Critical Infrastructure \\nthreat landscape, that of cyberattacks; Protection against them is the primary focus of this paper. In order to do so the analysis first aims \\nto drop some light into the differences between Critical Infrastructures and Critical Information Infrastructures, terms that are often \\nconfused, and to indicate possible inadequacies in the applicable protection regulatory regime. Finally, the health sector has been chosen \\nas a sector-specific case in an effort to demonstrate how protection of a Critical Infrastructure, challenged as it has been with a constantly \\nincreasing number of cyber incidents, could be sufficiently protected in the new digitalised era. \\n\\n© 2021 The Authors. Published by Elsevier Ltd. \\nThis is an open access article under the CC BY license ( http://creativecommons.org/licenses/by/4.0/ ) \\n\\n1. \\n\\nIntroduction \\n\\nThe concept of “Critical Infrastructures” is constantly evolv- \\ning in order to reflect current concerns and to respond to new \\nchallenges, especially in terms of security and resilience. At \\nthe same time, over the last decades, the number and va- \\nriety of Critical Infrastructures have increased significantly, \\nwhereas their protection against numerous threats and the \\nsafeguarding of their uninterrupted operation has developed \\n\\ninto a high priority at national and EU level. Disruption or de- \\nstruction of their operation may be the result of natural dis- \\nasters (earthquakes, floods), mechanical failures, poor design \\nand human actions ranging from a simple theft or arson to \\na terrorist attack. Operators of Critical Infrastructures, both \\npublic and private entities, have, over the years, taken mea- \\nsures to protect their Critical Infrastructures against different \\ntypes of attacks. The complexity of the attacks and the vulner- \\nabilities of the infrastructures, however, indicate the need for \\nconstant alert from both operators and governments in order \\n\\n∗ Corresponding author. \\n\\nE-mail addresses: Dimitra.Markopoulou@vub.be (D. Markopoulou), Evangelos.Papakonstantinou@vub.be (V. Papakonstantinou). \\n\\nhttps://doi.org/10.1016/j.clsr.2020.105502 \\n0267-3649/© 2021 The Authors. Published by Elsevier Ltd. This is an open access article under the CC BY license \\n( http://creativecommons.org/licenses/by/4.0/ ) \\n\\n\\x0c2 \\n\\ncomputer law & security review 41 (2021) 105502 \\n\\nto develop and implement updated policies for the protection \\nof their Critical Infrastructures.1 \\n\\nThe 9/11 terrorist attacks demonstrated the vulnerability \\nof the USA’s Critical Infrastructures to the threat posed by \\na terrorist attack of this magnitude. The catastrophic conse- \\nquences that these attacks had in the operation of Critical \\nInfrastructures and the provision of critical services resulted \\nto the birth of Critical Infrastructure protection as a distinc- \\ntive policy area in the US and provided significant motivation \\nto all stakeholders worldwide to review their Critical Infras- \\ntructures Protection policies in order to strengthen the ex- \\nisting instruments. It was the 9/11 attacks that attributed a \\nnational security element to the definition of critical infras- \\ntructures, taking it a step forward from the traditional pub- \\nlic sector approach. At European level, the first coordinated \\nsteps to this direction were made in 2004, following the ter- \\nrorist attacks in Madrid, when the Commission published its \\nCommunication on Critical Infrastructure Protection in the \\nfight against terrorism,2 \\nfollowed by the release in 2006 of \\nthe first European Programme for the Protection of Critical \\nInfrastructure.3 \\n\\nDuring the last two decades a new type of threat has pre- \\nvailed in the Critical Infrastructure threat landscape, that of \\ncyberattacks. Recent years have seen a dramatic increase in \\nthe volume of cyber threats, as well as a diversity in both their \\nnature and complexity. This new enemy brought to the sur- \\nface the need to protect the Information and Communica- \\ntion Technologies (ICT) that constitute the backbone of Crit- \\nical Infrastructures.4 \\nThe term used, when referring to these \\nunderlying systems and technologies is “Critical Information \\nInfrastructure”. Either as direct targets of a cyber threat or as \\na vehicle used by the cyber offender in order to reach the fi- \\nnal targets, namely the Critical Infrastructure itself, Informa- \\ntion and Communication Technologies constitute a vulnera- \\nble target. Safeguarding the uninterrupted operation of these \\nsystems and technologies is crucial for the uninterrupted op- \\neration of the Critical Infrastructures they support. Therefore, \\ntheir protection, their availability and resilience against any \\nkind of threats, has been placed in the centre of national and \\nEU interest. \\n\\nThe first part of this paper examines the differences be- \\ntween Critical Infrastructures and Critical Information Infras- \\ntructures. The two terms appear, in many cases, to be used in- \\nterchangeably despite their conceptual and actual differences. \\nThe EU applicable regulatory framework for the protection of \\nCritical Infrastructure and Critical Information Infrastructure \\nwill also be addressed in this analysis. Even though the current \\n\\nprotection regime adopts an “against all-hazards approach”, \\nthis paper focuses on the protection of the infrastructures \\nagainst cyber threats and examines the effectiveness of the \\nexisting regulatory measures. Findings of the above analysis \\nare subsequently exemplified in the second part of this pa- \\nper while focusing on a specific field, that of the health sector. \\nThe health sector has been identified as one of the most im- \\nportant Critical Infrastructures, that has also been the target \\nof a continuously increasing number of cyber incidents. Con- \\nsequently, an assessment of its regulatory framework with an \\nemphasis on security-related matters is expected to demon- \\nstrate in practice how specific measures and EU legislation \\non Critical Infrastructures apply in practice and help mitigate \\never-increasing cyber threats. \\n\\nThe distinction between critical \\n\\n2. \\ninfrastructure (CI) and critical information \\ninfrastructure (CII): The role of industrial control \\nsystems (ICS) \\n\\nDefining critical infrastructures: What does “critical”\\n\\n2.1. \\nmean? \\n\\nWhat do we mean by “Critical Infrastructures”? An official in- \\ntroduction to the term was made by the Commission in its \\nCommunication on Critical Infrastructure Protection in the \\nfight against terrorism that was published in 2004 : 5 \\n“Criti- \\ncal infrastructures consist of those physical and information tech- \\nnology facilities, networks, services and assets which, if disrupted \\nor destroyed, would have a serious impact on the health, safety, \\nsecurity or economic well-being of citizens or the effective func- \\ntioning of governments in the Member States. Critical infrastruc- \\ntures extend across many sectors of the economy, including bank- \\ning and finance, transport and distribution, energy, utilities, health, \\nfood supply and communications, as well as key government ser- \\nvices ”. Following the Commission’s Communication, similar \\ndefinitions on CIs may be found in different EU documents, \\nall of which follow the same pattern. The definition that pre- \\nvailed, however, and is used broadly until today, is the one \\nincluded in the Council Directive 2008/114/EC 6 \\n: “critical infras- \\ntructure means an asset, system or part thereof located in Member \\nStates which is essential for the maintenance of vital societal func- \\ntions, health, safety, security, economic or social well-being of people, \\nand the disruption or destruction of which would have a significant \\nimpact in a Member State as a result of the failure to maintain those \\nfunctions ”. \\n\\nA close look at the definitions provided above indicates \\nthat the characterisation of an infrastructure as “critical” is \\nsubjective and rests, to a large extent, to the Member State \\nthat suffers the consequences of a CI’s failure. What there- \\nfore constitutes a CI in a Member State, may not be iden- \\ntified as such in another one, since not all sectors are rele- \\nvant for all countries. Furthermore, based on the special char- \\n\\n\\n3 \\n\\nacteristics of each country, the list may need to be enriched \\nwith new sectors. While this divergence is justified, the free- \\ndom afforded to Member States entails a risk that ranges from \\noverregulating sectors that do not need additional protection, \\nwith any inflexibility that this may cause, to underregulating \\nothers, where stricter security requirements would be critical \\nfor the continuity of their operation. The introduction there- \\nfore of some EU-wide standards and of a CI identification pro- \\ncess that would be used as a guide by all Member States was \\ndeemed necessary.7 \\n\\nIn this context the most frequently listed examples of CIs \\nin EU documents, with some variations in terminology, en- \\ncompass the sectors of banking and finance, government ser- \\nvices, telecommunication and information and communica- \\ntion technologies, emergency and rescue services, energy and \\nelectricity, health services, transportation, logistics and distri- \\nbution, and water supply. The list is, however, indicative. As re- \\ngards the next step, namely the identification and designation \\nby Member States of specific national CIs within their territo- \\nries, guidelines are provided in order to achieve uniformity at \\nEU level to the greatest extent possible. Therefore, each Mem- \\nber State must do so based on national predefined criteria, \\nwhich however must be developed with minimum require- \\nments in mind as these are included in official EU guidance. \\nThe Commission’s Communication on a European Programme \\nfor Critical Infrastructure Protection, for instance, suggests the \\napplication of qualitative and quantitative effects of the dis- \\nruption or destruction of a particular infrastructure as indica- \\ntive for its characterisation as “Critical”: The scope (mean- \\ning the extent of the geographic area which could be affected \\nby its loss or unavailability) and severity in terms of public \\neffect (eg. number of population affected), the economic ef- \\nfect (significance of economic loss and/or degradation of prod- \\nucts or services), as well as, the environmental effect, po- \\nlitical effects, psychological effects, or public health conse- \\nquences.8 \\nThe 2008 Directive on the identification of European \\nCritical Infrastructures (ECIs) 9 \\nalso attempts to set some ba- \\nsic standards as regards identification and designation of ECIs \\nthrough the adoption by all Member States of a common pro- \\ncedure.10 \\nHowever, the provisions of the Directive have a lim- \\nited scope because they refer exclusively to ECIs, as these are \\ndefined in its text, thus leaving national infrastructures out- \\nside its scope. The NIS Directive,11 \\non the other hand, has a \\nbroader application as it applies to all Operators of Essential \\nServices; In practice, it describes the process Member States \\n\\n2.2. \\n\\nDefining critical information infrastructures \\n\\nThere is no straightforward approach when it comes to defin- \\ning a “Critical Information Infrastructure”. From a legal per- \\nspective at least, the differences between the two terms are \\nnot obvious, and, until today, even though definitions of both \\nterms can be found in official documents, there are few clear \\nreferences regarding their relationship. On the contrary both \\nterms are sometimes used interchangeably and when this is \\nnot the case, there is a considerable amount of overlap in their \\nuse.14 \\nAccording to Brunner and Suter “The definition of exactly \\nwhat should be subsumed under CI, and what should come under \\nthe heading of CII, is another question: Generally, the CII is that part \\nof the global or national information infrastructure that is essentially \\nnecessary for the continuity of a country’s critical infrastructure ser- \\nvices. The CII, to a large degree, consists of, but is not fully congruent \\nwith, the information and telecommunications sector, and includes \\ncomponents such as telecommunications, computers/software, the \\ninternet, satellites, fibre-optics, etc. The term is also used for the to- \\ntality of interconnected computers and networks and their critical \\ninformation flows ”.15 \\nDunn, refers to CI and CII as follows: “T hat \\nthe two concepts are closely interrelated is apparent from the current \\ndebate in protection necessities: the debate jumps from a discussion \\nof protecting critical physical infrastructure to talk of protecting data \\nand software residing on computer systems that operate these phys- \\nical infrastructures. This indicates that the two cannot and should \\nnot be discussed as completely different concepts. Rather CIIP seems \\nan essential part of CIP: While CIP comprises all critical sectors of \\na nation’s infrastructure, CIIP is only a subset of a comprehensive \\nprotection effort, as it focuses in the critical information infrastruc- \\nture ”.16 \\n\\nDefinitions of both terms can be found in different EU of- \\nficial documents. ENISA refers to Critical Information Infras- \\ntructure Protection in its 2016 report on the protection of CII.17 \\n18 \\nENISA understands CII as part of a CI and more particu- \\n\\n\\ncomputer law & security review 41 (2021) 105502 \\n\\nlarly as the underlying information infrastructure. Another \\ndefinition is introduced by the Commission’s Green Paper.19 20 \\nThe OECD, on the other hand, in its 2008 Recommendation,21 \\ndefines CII as “those interconnected information systems and net- \\nworks, the disruption or destruction of which would have a serious \\nimpact on the health, safety, security, or economic well-being of citi- \\nzens, or on the effective functioning of government or the economy ”. \\nWhat may be concluded by these definitions is that CIs are \\ncomplemented by CIIs, which are perceived as a sub-segment \\nof CIs, in particular as the ICT systems that support their op- \\neration. \\n\\nThe realisation that ICT systems, services and networks \\nform a vital part of the European economy and society placed \\nthe ICT sector’s protection high on the European priorities’ \\nagenda early on. As early as 2005 the ICT sector was perceived \\nas a CI, when the Commission published its Green Paper and \\nthe ICT was listed as one of the CI sectors that should fall un- \\nder the European protection programme.22 \\nICTs could either \\nbe perceived as CIs themselves, through provision of essen- \\ntial goods and services, or as the underpinning platform of \\nother CIs. In either case their protection is of the essence. The \\nneed to give a priority to the ICT sector was also identified by \\nthe Commission’s Directive on European Critical Infrastruc- \\ntures.23 \\nIn its text it is stated that, in the event of considering \\nof adding additional sectors under the Directive’s scope dur- \\ning the review process, the ICT sector should be first in the list \\n– however the Directive is still under review. The Commission \\nneeded however another four years (since the Green Paper) \\nto move from these simple references to specific legislative \\nmeasures that addressed CIs’ protection separately.24 \\nThis ef- \\nfort led eventually to the adoption of the NIS Directive and the \\nimplementation of a more consistent European approach on \\nthe protection of network and information systems. \\n\\nIn practice, the argumentation regarding the differences or \\noverlaps between the two terms should not be limited to a \\ntheoretical evaluation of their contents. A more precise and \\nconsistent reference to each in the relevant EU and Member \\nState documentation could contribute to better identification \\n\\nan immaterial component, which is the actual information transported by \\nand through the physical components ”\\n\\n\\nby operators of CIs and/or CIIs respectively of the risks their in- \\nfrastructures are up against. Ultimately, it would contribute to \\na more targeted implementation of protection measures de- \\npending on their recipients, based on whether these are the \\nphysical facility and asset or the information technology facil- \\nity that supports it. This is exemplified in Part 4 of this anal- \\nysis: The eHealth sector is an example of lack of uniformity, \\nwhereby lack of clarity is noted as early as regarding its own \\nidentification as a CII. Even in these cases where the eHealth \\nsector has indeed been identified as a critical sector, still on- \\ngoing debates question whether it should be considered a CII \\nitself or part of another CI, such as the broader health sector \\nor, even, the ICT sector.25 \\n\\nIntegration of industrial control systems into critical \\n\\n2.3. \\ninfrastructures: Why are these systems so vulnerable? \\n\\nMost CIs nowadays such as energy, oil and gas, water, trans- \\nportation systems, manufacturing facilities are controlled and \\nmonitored by Industrial Control Systems (ICS). ICS is a gen- \\neral term describing industrial automation systems responsi- \\nble for data acquisition, visualization and control of industrial \\nprocesses, often found in various industrial sectors and CIs. \\nENISA notes in a report released in 2015 that “the ICS-SCADA \\nenvironment is the fundamental component of European and na- \\ntional Critical Infrastructures ”.26 \\nOver the last years a constantly \\nincreasing number of cyberattacks against these systems has \\nbeen identified, which has highlighted the security of ICS as \\na high priority area among CIs’ operators.27 \\nAt the same time, \\ntheir complexity and the high level of preparedness of the cy- \\nber offenders are additional parameters that raise concerns as \\nregards their safety.28 \\n\\nThere are basically two factors that have contributed to the \\ntargeting of ICS. The first is directly related to the indispens- \\nable contribution of ICSs to the operation of CIs and the se- \\nvere consequences a successful attack could have. The bigger \\nthe damage the stronger the motivation for a cyberattack. The \\nother refers to the vulnerabilities of the ICS, which, in many \\ncases, make them a soft target. More specifically, ICS currently \\nuse open architectures and are often connected to external \\nsystems such as office systems. From being isolated systems \\nrunning proprietary software and control protocols, thus hav- \\ning little resemblance to traditional information systems, they \\nhave begun to resemble the more traditional information sys- \\ntems. Increasingly, ICS use the same commercially available \\nhardware and software components, which is translated to \\nsignificantly less isolation from the outside world, introduc- \\n\\n5 \\n\\ning many of the same vulnerabilities that exist in current net- \\nworked information systems.29 \\nAs noted by ENISA “Today ICS \\nproducts are mostly based on standard embedded systems platforms, \\napplied in various devices, such as routers or cable modems, and they \\noften use commercial off-the shelf software. All this has resulted in \\nreduction of costs, ease of use and enabled the remote control and \\nmonitoring from various locations. However, an important draw- \\nback derived from the connection to intranets and communication \\nnetworks, is the increased vulnerability to computer network-based \\nattacks ”.30 \\n\\nDespite, however, the above realisations, ICS have not at- \\ntracted the EU interest as far as regulatory initiatives are con- \\ncerned, as this will be demonstrated in the relevant section \\nthat follows. \\n\\nThe protection policies for CIs and CIIs \\n\\n3. \\nagainst cyberattacks. What is the protection \\nregime for industrial control systems? \\n\\n3.1. \\n\\nSetting the regulatory landscape \\n\\nCritical Infrastructures and their protection have been in the \\ncentre of EU regulatory efforts since 2004. The severe con- \\nsequences a possible disruption or manipulation of CIs may \\ncause has motivated all involved stakeholders to contribute \\nto their protection against cyberattacks by reducing their vul- \\nnerabilities and enhancing their resilience. The first official \\nstep to this direction was taken in June 2004, when the Eu- \\nropean Council asked the Commission to prepare an overall \\nstrategy to protect CIs. At that time, the main concern was \\nthe protection against terrorist attacks.31 \\nThe Commission re- \\nsponded immediately by publishing a Communication to the \\nCouncil and the European Parliament.32 \\nThe official defini- \\ntion of CIs, as well as the framework for implementing a Eu- \\nropean Programme for Critical Infrastructure Protection were \\nincluded in this document. The Communication was followed \\nby a Green Paper that was adopted by the Commission in \\nNovember 2005.33 \\nMain purpose of the Green Paper was to re- \\nceive feedback concerning a possible European Programme on \\nCritical Infrastructure Protection policy options by involving a \\nbroad number of stakeholders. The Green Paper introduced \\n\\n\\nthe notion of EU CIs, thus paving the way for the adoption of \\nthe main legislative EU instrument on this matter, the Direc- \\ntive on European Critical Infrastructures.34 \\n\\nAn overall policy approach and the framework for Critical \\nInfrastructure Protection activities in the EU was presented \\nby the Commission in its EPCIP Communication issued in De- \\ncember 2006.35 \\nThe European Programme for Critical Infras- \\ntructure Protection (EPCIP), while recognising the threat from \\nterrorism as a priority, aimed to respond to all kind of threats, \\nincluding criminal activities as well as natural disasters and \\nother causes of accidents, using an “all-hazards” approach. To- \\ngether with the Communication, the Commission presented a \\nproposal for a Directive on the identification and designation \\nof European Critical Infrastructures and a common approach \\nto assess the need to improve their protection.36 \\nThe Directive \\nwas officially published in December 2008 and it will be briefly \\npresented in the section that follows. \\n\\nEven after adoption of the Directive, however, protection \\nof CIs and of CIIs remained in the centre of the Commis- \\nsion’s interest. In 2009, the Commission adopted a Commu- \\nnication on Critical Information Infrastructure Protection set- \\nting out a plan (the CIIP Action Plan) to strengthen the security \\nand resilience of vital Information and Communication Tech- \\nnology (ICT) infrastructures. The Communication focused on \\nstrengthening the security and resilience of CII, thus turning \\nthe interest to the information society.37 38 \\nThe emphasis on \\nthe security of CIIs was consistent with the debate launched at \\nthat time at the request of the Council and the European Par- \\nliament, to address the challenges for network and informa- \\ntion security, a debate that, several years later, resulted in the \\nNIS Directive.39 \\nIn 2011 a new Communication was released \\nby the Commission, which focused on the evaluation of the \\nachievements and next steps of the CIIP Action Plan.40 \\nA new \\n\\ncomputer law & security review 41 (2021) 105502 \\n\\napproach on the EPCIP plan, was incorporated in the Commis- \\nsion’s Staff Working Document, that was adopted in 2013 to \\ntake account of increasing cross-border interdependencies.41 \\n42 \\n\\nThe 2008 directive on European critical \\n\\n3.2. \\ninfrastructures \\n\\nThe 2008 Directive is a key pillar of the Commission’s EPCIP \\nprogramme. The Directive constitutes a first step in an ef- \\nfort to identify and designate ECIs and to assess the need \\nto improve their protection. One critical point that needs to \\nbe made before examining the Directive’s specific provisions \\nconcerns its scope. The Directive adopts a sector-specific ap- \\nproach, limiting its implementation to the energy and trans- \\nport sectors only leaving thus outside its scope several policy \\nsectors such as the health sector or the drinking water supply \\nand distribution sector or the financial sector. This limitation \\nis acknowledged in its text, where it is specifically mentioned \\nthat, by the time of its review, subsequent sectors may be iden- \\ntified, with a priority to be given to the ICT sector.43 \\nGiven that \\nboth the Green Paper and the Proposal for the Directive in- \\nclude in their Annexes a list of eleven different CI sectors, it is \\ninteresting to note that the regulator decided against a more \\nextensive list. A possible explanation could be that these two \\nsectors were selected on a trial basis and that the list would be \\nexpanded together with the Directive’s review which was due \\nfor the year 2012.44 \\nHowever, even though the process of re- \\nviewing commenced in 2012, it has not been completed until \\ntoday. \\n\\nAnother issue that needs special attention is that the Di- \\nrective focuses specifically on European Critical Infrastruc- \\ntures, namely infrastructures that are critical from a European \\nperspective, i.e. where their disruption or destruction would \\nhave a significant impact on at least two Member States. In \\nother words, not all CIs fall under the Directive’s scope but \\nrather a limited category that fits its definition.45 \\nWhile it is \\nindeed true that the Directive was perceived in the context \\nof the European Programme for Critical Infrastructure Protec- \\ntion, thus aiming protection at EU level, nevertheless it is also \\ntrue that it ended up being a regulatory instrument of a very \\nlimited scope, that eventually left national CIs unregulated at \\nEU level until such a late time as in 2016, when the NIS Direc- \\ntive came into force.46 \\n\\ntion Infrastructure Protection ‘Achievements and next steps: to- \\nwards global cyber-security, COM/2011, 163 https://eur-lex.europa. \\neu/LexUriServ/LexUriServ.do?uri=COM:2011:0163:FIN:EN:PDF \\n\\nAs far as the specific provisions of the Directive are con- \\ncerned, the Directive requires each Member State to identify \\nthe CIs that may be designated as European Critical Infras- \\ntructures within its territory. The identification procedure is \\ndescribed in Annex II of the Directive. Once an ECI is identi- \\nfied, the Member State needs to communicate it to any other \\nMember State which may be affected by its disruption in order \\nto reach an agreement regarding its designation. The process \\nmay be initiated by a Member State which believes that is sig- \\nnificantly affected by a potential European Critical Infrastruc- \\nture but has not been identified as such by the Member State \\non whose territory the same is located. As a next step, the Di- \\nrective requires a specific set of actions to be taken by the CI’s \\nowner/operators in order to develop an Operator Security Plan. \\nMinimum requirements for such a plan are incorporated in \\nAnnex III of the Directive. Provisions for establishment of a \\nSecurity Liaison officer are included in the Directive: The Se- \\ncurity Liaison officer is to function as the point of contact for \\nsecurity related issues between the owner/operator of the CI \\nand the relevant national authority.47 \\n\\nDespite therefore its innovative character the Directive in- \\ntroduces a generic approach regarding protection of CIs. Its \\nefficiency is examined in the Commission Staff Working Doc- \\nument published in June 2012.48 \\nThe document presented a \\nstrong perception by Member States that implementation of \\nthe Directive did not result in sufficiently clear and tangible \\nimprovements to ECIs security levels. Basic fact supporting \\nthis view was that few European Critical Infrastructures had \\nbeen identified and very few Operator Security Plans had been \\nproduced until then. Despite though however the existence of \\ncontradicting opinions on the actual improvement of security, \\nMember States reached a near consensus on the added value \\nof side-effects of the Directive, such as increased awareness \\nand cooperation. Furthermore, it was supported that the very \\nexistence of a legal instrument nurtured policies on the pro- \\ntection of national CIs. \\n\\nSame conclusions were adopted in the Commission’s eval- \\nuation roadmap on the Directive that was released in March \\n2018.49 \\namong others, it was observed that, even though the \\nDirective was quickly transposed in the national laws of Mem- \\nber  States,  its  application  remained  limited.  Furthermore, \\nwide discrepancies in the application of the Directive among \\nMember States were pointed out: For instance, at the time of \\npublication of the evaluation the vast majority of CIs were \\ndesignated by two Member States only (approximately 60% \\nof the total number of designations), and primarily in the en- \\nergy sector. As of August 2018, the Member States had desig- \\nnated ninety-three European Critical Infrastructures; Of these, \\n\\n\\n7 \\n\\neighty-eight were in the energy sector and five in the transport \\nsector. \\n\\nOn July 2019 the Commission published its latest evalua- \\ntion of the Directive.50 \\nAmong the conclusions presented were \\nthat the Directive appears to have partial relevance in view \\nof recent technological, economic, social, policy/political and \\nenvironmental developments and the challenges they entail. \\nAlso, the limited sectoral scope of the Directive means that it \\ndoes not fully account for growing cross-sectoral interdepen- \\ndencies. As regards its effectiveness, the evaluation concluded \\nthat the Directive has been partially effective in achieving its \\nstated objectives, namely the establishment of a common ECI \\nidentification and designation procedure. It remains therefore \\nto be seen, once the process of reviewing the Directive will \\nhave been concluded, how these challenges will be addressed \\nin the updated document.51 \\n\\nthe identification of CIIs and their protection ; 53 54 \\nIn addition, \\nENISA has developed a series of guidelines in order to assist \\nMember States to implement the NIS Directive, including a \\ntool that maps security measures for Operators of Essential \\nServices to international standards,55 \\nas well as, a report on \\nmapping of Operators of Essential Services’ security require- \\nments for specific sectors, including the health sector that will \\nbe thoroughly presented below.56 \\nENISA’s role in supporting \\nthe NIS Directive’s implementation and in contributing to in- \\ncreasing cybersecurity capabilities at Union level was further \\nreinforced by the Cybersecurity Act.57 \\nAmong the objectives \\nof the new Regulation, which came into force on 27th June \\n2019, is the strengthening of ENISA’s role by granting to it a \\npermanent mandate and the development and implementa- \\ntion of Union policy on cybersecurity certification of ICT prod- \\nucts, ICT services and ICT processes. \\n\\nThe NIS directive and the role of Enisa in protecting \\n\\n3.3. \\ncritical infrastructures against cyberthreats \\n\\nWhen  it  comes  to  cyber  resilience  and  protection  of  CIs \\nagainst cyberthreats, in particular of the network and infor- \\nmation systems that support their operation, the NIS Directive \\nshould be taken into consideration. The NIS Directive does not \\nmake any explicit reference to CIs, it makes use however the \\nterm “Essential Services” which should be considered equiva- \\nlent. Operators of Essential Services, as recipients of the Direc- \\ntive’s requirements, include all public or private entities that \\nprovide a service which is essential for the maintenance of \\ncritical societal and/or economic activities.52 \\nThe type of en- \\ntities that fall under the definition of the NIS Directive for Op- \\nerators of Essential Services, more or less, coincides with the \\nindicative list of Critical Infrastructure sectors included in the \\nrelative European documents on Critical Infrastructure Pro- \\ntection. A thorough analysis of the NIS Directive’s scope and \\nprovisions lays beyond the purpose of this document; Here it is \\nenough to be noted that the NIS Directive, which was adopted \\nin 2016 and entered into force in May 2018, currently is the \\nmain EU cybersecurity legal instrument addressed to Member \\nStates in order for them to warrant high levels of protection \\nfor network and information systems supporting, among oth- \\ners, the operation of CIs and the provision of critical/essential \\nservices. \\n\\nENISA, from its part, has recognised the significant impact \\ncyberattacks may have on CIIs and related services. ENISA \\nshares the opinion that identification of a CII is the first step \\nin the process to secure and protect the availability of criti- \\ncal assets. In this context, it has published several reports on \\n\\n3.4. \\n\\nProtection of industrial control systems \\n\\nAs seen above, CIs and CIIs have been extensively addressed \\nat EU level and different policy areas have been developed to \\nthis effect. ICS’ protection, however, is not addressed explic- \\nitly in any of the EU’s relevant official documentation. Given \\nthe critical role of ICS in the uninterrupted operation of many \\nEuropean and national CIs, the lack of specific measures that \\ncould contribute to their protection is considered a significant \\nomission.58 \\n\\nENISA, having identified this regulatory gap, published in \\n2011 a study on protecting ICS.59 \\nThe study aims to identify \\nthreats, risks and challenges in the area of ICS protection, as \\nwell as, to recognize national, European and international ini- \\ntiatives on ICS security. The first challenge identified in the re- \\nport is the lack of specific initiatives on ICS security in combi- \\nnation with the lack of a European reference with regard to se- \\n\\n\\x0c8 \\n\\ncomputer law & security review 41 (2021) 105502 \\n\\ncurity standards and guidelines. The report goes on to recom- \\nmend actions that need to be undertaken in order to achieve \\nthe required level of ICS protection, such as reviewing the con- \\ncept of ICS and their role when embedded into CIs, reviewing \\nthe threats that could affect these systems from a multitude \\nof perspectives, describing the main differences between ICS \\nand regular IT systems, listing the challenges to ICS security, \\nsummarising the current policy context under which the pro- \\ntection of ICS should be framed at EU level and in the US, and \\nanalysing the different technical solutions that are currently \\napplied for protecting ICS. \\n\\nMaking the healthcare sector more resilient \\n\\n4. \\nagainst cyber incidents: Emerging vulnerabilities \\nand the applicable regulatory framework for its \\nprotection \\n\\nHospitals under attack: Setting the (cyber) threat \\n\\n4.1. \\nlandscape \\n\\nOver the last years the healthcare sector has been challenged \\nwith a constantly increasing number of cybersecurity inci- \\ndents. Ransomware, medjacking,60 \\nphishing (through target- \\ning email addresses of physicians), medical devices tamper- \\ning, denial of service,61 \\nand, even, cyberespionage are some \\nexamples of malicious actions targeting healthcare organisa- \\ntions and their ICT systems. These threats, if successful, may \\nhave disastrous consequences not only to the provision of \\nhealthcare services but also to the broader social and finan- \\ncial welfare. The Wannacry ransomware, for instance, dev- \\nastated the UK NHS in 2017, hit international shipper Fedex \\nand infected more than 300.000 computers in 150 countries. \\nIn the SingHealth attack, Singapore’s worst cyberattack, hack- \\ners infiltrated the data bases of SingHealth, the largest group \\nof healthcare institutions in the country, that eventually led \\nto the theft of personal data of 1,5 million patients. The cy- \\nberattack against Anthem Insurance in 2015 had also serious \\nconsequences: As a result of this data breach, 79 million per- \\nsonal records were affected, including names, birthdays, med- \\nical IDs, and social security numbers.62 \\n\\nThere are specific vulnerabilities and particularities of the \\nhealthcare industry that make it more attractive to cyber of- \\nfenders and at the same time constitute it a soft target. First \\nand foremost, the personal data that hospitals and healthcare \\norganisations store in their systems consist mainly of heath \\ndata. Given the monetary value and the high sensitivity of \\nmedical data, many cyber offenders are motivated by finan- \\n\\n\\n\\ncial gain, whereas others seek to obtain intellectual property \\nor consumer information. Data theft therefore is one of the \\nmain cyberthreats health institutions are facing. According to \\nresearch findings, healthcare data security incidents ranked \\nsecond for the health services industry in 2016.63 \\nAnother fac- \\ntor that contributes to the increase in the occurrence of cy- \\nber incidents targeting the health sector refers to the techno- \\nlogical advancements. The health sector is becoming increas- \\ningly connected, whereas the integration of ICT systems in the \\nhealth services and infrastructures has increased significantly \\nover the last decades. In this rapidly advancing technologi- \\ncal environment, traditional hospitals move to a smart hospi- \\ntal environment, thus introducing new capabilities in patient \\nhealthcare.64 \\nFurthermore, modern healthcare is dominated \\nby an extensive network of connected medical devices, the \\nuse of which has changed the ICT landscape in the healthcare \\nindustry worldwide. ENISA mentions in its Guidelines for Cy- \\nbersecurity in Hospitals that medical technology companies \\ncurrently manufacture more than 500,000 different types of \\nmedical devices, such as wearables, implantable and station- \\nary medical devices. The Internet of Medical Things market in \\nEurope alone is expected to grow from 11 billion in 2017 to 40 \\nbillion in 2022, while the European medical technology market \\nwas estimated at roughly 115 billion in 2017.65 \\n\\nIn addition, so-called “eHealth” is another digital develop- \\nment which has, during the past few years, developed into an \\nimportant segment of the provision of health services over- \\nall. eHealth denotes the use of ICT in support of health and \\nhealth-related services. The term is widely used to describe \\nthe interaction between patients and health-service providers \\nranging from patients’ online access to basic data on their \\ntreatment to national schemes, like ePrescription services or \\ncross border eHealth information sharing. Similarly, so-called \\n“Mobile health” (mHealth) is a rapidly developing component \\nof E-Health that covers “medical and public health practice sup- \\nported  by  mobile  devices, such  as  mobile  phones, patient  moni- \\ntoring devices, personal digital assistants, and other wireless de- \\nvices ”.66 \\nIt particularly includes the use of mobile commu- \\nnication devices for health and well-being services and in- \\nformation purposes, as well as, mobile health applications. \\nOver 97,000 mHealth apps are currently available across mul- \\ntiple platforms on the global market; Of these, 70% target con- \\nsumers and fitness while 30% target health professionals.67 68 \\n\\n\\n\\n9 \\n\\nDigital transformation of healthcare and the use of elec- \\ntronic means to acquire, transfer or store healthcare related \\ninformation and to provide services used by health profes- \\nsionals and patients/consumers has improved the provision \\nof health services and is anticipated to increase the well-being \\nof millions of citizens. At the same time the increased pace of \\ndigitalisation opens up “opportunities” for cyberattacks and \\nconsequently new challenges for cybersecurity. The adoption \\nof a comprehensive and consistent EU regulatory framework \\nthat will address these new challenges and will introduce EU- \\nwide standards for the provision of health services is therefore \\nnecessary. The EU has been intensively working to this effect \\nsince 2004, as elaborated in the section that follows. \\n\\nRegulations is considered necessary for two reasons: First, \\nthey constitute an inseparable part of the EU regulatory frame- \\nwork on the health sector; Second, the increased dependency \\nof their subject-matter (medical devices) on ICT and their ex- \\nposure to cyber threats makes the discussion on their protec- \\ntion against cyberattacks relevant. Furthermore, a short pre- \\nsentation of the initiatives adopted at EU level on eHealth has \\nbeen included in this paper. Even though there is no specific \\nsecurity parameter of the applicable framework in eHealth (in- \\ncluding mHealth), this was considered necessary for picture \\ncompleteness purposes, especially taking into account the on- \\ngoing discussion on the identification of eHealth as a CII, as \\nthis will be elaborated below. \\n\\nThe regulatory framework to address (cyber)security \\n\\n4.2. \\nrequirements in the health sector \\n\\nThe following analysis focuses on the main regulatory instru- \\nments applicable to the health sector, with a particular em- \\nphasis on those addressing (cyber)security issues in the pro- \\nvision of health services and the operation of health infras- \\ntructures. The regulatory framework presented here consists \\nof both regulation of a horizontal scope which applies to the \\nbroader health sector, as well as, sector-specific legislation. As \\nregards the first category, healthcare is, without exception, listed as \\na CI in all relevant EU official documentation. Consequently, the reg- \\nulatory framework on the protection of CIs, as elaborated in the first \\npart of this analysis, finds full application on the health sector as \\nwell. At the same time, the provision of healthcare services is con- \\ntinuously dependent upon an ICT environment. Increased ICT de- \\nployment inevitably leads to greater ICT dependency and, in turn, \\nto greater need for information security. Protection of the underlying \\ninformation infrastructure of the health sector falls under the protec- \\ntion regime for CII, as this will be explained below where the percep- \\ntion of eHealth as a CII is being considered.. Accordingly, h ealthcare \\nproviders have been identified as Operators of Essential Ser- \\nvices, in the context of the NIS Directive, while eHealth has \\nbeen characterised as a CII by most Member States. In addi- \\ntion to the general framework for the protection of CIs, the \\nNIS Directive is the main regulatory instrument available to \\nhospitals and healthcare organisations in order to minimise \\nthe security risks posed to their network and information sys- \\ntems. The General Data Protection Regulation 69 \\nis also appli- \\ncable (see the analysis that follows): Processing of health data \\nis extensively addressed in its text, which introduces security \\nrequirements and specific obligations applicable to healthcare \\norganisations, as data controllers. \\n\\nAt  the  same  time  the  EU  has  been  working  on  sector- \\nspecific legislation. In this context, two Regulations have been \\nrecently adopted by the Commission to strengthen the Euro- \\npean regulatory framework for medical devices and in vitro di- \\nagnostic medical devices. Reference in this analysis to these \\n\\nLeenes  R  (Editors), Under  Observation:  The  Interplay  Between \\neHealth and Surveillance, Springer, 2017. \\n69 \\n\\nSee Regulation (EU) 2016/679 of the European Parliament and \\nof the Council of 27 April 2016 on the protection of natural per- \\nsons with regard to the processing of personal data and on the free \\nmovement of such data, and repealing Directive 95/46/EC (General \\nData Protection Regulation) . \\n\\n4.2.1.  Health sector security requirements in the NIS directive \\nAs see above under 3.3. the NIS Directive constitutes, at the \\ntime being, the main legislative EU cybersecurity legal instru- \\nment at Member States’ disposal in order to warrant a high \\nlevel of protection for network and information systems that \\nsupport, among others, the operation of CIs and the provision \\nof critical/essential services. As regards the health sector, in \\nparticular, healthcare providers are listed among the entities \\nidentified in the NIS Directive’s Annex as Operators of Essen- \\ntial Services.70 \\nAs a result, hospitals and healthcare settings \\nmust implement the NIS Directive’s security and notification \\nrequirements. In particular, they need to take appropriate and \\nproportional technical and organisations measures to man- \\nage the risks posed to the security of network and informa- \\ntion systems that they use in their operations and to prevent \\nand minimise the impact of incidents affecting the security of \\nsuch systems. The obligation to notify the competent author- \\nity of incidents having a significant impact on the continuity \\nof the essential services they provide complements the set of \\nobligations set under the NIS Directive for all entities operat- \\ning within the health sector. \\n\\nENISA, in the same context as above, assisting Member \\nStates and organisations to implement the NIS Directive, has \\npublished a number of reports and guidelines for the health \\nsector: Having recognised the significance of digital health \\nnetworks as CII, it has developed actions focusing on the secu- \\nrity challenges and risks faced by the health sector in Member \\nStates.71 \\nENISA has also launched an “eHealth Security Ex- \\nperts Group” with the aim to create an active community to \\nshare information and exchange knowledge on this field. \\n\\n4.2.2.  Health sector security requirements in the general data \\nprotection regulation \\nThe General Data Protection Regulation (GDPR) is particularly \\nrelevant in the health sector because essentially all or most \\nof health data or medical records are “personal data” in the \\ncontext of its provisions.72 \\nWhile a comprehensive analysis \\n\\n\\x0c10 \\n\\ncomputer law & security review 41 (2021) 105502 \\n\\nof health-related personal data processing under the GDPR \\nlies beyond the purposes of this analysis, here it is only noted \\nthat hospitals and healthcare providers should, when process- \\ning patients’ data, comply with the processing principles and \\nother obligations provided in the GDPR. In essence, they must, \\nas data controllers, take all appropriate technical and organi- \\nsational measures to ensure and be able to demonstrate that \\nthe requirements of this Regulation are met, including the se- \\ncurity of the processing. \\n\\nIn brief, as regards health data in particular, the GDPR aims \\nto strike the right balance between the protection of individu- \\nals in relation to the processing of their personal data, which \\nare by nature particularly sensitive, and the social welfare, in \\nparticular in the context of the management of health or so- \\ncial care services and systems. In this context, hospitals are \\nexcluded from the general rule of Article 9 of the GDPR, which \\nprohibits any processing of special categories of data, on the \\ngrounds that processing of such data is carried out for certain \\nhealth-related purposes by persons subject to a legal obliga- \\ntion of professional secrecy.73 \\nAt the same time, however, the \\nprocessing of special categories of personal data entails high \\nrisks for the data subjects. On these grounds, the GDPR pro- \\nvides a set of additional obligations to controllers that are en- \\ngaged, among others, in processing on a large scale of special \\ncategories of data pursuant to Article 9, such as hospitals and \\nhealthcare providers. These organisations must therefore des- \\nignate a Data Protection Officer,74 \\ncarry out a data protection \\nimpact assessment 75 \\nand notify a personal data breach likely \\nto result in a risk to the rights and freedoms of individuals.76 \\nSecurity of processing is another obligation that burdens both \\nthe controller and the processor of personal data. According \\nto Article 32 of the Regulation, the controller and the proces- \\nsor shall implement appropriate technical and organisational \\nmeasures to ensure a level of security appropriate to the risk, \\nsuch as pseudonymisation, encryption, ability to ensure con- \\nfidentiality and to restore the availability etc. \\n\\nThe rapid development of eHealth, including mHealth, cre- \\nates new challenges in terms of safeguarding the lawfulness \\nof processing of the personal data collected through health \\napps and platforms and through the provision of digitalised \\nhealth services as a whole. Exchange of personal data through \\nthe  eHealth  Digital  Service  Infrastructure  for  Cross-Border \\neHealth Information Services has been addressed in the Com- \\nmission’s Implementing Decision. In particular, it has been \\nclarified that, as regards such processing, the Commission \\nshall be regarded as data processor for patients’ personal data, \\nwhereas the Member States shall be regarded as controllers.77 \\n\\n4.2.3.  The medical devices regulations \\nIt is undisputable that medical devices have dominated the \\nhealth sector and that their use for the provision of health ser- \\n\\n\\nvices is constantly increasing. Therefore, implementing regu- \\nlatory schemes for medical devices is deemed necessary for \\nthe protection of public health and patient’s safety. At the \\nsame time medical devices have developed a significant de- \\npendence on ICT systems for their operation, which makes \\nthem even more vulnerable to security risks, thus turning \\ntheir  safety  into  a  priority  for  all  involved  stakeholders.78 \\nMedical device cybersecurity is a growing concern in light of \\nthe increasing number of cybersecurity incidents and data \\nbreaches. The new regulatory framework for medical devices \\naims to address these concerns by laying down a set of rules \\nconcerning the placing on the market, making available on \\nthe market or putting into service of medical devices for hu- \\nman use and accessories for such devices in the EU. The two \\nnew Regulations on medical devices and on in vitro diagnos- \\ntic medical devices, Regulation 745/2017 (MDR) and Regula- \\ntion 746/2017 (IVDR) entered into force in May 2017. The new \\nRegulations will replace the existing regulatory framework for \\nmedical devices that consists of Directives 90/385/EEC and \\n93/42/EC. The MDR has a transition period of three years and \\nwill fully apply from 26 May 2020. The IVDR has a transition \\nperiod of five years and will fully apply from 26 May 2022.79 \\n\\nAs regards security issues in particular, the Regulations \\nintroduce  specific  provisions  related  to  IT  security  for  all \\nmedical devices. These security requirements are included in \\nAnnex I of the Regulations and deal with both pre-market \\nand post market aspects. In particular, the Regulations make \\nexplicit  reference  to  devices  that  “incorporate  electronic  pro- \\ngrammable systems and software that are devices themselves ”. For \\nthese medical devices, manufacturers need to comply with \\nspecific design requirements in order to ensure repeatability, \\nreliability and performance in line with their intended use.80 \\nFurthermore, whenever software is incorporated into medi- \\ncal devices it must be developed and manufactured in ac- \\ncordance with the state of the art, taking into account the \\nprinciples of development life cycle, risk management, infor- \\nmation security, verification and validation.81 \\nAnother obliga- \\ntion imposed upon manufactures is to set out minimum re- \\nquirements concerning hardware, IT networks and IT security \\nmeasures, including protection against unauthorised access, \\nnecessary to run the software as intended.82 \\nAs regards post- \\nmarket measures, manufacturers need to implement a post- \\nmarket surveillance system proportionate to the risk and ap- \\npropriate to the type of device.83 \\nA notification obligation is \\n\\n\\nalso provided under the new Regulations, according to which \\nmanufactures have to report any serious incidents involving \\ndevices made available on the EU market.84 85 \\n\\n4.2.4.  E-health as a critical information infrastructure \\neHealth 86 \\nhas been in the centre of the EU agenda since 2004, \\nwhen the first eHealth action plan was adopted.87 \\nSince then, \\nthe Commission and the Member States have been developing \\ninitiatives aimed at incorporating eHealth into their health- \\ncare systems. Global statistics published by the WHO show \\nthat 58% of the Member States have an eHealth strategy, 55% \\nof them have introduced legislation to protect electronic pa- \\ntient data and 87% of the same group of countries report hav- \\ning one or more national initiatives under development on \\nmHealth. Improving cross border exchange of health data in \\nparticular and achieving interoperability of national eHealth \\nsystems have been treated as a priority at European level. Both \\ninitiatives are mainly supported by Directive 2011/24.88 \\nTo at- \\ntain its objectives the Directive established the eHealth net- \\nwork; The rules for the establishment, the management and \\nthe functioning of the eHealth Network were further clarified \\nby the Commission’s Implementing Decision 2019/1765.89 \\nIn \\n2012 the Commission published the eHealth Action Plan 2012–\\n2020 90 \\nin an effort to remove the barriers to deployment of \\neHealth that continued to exist until that point. \\n\\nThe latest developments in the eHealth field include the \\nCommission’s Communication on the transformation of digi- \\ntal health and care, which was released in April 2018.91 \\nOne \\n\\nof the initiatives presented in the Communication was the \\ndevelopment by the Commission of the eHealth Digital Ser- \\nvice Infrastructure for the facilitation of the interoperability \\nof European eHealth systems and the exchange of patients’ \\nhealth data. Currently two electronic cross-border health ser- \\nvices are operational, e-prescription, which allows citizens in \\nEurope to retrieve their medication in a pharmacy located in \\nanother European country, and patient summary, which pro- \\nvides information on important health-related aspects of each \\nindividual.92 \\nThe first cross-border exchanges started in 2019. \\nBy 2021, both services will gradually be implemented in 22 EU \\ncountries. In the longer term, the Commission is working to- \\nwards a European electronic health record exchange format \\naccessible to all EU citizens. The plan is that a full Health \\nRecord will become available across the EU. \\n\\nAs regards mHealth in particular, the Commission pub- \\nlished a Green Paper on mobile Health in 2014.93 \\nThe Green \\nPaper was announced in the eHealth Action Plan 2012–2020 94 \\nand its objective was to launch a broad stakeholder consul- \\ntation  on  existing  barriers  and  issues  related  to  mHealth. \\nA  wide  range  of  stakeholders  (industry,  national  and  re- \\ngional authorities, health professionals, research community, \\nnon-governmental organisations, patient associations etc.) re- \\nsponded to the consultation and provided their input on sev- \\neral issues relating to the uptake of mHealth in the EU, such \\nas data protection, big data, applicable legal framework, pa- \\ntient safety, liability and others.95 \\nThe Green Paper was ac- \\ncompanied by the Commission’s Staff Working document to \\nraise app developers’ awareness of EU rules on data protec- \\ntion, medical devices and consumer directives.96 \\n\\nThere is no doubt that eHealth has attracted significant leg- \\nislative attention as regards both its definition and regulation. \\nHowever, there is no official reference to eHealth as a CII. Even \\nthough ENISA has acknowledged the significance of eHealth 97 \\nnot only as a major contributor to the societal and financial \\nwelfare but, more specifically, as a CII, most Member States \\nhave not developed a specific methodology or legislation for \\nthe identification of critical eHealth infrastructures. In many \\ncases eHealth is identified as part of a critical sector such as \\nHeath care and/or ICT. Therefore, the approach that has been \\nadopted until today by the majority of Member States is that of \\nidentifying and protecting eHealth infrastructures in the con- \\n\\nabling the digital transformation of health and care in the Dig- \\nital Single Market; empowering citizens and building a health- \\nier  society,  COM/2018/233  finalhttps://eur-lex.europa.eu/legal- \\ncontent/EN/TXT/?uri = COM%3A2018%3A233%3AFIN \\n92 \\n\\nThe digital Patient Summary is meant to provide doctors with \\nessential information in their own language concerning the pa- \\ntient, when the patient comes from another EU country and there \\nmay be a linguistic barrier. \\n\\ntext of the general regulation and strategy for CIIP. ENISA in \\nits report on Security and Resilience in eHealth,98 \\nin an effort \\nto treat eHealth as an CII, lists a number of assets that, based \\non feedback received by interviewees, are considered as criti- \\ncal. The list includes, among others, Health Information sys- \\ntems, Laboratory Information Systems, Patient Health Record \\nservices, Authentications server etc. The report places empha- \\nsis upon two systems that were considered critical by all in- \\nterviewees, namely the Electronic Health Record System (EHR) \\nand the e-Prescription system. The discussion on the identifi- \\ncation of eHealth as an independent CII may still be found at \\nan early stage, however it is foreseeable that the constantly in- \\ncreasing use of eHealth services and their contribution to the \\noperation of the healthcare sector overall, combined with the \\nsecurity challenges emerging in eHealth, will accelerate this \\nprocess. \\n\\n5. \\n\\nConclusion \\n\\nCritical Infrastructures constitute the backbone of our societal \\nand economic well-being. Improving their resilience against \\ndifferent kind of attacks has therefore become a priority for \\nthe authorities around the globe. The list of risks and threats \\nthat CIs encounter has expanded over the last decades to in- \\nclude anything from traditional risks such as natural disas- \\nters and human errors to emerging and unpredictable threats, \\nsuch as cyberattacks. At the same time the constantly grow- \\ning dependence of CIs on ICT for their operation has placed \\nthe protection of CIIS firmly into the EU and national agen- \\ndas. This high dependence on CIIs, their cross-border con- \\nnectivity and interdependencies with other infrastructures in \\ncombination with the sophistication and the volume of cy- \\nberthreats targeting them have developed into a challenging \\ntask for both operators of these infrastructures and legisla- \\ntors. As regards the legislative effort undertaken to this effect, \\nit is undisputable that Europe has placed substantial resources \\ninto implementing an EU-wide regulatory framework for the \\nprotection of CIs and the underlying network and information \\nsystems that support them, with the NIS Directive being at the \\nspearhead of this effort. \\n\\nThere is of course still plenty to be done in terms of pro- \\nmoting cooperation at EU and international level, enhancing \\npreparedness for better response to the constantly emerging \\nnew threats and adapting to the new challenges that the con- \\ntinuous integration of digital technologies in CIs brings along. \\nAs regards the current regulatory approach, it is expected that \\nthe upcoming review of the Directive on the Protection of Eu- \\nropean Critical Infrastructures, will acknowledge the short- \\ncomings of the first draft and will adequately address the new \\n\\ndevelopments and emerging challenges in the field. As the Di- \\nrective is, at the moment, the main legislative instrument for \\nthe protection of CIs at EU level, it is expected that the revised \\ndocument will live up to these expectations. When it comes to \\nprotection of network and information systems that support \\nCIs, the NIS Directive assumes the role of the applicable mech- \\nanism for protection against cyberattacks. Given that the NIS \\nDirective came into force in 2018, it remains to be seen how \\nthe Member States and the Operators of Essential Services will \\nmake use of its provisions in practice. Both the Commission \\nand ENISA are expected to contribute to this effort by further \\nclarifying the security and notification requirements provided \\nin the NIS Directive and by assisting all involved parties in im- \\nplementing them. Last but not least, protection of CIs seems \\nincomplete without a regulatory framework for the protection \\nof Industrial Control Systems. Even though ENISA identified \\nthis regulatory gap since 2011, this issue remains pending. \\n\\nThe health sector in particular offers an example of how \\ndigitalisation  opens  up  new  transformative  opportunities. \\nWhile the quality of services and therefore the safety and \\nwell-being of patients have been drastically improved as a re- \\nsult of the extensive use of ICT in the provision of health ser- \\nvices, from medical devices and smart hospitals to eHealth \\nand mHealth, at the same time the sector has been extremely \\nvulnerable to cyberattacks. Taking into consideration what is \\nat stake, from human lives due to a device malfunction to vi- \\nolation of privacy as a result of a personal data loss or theft, \\nsafeguarding the protection of this CI has been treated as a \\nhigh priority by all involved parties. In this context, a num- \\nber of regulatory instruments have been introduced that con- \\nsist of legislation of a horizontal scope together with sector \\nspecific measures. Nevertheless, lack of clarity and uniformity \\nin terminology risk creating misunderstanding and, therefore, \\nwarranting a decreased level of protection. \\n\\nDigitalisation has transformed the lives of individuals and \\nthe organisation and functioning of the society, as a whole. \\nLiving in the digital era promises a more qualitive and com- \\nfortable life to the majority of the word population. At the \\nsame time, however, digitalisation comes with a price. Protect- \\ning our CIs and other assets against threats that did not exist \\nbefore has been turned into a speed and endurance race that \\ndemands alertness, flexibility, preparedness and substantial \\neffort by all the parties involved. \\n\\nDeclaration of Competing Interest \\n\\nThis  research  has  been  funded  under  the  European  Com- \\nmission’s H2020 project SPHINX – A Universal Cyber Security \\nToolkit for Health-Care Industry, Grant Agreement 826183. \\n', 'Multidimensional Diversity Employment for Software Behavior Encryption \\n\\nMohamed Azab \\nThe City of Scientific Research  \\n& Technology Applications,  \\nAlexandria, Egypt  \\nEmail: Mohamed.m.azab@gmail.com \\n\\nAbstract—  Modern  cyber  systems  and  their  integration  with \\nthe  infrastructure  has  a  clear  effect  on  the  productivity  and \\nquality  of  life  immensely.  Their  involvement  in  our  daily  life \\nelevate  the  need  for  means  to  insure  their  resilience  against \\nattacks  and  failure.  One  major  threat \\nis  the  software \\nmonoculture.  Latest  research  work  demonstrated  the  danger \\nof software monoculture and presented diversity to reduce the \\nattack  surface.  In  this  paper,  we  propose  ChameleonSoft,  a \\nmultidimensional  software  diversity  employment  to,  in  effect, \\ninduce  spatiotemporal  software  behavior  encryption  and  a \\nmoving  target  defense.  ChameleonSoft  introduces  a  loosely \\ncoupled,  online  programmable  software-execution  foundation   \\nseparating  logic,  state  and  physical  resources.  The  elastic \\nconstruction  of  the  foundation  enabled  ChameleonSoft  to \\ndefine  running  software  as  a  set  of  behaviorally-mutated \\nfunctionally-equivalent \\nvariants.  ChameleonSoft \\nintelligently Shuffle, at runtime, these variants while changing \\ntheir  physical  location  inducing  untraceable  confusion  and \\ndiffusion  enough  to  encrypt  the  execution  behavior  of  the \\nrunning  software.  ChameleonSoft  is  also  equipped  with  an \\nautonomic failure recovery mechanism for enhanced resilience. \\nIn order to test the applicability of the proposed approach, we \\nthe  ChameleonSoft  Behavior \\npresent  a  prototype  of \\nEncryption  (CBE)  and  recovery  mechanisms.  Further,  using \\nanalysis  and  simulation,  we  study  the  performance  and \\nsecurity  aspects  of  the  proposed  system.  This  study  aims  to \\nassess  the  provisioned  level  of  security  by  measuring  the \\navalanche  effect  percentage  and  the  induced  confusion  and \\ndiffusion levels to evaluate the strength of the CBE mechanism. \\nFurther,  we  compute  the  computational  cost  of  security \\nprovisioning and enhancing system resilience. \\n\\ncode \\n\\nKeywords—  Cyber  security,  Ubiquitous  computing,  Software \\ndiversity, Online programmability, Biologically-inspired security. \\n\\nI. \\n\\nINTRODUCTION \\n\\nto  our \\nis \\n\\nthreat \\nresilience \\n\\ninter-networked  systems \\nA  major \\ninfrastructure \\nthe  software  monoculture. \\nSoftware diversity has a long history of research work in the \\nfields  of  software  security  and  fault  tolerance.  Diversity \\ndecreases  the  virulence  of  worms  and  the  effectiveness  of \\nrepeated application of similar attack vectors [1].  \\n\\nIn  this  paper,  we  propose  a  diversity-based  defense \\nmechanism against software attacks, termed ChameleonSoft. \\nWe  utilize  spatiotemporal  software  diversity  and  hot \\nshuffling  of  functionally  equivalent  code  variants.  This  is \\nmade possible by our  new  ChameleonSoft  Architecture  and \\nfoundation. ChameleonSoft defines running software as a set \\nof  cooperating  and \\ninterconnected  active  capsules. \\nChameleonSoft  Capsule  (CSC)  can  be  described  as  a  smart \\nmicro sandbox/virtual machine encapsulating a single active \\ncode  variant  as  a  part  of  a  running  application.  CSC \\nseparates  logic,  state  and  physical  resource  management. \\n\\nApplications  are  defined  as  a  set  of \\ninterconnected \\ndynamically  composable  capsules.  Such  treatment  provides \\nonline  programmability,  hot  code  swapping  and  automated \\nrecovery.  Combined, these  features  enable  what  we  term  as \\n“ChameleonSoft  Behavior  Encryption  (or  CBE)”  akin  to \\nmessage encryption. \\n\\nChameleonSoft  divides  software  programs  into  smaller \\ntasks. Each of these tasks is assigned to one or more capsule \\nin  the  form  of  a  manually  or automatically  generated  set of \\nsimilar  function  and  different  behavior  executable  variants. \\nThese  variants  might  have  different  objectives  targeting \\ndifferent  quality  attributes,  like  reliability,  performance, \\nrobustness, mobility, etc.  \\n\\nfeatures \\n\\nleverages \\n\\nThe goal of CBE is to make the attack target (a flaw/bug \\nin  a  running  application)  in  continual  random  motion \\nloosely  coupled \\nevading  attackers.  CBE \\nruntime,  different \\nfoundation \\nfunctionally-equivalent, \\nsoftware \\nvariants to hide software flaws that attackers target. In doing \\nso,  we  induce  confusion  and  diffusion  along  multiple \\ndimensions.  Time,  Space,  and  Platform  heterogeneity  are \\nthree of such dimensions.   \\n\\nbehaviorally-mutated \\n\\nto  shuffle,  at \\n\\nits \\n\\nThe  scope  of  shuffling  might  extend  beyond  security \\ngoals to other quality attributes. The system might shuffle to \\na variant that aims at high system performance in overloaded \\nbut  low  security  risk  situations.  Alternatively,  the  system \\nwould resort to a higher security, perhaps lower performance \\nvariant in higher risk situations.  \\n\\nWe  designed  and  implemented  a  prototype  of  the  CBE \\nequipped  with  autonomous  hot  and  cold \\nrecovery \\nmechanisms. Researchers in [2] mentioned that multi-variant \\nsystems without appropriate recovery mechanism might face \\na  larger  amount  of  coincident  failures.  ChameleonSoft  is \\nequipped  with  multimode  recovery  mechanisms  providing \\ndifferent  levels  of  fault  tolerance  granularity.  Such  feature \\nincreases  the  system  resilience  against  coincidental  or \\nintentionally-induced failures.  \\n\\nstudied \\n\\nsimulation,  we \\n\\nUsing  analysis  and \\n\\nthe \\nperformance  and  security  aspects  of  the  proposed  system. \\nThis study aims to evaluate the provisioned level of security \\nby measuring the avalanche effect percentage as a reflection \\nof  the  induced  level  of  confusion  and  diffusion  to  quantify \\nthe  strength  of  the  CBE  mechanism.  We  also  estimated  the \\ncomputational  cost  of  security  provisioning,  and  enhancing \\nsystem  resilience  in  ChameleonSoft  with  regards  to  the \\namount  of  consumed  resources,  task  completion  time,  and \\nrecovery downtime.  \\n\\nThe balance of this paper is as follows. Section 2 presents \\na brief literature survey.  Section 3 describes ChameleonSoft \\nFoundation.  Section  4  presents  the  moving  target  security \\n\\nAuthorized licensed use limited to: Ryerson University Library. Downloaded on May 06,2022 at 21:02:42 UTC from IEEE Xplore.  Restrictions apply. \\n\\n978-1-4799-3223-8/14/$31.00 ©2014 IEEE \\n\\x0cmechanism.  Section  5  discusses  the  evaluation  of  the \\nproposed system. Finally the paper concludes in section 6. \\n\\nII.  RELATED WORK \\n\\nSoftware diversity has a long history of research work in \\nthe field of software security and fault tolerance dated back \\nto  the  70’s.  Basically  software  diversity  was  presented  as \\nmultiple independent solutions for the same problem.  \\n\\nThe realization of that is to develop multiple independent \\nversions  of  a  program  with  different  teams  using  different \\nlanguages. The main goal from that approach was to increase \\nthe  attacker  confusion  by  changing  the  behavior  of  the \\nsoftware; which will make harder system exploitation. They \\nexpected that at any given time the majority of these versions \\nwill be working correctly [1, 2]. \\n\\nSome  research  work  showed  that  there  is  a  high \\nprobability that a multi-variant software approach might face \\nmany  coincident  failures  [3,  4].  On  the  contrary  other \\nresearch work suggested that from the cost and the reliability \\npoint of view, the multi-variant approach is much better than \\nthe  one  “good”  version,  especially  in  mission  critical \\napplications  where  the  cost  of  failure  could  be  very  high \\n[10].  \\n\\nGenesis  [5]  was  one  of  the  first  to  present  Component \\ndiversity. They proposed both design diversity in the form of \\nmultiple  variants  representing  different  designs  of  the  same \\nspecification  as  well  as  data  diversity.    Data  diversity  uses \\nmultiple  copies  of  a  single  implementation  operating  on \\ndifferent data inputs but yielding the same desired results.  \\n\\nThe  help  of  automated  variant  generation  and  utilizing \\nmulticourse  platforms  presented  Massive-scale  software \\ndiversity  for  detecting  anomalies  by  replicated  execution \\n[11].  They  mixed  diversity  with  parallelism  and  check \\npointing.  \\n\\nA major drawback of existing solutions was the need for \\nvirtualizing every input to the whole set of executing variants \\nat  the  same  logical  point  to  be  able  to  detect  the  abnormal \\ndeviation of the execution flow.  \\n\\nThese  approaches  generally  apply  different  types  of \\ndiversity mainly for reliability by replication or for intrusion \\ndetection by program flow-deviation detection at runtime [7]. \\nHowever, existing solutions used diversity to target specific \\nquality  attribute.  Failure  recovery  mechanisms  were  not \\ninvestigated  as  most  of  these  solutions  presented  static \\ndiversity  with  low  probability  of  failure.  Another  drawback \\nof these solutions was the massive use of resources to realize \\ndiversity  using  virtualization  techniques  and  multicore  or \\nmultiprocessor platforms. ChameleonSoft [6] was the first to \\ninvestigate  the  idea  of  presenting  a  comprehensive  solution \\nthat  provides  elastic,  autonomous,  resilient,  situationally-\\naware  platform  targeting  different  quality  attributes,  while \\ndynamically  shuffling  its  software  components  to  suit \\nchanges  in  and  requirements  of  the  surroundings.  While \\nassessing  the  level  of  presented  level  of  security  was  not \\nquite  clear.  In  this  paper,  we  present  a  formal  method  of \\nassessing  the  presented  level  of  security  by  measuring  the \\navalanche effect induced by the chameleonization process.  \\n\\nIII.  CHAMELEONSOFT FOUNDATION \\n\\nChameleonSoft  is  an  employment  of  a  mission-oriented \\napplication  design  and  inline  code  distribution  to  enable \\nadaptability,  dynamic  re-tasking,  and  re-programmability. \\nThe capsule, is the basic building block.  \\n\\nGeneric  capsules  cells  are  seamlessly  created  by  a \\nmiddleware  installed  on  the  physical  resource  nodes  as  an \\nabstraction  of  these  resources.  These  generic  capsules  are \\nspecialized  by  participating \\nthe  execution  of  an \\napplication. The specialization process begins by assigning a \\ndedicated  task  (part  of  the  running  application),  to  the \\ncapsule in the form of an active code variant. The main rule \\nof  the  capsule  is  to  virtualize  the  physical  resources  of  the \\nhost to facilitate the encapsulated code-variant execution.   \\n\\nin \\n\\nFigure 1.   ChameleonSoft Foundation \\n\\nFigure  1 \\n\\nillustrates  ChameleonSoft  foundation \\n\\nthe \\n\\nabstract construction of the capsule.   \\n\\nThe  foundation’s  separation  of  design  concerns  data, \\nlogic  and  physical  resources  enabled  cells  online  re-\\nprogrammability.  The  capsule  can  be  reprogrammed  with \\nnew  tasks  without  worrying  about  the  resources  that  was \\nreserved or the data that is being used by the old task. These \\ndetails  are  seamlessly  and  autonomously  managed  by \\nChameleonSoft management units. \\n\\nThe  capsule  is  composed  of  a  set  of  components \\nillustrated  in  Figure  2.  I  will  brief  the  major  players  in \\nrealizing CBE. \\n\\nThe  execution  unit  autonomously  manages  receiving, \\n\\nterminating, and executing software variants. \\n\\nFigure 2.   The capsule architecture. \\n\\nThe  state  transaction  manager  (STM)  autonomously \\nmanages the execution flow of the current cell variant. Upon \\nchanging  this  variant,  STM  will  seamlessly  maintain  the \\nexecution flow in the correct order.  \\n\\nThe  recovery  and  replication  handles  cell  recovery  and \\nreplication. It cooperates with the data stores and the STM to \\n\\nAuthorized licensed use limited to: Ryerson University Library. Downloaded on May 06,2022 at 21:02:42 UTC from IEEE Xplore.  Restrictions apply. \\n\\n \\n \\n \\n\\x0csafely save the state transitions and cell sensitive data to be \\nused for recovery purposes. \\n\\nThe  capsule  takes  independent  shuffling  decisions  to \\nincrease  the  complexity  of  the  behavior  encryption  module \\nby  more  randomization.  The  Shuffler  unit  is  responsible  of \\nissuing these decisions.  \\n\\nIV.  CHAMELEONSOFT MOVING TARGET DEFENSE \\n\\nAPPROACH  \\n\\nWe  promote  the  novel  moving  target  approach  by \\nChameleonSoft  as  a  defense  mechanism  against  software \\nattacks. Inspired by the chameleon diversity employment for \\ncamouflaging, ChameleonSoft encrypts software behavior by \\nemploying  multidimensional  diversity.  The  outcome  is  a \\ncontinuous  spatiotemporal  change  of  the  network  behavior \\nto, in effect, move the attack target away from the attacker. \\nOur  system  is  equipped  with  an  autonomous,  situational \\naware,  multi-mode  failure  recovery  mechanisms.  Such \\nrecovery  mechanisms  enhance  the  system  resilience  against \\nboth intentional and un-intentional failures.   \\n\\nA.  Behavior encryption \\n\\nthe \\n\\nTypical encryption entails transforming the plain text into \\ninterceptor.  Strong \\nto \\nan  unrecognizable  message \\nencryption  schemes  have  two  major  properties  namely \\nconfusion  and  diffusion.  The  confusion  property  virtually \\nprohibits interceptors from predicting the ciphertext resulting \\nfrom  changing  one  character  in  the  plaintext.  An  effective \\nconfusion  is  enforced  via  a  complex  functional  relationship \\nbetween the plaintext, key pair and the ciphertext. Confusion \\naims  at  maximizing  the  time  that  the  attacker  consumes  to \\ndetermine the relationship between the plaintext and the key \\npair.    Diffusion  is  the  other  property  of  strong  encryption \\nschemes. Diffusion enables the cipher to spread the plaintext \\ninformation over the entire ciphertext so that the changes in \\nthe plaintext affect many parts of the ciphertext [10].  \\n\\nBehavior  encryption  in  ChameleonSoft  is  analogous  to \\ntypical  encryption  in  the  way  it  exhibits  the  confusion  and \\ndiffusion  properties.  ChameleonSoft  induces  confusion  by \\ndynamically changing the behavior of the executing software \\nvariant  using  runtime  shuffling  of  code  variants.  The \\ndynamic  software  behavior  change  makes  it  more  difficult \\nfor an attacker to generate a profile with the possible flaws of \\nthe  executing  variant.  The  shuffling  pattern  is  a  supervised \\nreflection  for  the  continuous  change  in  the  environs.    In \\nChameleonSoft, an effective confusion is determined by how \\ncomplex  to  correlate  the  change  in  the  output  behavior \\nrelative to a single induced change in the environment.   \\n\\nFigure 3.   CBE Encryption Process  \\n\\nChameleonSoft induces diffusion by generating a random \\nvirtually intractable significant change in the spatiotemporal \\n\\nnetwork behavior using the cell independent decision making \\ncapability.  Each cell in the network takes its own shuffling \\ndecision  regarding  when  to  shuffle  the  current  variant,  the \\nshuffling  frequency,  and  the  variant  selection  for  the  next \\nshuffle. These decisions are guided by a continuous feedback \\nfrom  the  situational  awareness  units  that  monitor  the  cell \\nsurroundings  and  the  shuffling  policy.  Figure  3  illustrates \\nChameleonSoft behavior encryption process. \\n\\nFor  example,  an  attacker  might  be  able  to  induce  a \\nchange  in  the  system  surroundings  “like  overloading  the \\nnetwork”  to  force  the  system  to  shuffle  the  currently \\nexecuting  variant.  The  cells  close  to  the  induced  event \\nchange their variant set to target a different quality attribute \\n(e.g.  performance)  that  suits  the  induced  change  in  the \\nenvironment.  Further,  an  alert  is  announced  based  on  a \\npredetermined announcement policy to other remote cells to \\ninform them about that event. Based on that announcement, \\nthese  cells  make  independent  shuffling  decisions  regarding \\ntheir  currently  executing  variants.  Those  who  decide  to \\nshuffle shall replace the current variant by another one from \\nthe  same  set  to  preserve  their  previously  targeted  quality \\nattribute. These independent decisions make the attack target \\n“a  flaw  in  a  specific  variant”  in  continual  random  motion \\nevading attacks. \\n\\nWe propose a variant layout randomization technique to \\nincrease the level of CBE’s confusion induction. The system \\nassigns the variant shuffling index based on a predetermined \\nsequence.    Variants’  indices  are  shuffled  internally  within \\neach  cell  based  on  a  cell  independently  generated  random \\nnumber that changes over time. This random number is used \\nto  shift  the  next  executing  variant  selection  index  to  a \\nrandom location in the variant layout space.  \\n\\nSoftware behavior encryption by runtime hot shuffling of \\nsoftware variants is a realization of ChameleonSoft temporal \\ndiversity.  ChameleonSoft \\nrealizes  space  diversity  by \\nseamlessly  moving  the  cell  at  runtime  among  different \\nphysical hosts. During this process, the COA autonomously \\nmaintains  communications,  cell  sensitive  data,  and  state \\nlogic.  \\n\\nChameleonSoft can follow different shuffling policies at \\nruntime  to  suit  the  dynamic  change  in  the  surrounding \\nenvironment. A policy change might induce a change in the \\nshuffling  frequency  for  more  security,  or  the  shuffling \\norientation  to  favor  time  over  space  diversity  or  vice  versa. \\nChameleonSoft can use space diversity only mode to encrypt \\nthe  software  behavior  of  legacy  software  packages  that \\ncannot  be  chameleon-ized  (by  enabling  check-pointing).  In \\nthis  case  ChameleonSoft  will  deploy  multiple  remote \\nreplicas  for  the  cells  executing  such  legacy  packages.  All \\nreplicas will receive same inputs, communication redirection \\nbetween  cells  output  ports  will  be  used  to  achieve  space \\ndiversity among these replicas. Software chameleonization is \\nbeyond  the  focus  of  this  paper,  we  intended  to  present  the \\ndetails of this process in our sequel papers.  \\n\\nThe  overall  diversity  induced  by  our  system  can  be \\nexpressed in the form of X missions represented in Y roles. \\nThese  roles  are  played  by  M  organisms,  composed  of  K \\ncells.  Each  cell  has  P  quality  attribute  sets  containing  Z \\n\\nAuthorized licensed use limited to: Ryerson University Library. Downloaded on May 06,2022 at 21:02:42 UTC from IEEE Xplore.  Restrictions apply. \\n\\n \\n\\x0cchange in the network. Each of these sets contains a group of \\nsimilar  functionally  different  behavior  variants.  After \\nautomatically  deploying  these  capsules,  our  attack  event \\ngenerator  produces  different  events  following  the  user \\npredetermined settings. \\n\\nThe  variant  shuffling  at  each  cell  works  seamlessly  for \\nconfusion  induction.  The  set  shuffling  occurs  only  in \\nresponse to an induced change in a specific network location. \\nFurther,  independent  variant  shuffling  decision  is  taken  at \\nrandom  locations  to  increase  the  level  of  behavior  change \\ndiffusion all over the network. \\n2)  Simulation Results: \\n\\nWe  examined  the  behavior  encryption  module  through \\nthree  experiments  with  different  simulation  parameter \\nvalues.  The  conducted  experiments  aimed  to  measure  the \\neffect  of  changing  attack  arrival  rate  and  location  with  the \\nchange of shuffling event generation on the behavior output \\nas  illustrated  in  Figure  4.  The  effect  of  continuous  variant \\nshuffling  with  our  diffusion  induction  mechanism  on  the \\noutput  behavior  was  obvious.  A  simple  change  in  any  of \\nthose inputs leads to a significant change in the output. Our \\nprimary  goal  in  this  study  is  to  illustrate  the  effect  of  our \\nbehavior  encryption  on  the  network  behavior  after  attack \\nevents.  This  study  focuses  only  on  the  security  analysis  of \\nthe  system  by  showing  the  avalanche  effect  percentage  and \\nthe  induced  level  of  induced  confusion  and  diffusion. \\nPerformance  analysis  will  be  discussed \\nthe  next \\nsubsection.  \\n\\nin \\n\\nFigure  4A  gives  a  snapshot  on  the  set  and  variant \\ndistribution  over  the  cells  at  the  bootstrap.  Each  column \\nrepresents  a  cell  in  the  network  where  the  value  represents \\nthe current executing set index or variant index. In Figure 4B \\nwe  illustrate  the  behavior  output  after  short  period  of \\ncontinuous  behavioral  encryption  for  the  three  experiments. \\nWe notice that the behavior changes are diffused all over the \\nnetwork.  This  can  be  seen  by  the  massive  change  in  the \\nbehavior of the whole network by the end of the experiment. \\n\\nsoftware  variants,  to  be  executed  on  Q  nodes  all  over  the \\nnetwork with average of R shuffling events/sec.  \\n\\nOur  current  work  focuses  on  the  behavior  encryption \\nthrough  hot  shuffling  of  software  variants.  We  anticipate \\nemploying  the  variant  generation  process  of  [8]  for  an \\nautomated  variant  generation.  Also  functional programming \\ntools are helpful in manually generating these variants. \\n\\nV.  CHAMELEONSOFT EVALUATION \\n\\nWe  use  simulation \\n\\nthe  security  and \\nperformance  of  ChameleonSoft.  Further,  we  developed  a \\nprototype as a step towards realizing the proposed system.  \\n\\nto  evaluate \\n\\nA.  Security analysis \\n\\nWe  simulated  the  behavior  encryption  module  using \\nMatlab to assess the provisioned level of security. We mainly \\nmeasure the avalanche effect percentage as a reflection of the \\ninduced level of induced confusion and diffusion to quantify \\nthe \\nstrength  of  ChameleonSoft  behavior  encryption \\nmechanism.  Table  I  shows  the  parameters  used  in  the \\nsimulation.  The  network  parameters  are  mainly  static \\nparameters  used  to  setup  the  experiments.  The  shuffling \\nevent parameters represent the spatiotemporal distribution of \\nshuffling commands to induce confusion while the attack or \\nchange  in  environment  parameters  show  the  spatiotemporal \\ndistribution  of  attack  events  and  the  event  type  that \\nnecessities  variant  set  change  to  respond  to  the  change. \\nEvents  shuffling  variants  selection  parameters  represent  the \\nselection criteria of the next variant to be shuffled while the \\nindependent  shuffling  decision  on  each  cell  parameter \\nrepresents  when  the  cell  should  take  shuffling  decision  for \\ndiffusion induction.   \\n\\nTABLE I.  \\n\\nSIMULATION PARAMETERS \\n\\nClassificatio\\nn \\n\\nNetwork \\n\\nParameter \\n\\nNetwork size \\n\\nEvent \\n\\nTiming \\n\\n# shuffling variants in \\neach set \\n# shuffling  sets \\nExp_Time \\nNormal \\nShuffling \\nevent \\nAttack or \\nchange in \\nenvironm\\nent event \\n\\nLocation  Normal \\nTiming \\n\\nLocation  Normal \\nType \\n\\nStatic \\nStatic \\nPoisso\\nn \\n\\nPoisso\\nn \\n\\nUnifor\\nm \\nUnifor\\nm  \\nUnifor\\nm \\n\\nSoftware \\n\\nShuffling \\n\\nShuffling Variants \\nSelection \\nIndependent  shuffling \\ndecision on each cell \\n\\nP_Typ\\ne \\nStatic \\n\\nStatic \\n\\nRun1  Run2 Run3\\n\\n10*1\\n0 \\n8 \\n\\n10*1\\n0 \\n8 \\n\\n10*1\\n0 \\n8 \\n\\n5 \\n15 \\n20 \\n\\n10,2 \\n21 \\n\\n11,3 \\n10 \\n\\n10 \\n\\n10 \\n\\n5 \\n15 \\n18\\n\\n8,3\\n20 \\n\\n9,4 \\n10 \\n\\n10 \\n\\n10 \\n\\n5 \\n15 \\n16\\n\\n6,5\\n21 \\n\\n10,2 \\n10 \\n\\n 10 \\n\\n10 \\n\\n1)  Simulator Design: \\n\\nWe  devised  a  capsule  representation  to  simulate  the \\nbehavior  encryption  module.  Our  simulator  starts  by \\ndeploying  capsules  all  over  the  network  based  on  the  input \\nparameters. Each capsule should have a representation for a \\ngroup  of  software  variant  sets  for  each  possible  induced \\n\\nFigure 4.   CBE cyphering effect on the network behavior  \\n\\nFurther, we used the Avalanche Effect Percentage (AEP) \\nas  an  indicator  of  how  secure  ChameleonSoft  can  be  in \\ncomparison with a set of well know cyphering mechanisms. \\nHigh AEP is an indication of a massive change in cipher text \\n\\nAuthorized licensed use limited to: Ryerson University Library. Downloaded on May 06,2022 at 21:02:42 UTC from IEEE Xplore.  Restrictions apply. \\n\\n \\n \\n \\n \\n \\n\\x0cin  response  to  a  minor  change  in  the  plaint\\ncalculated as follows: \\n\\ntext.  The  AEP  is \\n\\nconsider  using  the  right  resources  a\\nbalancing the security and performan\\n\\nat  the  right  time  towards \\nnce output of the system. \\n\\nAEP= N(cid:2931)(cid:2923)(cid:2912)(cid:2915)(cid:2928) (cid:2925)(cid:2916) (cid:2912)(cid:2919)(cid:2930)(cid:2929) (cid:2913)(cid:2918)(cid:2911)(cid:2924)(cid:2917)(cid:2915)(cid:2914) (cid:2919)(cid:2924) (cid:2913)(cid:2919)(cid:2926)(cid:2918)(cid:2915)(cid:2928) (cid:2930)(cid:2915)(cid:2934)(cid:2930)\\n\\n(cid:3021)(cid:3042)(cid:3047)(cid:3028)(cid:3039) (cid:3041)(cid:3048)(cid:3040)(cid:3029)(cid:3032)(cid:3045) (cid:3042)(cid:3033) (cid:3029)(cid:3036)(cid:3047)(cid:3046) (cid:3036)(cid:3041) (cid:3030)(cid:3036)(cid:3043)(cid:3035)(cid:3032)(cid:3045) (cid:3047)(cid:3032)(cid:3051)(cid:3047)\\n\\n(cid:1499) 100 \\n(cid:1499)\\n\\nFor the test we use a common plaintext s\\nfor AES we use 128 bit .In order to conduct \\nWe  ran  this  experiment  for  multiple  ro\\nthat  38  bit  change  is  the  average  number  o\\nnetwork  behavior  for  cipher  text  in  respon\\nsingle  bit  in  the  plain  text  giving  an  AE\\nshown in Figure 5. \\n\\nsize 64 bit except \\nthis comparison  \\nounds;  we  found \\nof  changes  in  the \\nnse  for  changing \\nEP  of  59.38%  as \\n\\nFigure 5.   The Avalanche Effect Perce\\n\\nentage \\n\\nAs  illustrated  in  Figure  5,  ChameleonS\\nAEP  that  exceeds  the  AEP  provided  by  th\\nwas  very  close  to  the  AEP of  the  AES. Th\\nbehind  this  comparison  is  to  show  that  C\\nuntraceable  changes  in  the  cypher  making\\nattacker  to  conduct  a  successful  attack  on \\nsoftware.   \\n\\nSoft  provided  an \\nhe  DES,  while  it \\nhe  main objective \\nCBE  can  induce \\n  it  harder  for  an \\na  CBE  protected \\n\\nB.  Performance Analysis \\n\\nIn  this  section,  we  scrutinize  an  analyti\\nperformance  aspects  of  ChameleonSoft.  T\\nstudy  is  to  estimate  the  computational  co\\nsystem resilience in regards to the task comp\\n\\nical  study  on  the \\nThe  goal  of  this \\nost  of  enhancing \\npletion time. \\n\\nFigure 6.   CBE effect on the task complet\\n\\ntion time  \\n\\nFigure  6  illustrates  that  increasing  the \\nconfusion  by  increasing  the  frequency  of  s\\nenhancing  the  level  of  provisioned  security\\nthe  task  completion \\ntime.  Similarly,  c\\ncorrelation  between  the  input  and  output  n\\nby  employing  both  the  temporal  and  spa\\nmore time to the overall task completion tim\\nbefore  ChameleonSoft  is  capable  of  chang\\nappliance  technique  at  runtime  to  suit \\napplic\\nenvironment \\nrequirements. The reason behind enabling s\\nprovide  some  guarantees  that  the  syste\\n\\nlevel  of  induced \\nshuffling  towards \\ny  linearly  affects \\ncomplicating \\nthe \\nnetwork  behavior \\nace  diversity  add \\nme. As mentioned \\nging  its  diversity \\nthe  surrounding \\ncation  dynamic \\nsuch feature is to \\nem  shall  always \\n\\nchange \\n\\nand \\n\\nthe \\n\\nVI.  CONCLU\\n\\nUSION \\n\\nIn  this  paper,  we  proposed  Cha\\ntarget  defense  against  software \\nleveraged its elastic foundation to e\\nspatiotemporal diversity and hot shu\\neffecting  software  execution  b\\nprototype  implementation,  and  pe\\nevaluation  were  presented  .The  st\\ncould  encrypt  the  execution  beha\\ndiffusion  induction  at  a  reasonab\\nseveral  interesting  challenges  to  be\\ninclude  autonomous  detec\\nThese \\nbehavior; adjusting shuffling decisio\\nsoftware  chameleon-ization \\nincl\\nautomated  variant  generation  s\\nalternatives  for  legacy  non  chamel\\nsimulation  and  exper\\nrigorous \\nconfusion, diffusion and shuffling po\\n\\nameleonSoft  as  a  moving \\nattacks.  ChameleonSoft \\nemploy multidimensional \\nuffling of variants, hence \\nehavior  encryption.  A \\nerformance  and  security \\ntudies  showed  that  CBE \\navior  by  confusion  and \\nble  overhead.  There  are \\ne  addressed  in  the  future. \\nction  and  profiling  of \\nons based on that profile; \\nluding \\nformalizing  an \\nystem,  and  presenting \\neon-izable  software;  and \\nrimental  evaluation  of \\nolicies. \\n\\nACKNOWLE\\n\\nEDGMENT \\n\\nThe author wish to thank ENG. \\nin the figure formulation and represe\\n\\nMona Salah for her help \\nentation.  \\n', 'UK cyber security and \\n\\ncritical national infrastructure protection\\n\\nKRISTAN STODDART*\\n\\nDavid Cameron,  then the  British Prime Minister, stated in his foreword to the \\nUK’s 2015 Strategic Defence and Security Review (SDSR) that one of the priori-\\nties for Britain should be to ‘remain a world leader in cyber security and ensure \\nwe have the capability to respond rapidly to crises as they emerge’.1 This article \\nanalyses how the British government is handling the threats the UK is now facing \\nat the high end of the cyber-security spectrum through potential attacks on UK \\ncritical national infrastructure (CNI).\\n\\nThe  article  will  proceed  in  two  stages.  First,  it  will  look  at  the  public  and \\nprivate organisations and mechanisms that have been put in place to try to build \\ncyber-resilience for CNI within the UK. Second, it will question whether these \\nare  sufficient  to  deal  with  the  depth  of  the  problems  now  facing  the  UK,  and \\nmany  other  countries,  in  protecting  their  computer-controlled  CNI  assets.  In \\ndoing so it will offer a series of recommendations to help increase CNI resilience, \\ngiven that  mainstream policy  debates tend  to subsume CNI  vulnerabilities  into \\nmuch broader discussions of cyber security and cybercrime when CNI protection \\ndeserves considered and focused debate.2\\n\\nOutlining the threats\\n\\nTraditional  forms  of  authority  and  power  in  the  UK  are  vested  in  parliament, \\nthe judiciary, the police force and the military. Each is under challenge in cyber-\\nspace. The British government is largely unable to exercise sovereign control of \\n\\n*  This work is funded and supported by the SCADA-CSL programme of Airbus Group Endevr Wales, a joint \\nresearch funding initiative of Airbus Group and the Welsh government. I wish to thank my partners on this \\nproject who have facilitated this programme of work and helped enormously with the research underpinning \\nthis article. They are: Dr Kevin Jones, who put together this project at Airbus Group Innovations; Hugh \\nSoulsby,  also  of  Airbus  Group  Innovations;  Professor  Andrew  Blyth  and  Peter  Eden  of  the  University  of \\nSouth Wales; and Dr Peter Burnap and Dr Yulia Cherdantseva of Cardiff University. All are most valued \\ncolleagues on the SCADA Cyber Security Lifecycles Project that has funded and enabled this article and our \\nrelated research. I also wish to thank the anonymous peer reviewers for this journal for helping make this a \\nsharper and more comprehensive article, and Professor Andrew Dorman for his support as Commissioning \\nEditor of International Affairs.\\n\\n\\n\\x0cUK cyberspace as it is unbounded by geographical constraints. The 2015 SDSR \\nrightly  highlighted  that:  ‘The  range  of  cyber  actors  threatening  the  UK  has \\ngrown.  The  threat  is  increasingly  asymmetric  and  global.’3  There  are  few  clear \\nand unambiguous norms, rules and regulations in cyberspace, and the legal and \\ngovernance frameworks currently in place are contested.4 As noted above, this is \\nnot UK-specific but a global problem; the Deputy Director of the US National \\nSecurity Agency (NSA), Richard Ledgett, publicly outlined these jurisdictional \\ndifficulties in an interview with the BBC in October 2015.5\\n\\nCurrent cyber norms, rules and regulations are rooted at the national level and \\ninclude laws governing what can or cannot be said or done on social media such \\nas Twitter and Facebook. These have had to be updated or enacted as technology, \\nand  the  take-up  of  that  technology,  evolve  and,  as  they  do  so,  change  social, \\npolitical  and  security  dynamics.  This  is  a  fluid  and  dynamic  environment  and \\nthe law, whether national or supranational, is constantly playing catch-up with \\ntechnology and what technology enables. Through this process of technological \\ninnovation and take-up:\\n\\nanyone  with  a  laptop  and  a  network  connection  can  transmit  information,  whether \\n‘one-to-one’  or  ‘one-to-many’,  effectively  globally  and  instantaneously  in  a  variety  of \\nforms; process information ... easily and cheaply with standard commercial software; and \\nstore information in vast quantities indefinitely on cheap, miniature and portable digital \\ndevices, or in the ‘cloud’, independent of any particular device.6\\n\\nWithin this rapidly evolving context it is clear that the British government at \\nboth national and regional levels is faced with a series of mounting difficulties in \\nattempting to manage an ever-growing and deepening number of cybercrimes and \\ncyber breaches, now seen every day in the UK and across the globe. The range \\nof these is accelerating, promoted both by the expansion and low entry costs of \\ncomputer technology and by the benefits this bestows and the malicious activi-\\nties it enables in the ever-growing ‘Internet of Things’, which refers to the mass \\nproliferation of sensors, devices and smart products, used to gather and transmit \\ndata over the Internet. \\n\\nThe  actors  behind  these  crimes  and  breaches  are  both  foreign  and  domestic. \\nThey  range  from  ‘script  kiddies’—(predominantly)  young  people  engaging  in \\nillegal  activities  ranging  from  probing  organizations  to  distributed  denial  of \\nservice attacks, either singly or through collectives such as the ‘hacktivist’ group \\n‘Anonymous’—through to sophisticated hackers and crackers who could repre-\\n\\n\\n\\nThe exercise of such authority and control is problematic given that the internet \\nhas  no  geographical  borders  and  domestic  state  intrusion  is  widely  resisted  (as \\nevidenced  in  the  wake  of  the  PRISM  mass  surveillance  programme  and  polar-\\nizing  views  of  the  whistleblower  and  ex-NSA  contractor  Edward  Snowden). \\nThe  internet  can  be  policed  only  weakly,  owing  to  the  sheer  volume  of  traffic \\n(Big Data and associated metadata), and a series of political, social and legal issues \\nsurrounding norms and jurisdictions. As Jamie Bartlett notes in his book on the \\nhidden ‘dark net’, ‘the battle for ideas, influence and impact is moving online’ (and \\nis particularly active among extremist groups).8 \\n\\nPlacing these observations in a wider context, Betz and Stevens argue that in \\nterms  of  ‘cyber  war’,  ‘Perhaps  the  most  persistent  concern  ...  is  the  idea  that \\nit  [the  cyber  realm]  deepens  asymmetries  of  power  between  strong  states  and \\nweaker  states,  and  between  all  states  and  some  “super-empowered”  non-state \\nactors ... as David proved against Goliath, strength can be beaten.’9 Such ‘David \\nand Goliath’ metaphors draw their basis from the huge extent of reliance upon \\ncomputer technology in developed states. This dependence, and the concomitant \\nvulnerability to cyber attack, is at its most potent in relation to Industrial Control \\nSystems (ICS)—particularly SCADA (Supervisory Control and Data Acquisition) \\nsystems.  They  are  a  deeply  embedded  and  longstanding  technology  in  the  UK \\nand many other developed states, dating back to the 1940s. Many SCADA systems \\nhave been in place since the 1980s and 1990s, when the internet was in its infancy \\nand  computer  security  not  an  acute  consideration.  Today,  the  situation  is  very \\ndifferent.  Attacks  on  these  computer-controlled  industrial  systems  could  cause \\nelectricity blackouts and water shortages, or disrupt financial services. Now there \\nare publicly discussed fears of a ‘cyber Pearl Harbor’, a ‘cyber 9/11’ or even a state-\\nwide  ‘Cybergeddon’  attack,  aimed  at  crippling  or  seriously  damaging  a  nation, \\nwhich could cascade to other states through attacks on CNI.10\\n\\nThe UK’s national infrastructure is defined by the government as: \\n\\nthose  facilities,  systems,  sites  and  networks  [physical  and  electronic]  necessary  for  the \\nfunctioning of the country and the delivery of the essential services upon which daily life \\nin the UK depends ... There are certain ‘critical’ elements of national infrastructure that \\nif lost would lead to severe economic or social consequences or to loss of life in the UK. \\nThese critical elements make up the critical national infrastructure (CNI).11\\n\\nUK cyber security and critical national infrastructure protectionInternational Affairs 92: 5, 2016Copyright © 2016 The Author(s). International Affairs © 2016 The Royal Institute of International Affairs.\\x0cThe  potential  for  disruption  or  damage  of  CNI  was  recognized  by  the  2015 \\nSDSR, which reasserted cyber attacks as a Tier One threat to national security. \\nIt warned that:\\n\\nGrowing numbers of states, with state-level resources, are developing advanced capabili-\\nties which are potentially deployable in conflicts, including against CNI and government \\ninstitutions. And non-state actors, including terrorists and cyber criminals can use easily \\navailable cyber tools and technology for destructive purposes.12 \\n\\nUK central government organizations and responsibilities\\n\\nUK  central  government  departments  and  agencies,  including  the  Ministry  of \\nDefence (MoD), work with other governments across a range of common issues. \\nFor the MoD these channels of collaboration include the Foreign and Common-\\nwealth  Office’s  (FCO’s)  International  Cyber  Policy  Unit  and  NATO;13  at  the \\nEuropean  level  they  include  the  European  Network  and  Information  Security \\nAgency (ENISA).14\\n\\nDomestically there is little direct ‘governance’ of CNI in the UK comparable \\nto  the  way  nationalized  industries  were  run  centrally  by  government  prior  to \\ntheir privatization during the 1980s and 1990s. Instead, as CNI is largely owned \\nand operated by private industry, its governance resembles more a form of macro-\\nmanagement in terms of oversight and regulation, similar to the way the National \\nHealth Service and National Rail are now run. Micro-management in the nine \\nsectors that comprise CNI (communications, emergency services, energy, financial \\nservices, food, government, health, transport, water), each of which constitutes \\na large and complex set of organizations with enormous budgets, is undertaken \\nthrough  regulation  and  oversight  via  formal  and  informal  statutory  regulators \\nand legal bodies. This is in line with neo-liberal practices that promote minimum \\nstate intervention. \\n\\nActivities to combat threats to SCADA and other ICS embedded across industries \\nare currently overseen in the UK by a national Computer Emergency Response \\nTeam  (CERT-UK)  established  in  2014,  along  with  the  Government  Computer \\nEmergency Response Team, whose task is to provide warnings, alerts and assis-\\ntance to public-sector organizations. CERT-UK is one of many such bodies that \\nhave been set up by national governments. It is designed to ‘work closely with \\nindustry, government and academia to enhance UK cyber resilience’.15 Another \\ninitiative was the formation of the Cyber Security Information Sharing Partner-\\n\\non improving the resilience of critical infrastructure to disruption from natural hazards (London, March 2010), p. 8, https://\\nwww.gov.uk/government/uploads/system/uploads/attachment_data/file/62504/strategic-framework.pdf. \\n\\n\\nCiSP is now a part of CERT-UK. CiSP was launched in March 2013 and is a joint, collabo-\\nrative initiative between industry and government to share cyber threat and vulnerability \\ninformation in order to increase overall situational awareness of the cyber threat and there-\\nfore reduce the impact upon UK business ... CERT-UK will be able to add the day to \\nday experience of working with critical national infrastructure companies in handling the \\nincidents they face alongside\\xa0the international dimension.17\\n\\nIn addition, the CiSP forums (which were established in the run-up to the 2014 \\nCommonwealth Games in Glasgow and that year’s NATO summit in Newport, \\nWales) are intended to become ‘permanent hosts for such information sharing in \\nScotland and Wales’.18 These programmes of work and education were augmented \\nin June 2014 with the launch of ‘Cyber Essentials’, which is intended to be\\n\\na  major  new  Government-backed  and  industry  supported  scheme  to  incentivise \\nwidespread  adoption  of  basic  security  controls  that  will  help  to  protect  organizations \\nagainst the commonest kind of internet attacks. The scheme is constructed to be affordable \\nand practical for all firms, small as well as large. Certification comes with a badge which \\nfirms can use to help demonstrate their security credentials to customers and investors, \\nand which insurers can take into account when considering firms for relevant insurance \\npolicies.19\\n\\nIt is run by the Government Communications Headquarters (GCHQ), the Depart-\\nment for Business, Innovation and Skills (BIS)20 and the Cabinet Office, and also \\nseeks to improve cyber-security risk management and companies’ ability to take \\nout insurance against cyber attacks.21 \\n\\nIn the attempt to keep up to date with the multiplying cyber threats Britain \\nfaces, CERT-UK works with a number of other agencies—some public sector and \\nsome private. Also, working with Britain’s allies (particularly the United States) \\nto combat cross-border threats, it ‘oversees a programme of exercises to support \\ncritical sectors in preparing for the potential impact of a destructive cyber attack’, \\nincluding through the Heartbleed and Shellshock vulnerabilities.22\\n\\nActivities  to  combat  serious  crime  are  undertaken  by  the  National  Crime \\nAgency  (NCA),  established  in  October  2013,  which  now  incorporates  legacy \\norganizations  including  the  National  Cyber  Crime  Unit  (NCCU),  the  Police \\ne-Crime Unit and the Serious Organized Crime Agency (SOCA).23 The NCCU \\n\\n16  Cabinet Office, The UK Cyber Security Strategy: report on progress and forward plans December 2014 (London, Dec. \\n2015),  p.  5,  https://www.gov.uk/government/uploads/system/uploads/attachment_data/file/386093/The_\\nUK_Cyber_Security_Strategy_Report_on_Progress_and_Forward_Plans_-_De___.pdf. \\n\\n\\nUK cyber security and critical national infrastructure protectionInternational Affairs 92: 5, 2016Copyright © 2016 The Author(s). International Affairs © 2016 The Royal Institute of International Affairs.\\x0c‘brought together specialists from the Police Central e-Crime Unit in the Metro-\\npolitan Police Service and SOCA Cyber to create expert technical, tactical intel-\\nligence and investigation teams’.24 These bodies work with GCHQ ‘to develop the \\nskills and technology required to combat elite cyber crime threats to the UK’.25 \\nThere are also nine Regional Organized Crime Units (ROCUs), each of which \\nhas a dedicated cybercrime unit. This also includes Operation Falcon (Fraud and \\nLinked Crime Online) within the Metropolitan Police—the largest of the UK’s \\n48 police forces and the lead force for cybercrime.26 The remit of Falcon, a joint \\noperation by the Fraud Squad and the Met’s cybercrime unit, is ‘to disrupt and \\narrest cyber criminals attacking London businesses’.27 In addition the NCCU has \\naugmented its activities overseas to work with Europol, US agencies and Interpol \\nto  understand  the  global  cybercrime  threat,  coordinate  activity  against  priority \\nthreats and develop relationships with international partners to support coopera-\\ntion on prosecutions, including posting officers overseas.28\\n\\nWith the vast majority of cybercrime emanating from abroad, more needs to be \\ndone, including through the ‘Cyber Streetwise’ public awareness campaign.29 The \\navailability of inexpensive software, and of online evasion software and tactics on \\nthe internet, makes it difficult for the police to track and trace cybercrime, and \\nthey have to assess whether they are able to pour scarce resources into difficult \\nprosecutions.30  The  use  of  The  Onion  Router  (TOR)  and  proxy  servers  only \\ncompounds the problems facing the police and intelligence agencies in terms of \\nidentification/attribution and prosecution, as does the growing use of encryption \\nby major technology companies.31 As the police might well be tasked as one of the \\n‘first responders’ to any industrial emergency, their role is important, but they are \\nunder-resourced and they do not appear to have received any new money from \\nthe SDSR.32 This deficiency needs to be addressed.\\n\\nThe UK government tasked the ROCUs with sharing cyber-security informa-\\ntion regionally to assist local businesses to protect themselves from cybercrime. \\nThis information-sharing operation, carried out in conjunction with CERT-UK, \\n\\nalso  NCA,  ‘Working  in  partnership’,  http://www.nationalcrimeagency.gov.uk/about-us/working-in-part-\\nnership.\\n\\nKristan StoddartInternational Affairs 92: 5, 2016Copyright © 2016 The Author(s). International Affairs © 2016 The Royal Institute of International Affairs. \\x0cbegan in the east Midlands and south-east of England in August 2014 as part of \\nCiSP.  The  global  context  for  these  efforts  is  illustrated  by  Verizon’s  2014  Data \\nBreach  Report  demonstrating  the  wide  range  of  sectors  and  businesses  being \\nattacked and how they are being attacked.33 Notwithstanding the policies set out \\nin the 2015 SDSR, which will require time to mature, current government and \\npolice action has not stopped UK organizations and UK-based companies from \\nbeing hacked. \\n\\nAmong  organizations  attacked  in  this  way  are  internet  service  providers: \\nfor  example,  in  October  2015  TalkTalk’s  unencrypted  customer  data,  including \\naddresses  and  banking  details,  were  compromised  with  simultaneous  financial \\nreputational damage, including an immediate 10 per cent dip in share value. These \\nhacks produce a wider loss of confidence in business dealings over the internet and \\nexact  unwelcome  costs  to  business  in  insuring  against  malicious  cyber  breaches \\nand the range of threats and risks. It is perhaps no surprise that business leaders \\nare calling on the government to do more while recognizing that this is mainly a \\ncorporate responsibility. With the 2015 SDSR making clear that the government \\nwill seek to help companies secure their data, it remains to be seen what further \\nbreaches will occur and where blame will be directed.\\n\\nThe Institute of Directors has pointed out that ‘only “serious breaches” made \\nthe  headlines,  but  attacks  on  British  businesses  “happen  constantly”’,34  while \\nthe City of London Police Commissioner has stated publicly that 80 per cent of \\ncybercrime goes unreported and ‘cyber-crime could become bigger than the drugs \\ntrade’.35 Cyber attacks already grab headlines and public attention; an attack on \\npublic  utilities  or  financial  services  could  have  far  more  profound  social,  finan-\\ncial and political consequences than any cybercrime yet reported. This is already \\nrecognized by the EU, which is finalizing the Directive on Security of Network \\nand  Information  Systems  (NIS  Directive):  this  requires  CNI  owner–operators \\n‘to adopt risk management practices and report major incidents to the national \\nauthorities’.36\\n\\nAgainst this background, the UK’s 2009 ‘Cyber Security Strategy’ led to the \\nformation of the multi-agency Cyber Security Operations Centre (CSOC) hosted \\nby GCHQ, operating alongside the Communications Electronics Security Group \\n(CESG).37 CSOC is intended to ‘actively monitor the health of cyber space and \\nco-ordinate incident response; enable better understanding of attacks against UK \\n\\n33  Verizon  Data  Breach  Investigations  Report  2014,  26  July  2016,  http://www.nu.nl/files/Verizon.pdf.  These \\nfindings were reconfirmed in Verizon’s Data Breach Investigations Report 2016, 26 July 2016, http://www.\\nverizonenterprise.com/verizon-insights-lab/dbir/2016/.  \\n\\n\\nUK cyber security and critical national infrastructure protectionInternational Affairs 92: 5, 2016Copyright © 2016 The Author(s). International Affairs © 2016 The Royal Institute of International Affairs.\\x0cnetworks and users; [and] provide better advice and information about the risks \\nto business and the public’.38 It is designed: \\n\\nto monitor developments in cyber space (ultimately providing collective situational aware-\\nness), analyse trends, and to improve technical response coordination to cyber incidents ... \\n[for] a better understanding of cyber security risks and opportunities, it will also help to \\nensure coherent dissemination of information across government, industry, international \\npartners, and the public ... [drawing] from across government and key stakeholders.39\\n\\nIt is directed by the Office of Cyber Security and Information Assurance (OCSIA), \\nwhich  in  2010  replaced  the  Office  of  Cyber  Security  (itself  only  established  in \\n2009) and works with government agencies and departments including the Home \\nOffice, MoD, GCHQ, CESG  (which is housed within  GCHQ), the  Centre for \\nthe Protection of National Infrastructure (CPNI), FCO and BIS/BEIS. OCSIA is \\ndesigned to advise the cabinet and National Security Council (NSC) by providing \\nstrategic direction and coordination for government in the field of cyber security \\nand information assurance.40\\n\\nIn  essence  OCSIA’s  remit  is  to  try  to  ‘secure’  the  UK’s  cyberspace.41  This \\nfollows a line of reasoning presented by Betz and Stevens who, in Cyberspace and \\nthe state, argue that cybercrime and hacking represent ‘a significant challenge to \\nstates whose sovereignty and data security are in a state of constant skirmish with \\ncyberspace challengers, whether they be state, non-state or quasi-state’.42 OCSIA \\nbuilt on the UK’s 2011 National Cyber Security Strategy, which had four main \\nobjectives:\\n\\n1)  The UK to tackle cyber crime and be one of the most secure places in the world to do \\nbusiness in cyberspace\\n\\n2)  The UK to be more resilient to cyber attacks and better able to protect our interests in \\ncyberspace\\n\\n3)  The UK to have helped share an open, stable and vibrant cyberspace which the UK \\npublic can use safely and that supports open societies\\n\\n4)  The UK to have the cross-cutting knowledge, skills and capability it needs to underpin \\nall our cyber security objectives.43\\n\\nThe last of these objectives was part of a national education programme begun by \\nthe Cabinet Office and GCHQ through the National Cyber Security Programme \\n\\nKristan StoddartInternational Affairs 92: 5, 2016Copyright © 2016 The Author(s). International Affairs © 2016 The Royal Institute of International Affairs. \\x0c(NCSP).44 The NCSP began in 2011 (and continues to date), with funding of £860 \\nmillion  through  to  2016,  although  the  overall  figure  spent  on  cyber  security  is \\nhigher.45 This £860 million was more than doubled in the 2015 SDSR, and the \\n£1.9 billion  earmarked for  cyber security from 2016 to 2020 heralds the second \\nfive-year National Cyber Security Strategy and NCSP planned to be launched in \\nOctober  2016.46  It  includes  funding  for  offensive  cyber  capabilities  through  the \\nNational Offensive Cyber Programme run jointly by the MoD and GCHQ and \\nfor strengthened computer networks within government. The SDSR also makes it \\nclear that the government intends to be more open in sharing information on cyber \\nthreats, ranging from ‘lone wolves’ to APTs, in partnership with the private sector. \\nSome information will also be shared with NATO and allied nations.47\\n\\nImportantly, given the large number of organizations (a number of which are \\nrelatively recent creations) dealing with cyber security, the SDSR also announced \\nthe establishment of a new National Cyber Security Centre (NCSC). This is to be \\nbased in London but under the leadership of GCHQ. The NCSC is designed to \\n‘manage our future operational response to cyber incidents, ensuring that we can \\nprotect the UK against serious attacks and minimise their impact’.48 It is intended \\nthat  the  NCSC  ‘will  be  the  bridge  between  industry  and  government,  simpli-\\nfying  the  current  complex  structures,  providing  a  unified  source  of  advice  and \\nsupport, including on managing incidents. It will be a single point of contact for \\nthe private and public sectors alike’ and will run CiSP.49 As the then Chancellor \\nGeorge Osborne recognized, ‘we need to address the alphabet soup of agencies \\ninvolved in protecting Britain in cyberspace’.50 \\n\\nDespite ambitions for the NCSC, GCHQ continues to claim the majority of \\ncyber-security funding to ‘provide protection at pace and scale to key networks \\nof  national  significance’.  It  will  share  intelligence  on  state-level  threats  and \\nserious crime through cleared communications service providers to enable early \\nwarning to be given and action to be taken. While the 2015 SDSR suggests that \\nthis information-sharing will now be more forthcoming than formerly,51 much \\nof GCHQ’s work to protect Britain’s CNI from cyber attack remains classified, \\nwith government oversight provided through the parliamentary Intelligence and \\nSecurity Committee. \\n\\n\\nUK cyber security and critical national infrastructure protectionInternational Affairs 92: 5, 2016Copyright © 2016 The Author(s). International Affairs © 2016 The Royal Institute of International Affairs.\\x0cIn addition, a Centre for Cyber Assessment (CCA) was established at GCHQ \\nin  April  2013.  The  CCA,  whose  membership  is  drawn  from  across  government \\ndepartments,  agencies  and  law  enforcement  bodies,  is  the  cyber  equivalent \\nof  the  Joint  Terrorism  Analysis  Centre  ( JTAC).52  It  is  funded  from  the  NCSP \\nand is designed to provide all-source intelligence-driven reports to government \\ncustomers  including  ‘top  industry  bodies  and  companies  as  part  of  our  wider \\nwork  to  protect  British  national  security,  our  citizens  and  businesses’.53  These \\ndialogues with industry are intended to represent a partnership between govern-\\nment, regulators and industry.54\\n\\nThe  government  has  promulgated  a  list  of  ‘10  Steps  to  Cyber  Security’  as \\npart  of  this  programme  in  an  attempt  to  improve  business  awareness  of  cyber \\nrisks.55  Other  initiatives  include  a  cyber  ‘health  check’  for  FTSE350  companies \\nand  guidance  from  BIS  for  the  financial  services  sector  and  for  non-executive \\ndirectors. In addition BIS has hitherto published an annual Information Security \\nBreaches Survey, ‘to assess the level of information security breaches affecting UK \\nbusinesses and raise awareness of the need for industry to take action’. This survey \\nfound that 81 per cent of large organizations and 60 per cent of small organizations \\nreported at least one breach during 2014. These percentages were down from 2013, \\nbut the scale of attacks in terms of cost and severity was higher, with average losses \\nof £65,000–£115,000 reported for small organizations and between £600,000 and \\n£1.15 million for large organizations. Over two-thirds (69 per cent) of company \\nboards now actively assess their cyber-security vulnerabilities, up from 44 per cent \\nin July 2013.56 ‘Cyber’ has long been considered the business of ‘IT departments’, \\nwhich are simply tasked to ‘get on with it’ with minimal board-level involvement. \\nOn the contrary, shared cyber security best practices need to be embedded in the \\nsame way that industrial and workplace safety and security are part of business \\nculture, not an afterthought.\\n\\nGCHQ also certifies companies working in cyber incident response, providing \\nguidance  on  a  ‘bring  your  own  device’  security  policy  which  allows  people  to \\nuse  their  personal  computer  devices  at  work,  and  engages  with  industry  to  try \\nto  ensure  companies  have  cyber-security  products  able  to  defend  against  cyber \\nattack. It does the latter through commercial product assurance, which includes \\npublishing  a  set  of  security  characteristics  for  domestic  equipment  required  for \\nthe UK’s smart metering programme. GCHQ also works with private industry to \\nconduct unclassified research, experimentation and code development.57\\n\\n\\nKristan StoddartInternational Affairs 92: 5, 2016Copyright © 2016 The Author(s). International Affairs © 2016 The Royal Institute of International Affairs. \\x0cCPNI,  meanwhile,  works  in  close  collaboration  with  key  partners  including \\nCESG and the police, including specialist organizations within the police such as \\nthe National Counter Terrorism Security Office (NaCTSO), located within the \\nsame building as CPNI, and the countrywide Counter Terrorism Security Advisor \\n(CTSA) network. CPNI states that: ‘Government departments have lead respon-\\nsibility for ensuring appropriate steps are taken within their sectors to improve \\nprotective security. They also lead on the identification of critical infrastructure \\nwithin their sectors in consultation with CPNI and sector organizations.’58 CPNI \\nidentifies the following government departments as having lead responsibility in \\nthe nine key sectors identified above: \\n\\n•  communications—Department for Business, Innovation and Skills;\\n•  emergency services: \\n\\nAmbulance—Department of Health;\\nFire—Department for Communities and Local Government;\\nMaritime and Coastguard Agency—Department for Transport;\\nPolice—Home Office;\\n\\n•  energy—Department for Energy and Climate Change;\\n•  finance—HM Treasury;\\n•  food—Department  for  the  Environment,  Food  and  Rural  Affairs  and  Food \\n\\nStandards Agency;\\n\\n•  government—Cabinet Office;\\n•  health—Department of Health;\\n•  transport—Department for Transport;\\n•  water—Department for the Environment, Food and Rural Affairs.\\n\\nDespite  these  overarching  roles,  organizations  and  policies,  cyber  attacks \\ncontinue to grow both quantitatively and qualitatively. In terms of CNI vulner-\\nabilities, Misha Glenny notes: \\n\\nCyber weapons are the hacking tools ... to penetrate the computer systems of an enemy’s \\nCNI ... such as their energy and water grids. Once in control of the system ... the cyber \\ncommander  can  order  their  shutdown  (or,  as  we  know  from  Stuxnet,  trigger  a  very \\ndamaging explosion59) so that in a matter of days the affected society will be reduced to \\nStone-Age technology.60 \\n\\nStuxnet was the vehicle for the most widely known, and most widely reported, \\nattack to date on a SCADA system. Stuxnet adversely affected the centrifuges in \\nthe  Natanz  nuclear  processing  plant  in  Iran,  unbeknown  to  the  operators.  The \\nsoftware might have been installed in the plant via a USB device rather than through \\nexternal infection, although later it did ‘escape’ onto the internet, where it can be \\nfurther refined beyond the original intent of its programmers (widely suspected \\n\\n\\x0cto be elements of the Israeli and US intelligence agencies).61 A less widely known \\nbut disturbing attack was made on the SCADA systems of a German steel mill in \\n2014, causing the blast furnace to shut down with massive damage but no loss of \\nlife.62 States can lose control of the coding capabilities of the next generation of \\nStuxnets, which will have the potential to act on a much greater scale, and this \\nposes a proliferation problem.63\\n\\nIn view of the burgeoning threats and potential perpetrators, the current patch-\\nwork quilt of responsibilities and government organizations needs to be coordi-\\nnated through a dedicated and strengthened single body. The 2015 SDSR appears \\nto  intend  the  NCSC  to  be  this  focal  point  for  CNI  protection  and  for  ‘cyber \\nincidents’ more generally. But what now happens to OCSIA and CPNI and the \\nother government organizations with a stake in cyber security? While the creation \\nof a central hub for UK cyber security is to be welcomed, as is the then Chancellor \\nGeorge Osborne’s declared intent (as chair of the cyber subcommittee of the NSC) \\nto make a ‘top priority of cyber security’, it is important to get this right.64 The \\nNational Cyber Security Centre could significantly improve macro-level tactical \\nand strategic oversight, but still the risk remains that there are simply too many \\norganizations dealing with many common issues.\\n\\nThe  Royal  United  Services  Institute  has  also  expressed  concern  that  cyber \\nsecurity in the UK is being dominated by GCHQ. Although there will be ‘repre-\\nsentation from a broad range of stakeholders’ at the NCSC, under the new struc-\\nture  ‘almost  the  entire  focus  of  the  UK  approach  to  cyber-security  [will  be] \\nlocated in GCHQ’. RUSI legitimately questions ‘whether this is entirely helpful’ \\nand calls for ‘further debate’ on the point.65 Although much is yet to be resolved \\nahead of the 2016 National Cyber Security Strategy, this debate should focus on \\nwhere to recruit new blood across a wide spectrum encompassing both technical \\nand  policy worlds,  and  where  to  draw  from  existing expertise,  found  not  only \\nwithin GCHQ, but also in OCSIA, CPNI and other relevant bodies, as well as \\nindustry.\\n\\nIt is commendable that the NCSC is intended to be staffed by ‘series of teams, \\nexpert in the cyber security of their own sectors, from banking to aviation, but \\nable to draw on the deep expertise here [GCHQ], and advise companies, regula-\\ntors, and government departments’.66 Nevertheless, it is worthwhile considering \\nwhether GCHQ is set to become too powerful in the field of cyber security at \\nthe  expense  of  other  agencies  and  other  bodies,  such  as  the  police—especially \\n\\n\\nKristan StoddartInternational Affairs 92: 5, 2016Copyright © 2016 The Author(s). International Affairs © 2016 The Royal Institute of International Affairs. \\x0cwhen the police, and many government departments, have seen their budgets cut \\nthrough financial austerity and spending reviews.\\n\\nCPNI already works closely with OCSIA and CSOC as well as the Civil Contin-\\ngencies Secretariat in the Cabinet Office, ‘which\\xa0works to enhance the UK’s ability \\nto prepare for, respond to and recover from emergencies’.67 Significantly, CPNI also \\nmaintains ‘close relationships with organizations and businesses that own or oper-\\nate\\xa0the national infrastructure. Relationships\\xa0have been built up over many years \\nbetween our experienced security advisers and security managers in the sectors.’68 \\nOn the hardware front, CPNI ‘assures a wide range of physical security products \\ndeveloped by manufacturers for use on critical national infrastructure (CNI) sites ... \\n[and] works with a range of external partners on the development of professional \\nstandards’.69 Domestically, cyber risk is built into departmental risk management \\nas part of each department’s audited Statement of Internal Control.70 Cyber risk \\nreviews for companies operating CNI have also been adopted.71\\n\\nAt  the  global  level,  CPNI  has  a  ‘close  relationship  with  many  international \\npartners, including overseas Governments, agencies and businesses’. This includes \\ncontributing to\\xa0Overseas Business Risk, a joint endeavour run by the FCO, UK \\nTrade and Investment and BIS, providing UK business with information relating \\nto ‘security related risks companies face when operating overseas’.72\\n\\nThe  British  government  also  has  responsibilities  to  its  partners  in  NATO \\nand, until the  UK negotiates withdrawal following the 2016 Brexit referendum,  \\nthe  EU  that  are  described  in  the  MoD’s  Cyber  primer  document  as  complex—\\n‘a complexity aggravated by the need to include national organizations, such as \\ncomputer  emergency  response  teams  (CERTs),  and  national  and  international \\nlegal requirements’.73 This complexity embraces:\\n\\na)  The NATO Communications and Information (NCI) Agency [which] manages those \\nnetworks actually owned by NATO. Formed on 1 July 2012 ... the NCI Agency also has a \\ncoordinating role across individual NATO and NATO-nation CERTs.\\n\\nb)   Cooperative  Cyber  Defence  Centre  of  Excellence  [CCDCOE].  Their  mission  is  to \\nenhance  capability,  cooperation  and  information  sharing  across  NATO,  and  its  nations \\nand partners in cyber defence through education, research & development, lessons-learned \\nand consultation. \\n\\nc)  ENISA. This agency is the European Union focus for technical assistance for the security \\naspects of cyberspace.74\\n\\nThis  tier  of  international  institutions  operates  alongside  national  cyber \\ncommand structures, a number of which are engaged in liaison with the MoD. In \\n\\n\\nUK cyber security and critical national infrastructure protectionInternational Affairs 92: 5, 2016Copyright © 2016 The Author(s). International Affairs © 2016 The Royal Institute of International Affairs.\\x0caddition, there is a series of CERTs operating for national governments, universi-\\nties and within industry—several of which are members of the global, but limited, \\nForum for Incident Response and Security Teams (FIRST).75 \\n\\nThe reasons for attacks on CNI are multifarious; Verizon’s 2014 Data Breach \\nInvestigations Report lists among them the longstanding problem posed by espio-\\nnage.76 This encompasses espionage by states as well as from private companies. \\nThe national interest remains dominant in conceptualizing cyber threats, but as \\nwe all swim in the same information ocean this does not deal sufficiently either \\nwith organized crime, which spans national jurisdictions (including those outside \\nthe EU and North America), or with building trust between states and state organ-\\nizations. This need for ‘building blocks’ at the diplomatic level to establish ‘red \\nlines’ and rules for state behaviour in cyberspace was an issue publicly raised by \\nRichard Ledgett in the October 2015 interview he gave to the BBC.77 In the same \\nmonth, the Director-General of MI5, Andrew Parker, argued that the threat from \\nterrorism stood at its highest level in his 32 years in the service, and that there were \\ngood reasons to increase international state-level collaboration.78\\n\\nThis call for increased state-based collaboration was subsequently incorporated \\ninto the 2015 SDSR, with responsible state-based behaviour in cyberspace champi-\\noned by the ‘London Cyber Process’, which also paid heed to the challenges facing \\nthe current international economic and political order, identified as being ‘driven by \\ndevelopments such as the growing role of non-state actors, the impact of technol-\\nogy and longer-term shifts of economic wealth to the south and east of the world’.79\\nFor the UK, as a global financial and commercial hub, increased transparency, \\ntrust, and cooperation are also important for trade relations.80 This realm encom-\\npasses the series of agreements, to a value of £30 billion, into which Britain has \\nentered with China (including deals on the UK’s next generation of civil nuclear \\npower plants), and which raised concerns that these might provide gateways into \\nstrategic influence over computer-controlled UK CNI.81 With China and Russia’s \\nintelligence agencies both accused of mapping the electricity grids in the United \\nStates and installing software traps which could be used to damage or disrupt their \\nCNI, this concern cannot be easily dismissed, despite Chinese assurances.82 These \\nconcerns  are  sufficient  for  the  new  UK  Prime  Minister,  Theresa  May,  to  delay \\nthese civil nuclear deals with China while the government re-examines them.83\\n\\n\\nAs outlined above, part of the protective barrier for CNI comes in the form of \\ndata  collection  by  the  UK’s  intelligence  agencies:  these  comprise  the  Security \\nService  (MI5),  the  Secret  Intelligence  Service  (SIS/MI6)  and  GCHQ,  with  SIS \\nand  GCHQ  reporting  to  the  Foreign  Secretary.84  MI5  is  primarily  responsible \\nfor  combating  domestic  and  international  terrorism  and  for  counter-espionage, \\ncounter-proliferation and protective security and reports to the Home Secretary \\nbut it is not part of the Home Office.85 The mainstay of MI6’s remit is to collect \\nsecret  intelligence  and  mount  ‘covert  operations  overseas  in  support  of  British \\nGovernment objectives’ relating to British foreign and defence policy, the UK’s \\neconomic well-being, and the prevention and detection of serious crime.86\\n\\nAs Alex Younger, the current head of MI6, warned in March 2015: ‘Using data \\nappropriately  and  proportionately  offers  us  a  priceless  opportunity  to  be  even \\nmore deliberate and targeted in what we do and thus be better at protecting our \\nagents  and  this  country.’  He  went  on  to  caution:  ‘That  is  good  news.  The  bad \\nnews is that the same technology in opposition hands, an opposition often uncon-\\nstrained by consideration of ethics and law, allows them to see what we are doing \\nand put our people and agents at risk.’87 \\n\\nWithin  GCHQ,  whose  ‘primary  customers  are  the  MOD,  Foreign  and \\nCommonwealth Office and law enforcement agencies’,88 the main arm for dealing \\nwith threats to CNI is CESG. CESG acts as the ‘National Technical Authority for \\nInformation Assurance within the UK’ through three sets of interrelated activi-\\nties ‘in partnership with industry and academia’ alongside their partner agencies, \\nCPNI, MI5 and SIS/MI6.89 These three activities are:\\n\\n•  guidance and tailored advice to UK government and the critical national infra-\\nstructure on the security risks of new and existing IT systems, providing ideas, \\ndesigns and consultancy to protect against these risks;\\n\\n•  ensure appropriately assured products, services and people are available;\\n•  deliver operational support to existing systems by alerting to specific threats and \\nvulnerabilities, and provide incident response and technical solutions (such as \\ncryptographic keys) to protect the most sensitive information.90\\n\\nCESG  also  supports  the  British  government  by  ‘protecting  sensitive  material \\nfrom hostile threats’, ensuring ‘capability and capacity needed to manage cyber secu-\\nrity risks’, ‘securing Government interactions online with citizens’, and ‘advice on \\n\\nworld-36937511, 31 July 2016\\n\\n84  MoD,  Cyber  primer,  p.  1-17.  See  also  ‘Intelligence  and  Security  Act  (ISA)  section  7’,  24  July  2016,  http:// \\n\\nintelligencecommissioner.com/content.asp?id=24#.\\n\\nUK cyber security and critical national infrastructure protectionInternational Affairs 92: 5, 2016Copyright © 2016 The Author(s). International Affairs © 2016 The Royal Institute of International Affairs.\\x0cInformation Assurance Architecture and cyber security to UK government, critical \\nnational infrastructure, the wider public sector and suppliers to UK government’.91\\nIn addition, there is JTAC, which analyses and assesses all-source intelligence \\nrelating  to  domestic  and  international  terrorism.  JTAC  ‘sets  threat  levels  and \\nissues warnings of threats and other terrorist-related subjects for customers from \\na wide range of government departments and agencies, as well as producing more \\nin-depth reports on trends, terrorist networks and capabilities’. It functions as a \\n‘self-standing organization comprised of representatives from sixteen government \\ndepartments and agencies’.92\\n\\nThe 2015 SDSR increased funding for the security and intelligence services by \\n£2.5 billion, half of which was dedicated to counterterrorism. This budget will \\npermit the recruitment of 1,900 additional staff across the agencies described above \\nto ‘respond to, and deter those behind, the increasing international terrorist, cyber \\nand other global threats’, by means including offensive cyber capabilities.93 The \\nbulk of this funding is expected to go to GCHQ, which remains the dominant \\nagency for UK cyber security.94 \\n\\nWithin this framework can be discerned part of the rationale for UK participation \\nin the PRISM mass surveillance programme.95 That rationale is also reflected in the \\nNational Security Strategy and in the MoD’s Cyber primer document, which states:\\n\\nThe  National  Cyber  Security  Strategy  seeks  to  secure  the  advantage  in  cyberspace  by \\nexploiting opportunities to gather intelligence and intervening as necessary against adver-\\nsaries.  Commanders  should  consider  cyberspace  to  be  an  area  of  intelligence  collection \\nand analysis in its own right. Intelligence support to operations within cyberspace is essen-\\ntial to provide knowledge, reduce uncertainty, and support effective operational decision-\\nmaking in defending MOD networks. It ... will include providing timely indicators and \\nwarnings ... [and] focuses on developing sound situational awareness and understanding \\nby identifying trends and scanning for emerging threats, hazards or opportunities as well \\nas understanding the consequences of any action. Cyberspace contains huge amounts of \\ndata which can be exploited and assessed for intelligence and situational awareness.\\n\\nFurthermore:\\n\\nWhen  observing  changes  in  cyberspace,  timescales  vary  from  days  or  months  to  milli-\\nseconds. Individuals and groups operating in cyberspace leave digital trails but these can \\nbe disguised, thus making accurate identification, geo-location and attribution difficult. \\nExploiting this data-rich environment requires thorough intelligence preparation of the \\nbattlespace (IPB). Cyberspace has three interdependent layers which align with, and span, \\nthe physical, virtual and cognitive domains.96\\n\\nWhile there are no international treaties specifically governing cyber activity, cyber opera-\\ntions must be conducted in accordance with existing domestic law. The international law \\nthat applies to military cyber operations will depend on whether an armed conflict is in \\nexistence,  be  it  an  international  armed  conflict  or  a  non-international  armed  conflict. \\nWhere there is no armed conflict, military cyber activities are governed by domestic and \\ninternational law applicable in peacetime.97\\n\\nRelevant  domestic  legislation  includes  the  Computer  Misuse  Act  1990,98  the \\nData Retention and Investigatory Powers Act 201499 and the controversial Regula-\\ntion of Investigatory Powers Act (RIPA) 2000,100 as well as the equally contro-\\nversial  Draft  Communications  Data  Bill  (colloquially  dubbed  the  ‘Snooper’s \\nCharter’).101 International law includes the Law of Armed Conflict (LOAC) which \\nadds both context and complexity to conflict in cyberspace. As the Cyber primer \\nargues, this includes:\\n\\nthe prohibition on perfidy (inviting the confidence of an adversary as to protection under \\nLOAC) and principles of neutrality. If the UK is the subject of an imminent or actual cyber \\nattack that crosses the threshold so as to be an ‘armed attack’ as recognised by Article 51 of \\nthe UN Charter, the UK would be entitled to use force in national self-defence ... Any \\nresponse under self-defence must be necessary and proportionate. There is no consensus as \\nto what degree of force constitutes an armed attack, other than that it must be an act/acts \\nof armed force of sufficient gravity, having regard to its/their scale and effects.102\\n\\nIn addition, the implications of the law of self-defence turn on three practical \\nissues: attribution; the speed with which an attack can be conducted, which can \\ngreatly  reduce  the  ability  to  respond  to  an  imminent  attack;  and  the  difficulty \\nof determining intent, even if actions are provable and actors identifiable. Other \\ndifficulties posed by cyber events include deciding what is a lawful response to a \\n(potentially  hostile)  cyber  incident  that  may  or  may  not  cross  the  armed  attack \\nthreshold.103 This calculation, which has to be backed by legal opinion, is compli-\\ncated by the ‘attribution problem’. Such an incident could be generated by a state; \\na  state-based  actor;  a  private-sector  company  engaged  in  espionage;  a  group  of \\nindividuals involved in cybercrime, or a state sponsoring it for its own ends (includ-\\ning  for  terrorist  purposes);  or  an  individual—whose  reasons  might  range  from \\nmalicious activity to curiosity. It is worth noting there have been cases of each.104 \\nUK cyber security and critical national infrastructure protectionInternational Affairs 92: 5, 2016Copyright © 2016 The Author(s). International Affairs © 2016 The Royal Institute of International Affairs.\\x0cAlthough advances in computer forensics mean that the attribution problem \\nis  decreasing  there  have  also  been  cases  where  it  is  problematic  (often  deeply \\nproblematic  from  a  legal  standpoint)  to  identify  the  perpetrator.105  This  form \\nof  the  ‘attribution  problem’  leads  to  particular  difficulties  when  the  incident  is \\na  ‘nation-state  like  attack’,  as  it  is  known  in  the  cyber-security  community.106 \\nThe  attribution  problem  is  already  well  recognized,  and  although  a  number  of \\nindividuals  have  faced  prosecution,  many  escape  judicial  proceedings  (and  it  is \\nquite  likely  that  private-sector  intrusions  go  undetected).  Whether  acts  such  as \\nan attack on CNI committed by a cyber ‘gun for hire’ through the ‘Dark Net’ \\ncan be deterred or prosecuted is a major problem. By such means both states and \\nnon-state  actors  such  as  Al-Qaeda  or  Islamic  State  in  Iraq  and  Syria  (ISIS)  can \\nhave  a  force  multiplier  effect  on  states  hostile  to  them  and  become  ‘David’  to \\n‘Goliath’.107 The possibility that ISIS and other hostile terrorist groups, as well as \\nnation-states, might attack CNI was part of the reason why the SDSR increased \\nthe budgets for the security and intelligence agencies. In a speech at GCHQ in \\nNovember 2015, George Osborne stated:\\n\\nISIL [ISIS] are already using the internet for hideous propaganda purposes; for radicalisa-\\ntion, for operational planning too. They have not been able to use it to kill people yet by \\nattacking our infrastructure through cyber attack. They do not yet have that capability. \\nBut we know they want it, and are doing their best to build it. So when we talk about \\ntackling ISIL, that means tackling their cyber threat as well as the threat of their guns, \\nbombs and knives. It is one of the many cyber threats we are working to defeat.108\\n\\nIn that same speech Osborne unequivocally stated: ‘GCHQ is rightly known as \\nequal to the best in the world. And I am clear that the answer to the question “who \\ndoes cyber?” for the British government is—to very large degree—GCHQ.’109\\n\\nRisk/resilience and UK ‘governance’ of CNI and devolved powers\\n\\nCyber  security,  which  formerly  fell  within  the  purview  of  the  Home  Office, \\nhas  since  2011  been  overseen  by  the  Cabinet  Office,  with  scrutiny  and  political \\nauthority provided by the NSC. However, the picture is complicated by the fact \\nthat authority in some areas, including education and health, is now devolved to \\nthe Scottish Parliament, Northern Ireland Assembly and Welsh Government.110 \\nThe political and social debates regarding the extent of devolution continue to \\nevolve and are especially active in Scotland, which in September 2014 voted no in a \\n\\n\\nKristan StoddartInternational Affairs 92: 5, 2016Copyright © 2016 The Author(s). International Affairs © 2016 The Royal Institute of International Affairs. \\x0creferendum on full independence tabled by the ruling Scottish National Party, and \\nwhere  a  second  referendum  cannot  be  ruled  out.  These  constitutional  arrange-\\nments naturally affect the governance of CNI in the UK as a whole, and will affect \\nit further if more devolved powers or full independence (in the case of Scotland) \\nare ceded by Westminster. The so-called ‘West Lothian Question’, whereby issues \\npertaining to only a part of the union—especially issues affecting only England—\\nare voted on by all Westminster MPs, also bears on issues of governance of CNI.111\\nIt is clear from the lists of devolved and non-devolved powers that while defence \\nand national security remain under the control of Westminster, Scotland already \\nhas power for health, policing, the fire service and elements of transport; Northern \\nIreland for health and policing; and Wales for health, fire and rescue, and highways \\nand transport. As noted above, each of these areas represents elements of CNI as \\ndefined by CPNI. It is important that cross-border collaboration for cyber resilience \\nis clear and mutually reinforcing, because Britain is a relatively small land mass and \\nwhat might appear to be a local incident could well disrupt or cascade to other areas.\\nMoreover, as the 2010 Strategic framework and policy statement on improving the resil-\\nience of critical infrastructure to disruption from natural hazards noted: ‘There are some \\ncross-sector themes such as technology wherein there may be infrastructure which \\nsupports the delivery of essential services across a number of sectors.’112 CPNI, \\nwhich also supports Britain’s counterterrorism strategy (CONTEST), explains:\\n\\nThis  categorisation  is  done  using  the  Government  ‘Criticality  Scale’,  which  assigns \\ncategories for different degrees of severity of impact. Not everything within a national \\ninfrastructure  sector  is  ‘critical’.  Within  the  sectors  there  are  certain  ‘critical’  elements \\nof  infrastructure  ...  The  Criticality  Scale  includes  three  impact  dimensions:  impact  on \\ndelivery of the nation’s essential services; economic impact (arising from loss of essential \\nservice) and impact on life (arising from loss of essential service).113\\n\\nAs  Philip  Hammond,  the  then  Defence  Secretary,  told  the  Defence  Select \\n\\nCommittee in October 2013, CPNI is\\n\\nwhere the impacts of cyber issues and cyber attacks on the broader national infrastructure \\nare worked through, so that the vulnerabilities of utilities and other services that might be \\nimpacted by an attack on critical networks can be worked through and defensive strategies \\nput in place. We have a number of mechanisms across Government that can absorb devel-\\nopments in one area and translate them into potential effects in other areas.114\\n\\nFood and water are elements of national infrastructure (including some aspects \\nclearly judged to be critical); these are among the areas devolved to the regional \\nassemblies. Furthermore, central and local government is but one layer of ‘gover-\\n\\n\\nUK cyber security and critical national infrastructure protectionInternational Affairs 92: 5, 2016Copyright © 2016 The Author(s). International Affairs © 2016 The Royal Institute of International Affairs.\\x0cnance’; private industry arguably has as great a (or a greater) say over the rules, \\nregulation and governance of each of these sectors—a number of which will, at \\nsome level, be integrated with one another.115 Clearly, there is a ‘patchwork quilt’ \\nof responsibilities for CNI in these sectors and regions. The picture is complicated \\nfurther  by  the  fact  that  local  councils,  water  boards  and  health-care  trusts  have \\ntheir own sets of responsibilities and reporting mechanisms, while in some areas \\nthe private sector is dominant: these include communications, energy, financial \\nservices, food and transport.\\n\\nFor  CNI  protection  in  the  event  of  natural  disasters,  there  already  exists  a \\nframework established following the Pitt Review conducted in the wake of the \\nUK floods of 2007. The Pitt Review highlighted a number of resilience measures, \\namong them:\\n\\n•  careful assessments of vulnerability, and prudent and proportionate risk mitiga-\\n\\ntion activity, based on new, centrally defined standards;\\n\\n•  a shared framework to support cross-sector activity to assess, enhance and sustain \\n\\nthe resilience of critical infrastructure and essential services to disruption;\\n\\n•  enhancing the collective capacity of critical infrastructure to absorb shock and \\n\\nact quickly when faced with unexpected events;\\n\\n•  effective emergency responses at the local level through improved information-\\n\\nsharing and engagement before, during and after emergencies. \\n\\nThese could equally apply to cyber resilience and help ‘ensure that the Govern-\\nment,  regulators,  public  sector  bodies  and  owners  of  critical  infrastructure  are \\naware  of  the  risks  arising  from  ...  hazards  and  take  appropriate  action’.116  This \\nawareness encompasses the impact on society and the economy, which again can \\nbe analysed through a set of principles defined by the Pitt Review. These include:\\n\\n1)  a risk-based approach proportionate to the risks involved; \\n2)  assessments  of  the  likelihood  and  the  consequences  of  critical  infrastructure \\nand essential services being severely disrupted, used to define standards and to set \\npriorities;\\n3)  calibration  of  the  scale  and  cost  of  proposed  programmes  of  measures  to \\nenhance resilience within each sector proportionate to the risks they face, including \\nthe  ‘criticality’  of  the  infrastructure  in  question  and  its  vulnerabilities,  and  the \\ndifferent options available to improve resilience;\\n4)  cooperation and coordination within and between sectors and essential services, \\nbased on collaboration with the regional administrations on devolved matters to \\nharmonize work programmes where possible to ensure appropriate standards for \\nresilience are maintained across the UK;\\n5)  planning to clarify the differences between sectors that arise from their different \\nneeds, circumstances and regulations with a view to building a National Resilience \\nPlan for Infrastructure.\\n\\n\\nKristan StoddartInternational Affairs 92: 5, 2016Copyright © 2016 The Author(s). International Affairs © 2016 The Royal Institute of International Affairs. \\x0cIn practice this means government departments will continue to sponsor and \\ntake the lead for their sectors, and to share information on dependencies, interde-\\npendencies and arrangements for business continuity management across sectors. \\nThis instils a precautionary approach to the uncertainties in the estimation of the \\nrisks posed covering all nine sectors of national infrastructure while recognizing \\nthat  each  sector  is  at  a  different  starting  point  in  establishing  expectations  and \\ncommon goals. The sponsoring departments are responsible for deciding upon the \\nappropriate security approach to be taken for their respective sectors. This means \\nthat analysis can be developed, and supporting evidence gathered, through formal \\nand  informal  consultation  to  enable  the  development  of  sector  resilience  plans. \\nThis work should be coordinated with the CPNI and could be placed within the \\nNational Risk Register (NRR) or be made a subset of it.\\n\\nSome  elements  of  these  proposals  are  likely  to  fall  under  the  Civil  Contin-\\ngencies Act 2004, and would be subject to ministerial approval as well as parlia-\\nmentary/regional scrutiny. This could be accomplished via national multisector \\nstrategic coordination and planning groups for national infrastructure, such as can \\nalready, in principle, be provided by CPNI/OCSIA and overseen by the NCSC. \\nThis  could  help  coordinate  top-down  government  action  and  bottom-up  resil-\\nience and recovery. In addition a National Asset Database, similar to that operating \\nin the US and used as a ‘single classified prioritized list of [critical] systems and \\nassets’, should be developed if it is not already.117\\n\\nAs mentioned in the Pitt Review principles, the development of sector resil-\\nience plans could better enable ‘Government and industry working together to \\nfoster  a  collective  responsibility  for  enhancing  resilience’.118  The  Pitt  Review \\nproposed that these plans be ‘developed jointly through a tripartite relationship \\nbetween the relevant government department, economic regulator and industry \\nsector’, and that they ‘should be public documents with controlled sections where \\nnecessary for sensitive information’.119 The Pitt Review also recommended that:\\n\\nResponsibility  for  producing  the  Plans  will  rest  with  the  lead  government  department \\nfor  each  sector,  with  information  provided  by  owners  of  critical  infrastructure  within \\nthe sector. Sector Resilience Plans are reviewed in an agreed timeframe. The programme \\nwill review existing regulation and guidance, identifying best practice and existing gaps \\nin  provision.  It  will  also  review  current  affordability  appraisal  practices  in  each  sector, \\naddressing how any improvements can be funded and whether any legal powers are needed \\nto improve resilience.120\\n\\nAdopting this approach, which has both regional and national applications and \\n\\nimplications, would foster periodic bottom-up risk assessments and analysis. \\n\\nThe Criticality Scale, on which CPNI draws, utilizes ‘a co-ordinated approach to \\ndriving up the resilience of critical infrastructure’ while the Cabinet Office noted \\nthe ‘gap in the Government’s policy-making and delivery towards the protection \\nof critical infrastructure from severe disruption caused by natural hazards’.121 The \\nCriticality Scale is also useful for mapping the environment as it relates to cyber \\nsecurity, as can be seen in table 1.\\n\\nTable 1: The Criticality Scale for national infrastructure\\n\\nCriticality Scale \\ncategory\\n\\nDescription\\n\\nCAT 5 \\n\\nCAT 4 \\n\\nCAT 3 \\n\\nCAT 2 \\n\\nCAT 1 \\n\\nCAT 0 \\n\\nThis is infrastructure the loss of which would have a catastrophic \\nimpact  on  the  UK.  These  assets  will  be  of  unique  national \\nimportance whose loss would have national long-term effects \\nand may impact across a number of sectors. Relatively few are \\nexpected to meet the Cat 5 criteria. \\nInfrastructure of the highest importance to the sectors should \\nfall within this category. The impact of loss of these assets on \\nessential services would be severe and may impact provision of \\nessential services across the UK or to millions of citizens. \\nInfrastructure of substantial importance to the sectors and the \\ndelivery of  essential  services, the loss of which  could  affect  a \\nlarge  geographic  region  or  many  hundreds  of  thousands  of \\npeople. \\nInfrastructure  whose  loss  would  have  a  significant  impact  on \\nthe delivery of essential services leading to loss, or disruption, \\nof  service  to  tens  of  thousands  of  people  or  affecting  whole \\ncounties or equivalents. \\nInfrastructure  whose  loss  could  cause  moderate  disruption  to \\nservice delivery, most likely on a localized basis and affecting \\nthousands of citizens. \\nInfrastructure the impact of the loss of which would be minor \\n(on a national scale). \\n\\nSource: Strategic framework and policy statement on improving the resilience of critical \\ninfrastructure to disruption from natural hazards, March 2010.\\n\\nIn  terms  of  mitigating  risk  and  enhancing  resilience,  this  provides  a  useful \\nframework upon which CPNI can draw to map existing and future vulnerabili-\\nties and to examine in detail the sectors concerned. This examination should go \\non a voluntary basis; it should ideally be enshrined in law along the lines of US \\nlegislation and practices, as well as good practices found in Germany and Estonia, \\nand  the  principles  of  the  EU’s  NIS  Directive  should  be  embraced  (as  they  will \\nhave no legal standing in the UK after Brexit). These approaches are not an end \\nin themselves.122 Dialogue and information-sharing on threats and vulnerabilities \\nare a good starting point but do not go far enough. \\n\\nPrivate industry, as the owner–operators of the vast majority of CNI, along-\\nside the hardware and software companies upon which they rely for the mainte-\\nnance of their systems, needs to feel confident in the government’s ability to help \\nthem manage and mitigate these threats. In turn this would give the government \\ngreater confidence that they have grasped the national CNI environment and have \\na clear view of the landscape. It is not helpful to hold the view that ‘the owners \\nof  Critical  National  Infrastructure  need  to  be  held  to  account’.123  It  is  equally \\nalarming that risks for the private sector are growing faster than their ability to \\nact and governments are not seen to be doing enough. ‘Risk tolerance’ and risk \\nawareness varies between businesses and sectors, while the British government is \\naccused  of  being  reluctant  and  too  slow  in  sharing  information/intelligence.124 \\nThe  revelations  of  the  PRISM  programme  and  the  WikiLeaks  disclosures  of \\nclassified government information focused attention on the difficulties of where \\nto draw the lines between ‘the need to know’ and ‘the need to share’ information/\\nintelligence; and the balance between them needs to be better managed.125\\n\\nWhat is required in practical terms is for government experts from the various \\nbodies outlined above, especially those from the NCSC, OCSIA and CPNI, along \\nwith  those  of  the  NCA  as  the  main  police  body  overseeing  cybercrime,  to  be \\ninvited into the relevant facilities for ‘inside the fence’ site assistance visits. There \\nalso needs to be transparent discussion of the strengths and weaknesses of cyber-\\nsecurity practices within each site and company, from which best practices can be \\nidentified for each sector or nationwide. This set of best practices could function \\nin a similar vein to the US Protected Critical Infrastructure Information (PCII) \\nProgram. The PCII is designed in a way that protects commercially sensitive or \\nproprietary information and is used to analyse and secure critical infrastructure \\nand  protected  systems;  identify  vulnerabilities  and  develop  risk  assessments; \\nand  enhance  recovery  preparedness  measures.  Adopting  this  approach  through \\ndomestic  legislation  would  permit  the  British  government  and  its  constituent \\nelements to harden the protection of CNI from malicious attack.\\n\\nThis approach is not without its difficulties. Increased regulation, let alone new \\nlegislation, is likely to be resisted by private industry for a variety of longstanding \\nreasons. The UK government, with or without EU or US support, is also unlikely \\nto favour increased regulation or legislation which promotes state intervention—\\neven for state-wide security reasons. Not only could this increase costs; there is \\nalso a legitimate question of where the expertise, as well as the money, will be \\nfound. It is also worth asking whether there is any political appetite for endeav-\\nours of this nature in the absence of a major cyber attack on the UK’s CNI. Should \\nsuch an event occur, however, the question would inevitably be asked: ‘Could this \\nhave been prevented?’ The answer to that question will depend on the nature and \\nextent of the attack, the disruption or damage caused, any cascade effects, and the \\nresponse and responsibility of private industry. The possibilities are not lost on the \\ngovernment. George Osborne stated at GCHQ in November 2015:\\n\\nIf the lights go out, the banks stop working, the hospitals stop functioning or govern-\\nment itself can no longer operate, the impact on society could be catastrophic. So govern-\\nment has a responsibility towards these sectors, and the companies in those sectors have a \\nresponsibility to ensure their own resilience. Any new regulation will need to be carefully \\ndone—light enough and supple enough that it can keep up with the threat, so it encour-\\nages growth and innovation rather than suffocates it.126\\n\\nThe steps advocated in this article, alongside those contained in the 2015 SDSR, \\nare designed to improve resilience to these threats in advance of any such attack. \\nAt  the  very  least  they  will  help  both  government  and  private  industry  to  map \\ndomestic vulnerabilities, to assess what might be done to mitigate risk in a cost-\\neffective manner and to keep a watching brief on areas of mutual concern. Should \\nthe kind of ‘Cyber Pearl Harbor’ or ‘Cyber 9/11’ event evoked by the former US \\nDefense Secretary Leon Panetta actually materialize, the results could be poten-\\ntially catastrophic. Such an attack could be directed at, for example:\\n\\n•  a chemical plant or refinery, leading to the release of toxic gases, oil or chemical \\n\\nspillages, or explosions;\\n\\n•  part of the UK traffic system: manipulation of the traffic light system in a major \\n\\ncity alone could cause disruption or fatalities;\\n\\n•  dams, which regulate the water supply and provide electricity for large geograph-\\nical  areas;  damage,  destruction  or  disruption  here  could  cause  flooding,  lead \\nto a lack of clean drinking water and sanitation, disrupt navigation and trans-\\nport, and have serious effects on industrial plants dependent on water (e.g. for \\ncooling) and electricity supplies.127\\n\\n\\nKristan StoddartInternational Affairs 92: 5, 2016Copyright © 2016 The Author(s). International Affairs © 2016 The Royal Institute of International Affairs. \\x0cAn attack on any of these targets would place considerable strain on local and \\nnational response teams (including the emergency services and military). It would \\nalso  place  concomitant  pressure  on  local  and  central  government  and  agencies. \\nThe  government,  along  with  many  others,  is  well  aware  of  this.  As  the  MoD’s \\nCyber primer argues: \\n\\nBusiness continuity means being resilient and maintaining service while under attack. By \\ndeveloping a plan based on risk, resilience, impact and interdependency assessments, the \\neffects  of  such  an  attack  can  be  mitigated.  Operators  need  to  be  made  aware  of  which \\nsystems and, more importantly, what information/data is critical at which times during \\noperations. When considering business continuity plans, the following should be consid-\\nered.\\n\\n•  Where does the priority lie in maintaining system availability?\\n•  What is the impact of system loss?\\n•  Who  do  I  need  to  notify  if  I  intend  to  close  a  system—or  continue  running  it  with \\n\\nknown or even unknown faults?\\n\\n•  How is risk measured and managed and at what levels of command do various respon-\\n\\nsibilities lie?\\n\\n•  What is the recovery plan?\\n•  Is it frequently exercised using only back-up hardware, applications and data?128\\n\\nWhile  this  is  a  useful  series  of  questions  to  ask  owner–operators  in  private \\nindustry, the UK government still needs to do much more to map and manage the \\nvulnerabilities, mitigate major areas of risk, promote best practice through on-site \\ninspections,  and  maintain  a  meaningful  and  transparent  risk  assessment  process \\nand risk register in a sustained partnership with private industry. Central govern-\\nment can help to coordinate the work of local government, government agencies, \\nthe police and emergency services and, if required, provide assistance or request \\nhelp from its friends and allies—including NATO’s CCDCOE. These measures \\nwill help to improve resilience before moving into the post-attack phase and, it is \\nto be hoped, full recovery. \\n\\nConclusion and recommendations\\n\\nWith the rapid expansion of ‘the Internet of Things’, and moves within the UK \\nand other developed and developing states towards ‘smart’ cities and ‘smart’ grids, \\nthe  potential  for  malicious  action  will  only  rise.  The  MoD’s  Cyber primer  states \\nunequivocally:  ‘Cyberspace  is  contested  even  in  peacetime—threat  actors  are \\nconstantly probing our networks seeking vulnerabilities, intelligence or military \\nand commercial advantage.’ It pertinently adds that ‘civilian and military infor-\\nmation infrastructures, whether national, coalition or international, co-exist and \\noverlap,  posing  problems  for  managing  security’.129  For  these  reasons  the  UK \\ngovernment, as a responsible global actor, continues to promote ‘responsible state \\n\\n\\nUK cyber security and critical national infrastructure protectionInternational Affairs 92: 5, 2016Copyright © 2016 The Author(s). International Affairs © 2016 The Royal Institute of International Affairs.\\x0cbehaviour’  in  cyberspace.130  However,  this  may  not  be  enough.  As  Singer  and \\nFriedman argue: ‘Cyber deterrence may play out on computer networks, but it’s \\nall  about  a  state  of  mind.’131  Jason  Rivera  also  makes  the  case  that  ‘cyberdeter-\\nrence strategy remains largely unexplored and underdeveloped, due to a limited \\nunderstanding  of  how  the  principles  of  deterrence  can  be  applied  to  the  cyber \\ndomain’—with the added complexity posed by the attribution problem and legal \\nrestrictions.132\\n\\nWith this is mind, and despite the measures in place, it was noted in exchanges \\nof the Defence Select Committee intended to inform the 2015 SDSR that scenarios \\nfor a major cyber attack on CNI are not practised by ministers or by the NSC.133 \\nThis is a gap that can and should be addressed (for example, through the Cabinet \\nOffice  Briefing  Rooms).  This  would  be  especially  valuable  because  the  risk  of \\nescalation (intended or unintended) is high, and while governments are looking \\nto  private-sector  actors  to  do  more,  private  industry  is  also  in  the  line  of  sight \\nfor  hostile  state  actors.134  Furthermore,  the  2015  SDSR  correctly  noted  that: \\n‘Compromise or damage from these attacks may not be immediately visible.’135 \\nThe SDSR also publicized the government’s intention to work more closely with \\nthe owner–operators of CNI and drive up security across CNI, and announced the \\nintention to ‘establish a cyber training centre and test lab to support the develop-\\nment of more secure technology’.136 Alongside this the government will practise \\n‘new measures’ against electrical power cuts and will review current measures for \\npolicing CNI with a view to building increased resilience and integration between \\nsectors and organizations.137 This is all positive and needs to be followed through \\nin practice.\\n\\nCurrently,  jurisdictional  boundaries  mean  that  many  actors  believe  they  can \\n(and do) act with impunity. Responsible state behaviour means upholding the rule \\nof law within and between states. Doing little or nothing about this at a global \\nlevel ignores the fact that ‘cyberspace does have a direct effect on the information \\nenvironment ... is very disruptive of many processes heretofore considered safe \\nsuch as the exchange of money and the relative security of personal, industrial and \\ngovernmental data, as we can see from the burgeoning statistics on cyber-crime \\nand cyber-espionage’.138\\n\\nThe  volume,  types  and  complexity  of  cybercrime,  cyber  espionage,  and  the \\nkinds of APTs now being seen pose a problem that is not going to change unless \\nmore robust measures are put in place. This means the UK, its allies and its friends \\nneed to develop coordinated information-sharing on a global scale and a series of \\n\\nKristan StoddartInternational Affairs 92: 5, 2016Copyright © 2016 The Author(s). International Affairs © 2016 The Royal Institute of International Affairs. \\x0cstate-based confidence-building measures rooted in international law. Prosecutions \\noutside jurisdictional boundaries will need to be hammered out both bilaterally \\nin test cases and multilaterally in environments such as the Internet Governance \\nForum (IGF). Attempts to impose state-based law and state-based regulation must \\ntake account of the views of the private sector, which is responsible for 80 per \\ncent  of  the  business  that  takes  place  online  and  provides  most  of  the  hardware \\nand software underpinning the technology that enables the internet to function. \\nSystemic  resilience  can  only  take  root  through  a  multi-stakeholder  system  that \\nrecognizes  the  limitations  on  the  ability  of  nation-states  to  police  the  internet. \\nWhile recognizing these limitations, this article has highlighted a number of steps \\nthat can be taken to better protect the UK’s CNI from cyber threats, alongside the \\nplans outlined in the 2015 SDSR. \\n\\nIn summary: the National Cyber Security Centre is a positive step if it fully \\nengages all the relevant stakeholders within government and does not exclusively \\nreflect  the  views  of  GCHQ  or  government.  Engagement  and  partnership  with \\nthe  private  sector,  and  the  owner–operators  of  CNI,  are  vital  to  the  success  of \\nthe  NCSC  and  the  government’s  National  Cyber  Security  Strategy.  Legislating \\nthe  reporting  of  cyber-security  breaches  to  central  government  is  essential  for \\nthe protection of CNI. If problems remain hidden or unknown, this is a recipe \\nfor potential disaster. The Criticality Scale for natural disasters should be used as \\na measure of cyber resiliency and recommendations adapted from the 2007 Pitt \\nReview should be implemented. Sector resilience plans should be adopted through \\nCPNI and coordinated within the National Risk Register. A Protected Critical \\nInfrastructure Information (PCII) Program should be adopted along US lines but \\ntailored  to  the  UK.  Site  assistance  visits  led  by  the  NCSC  should  be  promoted \\nfor CNI sites and the threat environment as it relates to CNI should be mapped. \\nAll this can only be accomplished with the full agreement of private industry as \\nowner–operators. While the SDSR stated that ‘the Government will avoid regula-\\ntion wherever possible’, this may not be a feasible approach if it is fully to protect \\nthe critical national infrastructure which underpins the British state.139 \\n', 'SCADA Fusion With Commercial \\nFission\\n\\nby Matthew Horner\\n\\nHomeland Security Affairs, Volume 14 Article 4 (April 2018) WWW.HSAJ.ORG\\n\\n\\x0cHorner,  SCADA Fusion With Commercial Fission \\n\\n2\\n\\nAbstract\\n\\nNuclear  power  plants  rely  on  digital  components,  like  supervisory  control  and  data \\nacquisition (SCADA) devices, to perform daily operations. These devices can contain software \\nvulnerabilities.  To  address  SCADA  and  other  cyber  threats,  the  U.S.  Nuclear  Regulatory \\nCommission  (NRC)  has  issued  directives  for  licensed  operators  to  submit  cybersecurity \\nplans  for  their  facilities.  While  the  guidance  is  on  par  with  other  sectors,  the  application \\nmay be inadequate. Protection against cyber-attacks becomes more important as SCADA \\nsystems  become  more  standardized  and  connected  to  other  networks.  In  addition  to \\nresilient components, improvements like redundancy, whitelisting, and intrusion detection \\nsystems can help improve a SCADA network. Ultimately, the nuclear power industry may \\nneed  to  undergo  a  culture  shift  in  order  to  reduce  the  vulnerability  of  these  systems.  An \\ninformation- sharing and analysis center can also provide lessons learned and expertise to \\nthe NRC and nuclear power plants in the U.S.\\n\\nSuggested Citation\\n\\nHorner,  Matthew.  “SCADA  Fusion  With  Commercial  Fission.”    Homeland  Security  Affairs  14, \\nArticle 4 (April 2018).  https://www.hsaj.org/articles/14317\\n\\nIntroduction\\n\\nLike other power plants, nuclear power plants rely on digital components to perform daily \\noperations. Many of these components are supervisory control and data acquisition (SCADA) \\ndevices that can contain software vulnerabilities.1 The Nuclear Energy Institute (NEI) claims \\nthat “critical systems” in a nuclear reactor facility are not connected to the Internet or the \\nfacility’s internal network and therefore that the cybersecurity risk to these critical systems \\nis minimized.2\\n\\nHowever,  the  stakes  in  nuclear  power  are  always  high.  Not  only  do  the  facilities  provide \\nelectricity to communities, but they also contain nuclear fuel. Accidents at nuclear power \\nplants are well-publicized. Three Mile Island, Chernobyl, and Fukushima Daiichi are names \\nthat  invoke  the  dangers  of  nuclear  power,  and  they  will  likely  not  fade  anytime  soon. \\nAdditionally, terrorists can target nuclear power plants seeking to gain access to nuclear fuel \\nto create a “dirty bomb,” or an explosive device meant to spread radioactive particles over a \\nlarge area.3 Cyber-attacks add to the list of threats to a nuclear power plant, and they have \\nthe unique property of attacking from afar and anonymously. This paper will discuss SCADA \\nsystems in commercial nuclear power plants in the U.S., focusing on \\n\\n• \\n\\nincorporation of digital and networked components in U.S. commercial nuclear power \\nplants, \\n\\n•  a summary of policy for cybersecurity in nuclear power plants, \\n\\n• \\n\\ncybersecurity threats to and vulnerabilities of nuclear power plants, and consequences \\nof a successful exploitation, and \\n\\n• \\n\\nrecommendations to improve the cybersecurity of the nuclear power plant infrastructure.\\n\\nHomeland Security Affairs, Volume 14 Article 4 (April 2018) WWW.HSAJ.ORG\\n\\n \\n\\x0cHorner,  SCADA Fusion With Commercial Fission \\n\\n3\\n\\nIncorporation of Digital and Networked \\nComponents \\n\\nThe  Nuclear  Reactors,  Materials,  and  Waste  Sector  (or  Nuclear  Sector)  of  the  U.S.  is  one \\nof the 16 critical infrastructures (CI) as defined in Presidential Policy Directive-21.4 A basic \\nunderstanding  of  power  plant  construction  and  functionality  is  useful  to  help  the  reader \\nappreciate the risk to this sector. Instead of burning fossil fuels, nuclear power relies on a \\nprocess called fission which involves splitting atoms of a fissile material like Uranium-235. \\nFission  creates  thermal  energy  that  can  be  used  to  generate  electricity.  However,  it  also \\nproduces radioactive elements that must be trapped within a containment barrier. If these \\nradioactive elements are released, long-term environmental and public health consequences \\ncan result as seen in Chernobyl, Ukraine and Fukushima, Japan.5 According to the Department \\nof Homeland Security (DHS), the high-impact consequences of mishandling nuclear assets \\nmake the Nuclear Sector the “most highly regulated and heavily guarded” of all the U.S. CI \\nsectors.6\\n\\nA nuclear reactor presents additional challenges over fossil fuel combustion. One challenge is \\nthe generation of thermal energy when the reactor is shut down; unfortunately, the meaning \\nof a nuclear reactor shutdown is not synonymous with “no longer producing heat.” Even if \\nthe fission reaction is stopped by the reactor’s shutdown mechanism, the radioactive decay \\nof fission products continues to generate thermal energy called “decay heat” that must be \\nremoved to prevent damage to the reactor fuel. Coolant must continue to flow through the \\nreactor  core  to  remove  this  decay  heat.  If  heat  is  not  removed,  the  core  could  melt.  This \\nsituation occurred in the Three Mile Island Unit 2 reactor in Middletown, PA in 1979 where \\na combination of equipment failures, design flaws, and operator error led to a meltdown of \\nthe reactor core even though the reactor was shut down.7 The cleanup took approximately \\n12 years and cost $973 million.8 The public confidence in nuclear power dropped as well.\\n\\nHomeland Security Affairs, Volume 14 Article 4 (April 2018) WWW.HSAJ.ORG\\n\\n \\n\\x0cHorner,  SCADA Fusion With Commercial Fission \\n\\n4\\n\\nFigure 1. Three Mile Island Nuclear Power Plant in PA9\\n\\nSCADA System Benefits and Risks \\n\\n  SCADA  systems  can  help  reduce  the  number  of  personnel  required  to  operate  a  power \\nplant safely. In nuclear power plants built in the 1960s through the 1980s, SCADA systems \\nwere  analog  systems  with  hardware  and  software  designed  for  a  specific  function,  and \\nmodifying these systems was more difficult than hacking a networked component because \\nphysical  access  was  required.10  As  these  legacy  systems  were  upgraded,  programmable \\ncode usage increased the potential functions of SCADA systems, and because security was \\nnot initially designed into these systems, they have increased the vulnerability of a civilian \\nnuclear power plant.11\\n\\nHomeland Security Affairs, Volume 14 Article 4 (April 2018) WWW.HSAJ.ORG\\n\\n \\n\\x0cHorner,  SCADA Fusion With Commercial Fission \\n\\n5\\n\\nFigure 2. Summary of how a SCADA system with programmable logic controllers (PLC) can \\nwork12\\n\\nNevertheless, the problem posed by programmable code was not initially an alarming issue \\nin systems that used SCADA components. For example, in the case of the Massachusetts \\nWater Resource Authority, operators believed that the isolated SCADA systems were specific \\nto a particular plant, so specialized knowledge and physical access was required to cause real \\ndamage.13  Over  time,  SCADA  systems  have  implemented  open  protocols  and  commercial \\noff-the-shelf  (COTS)  software  reducing  the  possible  customization  in  a  power  plant.14 \\nAdditionally,  third  parties  requesting  data  from  the  nuclear  power  plant  typically  receive \\nthat data through an Internet connection, thus increasing possible avenues of attack.15\\n\\nWith  100  commercial  nuclear  reactors  in  operation  at  61  power  plants,  there  are  many \\npotential  targets.16  Each  of  these  power  plants  can  contain  over  one  thousand  “digital \\nassets” which includes SCADA systems.17 The opportunity for a cyber-attack exists through \\nthese  digital  assets,  but  according  to  the  NEI,  most  of  these  assets  are  not  connected  to \\nradiological safety and security.18\\n\\nHomeland Security Affairs, Volume 14 Article 4 (April 2018) WWW.HSAJ.ORG\\n\\n \\n\\x0cHorner,  SCADA Fusion With Commercial Fission \\n\\n6\\n\\nFigure 3. Distribution of nuclear power plants across the U.S. as of November 201519\\n\\nCybersecurity Policy in Nuclear Power \\nPlants\\n\\nIn the U.S., the Nuclear Regulatory Commission (NRC) is the regulatory body for all nuclear \\npower plants.20  Although the DHS is the sector-specific agency for the Nuclear Sector, the \\nNRC provides oversight.21  Thus, nuclear power plants in the U.S. have only one set of rules \\nto  follow,  which  helps  simplify  the  policies  and  procedures  required  to  operate  a  nuclear \\nreactor.\\n\\nHomeland Security Affairs, Volume 14 Article 4 (April 2018) WWW.HSAJ.ORG\\n\\n \\n\\x0cHorner,  SCADA Fusion With Commercial Fission \\n\\n7\\n\\nAfter  the  terrorist  attacks  of  September  11,  2001,  the  NRC  directed  nuclear  power  plant \\noperators to improve the physical security and cybersecurity of their facilities.22 By 2009, the \\nNRC had codified the cybersecurity requirement in CFR Title 10, Chapter 1, Section 73.54.23 \\nThis regulation requires an NRC-approved cybersecurity plan from current operators as well \\nas those applying for a license to operate nuclear reactors. According to this regulation, the \\ncybersecurity plan must protect digital systems, networks, and communications involved \\nwith\\n\\n•\\t safety,\\n\\n•\\t security,\\n\\n•\\t emergency preparedness, and\\n\\n•\\t support systems and equipment.24\\n\\nThe NRC and NEI provide additional guidance through Regulatory Guide 5.71 Cyber Security \\nPrograms for Nuclear Facilities and NEI 08-09 Revision 6 Cyber Security Plan for Nuclear Power \\nReactors.25  The  description  of  protected  systems  is  very  broad.  This  is  likely  due  to  the \\nvariance in design of nuclear power plants, but it forces power plant operators to analyze \\ntheir own power plants to determine which digital assets would fall under safety, security, \\nemergency preparedness, or support systems.\\n\\nNuclear Power Risk Analysis \\n\\nThis determination is similar to a risk analysis where assets are prioritized based on threats, \\nvulnerabilities, and consequences if an asset is damaged or disabled.26 Depending on their \\nconnectivity  and  function,  SCADA  systems  could  be  classified  as  high  risk.  For  example, \\nSCADA systems involved with safety, security, or emergency preparedness likely have large \\nconsequences  if  they  fail,  and  if  the  SCADA  system  is  connected  to  the  Internet  through \\na  path  like  a  corporate  network,  the  number  of  threats  increases  dramatically  because \\nphysical access is no longer required. The trend in U.S. nuclear power plants appears to be \\nisolation of SCADA systems connected to “critical safety and security systems.”27\\n\\nAccording to the NEI, all licensed operators have cybersecurity plans that have been approved \\nby the NRC.28 Additionally, the NRC has approved the plan of action and milestones (POAM) \\nfor each power plant and regularly verifies the status of this POAM.29 For example, the NRC \\nset one milestone to occur by December 31, 2012 and it included requirements such as:\\n\\n•\\t\\n\\n•\\t\\n\\n•\\t\\n\\n•\\t\\n\\nidentification of critical systems and their critical digital assets,\\n\\nisolation of critical plant systems allowing outbound communication only,\\n\\nimplementation of security controls for portable media, and\\n\\nimplementation of cybersecurity controls for the most important assets.30\\n\\nSome organizations like the Chatham House, however, believe that there are fundamental \\nflaws in both the timeliness and culture of cybersecurity protection in commercial nuclear \\npower plants.31 While power plants may meet the requirements set forth by the NRC, the \\nefficacy  of  a  cybersecurity  program  is  measured  using  performance  against  threats,  not \\nagreement with regulations.\\n\\nHomeland Security Affairs, Volume 14 Article 4 (April 2018) WWW.HSAJ.ORG\\n\\n \\n\\x0cHorner,  SCADA Fusion With Commercial Fission \\n\\n8\\n\\nCyber Threats, Vulnerabilities and \\nConsequences \\n\\nThere are several cases of a commercial nuclear power plant succumbing to a cyber-attack \\nor  malfunction  after  2001  that  can  provide  a  test  of  the  cybersecurity  controls  in  place. \\nOne example is the Slammer worm attack on the Davis-Besse Nuclear Power Station in Oak \\nHarbor, OH in January 2003.32 The Slammer worm infected a contractor network connected \\nto the nuclear power station’s business network which bypassed the properly configured \\nfirewall of the business network.33 The worm then infected SCADA systems through a remote \\ncomputer  using  a  virtual  private  network  (VPN).34  The  plant  operators  eventually  lost  the \\nSafety Parameter Display System (SPDS) for almost five hours which required operators to \\nwalk around and manually check on plant parameters.35 While no power outage occurred, \\nthe  loss  of  the  SPDS  could  slow  corrective  actions  if  a  malfunction  occurred  within  the \\nreactor plant. \\n\\nFigure 4. Davis-Besse Nuclear Power Station36\\n\\nHomeland Security Affairs, Volume 14 Article 4 (April 2018) WWW.HSAJ.ORG\\n\\n \\n\\x0cHorner,  SCADA Fusion With Commercial Fission \\n\\n9\\n\\nThe  Davis-Besse  case  highlights  the  vulnerability  of  SCADA  systems  when  connected  to \\nthe Internet. Plant operators desired to monitor plant parameters remotely and connected \\nSCADA systems to the business network.37 Lewis writes that the “openness and connectivity” \\nwith internal networks and external business partners is the largest security deficiency in \\nSCADA systems.38 The NEI shares this view, stating that the first line of defense is isolation \\nthrough air gaps or hardware-based isolation.39 However, external connections to a network \\ncan change daily, so believing that an isolated network stays isolated may be optimistic and \\nmistaken.\\n\\nHatch Nuclear Power Plant\\n\\nThe Hatch nuclear power plant near Baxley, GA experienced an unexpected shutdown of \\none of its reactors after a software update on the business network reset data on a control \\nnetwork in March 2008.40 The reactor safety program interpreted the reset as a loss of water \\nto cool the reactor core and initiated an automatic shutdown.41 While no damage occurred, \\nthere  was  a  loss  of  electrical  power  generation  because  the  plant  was  shut  down  for  48 \\nhours.42 The parent company, Southern Company, had to purchase electricity from another \\nprovider  which  cost  $5  million.43  The  Hatch  case  shows  that  SCADA  systems  that  are  fed \\nincorrect data can still take physical action based on that data; if connected to these SCADA \\nsystems, an attacker could cause a denial of service (DoS) of electrical power or worse.\\n\\nBrowns Ferry Nuclear Power Plant \\n\\nIn August 2006, the Browns Ferry nuclear reactor was shut down manually after two pumps \\nresponsible for pumping cooling water through the core failed; these pumps were controlled \\nby variable frequency drives (VFD) which contain microprocessors that send and receive data \\nover the control network.44 The VFD failed due to excessive traffic on the control network, \\nand  while  no  damage  to  critical  systems  occurred,  a  loss  of  electrical  power  generation \\noccurred  similar  to  the  Hatch  power  plant  incident.45  This  was  not  due  to  a  cyber-attack, \\nbut it shows how fragile SCADA systems can be. An attacker could execute a DoS attack by \\nflooding the control network with useless data, and SCADA systems could fail and prevent \\ncritical components from operating, resulting in a loss of electrical power or potential reactor \\ncore damage.\\n\\nFigure 5. Browns Ferry Nuclear Power Plant46\\n\\nHomeland Security Affairs, Volume 14 Article 4 (April 2018) WWW.HSAJ.ORG\\n\\n \\n\\x0cHorner,  SCADA Fusion With Commercial Fission \\n\\n10\\n\\nRecent Power Plant Hacking \\n\\nIn  a  recent  wave  of  attacks  starting  in  May  2017,  a  hacking  group  targeted  the  business \\nnetworks  of  companies  that  operate  nuclear  power  plants.  One  of  these  companies  was \\nthe Wolf Creek Nuclear Operating Corporation which operates a nuclear power plant near \\nBurlington, Kansas.47 The DHS and FBI reported that an advanced persistent threat (APT) actor \\nwas responsible for these attacks.48 The attackers generally attempted to exploit the insider \\nthreat by spear- phishing, or targeting specific users in order to gain sensitive information \\nor credentials. The APT sent emails containing malicious attachments to senior engineers, \\nhoping to steal the credentials of a recipient who opened an attachment.49 The APT used \\nother avenues of attack, like the watering hole attack, where a regularly-visited website is \\nhacked to attack the users who visit, and a man-in-the-middle attack, where attackers route \\nInternet traffic of users and their destinations through the attacker’s machine.50\\n\\nAPTs differ from other attackers in that they generally focus on intelligence gathering, trade \\nsecret theft, disruption of operations, or even physical destruction of equipment; they have \\nmany  financial  and  personnel  resources,  and  some  are  backed  by  nation  states.51  While \\nthese  attacks  were  aimed  at  the  business  network  rather  than  the  operational  network, \\nthe information that the APT could gain from infiltrating business networks could make any \\nfuture attacks on the operational network much more effective and dangerous.\\n\\nThe SCADA Vulnerability Market\\n\\nIn  addition  to  increasing  connectivity,  power  plants  are  using  SCADA  systems  with  open \\nprotocols and COTS.52 This can allow hackers to gain knowledge about SCADA systems. An \\nattacker can purchase a commercially available SCADA system, probe it for vulnerabilities, \\nand use those discovered vulnerabilities against a power plant using the COTS SCADA system \\nto gain unauthorized access. In fact, there is currently a market for this exact information, \\nand exploits are selling at a relatively low cost.53 For example, while Apple iOS 9 vulnerabilities \\ncan sell for up to $1 million, anonymous users can purchase SCADA vulnerabilities with an \\n$8,100 annual subscription fee.54 Gleg, ReVuln, and Exodus Intelligence are three companies \\ndevoted to finding SCADA vulnerabilities, and while their stance is to improve security by \\ndiscovering  vulnerabilities,  the  companies  take  no  responsibility  for  what  users  with  ill \\nintentions may do with those exploits.55\\n\\nRecommendations to Improve Cybersecurity \\n\\nBecause SCADA systems can control critical processes in a nuclear power plant, protection \\nof  these  systems  from  cybersecurity  threats  is  paramount.  However,  replacing  all  SCADA \\nsystems  with  more  robust  systems,  known  as  “rip  and  replace,”  is  likely  infeasible  due  to \\nthe massive cost and downtime of critical processes required to overhaul control systems. \\nFor example, in the oil and gas sector, replacing 200 gas turbine controllers could cost up to \\n$70 million before accounting for the cost of lost production.56 Because nuclear equipment \\ncould be radioactive, disposal could further increase the cost of a rip and replace strategy.\\n\\nHomeland Security Affairs, Volume 14 Article 4 (April 2018) WWW.HSAJ.ORG\\n\\n \\n\\x0cHorner,  SCADA Fusion With Commercial Fission \\n\\n11\\n\\nImprovement of Control Networks \\n\\nIt may be more economically feasible for older power plants to improve the control networks \\non which the SCADA systems reside. Specific network improvements include redundancy, \\nwhitelisting applications, and adding an intrusion detection system (IDS) to the network.57 \\nRedundancy can help with patch management by shifting normal processes to one SCADA \\ncomponent  while  the  other  is  being  updated.  Additionally,  redundancy  can  assist  with \\ninadvertent activation of automated safety functions. In the case of the Hatch power plant, \\nif  two  SCADA  components  were  required  to  activate  the  safety  shutdown,  the  plant  may \\nhave avoided the shutdown. Whitelisting can help ensure that only approved applications \\nare allowed to run on control networks that can reduce the potential effects of malware. An \\nIDS can alert operators to abnormal conditions on the control network. In the case of the \\nBrowns  Ferry  shutdown,  operators  could  have  been  alerted  to  abnormally  high  network \\ntraffic and mitigated the circumstances that caused the pump VFD to fail.\\n\\nThe  conventional  wisdom  within  the  NRC,  the  DHS,  and  the  NEI  is  that  SCADA  systems \\nare protected when they are isolated or air-gapped.58 However, critics argue that truly air-\\ngapped systems do not exist.59 The Stuxnet worm demonstrated that even air-gapped Iranian \\ncentrifuges were susceptible to infection.60 The primary method of infection of Stuxnet was \\nthrough USB flash drives which do not require a network connection.61 Also, the Davis-Besse \\ncase  shows  that  system  administrators  may  be  unaware  of  all  connections  to  its  SCADA \\ncontrol network.62 \\n\\nMinimize the Insider Threat \\n\\nAnother  significant  cybersecurity  problem  within  commercial  power  plants  is  the  insider \\nthreat.63 The Three Mile Island accident highlighted the need for competent operators; as a \\nresult, nuclear power plant operators are typically well-trained.64 However, this training may \\nentrench  nuclear  operators  in  a  certain  way  of  performing  their  duties,  and  information \\nsecurity  personnel  may  have  difficulty  trying  to  steer  nuclear  operators  away  from  risky \\nactivities.  One  of  these  activities  is  connecting  an  operator’s  personal  computer  to  the \\nSCADA control network; this can expose the control network to any malware residing on the \\npersonal computer.65 The attacks in 2017 demonstrate that APTs are relying on the insider \\nthreat as one way to hack into networks.\\n\\nAlthough the operators interact directly with the control networks, supervisors and senior \\nexecutives can also benefit from cybersecurity training. While those in a supervisory role \\nare well-versed in physical security for nuclear facilities, cybersecurity is considered a low \\npriority.66 This could be a result of recent adoption of digital systems in nuclear power, lack \\nof reported cybersecurity incidents at nuclear facilities, and a focus on physical security.67\\n\\nHomeland Security Affairs, Volume 14 Article 4 (April 2018) WWW.HSAJ.ORG\\n\\n \\n\\x0cHorner,  SCADA Fusion With Commercial Fission \\n\\n12\\n\\nNuclear Power Information Sharing and \\nAnalysis Center (ISAC)\\n\\nThere may be a dearth of cybersecurity experts in the nuclear field, so a national organization \\ncould help provide support to nuclear supervisors. As in other CI sectors, an ISAC could be \\ncreated for nuclear power plants.68 This can be an effective way to concentrate cybersecurity \\nexpertise and provide a method for nuclear facilities to disclose anonymously cybersecurity \\nincidents and lessons learned. The NRC could fill this role, but Kesler argues that the NRC \\nlacks cybersecurity expertise.69 Additionally, since the NRC functions as a regulatory body, \\nnuclear power plants may be less likely to disclose cybersecurity incidents to the NRC than \\nto an independent organization.\\n\\nConclusion\\n\\nSCADA  systems  are  pervasive  throughout  commercial  nuclear  power  plants  in  the  U.S. \\nSome of these systems are involved with the safety, security, and emergency preparedness \\nof  the  power  plant,  and  licensed  owners  must  have  an  NRC-approved  cybersecurity  plan \\nfor these systems according to 10 CFR 73.54. However, the nuclear sector may be lagging in \\nthe application of cybersecurity. Since 2001, two reported incidents involving cybersecurity \\nresulted in a shutdown of a nuclear reactor, and one reported incident was the result of a \\ncomputer worm. SCADA technology is becoming more standardized and more connected, \\nand there is a market for their vulnerabilities, so protecting these systems is paramount. \\nSCADA  systems  can  be  designed  to  be  more  resilient  against  cyber-attacks,  but  for  older \\nnuclear  power  plants  that  cannot  feasibly  rip  and  replace  SCADA  systems,  improving  the \\ncontrol  network  may  be  a  more  economical  option.  Cybersecurity  training  for  operators \\nand  supervisors  can  improve  security,  and  a  nuclear  ISAC  could  provide  lessons  learned \\nfrom  cybersecurity  incidents  at  nuclear  power  plants  and  provide  needed  cybersecurity \\nexpertise to the NRC.\\n\\nAbout the Author\\n\\nMatthew  Horner  is  a  Cybersecurity  Engineer  with  Engility  Corporation  in  Bedford,  MA \\nassessing the risk of Air Force information systems. He was previously a Lieutenant in the \\nUS Navy and served aboard the USS Alabama, a nuclear-powered ballistic missile submarine \\nin Bangor, WA, helping to prevent an unfriendly exchange of nuclear missiles. He may be \\nreached at matthewshorner@gmail.com.\\n\\nHomeland Security Affairs, Volume 14 Article 4 (April 2018) WWW.HSAJ.ORG\\n\\n \\n\\x0cHorner,  SCADA Fusion With Commercial Fission \\n\\n13\\n\\x0c', 'We Cannot Blindly Reap  \\nthe Benefits of a Globalized \\nICT Supply Chain!\\n\\nDon Davidson, Office of the DoD Chief Information Officer\\nStephanie Shankles, Booz Allen Hamilton\\n\\nAbstract. Information and Communication Technology (ICT) Supply Chain Risk \\nManagement (SCRM) seeks to manage and mitigate cyber and supply chain risk \\nthroughout an acquisition and sustainment lifecycle for an element or a system. \\nIt is a multi-disciplinary challenge that requires contributions and collaboration \\namong many disciplines. Key areas include systems engineering, system security \\nengineering, information security, software development, application security, supply \\nchain and logistics planning and management, IT resiliency, and risk management. \\nWhile many areas are making great strides in developing and implementing best \\npractices and tools to combat their individual cyber challenges, it is imperative for \\nsuccessful enterprise risk management to view the challenge holistically and align \\ncommon best practices and initiatives, some from/for the public sector and some \\nfrom/for the private sector. \\n\\nIntroduction\\n\\nA holistic view of supply chain risk management is one of \\nthe 12 key areas in the United States Comprehensive National \\nCyber Security Initiative (CNCI). CNCI-SCRM is a Federal Gov-\\nernment wide multi-pronged approach for managing risk while \\noperating in a global supply chain. Managing this risk requires \\na greater awareness of the threats, vulnerabilities, and conse-\\nquences associated with acquisition decisions; the development \\nand employment of tools and resources to technically and op-\\nerationally mitigate risk across the lifecycle of systems, products \\nand/or elements (from design through retirement); the develop-\\nment of new acquisition policies and practices that reflect the \\ncomplex global marketplace; and partnership with industry to \\ndevelop and adopt supply chain and risk management standards \\nand best practices.\\n\\n“Software and hardware are at risk of being tam-\\npered with even before they are linked together in an \\noperational system. Rogue code, including so-called \\nlogic bombs, which cause sudden malfunctions, can be \\ninserted into software as it is being developed. As for \\nhardware, remotely operated “kill switches” and hidden \\n“backdoors” can be written into the computer chips used \\nby the military, allowing outside actors to manipulate the \\nsystems from afar. The risk of compromise in the manu-\\nfacturing process is very real and is perhaps the least \\nunderstood cyberthreat. Tampering is almost impossible \\nto detect and even harder to eradicate.”  \\n(DEPSECDEF Lynn in FOREIGN AFAIRS in Sep 2010.)\\n\\nGlobalization has brought a unique set of SCRM challenges \\n\\nand threats to the U.S. Government and industry, especially \\nwith our ever-increasing reliance on ICT products and services \\nto meet mission and business needs and the interconnected \\n\\n4     CrossTalk—March/April 2013\\n\\nnature of our IT systems. Threats to the ICT systems are varied, \\ncomplex and demonstrate a wide array of motivations for at-\\ntack. They range from counterfeit items made for a quick profit, \\nintentional threats such as malicious code or hardware Trojans, \\nto poor software development practices that create software \\nvulnerabilities or hardware quality issues. These are all the more \\ndangerous because ICT is found everywhere in our environ-\\nment, from our home entertainment systems, mobile devices \\nthat hold/move our personal information, to our infrastructure’s \\nfinancial and energy sectors, and even to national security sys-\\ntems and weapons systems. \\n\\nChallenges With Globalization\\n\\nGlobally, USG represents a relatively minor share of the ICT \\nproduct and service market for the industry and alone does not \\ncommand the market power to drive commercial suppliers to \\nsubstantially change their SCRM practices. However, USG is \\nan important stakeholder in the process because of their role in \\nnational and global security and the variety of valuable lessons \\nlearned and best practices they can provide because they are \\nsuch a diverse organization. The ICT SCRM challenge is not \\nlimited to USG, it impacts every government and commercial \\norganization that acquires and uses ICT products and services. \\nFurthermore, many of the suppliers of ICT products and services \\nalso find themselves acquiring ICT products and services to \\nintegrate into their own solutions and therefore have a common \\ninterest in facing the ICT SCRM challenge.\\n\\nFederal acquirers and commercial acquirers and suppliers are \\n\\nall increasingly interconnected and interdependent in a global \\nsupply chain, both physically and digitally. We, in USG are not as \\nindependent as we used to be; we have fewer unique capabili-\\nties, systems and components. We all leverage an increasing \\nnumber of COTS products, including hardware, software and \\nservices. However, our mission remains unique, and in the inter-\\nest of national security and warfighter support, mission critical \\nacquisitions need to be evaluated in terms of product integrity, \\nmission assurance and SCRM best practices. \\n\\nIn this budget-conscious environment, there is no way to return \\n\\nto a supplier base of “all-American” companies for the U.S. Gov-\\nernment’s ICT acquisitions, nor can we have complete confidence \\nthat even American made products are free of supply chain \\nvulnerabilities. Knowing what challenges we face by applying \\nSCRM practices and guidance to our acquisition processes will \\nhelp us tackle our next big challenge, which is to build weapons \\nsystems and information networks that are resilient against the \\nmost sophisticated cyber adversaries using mostly commercial \\nand potentially untrustworthy products and services. This is both a \\nsourcing and a systems engineering challenge.\\n\\nAddressing the SCRM Challenge\\n\\nGAO recently published GAO Report-12-361 Code 311064, \\n\\n“IT Supply Chain: National Security-related Agencies Need to \\nBetter Address Risks.” They endorsed DoD SCRM strategy and \\nimplementation and recommended it as a model to others.  The \\nCommittee on National Security Systems (CNSS) recently pub-\\nlished CNSS Directive 505 on Supply Chain Risk Management. \\nGAO said DoD’s efforts to implement SCRM can be a learning \\ntool for others in the Federal government. DoD is currently imple-\\n\\nSUPPLY CHAIN RISK MANAGEMENT\\x0cReport Documentation Page\\n\\nForm Approved\\nOMB No. 0704-0188\\n\\nPublic reporting burden for the collection of information is estimated to average 1 hour per response, including the time for reviewing instructions, searching existing data sources, gathering and\\nmaintaining the data needed, and completing and reviewing the collection of information. Send comments regarding this burden estimate or any other aspect of this collection of information,\\nincluding suggestions for reducing this burden, to Washington Headquarters Services, Directorate for Information Operations and Reports, 1215 Jefferson Davis Highway, Suite 1204, Arlington\\nVA 22202-4302. Respondents should be aware that notwithstanding any other provision of law, no person shall be subject to a penalty for failing to comply with a collection of information if it\\ndoes not display a currently valid OMB control number. \\n\\n1. REPORT DATE \\nAPR 2013 \\n\\n2. REPORT TYPE \\n\\n4. TITLE AND SUBTITLE \\nWe Cannot Blindly Reap the Benefits of a Globalized ICT Supply Chain! \\n\\n6. AUTHOR(S) \\n\\n7. PERFORMING ORGANIZATION NAME(S) AND ADDRESS(ES) \\n517th SMXS/MXDEA,6022 Fir Avenue,Hill AFB,UT,84056 \\n\\n3. DATES COVERED \\n  00-00-2013 to 00-00-2013  \\n\\n5a. CONTRACT NUMBER \\n\\n5b. GRANT NUMBER \\n\\n5c. PROGRAM ELEMENT NUMBER \\n\\n5d. PROJECT NUMBER \\n\\n5e. TASK NUMBER \\n\\n5f. WORK UNIT NUMBER \\n\\n8. PERFORMING ORGANIZATION\\nREPORT NUMBER \\n\\n9. SPONSORING/MONITORING AGENCY NAME(S) AND ADDRESS(ES) \\n\\n10. SPONSOR/MONITOR’S ACRONYM(S) \\n\\n11. SPONSOR/MONITOR’S REPORT \\nNUMBER(S) \\n\\n12. DISTRIBUTION/AVAILABILITY STATEMENT \\nApproved for public release; distribution unlimited \\n\\n13. SUPPLEMENTARY NOTES \\n\\n14. ABSTRACT \\n\\n15. SUBJECT TERMS \\n\\n16. SECURITY CLASSIFICATION OF: \\n\\na. REPORT \\nunclassified \\n\\nb. ABSTRACT \\nunclassified \\n\\nc. THIS PAGE \\nunclassified \\n\\n17. LIMITATION OF \\nABSTRACT \\nSame as\\nReport (SAR) \\n\\n18. NUMBER\\nOF PAGES \\n4 \\n\\n19a. NAME OF\\nRESPONSIBLE PERSON \\n\\nStandard Form 298 (Rev. 8-98) \\nPrescribed by ANSI Std Z39-18 \\n\\n \\n\\x0cFigure 1\\n\\nmenting a strategy for achieving trusted systems and networks to \\naddress this challenge which has four key tenets: prioritizing re-\\nsources based on mission dependence; comprehensive program \\nprotection planning; enhanced vulnerability detection, and industry \\npartnership. This trusted systems and networks strategy is being \\nimplemented through existing Program Protection and Informa-\\ntion Assurance processes through the recently published DoD \\npolicy DoDI 5200.44 – “Protection of Mission Critical Functions \\nto Achieve Trusted Systems and Networks.” It integrates existing \\ndisciplines of SCRM, system security engineering, counterintel-\\nligence, hardware and software assurance among others, to \\nreduce the likelihood that warfighting capabilities will be impaired \\ndue to vulnerabilities in system design or sabotage of a system’s \\ncritical functions and components. The policy builds on best \\npractices, lessons learned, and evolving thinking from more than \\nfour years of piloting and incremental implementation within the \\nDepartment by requiring specific program protection and SCRM \\nactivities to protect the most critical DoD systems. We continue \\nto work across the Department and with our fellow interagency \\npartners, our suppliers, and our system integrators to implement \\na risk management strategy into other government organizations \\n(and their suppliers) and the country’s wider Critical Infrastructure \\nProtection initiatives.\\n\\nvention, risk mitigation, or even risk endurance posture.” \\n\\nIn Figure 1, the large purple arrow highlights information \\n\\nsharing as the key to harmonizing SCRM efforts currently being \\naddressed by different stakeholders, such as the civil govern-\\nment agencies, defense agencies and private industry. A number \\nof active joint efforts and information sharing forums exist, as \\nnoted by the red circled items. The Open Group’s Open Trusted \\nTechnology Forum is a collaborative effort between govern-\\nment and industry and is currently developing a framework of \\nSCRM best practices for use by industry. The SCRM Lifecycle \\nProcesses and Standards Working Group meets almost monthly \\nand is a DHS-DOD CNCI-11 (SCRM) effort co-chaired by DoD \\nand NIST representatives and serves as an interagency sharing \\nand collaboration venue. The Cyber Security 1 (CS1) ICT SCRM \\nAd Hoc group is comprised of civil and defense/government \\nrepresentatives and industry stakeholders. The primary focus \\nis SCRM input and development of international standards, as \\nCS1 supports the International Organization for Standardization \\n(ISO). Finally, the Common Criteria Development Board (CCDB) \\nis an ISO based effort supported by industry and government \\nparticipation and is actively incorporating SCRM into the CC \\ncertifications for global use. \\n\\nAs we develop better visibility into the global supply chain and \\n\\nWorking With Industry \\n\\nimproved trust in the products we consume or use we will be \\nable to develop more resilient system designs, which will move \\nus from a “risk response posture” to a more proactive, “risk pre-\\n\\nProduct development (from design through manufacturing, \\nintegration, and delivery) typically involves an array of develop-\\ners and suppliers around the world, many of whom the end user \\n\\nCrossTalk—March/April 2013     5\\n\\nSUPPLY CHAIN RISK MANAGEMENT\\t\\n \\xa0\\n\\x0cFigure 2\\n\\ndoes not know. As a consequence of our global supply chain, \\nadversaries have more opportunities to corrupt technologies \\nbefore we take ownership and introduce malicious, tainted or \\ncounterfeit code or hardware into the supply chain. And even \\noutside of the maliciously altered products, these incredibly \\ncomplex, commercial products may at times have vulnerabili-\\nties unintentionally left in as they leave the product line. These \\nvulnerabilities may be tolerable in cell phones and video games, \\nbut could prove catastrophic in a fighter jet or classified network \\nas such vulnerabilities may make it easier for adversaries to use \\nremote access attacks to otherwise gain access to the USG’s \\nsystems and networks. \\n\\nDoD has been working internally to enhance its acquisition, \\nengineering, and sustainment processes, while simultaneously \\nworking externally with commercial industry to advocate improved \\nproduct development standards to reduce vulnerabilities in com-\\nmercial products related to global sourcing. The study of ICT \\nSCRM standards landscape was completed in January 2010 in \\nthe form of a document and a key graphic provided in Figure 2.\\nThe graphic and the corresponding Standards Landscape \\ndocument are based on the portfolio of two international commit-\\ntees under the auspices of ISO/IEC JTC1 – SC 27 that focuses \\n\\non IT Security Techniques and SC7 that focuses on System and \\nSoftware Engineering. The graphic is color-coded as follows:\\n•  Blue indicates Standards Development Organization  \\n\\n(SDO) groups associated with ISO, IEC, or ITU\\n\\n•  Green indicates other SDOs \\n•  Pink indicates US-based organizations including the  \\n\\nTechnical Advisory Groups for SC7 (SC7 TAG) and SC27  \\n(CS1), their parent organizations (IEEE and ANSI), as well  \\nas US government agencies engaged in the development  \\nof ICT SCRM standards (NIST, DoD, DHS)\\n\\n•  Purple stars indicate specific SDOs currently engaging  \\n\\nin the development of ICT SCRM content, both  \\nnationally and internationally, including SC27, SC7, The  \\nOpen Group, CCDB, and NIST. Note these same starred  \\nareas are where DoD chose to engage with their  \\ninformation sharing activities.\\n\\nThe standards landscape identified a variety of groups that \\nare engaging in the collection/development of ICT SCRM or \\nrelated content and helped prioritize DOD engagement in these \\ngroups, as well as the areas of focus. Based on the outputs of \\nlandscape DOD has engaged with multiple stakeholders and \\ncontinues identifying other potential stakeholder groups to facili-\\n\\n6     CrossTalk—March/April 2013\\n\\nSUPPLY CHAIN RISK MANAGEMENT \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n\\t\\n \\xa0\\n\\x0ctate information sharing.\\n\\nThe standards landscape review led DOD standardization \\nactivities towards specific SDOs to focus on standardization \\nfor ICT SCRM. The standards landscape also recommended \\nrelevant standards efforts within SC27 and SC7 for participation, \\ninfluence, and monitoring based on the overall DOD engage-\\nment framework. DoD is actively working to coordinate external \\nstandards efforts with the DoD IT Standards Registry. \\n\\nBased on the landscape DOD focused its standardization \\non CS1 and worked with CS1 to establish and Chair CS1 ICT \\nSCRM Ad Hoc that is a joint group with SC7 TAG. The Ad Hoc \\nis a non-voting group that has the authority to review SC27 and \\nSC7 standards distributed to US National Bodies (CS1 and SC7 \\nTAG) for review and comment, works to achieve consensus on \\na single position, and then recommends positions for vote and \\napproval by CS1 or SC7 TAG as US positions to be submitted to \\nSC27 or SC7.\\n\\nAs the efforts progressed, other areas of focus were identi-\\nfied including The Open Group, North American Security Prod-\\nucts Organization, Information Security Forum, Object Manage-\\nment Group, Common Criteria / ISO15408 and SAE(G19), etc. \\nTrusted Mission Systems and Networks continues identifying \\nadditional SDOs for potential collaboration through the current \\nparticipation in various SDOs. These efforts were identified \\nbased on the inputs received from individual participants in \\nthe standardization processes, as well as to ensure that CS1/\\nSCRM AdHoc WG references relevant documents that are \\neither already in the standards domain or in the process of be-\\ning developed.\\n\\nConclusion\\n\\nThe SCRM community/stakeholders know that change will \\n\\nnot happen overnight and the implementation of this kind of \\ncomprehensive acquisition risk management for all of our sys-\\ntems and networks will take the investment of resources, time \\nand funding. Therefore a key element of the SCRM strategy is \\nto prioritize capabilities and their enabling systems and sub-\\ncomponents; identify our critical systems and plan for and build \\nin more trust, using a risk based approach.\\n\\nIn DoD we continually seek to improve our capabilities and \\ncyber posture; improving our capability to detect cyber problems \\nin our day-to-day operations, but that still puts us in a “risk re-\\nsponse posture”; we need to better understand the components \\nwithin our systems that enable our mission critical capabilities \\n(we call this criticality analysis); where do we source the critical \\nhardware, software, and services for those systems (especially \\nnational security systems and critical infrastructure), and how \\nshould we better design and manage our systems to minimize \\nvulnerabilities and assure critical functions, even when a system \\nis under attack. Understanding and managing the risk associated \\nwith those systems and their components, will make us and our \\nsystems more resilient. \\n\\nRecently, there has been a lot of news on microelectronic \\ncounterfeits, malicious or poor quality software and data breach-\\nes. All of these topics have roots in our global supply chain. Do \\n\\nStakeholder \\nAudience \\n\\nOngoing Effort \\n\\nPoints Of Contact \\n\\nDepartment of \\nDefense \\n\\nTrusted Systems and \\nNetworks Round Table \\n\\nJoe Wassel − joe.wassel@osd.mil \\nMelinda Reed − melinda.reed@osd.mil \\n\\nInteragency \\nCoordination \\n\\nCNCI SCRM Working \\nGroup 2 \\n\\nDon Davidson − don.davidson@osd.mi \\nJon Boyens − jon.boyens@nist.gov \\n\\nCritical Infrastructure \\nProtection \\n\\nDHS SCRM \\nDHS Software Assurance \\n\\nJoe Jarzombek − joe.jarzombek@hq.dhs.gov \\n\\nISO Standards and \\nHarmonization \\n\\nCS1 ICT SCRM Ad hoc \\n\\nDon Davidson − don.davidson@osd.mil \\nNadya Bartol − nadya.bartol@utc.org \\n\\nTable 1: SCRM Effort Contacts\\n\\nnot misunderstand our intent, this is not about becoming isola-\\ntionists—DoD embraces globalization and will continue to reap \\ncost and schedule benefits from it every day—but we do need to \\nbe more sensitive to the system and/or information security and \\nproduct and/or data integrity implications, to our systems and \\nultimately our capabilities, when outsourcing key components \\nand capabilities. We need to better “see” into some legs of the \\nsupply chain, especially where critical components are involved.\\nDoD is doing well in our strategy and implementation on \\n\\nSCRM, however we are developing capability through a  \\n“crawl-walk-run” process which has dependencies on potentially \\ndiminishing resources and external support, like private  \\nsector cooperation.\\n\\nFor additional information or to get involved in SCRM efforts, \\n\\ncontacts are listed in Table 1.\\n\\nABOUT THE AUTHORS\\n\\nDon Davidson is assigned to Trusted Mission Systems and \\nNetworks in the Office of the Department of Defense Chief \\nInformation Officer (DoD CIO), as Chief, Outreach, Science, and \\nStandards (CNCI-SCRM). He has 37 years of federal service \\nto include 11 years active duty, as well as civilian assignments \\nin Army Research Laboratory, Army Materiel Command, Army \\nSecretariat, US Joint Forces Command, OUSD-Acquisition, \\nTechnology & Logistics (AT&L), and DoD CIO. \\n\\nE-mail: Don.Davidson@osd.mil\\n\\nStephanie Shankles of Booz Allen Hamilton, is a subject mat-\\nter expert in software assurance and ICT supply chain risk \\nmanagement. She supports projects ranging from IT policy \\ndevelopment to IT security training to helping clients integrate \\nsecurity processes throughout their project lifecycle. She is cur-\\nrently supporting industry efforts to develop and implement ICT \\nsupply chain risk management guidelines and standards. She \\nhas spoken at multiple industry events on software assurance \\nimplementation, benchmarking and measurement. \\n\\nE-mail: shankles_stephanie@bah.com\\n\\nCrossTalk—March/April 2013     7\\n\\nSUPPLY CHAIN RISK MANAGEMENT \\n\\x0c', 'R&DSpotlight\\n\\nAdrian Davis\\n\\nSimply put, if the \\ncompromise of any part \\nof our organization’s \\ninfrastructure would \\ncause a high business \\nimpact, it’s critical\\n\\nISF member, manufacturing sector\\n\\n\\x0cSPOTLIGHT\\n\\nWhat Is Critical to \\nYour Infrastructure? \\n\\nCritical infrastructure means many things to many \\npeople. Adrian Davis, principal research analyst with \\nthe Information Security Forum (ISF), explains why \\ndetermining which infrastructure elements are critical to \\na business is the first step in keeping them safe\\n\\nGovernment and businesses often view the \\nworld through separate lenses. The list of \\nthat deemed ‘critical’ in the public sector, \\nalthough complexly inter-related, is far from \\na mirror image of the infrastructure concerns \\nof private businesses. \\n\\nThe simple fact is, most if not all \\n\\nbusinesses depend on numerous \\ninfrastructure elements to maintain smooth \\noperations. This article will look at what \\ncritical infrastructure is – and what it means \\nto a business – and then discuss what we, as \\ninformation security professionals working \\ntogether and with other IT, business and legal \\nprofessionals, can do to secure it.\\n\\nDeﬁning Critical Infrastructure  \\nFor many of us, when we think of critical \\ninfrastructure, we think of networks, of data \\ncenters and perhaps of utilities, such as \\nwater or electricity. Governments tend to \\nthink big, as demonstrated by this definition \\nfrom the US Government’s Department of \\nHomeland Security: \\n\\n“Critical infrastructure and key resources \\n(CIKR) includes physical or virtual assets, \\nsystems, and networks so vital to the United \\nStates that the incapacity or destruction of \\nsuch assets, systems, or networks would \\n\\nhave a debilitating impact on security, \\nnational economic security, public health or \\nsafety, or any combination of those matters.”\\n\\nIt’s worth remembering that not everything \\nwithin a national infrastructure sector \\nis critical. In the various sectors of the \\neconomy there are certain critical elements \\nof infrastructure, the loss or compromise \\nof which would have a major, detrimental \\nimpact on the availability or integrity \\nof essential services, leading to severe \\neconomic or social consequences, or loss \\nof life. These infrastructure assets make up \\nthe nation’s critical national infrastructure \\n(CNI) and may be physical (e.g., sites, \\ninstallations, pieces of equipment) or logical \\n(e.g., information networks, systems).\\n\\nFor most of us in business, we look \\n\\ntoward the government to deal with \\nthese big picture issues. We focus on \\nwhat we can control and protect – which \\nfrequently includes our organization’s \\nnetworks, buildings and IT. We may reach \\nout to our service providers and set \\nsecurity requirements they need to meet. \\nBut no matter what we believe is critical, \\nand thus try to protect, businesses \\nare becoming increasingly reliant on \\ninformation, IT, networks, and also SCADA \\n\\n(supervisory control and data acquisition) \\nsystems. \\n\\n“Any automated manufacturing facility \\n\\n– whether the product is a biscuit, clean \\nwater, electric energy, medicine, mass \\ntransportation, or almost anything – uses \\nSCADA systems to some degree”, says Eric \\nKnapp, director of critical infrastructure \\nmarkets for Nitro Security. “The impact \\nof disrupting such vital infrastructure can \\nhave huge ramifications for a company, \\nthe public or even national security.” \\n\\nWhat Is Critical to You?\\nOrganizations depend upon numerous \\nforms of infrastructure, such as operational \\nequipment, telecommunications, utilities \\nand buildings. For most organizations, \\ninfrastructure is thought of as the physical \\nstructures required to run it.\\n\\nBased on ISF research and discussions \\n\\nwith members on this topic, we suggest \\nthat there are a variety of reasons why \\norganizations classify parts of their \\ninfrastructure as critical. The primary \\nreason is when infrastructure is used to \\nsupport essential business operations, \\nsuch as manufacturing or assembling \\nproducts, delivering goods, and providing \\nservices.\\n\\nSEPTEMBER/OCTOBER   2011 SPOTLIGHT\\n\\n19\\n\\n \\n\\x0cSPOTLIGHT\\n\\ncritical and non-critical infrastructure \\noften establish levels of criticality, such as: \\ntier 1, 2 and 3; mission critical, business \\ncritical and business operational; or high, \\nmedium and low. The requirements of \\ninfrastructure components then determine \\nthe level (or category) with which they are \\nassociated.\\n\\nInfrastructure systems are typically – if \\n\\nnot always – supported by information \\nsystems. This use of information systems can \\nrange from small-scale information systems, \\nsuch as embedded systems and process \\ncontrol PCs, to highly distributed, integrated \\nand complex information systems, such \\nas computer-aided manufacturing (CAM) \\nterminals, air traffic control systems and \\nlogistical control systems. \\n\\nIn many cases, information \\n\\nsystems that support or enable critical \\ninfrastructure are outside of the \\norganization’s traditional computing \\nenvironment (e.g., the data center) and, \\nas a result, are not under the authority or \\ncontrol of the IT department. The drive \\nto outsource, offshore and focus on core \\ncompetencies, which may not include IT, \\nmay also mean that information systems \\nsupporting critical infrastructure are not \\nowned by the organization at all – and \\nmay be located in a different country.\\nFor example, one ISF member – a \\nmajor toy manufacturer – reveals it has \\nproduction lines in one country and \\nits outsourced packaging and logistics \\nhub in another. Further, the company’s \\noutsourced IT systems are run out of a \\nthird country. \\n\\nSecuring Critical Infrastructure\\nThe increasing use of information systems \\nto support and enable critical infrastructure \\nintroduces a new set of risks that \\norganizations need to navigate when meeting \\nthe security requirements relating to critical \\ninfrastructure. These include availability, \\nreliability and resilience. Based on the \\nISF’s work, several relevant examples of \\ninformation security issues can be grouped \\ninto four components of critical infrastructure \\n(see table 1). \\n\\nSecuring infrastructure requires more \\nthan just firewalls and patches – it requires \\nan understanding and agreement of what \\n\\nTable 1: Recommendations for securing critical infrastructure\\n\\n“Simply put, if the compromise of any \\n\\npart of our organization’s infrastructure \\nwould cause a high business impact, it’s \\ncritical”, asserts one ISF member within the \\nmanufacturing sector. \\n\\nOther grounds under which organizations \\nclassify infrastructure as critical include when \\nthe infrastructure (and, in some cases, the \\ncritical business operations it supports):\\n\\n• \\n\\n• \\n\\nIntroduces a significant health and safety \\nrisk because the infrastructure (e.g., \\nindustrial machinery, production lines \\nand energy production) is inherently \\ndangerous to individuals, or is operated in \\nan unsafe environment that could result \\nin injury or death;\\nIs subject to legal, regulatory and \\ncontractual obligations, and non-\\ncompliance would result in penalties, fines, \\nlegal liabilities, withdrawal of a license to \\n\\n• \\n\\noperate as a business or loss of customers;\\nIs considered to be of a high value (e.g., \\nmedical scanning equipment or drilling \\nequipment) or is associated with items \\nthat are of high value \\n\\n•  Supports or is considered part of \\n\\nthe country’s national infrastructure \\n(e.g., if the business provides energy, \\ntelecommunications or transportation \\nservices) and is therefore likely to require \\na greater level of protection.\\n\\nThis last point was illustrated by \\ncomments from one ISF member in \\nthe telecommunications sector. “We \\nprovide most of the telecommunications \\ninfrastructure in the country”, the member \\nshares. “We are therefore a vital element of \\nthe country’s national infrastructure.”\\nAcross the ISF membership, \\n\\norganizations that differentiate between \\n\\n20\\n\\nSPOTLIGHT\\n\\nSEPTEMBER/OCTOBER   2011\\n\\n\\x0cSPOTLIGHT\\n\\nComponents of Critical Infrastructure\\n\\nTypical Sub-components \\n\\nPotential Information Security Issues\\n\\nOperations \\n\\nProduction line equipment, warehouse operations, transport \\n\\nMalware infection of production line control devices, \\n\\nand logistics, and financial processing equipment\\n\\ntampering of ATM equipment\\n\\nTelecommunications\\n\\nData networks and landline, satellite and mobile \\n\\nPhysical damage or theft of landlines, theft of intellectual \\n\\nUtilities\\n\\nBuildings\\n\\ncommunications equipment \\n\\nproperty, telecommunications fraud, eavesdropping \\n\\nWater and gas pipelines, electrical supply and sewage  \\n\\nLoss of power to flow-control devices, failure of UPS  \\n\\ntreatment \\n\\nand/or standby generators, hacking of Supervisory \\n\\nControl and Data Acquisition (SCADA) devices \\n\\nPerimeter safety, gated access control and surveillance, \\n\\nLoss of physical access to premises and internal areas \\n\\nand environmental monitoring equipment \\n\\nof buildings, theft of assets, malicious damage to \\n\\ncontrolling equipment\\n\\nTable 2: The components of critical infrastructure and the potential security issues related to each component\\n\\nthe critical infrastructure for the organization \\nactually is. Information security professionals \\nneed to work with their business colleagues \\nand senior management to discover and \\nthen determine what infrastructure is critical \\n– and what information systems support that \\ninfrastructure. Remember that what people \\nview as critical can shift over time, and it can \\nradically change in the event of an outage.\\n\\nOnce the identification and agreement \\nis complete, an information risk analysis \\nof those supporting information systems \\nshould be undertaken. Business \\nrequirements for critical infrastructure \\nshould be translated into information \\nsecurity requirements; threats and \\nvulnerabilities assessed; and the findings \\nreported. The analysis should be broad \\nand cover topics such as the impact of \\n\\nIt doesn’t take much \\nfor one event to lead to \\nanother, and the next \\nthing you know, you’re \\ndealing with a major \\nevent that affects \\nsigniﬁcant parts of \\nthe organization’s \\ninfrastructure\\n\\nISF member, utilities sector\\n\\nconsumerization, use of cloud services, \\nubiquitous connectivity (including SCADA \\nconnecting to the internet) and the impact \\nof convergence on information systems. \\n“Security convergence is different \\nfrom normal data security”, asserts Ian \\nKilpatrick, chairman of IT specialist Wick \\nHill Group. He says this is “because the \\nlink between phone systems and the \\ninternet makes both voice and data more \\nvulnerable to problems, such as toll fraud \\nand the total loss of both voice and data \\ncommunications, if VoIP is hacked”.\\n\\nOnce the risk analysis is complete, a \\ncontrol framework for critical infrastructure \\nneeds to be established. This should cover \\nthe selection and application of a balanced \\nset of controls (e.g., preventative, detective \\nand reactive) to protect information \\nsystems; make use of concepts such as \\ndefense in depth, least privileges and \\ndefault-deny; and should look at controls \\nthat enhance resilience and business \\ncontinuity. Where external suppliers \\nare involved, a common baseline for \\ninformation security arrangements should \\nbe adopted.\\n\\n“We have to constantly be aware of \\n\\ncluster threats”, comments one ISF member \\nfrom the utilities sector. “It doesn’t take \\nmuch for one event to lead to another, and \\nthe next thing you know, you’re dealing with \\na major event that affects significant parts of \\nthe organization’s infrastructure.” \\n\\nAnother ISF member, from the \\n\\nscheme was ignored. Instead, the priority \\nwas to restore its email system (see figure, \\nwhich illustrates the process at a high \\nlevel).\\n\\n“We broke the whole process into smaller \\n\\ntasks focused on one group of components \\nat a time”, adds the ISF member. “For \\nexample, we looked at our production \\nline machinery, industrial equipment and \\ntransport as part of operations.”\\n\\nOf course, the process is not a \\nstatic, one-off piece of work; critical \\ninfrastructure must be reviewed and \\nprotected on a continual basis, to deal \\nwith changes in the infrastructure and \\nits environment. This process – and \\nany changes associated with it – must \\nfit in with other schedules, such as \\nmaintenance windows, to minimize \\nmachinery or infrastructure downtime. \\n\\nPulling it All Together\\nOrganizations rely on critical infrastructure \\neveryday – whether it is the national \\ncritical infrastructure or their own. Failure \\nto distinguish between critical and non-\\ncritical infrastructure will result in a mixed \\nenvironment, which is difficult to manage \\nand protect effectively. \\n\\nInformation systems that are used to \\nsupport critical infrastructure in a mixed \\nenvironment will inevitably be either over \\nprotected (when the infrastructure is not \\ncritical) or under protected (when the \\ninfrastructure is critical).\\n\\nmanufacturing sector, classified its systems \\ninto varying levels of criticality, with \\nproduction machinery having the highest \\nclassification. When an outage occurred \\nat one of their plants, the classification \\n\\nSecuring critical infrastructure and \\nmaintaining an adequate level of protection \\non an ongoing basis requires a consistent and \\npractical approach – which must be \\nsupported by the business. \\n\\nSEPTEMBER/OCTOBER   2011 SPOTLIGHT\\n\\n21\\n\\n\\x0c', 'Smart Security?\\nEvaluating Security Resiliency in the U.S. Department  \\nof Transportation’s Smart City Challenge\\n\\nKate Beck\\n\\nSmart city initiatives, which involve the connection and automation of \\ncity systems and services through the use of information and communi-\\ncation technology, offer significant opportunities to improve efficiency \\nand address many environmental, economic, and social issues faced by \\nU.S. cities. However, as systems become increasingly connected and auto-\\nmated, these systems and the people whom they serve become more vul-\\nnerable to an array of security threats, including cybersecurity attacks \\nand attacks on the physical infrastructure and human lives. This paper \\nfocuses on how U.S. cities plan to mitigate and respond to the security \\nrisks that may arise from the integration of technology into transpor-\\ntation systems and connecting transportation system databases. After \\nexamining the U.S. Department of Transportation’s recent competition \\nBeyond Traffic: Smart City Challenge, this paper evaluates 32 of the \\n77 first-round applications to the Smart City Challenge submitted by \\nmidsize American cities. The paper provides a set of criteria to evaluate \\nthe resiliency of the applicants’ transportation systems, that is, the abil-\\nity of the cities to withstand and respond to security threats and chang-\\ning conditions. These criteria include the responses of cities to a range \\nof security risks, the response to unknown risks, plans to accommodate \\nrisks, and whether cities plan to work with private or public partners to \\ndevelop security mitigation and response strategies. The paper concludes \\nthat only 19 of the 32 first-round applications to the Smart City Chal-\\nlenge evaluated in this paper address security concerns related to the \\ndevelopment of smart transportation systems, and the majority of cities \\nwith security plans focus only on mass cybersecurity risks.\\n\\nIn December 2015, the U.S. Department of Transportation (U.S. \\nDOT), in partnership with the private investment company Vulcan, \\nannounced the Smart City Challenge, in which U.S. DOT planned \\nto provide a total of $50 million to one U.S. midsize city (cities with \\npopulations of between 200,000 and 850,000) to develop a model for \\nintegrating technology into transportation systems that can be rep-\\nlicated in other American cities. After an extensive application and \\nreview process in which 77 midsize cities applied in the first round, \\nU.S. DOT selected Columbus, Ohio, as the winner in June 2016.\\n\\nIn the Smart City Challenge documentation, U.S. DOT empha-\\nsized the role that technology and data integration in transportation \\nsystems can have in addressing safety, improving efficiency, and \\nreducing greenhouse gas emissions (1). It was notable, however, \\nthat one issue addressed to a lesser degree in that documentation \\n\\nDepartment of City and Regional Planning and School of Public Health, University \\nof California, Berkeley, 1601 Allston Way, Berkeley, CA 94703. katembeck@\\nberkeley.edu.\\n\\nTransportation Research Record: Journal of the Transportation Research Board, \\nNo. 2604, 2017, pp. 37–43.\\nhttp://dx.doi.org/10.3141/2604-05\\n\\n37\\n\\nis the extent to which applicant cities would address the array of \\nsignificant security risks that may arise from the integration of tech-\\nnology into transportation networks. U.S. DOT’s Smart City Chal-\\nlenge offers an exceptional opportunity to consider municipalities’ \\nplans to mitigate and respond to many known and unknown security \\nthreats to transportation systems.\\n\\nThe security risks that arise from the integration of information  \\nand communication technology into transportation systems and phys-\\nical infrastructure and the development of connected networks that \\ncollect, store, and exchange user data can range from cyber attacks \\nthat target user information or financial databases to attacks on the \\nphysical infrastructure or transportation users (2, 3). Such attacks \\nhave become an increasingly important issue in recent years as pub-\\nlic transit, aviation, and, recently, ground transportation systems have \\nbeen targeted as locations for terrorist attacks (3, 4). Transportation \\nsystems that are integrated through technology are also increasingly \\nat risk of natural threats, for example, sea level rise, hurricanes, large \\nstorms, and earthquakes.\\n\\nThe Smart City Challenge proposal from Portland, Oregon, shows \\nthe complex, interconnected systems that will arise from smart city \\ninitiatives; however, each of these connections allows new avenues \\nto threaten the security and safety of city residents (5). For instance, \\nthe Marketplace, in which financial user data are stored, could be \\nhacked,  causing  a  cybersecurity  breach  that  could  affect  one  to \\nthousands of individuals, or connected advanced devices could be \\nhacked, threatening the physical safety of tens or thousands of road \\nusers or people in public spaces (6). Because the security risks that \\narise from the integration of technology into the transportation sys-\\ntem vary to such a degree (7), this paper proposes the development \\nof resilient transportation systems, which are transportation systems \\nthat are designed to mitigate and respond to a variety of known and \\nunknown security threats.\\n\\nThe smart city and the Internet of things seem to be relatively new \\nphenomena that are changing the ways in which private and public \\ntransportation systems are operating; however, technology has been \\nintegrated into transportation systems since the mid-20th century. \\nIntelligent transportation systems have led to the development of a \\nnumber of transportation system technologies, including in-vehicle \\nnavigation systems, traffic management centers, and GPS-based trans-\\nportation systems throughout the last 60 years. Intelligent transpor-\\ntation systems have established a network of technological systems \\nthat can be used as the backbone of many of the smart city transpor-\\ntation interventions suggested by applicant cities. By using these \\nestablished systems, cities may be able to avoid many of the risks \\nassociated with the establishment of new technological networks.\\n\\nSecurity risks arising from the integration of technology into urban \\nsystems and services have largely been examined on a case-by-case \\n\\n\\x0c38 \\n\\nTransportation Research Record 2604\\n\\nbasis rather than a comprehensive basis. Research to date has exam-\\nined the potential risks related to physical attacks and cyber attacks \\non the highway infrastructure, cybersecurity risks for road transpor-\\ntation, and security attacks on intermodal transit stations (6–9). This \\nprevious research identifies aspects of smart city systems that have \\nhigh numbers of connected electronic controls, analyzes the specific \\nvulnerabilities in these systems, and then proposes new technologies \\nor methods to address these security risks.\\n\\nRather than analyzing security risks on a case-by-case basis, this \\npaper analyzes the resiliency of transportation systems on the basis \\nof submissions to the U.S. DOT’s Smart City Challenge. This paper \\nfirst examines the previous literature on transportation security and \\nresiliency planning in the transportation field. The paper then ana-\\nlyzes aspects of resiliency found in the applications to the Smart City \\nChallenge (1). This analysis is based on the cities’ plans to (a) respond \\nto a range of security risks (2), (b) develop broad response strategies \\nto identify and mitigate unknown risks (3), (c) develop contingency \\nplans for when risks do occur (accommodate risk), and (d) work with \\nprivate and public partners to address security concerns and set secu-\\nrity standards. The paper then proposes a set of recommendations for \\nU.S. DOT and transportation agencies to consider when to develop \\nsmart transportation networks.\\n\\nA significant constraint to the development of resilient transpor-\\ntation systems is the cost of security systems (8). Because security  \\nmechanisms are not necessary for the day-to-day operation of \\ntransportation systems, they are often lower priorities for budget-\\nconstrained government and private entities. This paper does not \\naddress  how  cities  plan  to  fund  the  planned  security  systems; \\nhowever, this limitation is addressed throughout the article.\\n\\nMEThoDology\\n\\nAn analysis of the content of U.S. Smart City Challenge documen-\\ntation, federal and state policy documents, and public reports was \\ncarried out. The peer-reviewed academic literature on intelligent \\ntransportation system security was also reviewed. Additional infor-\\nmation was gathered from the University of California, Berkeley, \\nInstitute of Transportation Studies Smart City Round Table (which \\nfocused on the Smart City Challenge application of San Francisco,  \\nCalifornia), President Barack Obama’s keynote speech on smart cities \\nat South by South West (during which he introduced the Smart City \\nChallenge and announced the seven city finalists), and an in-depth \\nsemistructured interview with a public agency official specializing \\nin autonomous vehicle safety in San Francisco.\\n\\nOf the first round of applications to the Smart City Challenge,  \\n32 of the 77 were collected and analyzed, including those of all seven \\nof the finalists (San Francisco, California; Portland, Oregon; Colum-\\nbus, Ohio; Kansas City, Missouri; Denver, Colorado; Austin, Texas; \\nPittsburgh, Pennsylvania). The cities that applied in the first round \\nwere contacted, and their applications were requested. The sample \\nof applications that were received was relatively geographically \\nrepresentative of all cities that had applied in the first round, with \\nsouthern cities being overrepresented and northeastern cities being \\nunderrepresented, as seen in Table 1.\\n\\nTo evaluate the resiliency of the cities’ security systems, the \\napplications from the first round were analyzed for the following:\\n\\n•\\t Response to a range of security risks,\\n•\\t Response to unknown risks,\\n\\nTABLE 1    Geographic Distribution  \\nof First-Round Applicants of Smart  \\nCity Challenge\\n\\nAll Applicant \\nCities\\n\\nStudy Sample\\n\\nRegion\\n\\nCount\\n\\nWest\\n\\nMidwest\\n\\nSouth\\nNortheast\\n\\n21\\n\\n17\\n\\n27\\n12\\n\\n%\\n\\n27\\n\\n22\\n\\n35\\n16\\n\\nCount\\n\\n10\\n\\n  7\\n\\n13\\n  2\\n\\n%\\n\\n31\\n\\n22\\n\\n41\\n  6\\n\\n•\\t Risk  mitigation  (prevention  of  risk)  versus  accommodation \\n\\n(management of and recovery from security breaches), and\\n\\n•\\t Private and public partnerships to address risks.\\n\\nA security risk spectrum was created to analyze smart transporta-\\ntion security systems. This spectrum consists of two continua: the \\nuser continuum and the system continuum (Figure 1). At one end \\nof the user continuum are security breaches that target individual \\ntransportation system users (referred to here as “targeted security \\nbreaches”). At the other end are security breaches that target full user \\nor financial databases, the physical infrastructure, or large groups of \\nusers or employees (referred to here as “mass security breaches”) \\n(10). At one end of the systems continuum are breaches that threaten \\nthe physical security of people and the infrastructure (referred to \\nhere as “physical security breaches”). At the other end are breaches \\nthreatening technological systems or databases (referred to here as \\n“cybersecurity breaches”).\\n\\nOnly first-round applications were analyzed because of the timing \\nof the research, which occurred during the U.S. DOT application \\nreview process. Although security was more strongly emphasized in \\nthe U.S. DOT second-round notice of funding opportunity (NOFO), \\nthe winning city (Columbus, Ohio) did not mention security risks in \\nits first-round application. The second round of applications for the \\nseven finalist cities have not yet been released, so a further analysis \\nof the finalist cities’ security plans is not included here.\\n\\nDEfining SECURiTy\\n\\nTransportation security issues have traditionally been addressed on a \\ncase-by-case or risk-by-risk basis, with researchers and practitioners \\nfocusing on specific types of risks to specific modes of transportation \\n(6, 7, 9, 11, 12). Individual transportation agencies, municipalities, \\nand private transportation services consider the risk of individual \\nsecurity  breaches  according  to  the  probability  that  the  event  will \\noccur  and  the  consequences  that  will  occur  if  this  event  were  to \\nhappen and then allocate resources accordingly (6, 7, 13). Security \\nthreats are also traditionally categorized and assessed on the basis \\nof the asset that is at risk; for instance, a threat to the transportation \\ninfrastructure would be assessed differently than a threat to other \\nassets, like a threat to data or to clients or employees (7, 9).\\n\\nThe literature suggests that traditional methods of addressing \\nsecurity risks are problematic for a variety of reasons. First, such \\nmethods assume that enough information about the risk’s probability  \\n\\n\\x0cBeck \\n\\n39\\n\\nMass Security Breach\\n\\nTransit control\\nsystem breached\\n\\nOpen data not\\nproperly anonymized\\n\\nh\\nc\\na\\ne\\nr\\nB\\ny\\nt\\ni\\nr\\nu\\nc\\ne\\nS\\nl\\n\\na\\nc\\ni\\ns\\ny\\nh\\nP\\n\\nTransportation device/\\ninfrastructure breached\\n\\nPII or SPII breached\\n\\nh\\nc\\na\\ne\\nr\\nB\\ny\\nt\\ni\\nr\\nu\\nc\\ne\\ns\\nr\\ne\\nb\\ny\\nC\\n\\nIncreased device automation\\nleads to higher crime rates\\n\\nSurveillance system threatens\\nindividual privacy\\n\\nTargeted Security Breach\\n\\nFIGURE 1    Potential security threats to smart transportation system implementation on user \\n(vertical) and system (horizontal) continua (PII = personally identifiable information;  \\nSPII = sensitive personally identifiable information).\\n\\nand consequences is known when, in reality, security threats to trans-\\nportation systems are constantly changing and their probability of \\noccurring and the severity of the consequences can rarely be quan-\\ntified. Second, these methods assume that security events occur in \\nisolation and threaten a single asset when, realistically, one security \\nbreach can often lead to another, affecting multiple transportation \\nassets (referred to as “cascading failures” or “cascading effects”) \\n(7, 11). As transportation systems become increasingly connected \\nthrough the use of shared databases and information and the use of \\ncommunication technology, the risk of new threats that have not been \\nidentified by authorities and the risk of cascading effects increase.\\n\\nWith the expansion of automated devices equipped with the abil-\\nity to connect to, communicate with, and provide data to large, inte-\\ngrated networks in transportation systems, an array of security risks \\narises (13). These risks range from security breaches to the disclosure \\nof personally identifiable information (PII) and sensitive personally \\nidentifiable information (SPII) of city residents and threats to indi-\\nviduals’ physical safety and security when they use automated trans-\\nportation systems (targeted security breaches). They also include \\nlarge-scale cyber or physical attacks that target infrastructure, finan-\\ncial assets, or the lives of hundreds to thousands of transportation \\nusers (mass security breach) (14). The use of automated, connected \\ndevices and integrated databases in transportation systems blurs the \\nline between cybersecurity and physical security because a cyber \\nattack or hack into a system can now have substantial physical con-\\nsequences that range from the security of an individual user to that \\nof full transportation networks (fitting on various levels of the system \\ncontinuum) (15). Figure 1 shows examples of potential risks that \\narise from the integration of technology into transportation systems \\non the security risk spectrum introduced above. In addition to known \\nrisks, a number of unknown risks would also fall somewhere within \\nthese continua.\\n\\nSECURiTy RESiliEnCE\\n\\nThe term “resilience” has mainly been used to prepare cities to react \\nto natural disasters and climate change (16). U.S. Presidential Policy \\nDirective 21 defines resiliency as “The ability to prepare for and \\nadapt to changing conditions and withstand and recover rapidly from \\ndisruptions. This includes the ability to withstand and recover from \\ndeliberate attacks, accidents or naturally occurring threats or inci-\\ndents”(17). The term has been used to a much lesser extent to refer  \\nto terrorism threats in cities (9, 10, 18). However, many of the \\nsystems that are currently used to increase transportation system \\nresilience to natural risks can also be used to address human-made \\nsecurity threats.\\n\\nThe  literature  suggests  three  reasons  for  the  development  of  a \\nresilient, internetwork security system rather than the use of preven-\\ntion and management strategies only for specific events. First, secu-\\nrity threats shift over time, specifically with evolving technology, \\nand “a risk management approach that seeks strategies to lessen our \\nvulnerability to uncertainty will be more robust when considering an \\nevolving enemy” (10). Second, if risks are addressed one at a time, \\nresources may be tied up in specific programs. In turn, the ability to \\ndeploy resources to other emerging threats in a flexible manner is \\nlimited (10). Third, increased interconnectedness leads to an ampli-\\nfied risk, such that other systems will fail when one system or type \\nof infrastructure is compromised, referred to earlier as cascading \\neffects (11).\\n\\nWith information drawn from the literature, a resilient transporta-\\n\\ntion security system would include the following:\\n\\n•\\t Take an all-hazards approach. Cities develop security systems \\nthat can be used to respond to and mitigate human-made attacks as \\nwell as natural disasters. An all-hazards approach can work to prevent \\n\\n \\n \\n \\n\\x0c40 \\n\\nTransportation Research Record 2604\\n\\nthe cascading effects of natural and human-made risks and reduce the \\ncosts required to create multiple systems to address different types \\nof risks.\\n\\n•\\t Address a range of security risks. Security breaches that threaten \\nthe physical infrastructure, financial systems, databases, and trans-\\nportation system users and employees are identified and planned for \\n(6, 7, 10, 14). Specific strategies address the needs of different groups \\nof people within the city using all modes of transportation, includ-\\ning low-income individuals, those without cars, and those with dis-\\nabilities. System developers keep the following questions in mind: \\nWhom are we protecting, and whom are we protecting ourselves \\nfrom? (12, 15)\\n\\n•\\t Respond to unknown risks. Unknown risks include threats that \\nhave not yet been identified by authorities or threats that arise in \\ntransportation systems as they become connected to other systems \\nor grow in size. These responses include the integration of various \\ntransportation networks into one security system to avoid cascading \\neffects (10, 15).\\n\\n•\\t Use mitigation and accommodation strategies. Transportation \\nsystems have strategies to prevent and respond to security breaches \\nwhen they do occur (7, 9, 10). These responses include the develop-\\nment of redundant systems and strategies that take into consideration \\nthe ways in which transportation users and systems react to security \\nthreats (7, 10).\\n\\n•\\t Use private and public partners and standards. Private and public \\ntransportation networks and services are held to the same risk preven-\\ntion and response standards and have aligning risk management and \\nrecovery plans (9).\\n\\nEvalUaTing SECURiTy PlanS in SMaRT CiTy \\nChallEngE aPPliCaTionS\\n\\nThe development of policies and plans that ensure security in smart \\ntransportation systems is critical to the success of these systems in \\ntwo ways. First, when public agencies have robust data security \\npolicies and mechanisms in place, private firms may feel more com-\\nfortable partnering with governmental agencies to share the data on \\ntransportation systems that they collect. U.S. DOT has emphasized \\nthat municipalities should develop private–public partnerships (11) \\nto create comprehensive databases and connected transportation sys-\\ntems; however, private firms are often cautious about sharing data \\nbecause it is a valuable asset to their business models (11, 19).\\n\\nSecond, public trust in government is critical to the establish-\\nment of smart transportation systems (20). In working with the \\nCity of Seattle, Washington, to develop municipal security systems,  \\nWhittington et al. (20) emphasized the importance of public trust \\nin local government when collecting data and providing services, \\nwhereas Pavlou (21) found that trust and perceptions of risk act as \\nsignificant barriers to the acceptance of new technology by indi-\\nviduals. In addition, individuals are less likely to use specific types \\nof travel, including transit, walking, and cycling, when they believe \\nthat  their  personal  security  and  safety  could  be  threatened. This \\nresult means that individuals may be less likely to switch to alter-\\nnative modes of transportation if they believe that their safety and \\nsecurity could be compromised, and a focus on safety and security \\nis a high priority in the Smart City Challenge (12). For smart trans-\\nportation systems to be successfully implemented and adopted, con-\\nstituents must trust the government to collect granular data about \\ntheir travel patterns and also trust that smart transportation systems \\nare safe to use and dependable. The Smart City Challenge NOFO \\n\\ndoes briefly mention the importance of the development of public \\ntrust; however, this point is not emphasized or expanded on (1).\\n\\nThe Smart City Challenge offers an opportunity to evaluate a selec-\\ntion of U.S. cities’ current and proposed transportation security mecha-\\nnisms. By developing a framework to evaluate the resiliency of these \\nsecurity plans, this research can inform governmental entities and \\ntransportation agencies as they develop comprehensive policies and \\nprograms to address a variety of security risks.\\n\\nWith information drawn from the literature, the following evalu-\\nation criteria were used to measure the resiliency of cities’ security \\nmechanisms:\\n\\n•\\t The range of security risks addressed. This variable measures \\nthe extent to which cities plan to respond to a variety of known risks, \\nfrom mass to targeted security breaches and physical to technologi-\\ncal security breaches. This variable is measured by mapping out of \\nthe number and the nature of security risks that cities address in the \\nsecurity risk spectrum used in Figure 1.\\n\\n•\\t Response to unknown risks. This variable measures whether \\ncities have plans to respond to risks that have not yet been identi-\\nfied by authorities or threats that arise in systems as they become \\nconnected to other systems or grow in size. Responses may include \\nsystem redundancy and plans to adapt security systems to include \\nother smart devices or systems later on.\\n\\n•\\t Mitigation versus accommodation of risks. This variable mea-\\nsures whether cities have a range of strategies to prevent security \\nthreats as well as plans to manage and recover from security breaches \\nwhen they do occur.\\n\\n•\\t Private and public partners. This variable measures whether \\ncities plan to work with private and public partners when they develop \\nsecurity mitigation and response plans and policies.\\n\\nResponse to Range of Security Risks\\n\\nOf the 32 Smart City Challenge applications that were analyzed, the \\napplications from 15 cities mentioned security threats as a consider-\\nable risk to the development of smart transportation networks and \\nthe applications from 19 cities had relatively detailed security plans \\n(these plans were often provided in response to Vision Element 11: \\nLow-Cost, Efficient, Secure, and Resilient Information and Commu-\\nnication Technology, the only place in the first NOFO that security \\nwas mentioned).\\n\\nOne of the possible reasons for this finding is that security resil-\\niency was not a significant area of concern in the U.S. DOT’s first \\nNOFO, and the allowable length of the application was relatively \\nshort (the cities were limited to 30 pages). In addition, the U.S. DOT \\nrequested that cities consider security only in relation to information \\nand communication technology rather than address a range of phys-\\nical and cybersecurity concerns. However, some cities did address \\nsecurity much more than others; for instance, the applications from \\nNorfolk, Virginia, and Chattanooga, Tennessee, mentioned the term  \\n“security” or “secure” 23 and 20 times, respectively, whereas the \\napplications from three cities (Akron, Ohio; Newport News, Virginia; \\nand St. Petersburg, Florida) did not mention these terms at all. On \\naverage, the applications from the cities mentioned the term “secu-\\nrity” or “secure” 11 times and mentioned the term “privacy” three \\ntimes (Table 2). The nature of the security plans that were presented \\nin 19 of the applications was evaluated by use of the aforementioned \\ncriteria,  and  the  findings  of  that  evaluation  are  presented  below. \\nSpecific examples are also drawn from the cities’ plans.\\n\\n\\x0cBeck \\n\\n41\\n\\nTABLE 2    Examination of Security Plans of 19 First-Round Applicants of Smart City Challenge\\n\\nNumber of Times Security Issues Were Mentioned in Application Document\\n\\nPrivate \\nPartnership\\n\\nPublic \\nPartnership\\n\\nPartner with \\nEducational \\nInstitution\\n\\nMass \\nCyber-\\nsecurity \\nBreach\\n\\nMass \\nPhysical \\nSecurity \\nBreach\\n\\nIndividual \\nCyber-\\nsecurity \\nBreach\\n\\nIndividual \\nPhysical \\nSecurity \\nBreach\\n\\nAccommodation \\nof Risk\\n\\nResponse to \\nUnknown \\nRisks\\n\\n0\\n0\\n1\\n1\\n1\\n0\\n1\\n1\\n0\\n1\\n0\\n0\\n0\\n0\\n0\\n0\\n0\\n0\\n0\\n6\\n\\n1\\n0\\n1\\n0\\n1\\n1\\n1\\n1\\n1\\n0\\n1\\n1\\n0\\n1\\n0\\n1\\n0\\n0\\n1\\n12\\n\\n0\\n0\\n0\\n0\\n0\\n1\\n0\\n0\\n0\\n0\\n0\\n0\\n0\\n0\\n0\\n0\\n0\\n1\\n1\\n3\\n\\n1\\n0\\n0\\n1\\n0\\n1\\n1\\n1\\n0\\n1\\n1\\n1\\n0\\n1\\n0\\n1\\n0\\n1\\n0\\n11\\n\\n0\\n1\\n0\\n0\\n0\\n0\\n1\\n1\\n1\\n0\\n1\\n0\\n0\\n1\\n0\\n0\\n1\\n0\\n1\\n8\\n\\n1\\n0\\n0\\n1\\n0\\n1\\n1\\n1\\n0\\n1\\n0\\n1\\n1\\n0\\n0\\n0\\n0\\n0\\n0\\n8\\n\\n1\\n1\\n0\\n0\\n0\\n1\\n1\\n1\\n1\\n0\\n0\\n0\\n0\\n0\\n0\\n0\\n1\\n0\\n0\\n7\\n\\n0\\n0\\n0\\n0\\n0\\n0\\n0\\n0\\n1\\n0\\n1\\n0\\n0\\n1\\n0\\n1\\n0\\n0\\n0\\n4\\n\\n1\\n1\\n1\\n0\\n0\\n0\\n1\\n0\\n0\\n1\\n0\\n0\\n0\\n1\\n0\\n0\\n0\\n0\\n0\\n6\\n\\nCity\\n\\nLouisville, Ky.\\nSan Francisco, Calif.\\nKansas City, Mo.\\nPortland, Ore.\\nLong Beach, Calif.\\nAtlanta, Ga.\\nAustin, Tex.\\nMadison, Wis.\\nNorfolk, Va.\\nOakland, Calif.\\nOrlando, Fla.\\nProvidence, R.I.\\nRaleigh, N.C.\\nRichmond, Va.\\nSeattle, Wash.\\nTampa Bay, Fla.\\nWashington, D.C.\\nPittsburgh, Pa.\\nChattanooga, Tenn.\\nTotal\\n\\nResponse to individual and Mass  \\nCyber- and Physical Security Risks\\n\\nAs shown in Figure 2, the applications of most cities commonly \\naddressed  security  risks  that  fell  in  the  mass  cybersecurity  cate-\\ngory, whereas fewer cities addressed cyber- and physical security \\nbreaches that target individuals. The applications from only two cities \\n\\nMass Security Breach\\n\\nh\\nc\\na\\ne\\nr\\nB\\ny\\nt\\ni\\nr\\nu\\nc\\ne\\nS\\nl\\n\\na\\nc\\ni\\ns\\ny\\nh\\nP\\n\\n8\\n\\n7\\n\\n11\\n\\n8\\n\\nh\\nc\\na\\ne\\nr\\nB\\ny\\nt\\ni\\nr\\nu\\nc\\ne\\ns\\nr\\ne\\nb\\ny\\nC\\n\\nTargeted Security Breach\\n\\nFIGURE 2    Number of Smart City Challenge applicants that \\naddressed security breaches that fit along security risk spectrum.\\n\\n(Austin, Texas, and Madison, Wisconsin) addressed security breaches \\nthat fell into the individual and mass cyber- and physical security \\ncategories. For instance, the application from Austin included plans \\nfor communication security, physical security, and device control \\nfor information and communication technology devices and infra-\\nstructure, as well as encryption processes used to protect PII, SPII, \\nand  data  collected  from  connected  and  automated  devices  and \\nintelligent infrastructure (22). This plan adequately addressed both \\nindividual and mass cybersecurity risks by protecting PII and SPII \\nand communication technology and addressed individual and mass \\nphysical security risks by securing data collected from connected \\nand automated devices and infrastructure.\\n\\nResponse to Unknown Risks\\n\\nThe applications from six of 19 cities alluded to the development \\nof systems that could respond to risks that have not been identified \\nby authorities or that may arise as transportation systems expand \\nor become integrated with other systems. Among these were appli-\\ncations that planned for the development of secure connections \\nbetween new smart city elements that have not yet been developed \\nor adopted, that planned to set up systems that will allow additional \\nsystems and data transmissions to be included, and that planned \\nto set up redundant networks. The application from Richmond,  \\nVirginia, most clearly addressed how the city plans to develop tech-\\nnologically and physically redundant systems in its transportation \\nnetworks to mitigate the risk of cascading effects (23).\\n\\n \\n \\n \\n\\x0c42 \\n\\nTransportation Research Record 2604\\n\\naccommodation of Risks\\n\\nThe applications from very few cities (four of 19) not only addressed \\nthe setting up of a security system that attempted to prevent risks \\nbut also included plans on how to respond to and recover from \\nsecurity breaches after they have occurred. Proposals for recovery \\nfrom a security breach included setting up of alert systems for intru-\\nsions into databases or devices or emergency response strategies. \\nThe application from Norfolk, Virginia, for example, proposed the \\ndevelopment of a system in which transportation agencies could \\nprioritize emergency vehicles or critical infrastructure in the case \\nof a physical security breach (24).\\n\\nPrivate and Public Partnerships\\n\\nThe applications from six of the 18 cities with security plans stated \\nthat they were either currently or planning to work with private part-\\nners to develop comprehensive security measures or develop a set \\nof standards for private partners to follow. The applications from \\na higher number of cities (12 of the 19) mentioned that they were \\neither currently or planning to work with other public agencies and \\nlevels of governments. Among these applications, some included \\nproposals to work with U.S. DOT to implement the Security Cre-\\ndential Management System prototype currently being developed. \\nThe applications from three of the 19 cities proposed to work with \\nthe educational institutions in their cities. For instance, Seattle pro-\\nposed to work with project partners Microsoft and the University \\nof Washington to ensure that systems meet privacy and security \\nstandards (25).\\n\\ninSighTS anD iMPliCaTionS\\n\\nOverall, the applications from none of the cities fully addressed all \\nevaluation criteria. Mass cybersecurity breaches were the most com-\\nmon risk addressed, whereas security risks that target individual \\ntransportation users were less commonly addressed. Cities mentioned \\nphysical security risks more than was expected on the basis of infor-\\nmation previously mentioned in the literature (8). Few cities described \\nplans to address unknown risks, and very few cities addressed how \\nthey plan to respond to security breaches when they occur.\\n\\nMost notably, information about how the cities planned to develop \\nsecurity standards for private partners and establish security mecha-\\nnisms to share data between private and public sectors was lacking. \\nThis finding is surprising because private–public partnerships were \\nstrongly emphasized in the Smart City Challenge NOFO and media \\nreleases. Furthermore, in his South by Southwest keynote speech, \\nPresident Obama highlighted the important role that private partners \\nshould play in ensuring user privacy and security (22).\\n\\nColumbus,  Ohio,  was  awarded  the  Smart  City  Challenge’s \\n$50 million, although of the seven second-round participant cities, \\nColumbus addressed security issues the least in its first-round appli-\\ncation. It is unclear whether the 77 other applicant cities that did not \\nreceive U.S. DOT funding will find other ways to fund smart city \\nprojects. U.S. DOT has set up a separate funding stream that aims to \\nsupport specific smart city projects led at the municipal level, and the \\nmayors of some cities have said that they plan to pursue funding to \\nimplement some of the projects outlined in their cities’ applications \\n(26). At this point, it seems that, in the awarding of the $50 million \\nand in cities’ plans to implement smart city projects, little attention \\nhas been given to security concerns.\\n\\nOn the basis of the results of this study, provided below are several \\nrecommendations that U.S. DOT and municipalities could follow to \\nevaluate further municipal transportation security system plans and \\ndevelop policies and programs to ensure that cities have resilient \\nsecurity systems for their evolving transportation networks:\\n\\n1.  Develop interagency, national platforms that allow cities to \\nidentify a wider range of security threats. These platforms may \\ninclude online forums, widely circulated security reports and materi-\\nals, or regional and national meetings. The development of such plat-\\nforms will allow transportation agencies and governments to identify \\na wider range of possible security threats when adopting or planning \\nfor new forms of technology to be integrated into existing systems. \\nUse of the security risk spectrum described in this paper to map the \\ntypes of security threats may help to ensure that a variety of types \\nof security events are considered.\\n\\n2.  Develop transportation systems that can respond to and quickly \\nrecover from security breaches. As seen in recent world events, secu-\\nrity threats in cities can have widespread, long-lasting ramifications \\non the ways in which civilians and goods move around. It is critical \\nthat cities develop redundant, resilient systems to maintain the flow \\nof goods and people and prevent the occurrence of cascading effects \\nwhen security breaches do occur.\\n\\n3.  Collaborate with the private sector to develop security policies, \\nstandards, and programs. Private companies not only are becoming \\nmore involved in the provision of transportation services and the \\ncollection of transportation data, but also they can be more adept at \\naddressing evolving security concerns at a fast pace, specifically, \\nin the development of user-centered cyber-security systems (13). \\nPartnerships with this sector may allow the development of com-\\nmon security standards and more integrated prevention and response \\nstrategies.\\n\\n4.  Build on the existing intelligent transportation system architec-\\nture used in the public and private transportation sectors. As noted \\nin the introduction, public and private sectors have used intelli-\\ngent transportation system technology to improve the safety and \\nefficiency of transportation networks throughout the last century \\n(27), resulting in established technological systems that cities can \\nuse to implement the transportation technologies suggested in the \\nSmart City Challenge applications. Efforts to build on existing sys-\\ntems that address security risks may reduce the risk of future security  \\nthreats.\\n\\n5.  Budget for security mitigation and accommodation systems. \\nA resilient transportation system that mitigates and accommodates \\nrisk can be costly to develop and maintain; therefore, transporta-\\ntion agencies, governments, and private enterprises could conduct \\ncost–benefit analyses that compare specific security mechanisms (for \\nexample, secure data storage compared with data destruction) or risk \\nmitigation for different modes or geographic locations (for example, \\ncertain areas of the city or certain modes may be at a higher risk of \\nsecurity breaches than others) (7, 10, 27). Although it was beyond \\nthe scope of the research described in this paper, further research \\nshould be done to examine whether cities that did not receive the \\ngrant choose to continue with smart city plans and implement the \\nproposed security systems.\\n\\naCknowlEDgMEnT\\n\\nThanks go to Karen Trapenberg-Frick for guidance and support on \\nthis research project.\\n\\n\\x0cBeck ', '59J. Roy, From Machinery to Mobility: Government and Democracy in a Participative Age, Public Administration and Information Technology 2, DOI 10.1007/978-1-4614-7221-6_5, © Springer Science+Business Media New York 2013                       Systemic Vulnerability  The Internet facilitates a level of interoperability among individuals, organizations, sectors, and countries that generates widening opportunities for collaboration and innovation—central themes of the preceding chapters. Digital infrastructure is rap-idly becoming the lifeblood of a more virtual and interdependent globalizing econ-omy, as every major industrial sector widens its reliance on electronic systems and online connectivity—from power generation and supply to ﬁ nance and manufactur-ing. Furthermore, the previous chapter describes the ascent of cloud computing as a shared ownership model of networked and interoperable computing systems for data storage and management internally—as well as frontend usage of online pro-grams and social media platforms by users enjoined with more powerful and more mobile processing and communication devices.  At the same time, online and virtual threats to organizations in all sectors have become a way of life: one American survey undertaken in 2011, for instance, reported 100 % coverage of respondent organizations dealing with some form of cyber-breach or attack either from internal or external sources (   Ponemon  2011a ,  b ).    Many observers estimate the total cost of damages related to cyber-crime up to now having surpassed one trillion dollars annually, with the private security industry expected to surpass $80 billion in annual revenues by the year 2017 (ibid.). Despite signiﬁ cant and highly public breaches involving companies such as Citigroup, Sony, LinkedIn, and many others, some outside of the private sector suspect the security industry itself of bolstering such ﬁ gures and implied threats. Others insist that such ﬁ gures may underplay the problem since few companies are keen to divulge breaches and weaknesses and many individuals may unknowingly be victimized.  Facing increasingly frequent threats externally, governments carry the dual responsibilities of safeguarding their own infrastructures and information holdings as well as overseeing the digital resilience of their jurisdictions as a whole (Quigley and Roy  2011 ). Such public sector challenges were underscored in Canada in late 2012     Chapter 5    Cybersecurity \\x0c60and early 2013 by an Auditor General’s scathing review of the federal government’s cybersecurity efforts on the one hand and a massive loss of personal data just a few months later on the other hand. 1       Openness and Interdependence  As greater openness and mobility bring heightened interdependence, the impor-tance of cybersecurity deepens for both governments and all of society. For indi-viduals, the challenge lies in establishing and maintaining trusted and secure identities for conversations and transactions while mitigating intentional and unin-tentional risks—and deciding for oneself the appropriate trade-offs between privacy and openness. Organizations must foster strategies and systems in order to safe-guard information assets and infrastructure in a world of ubiquitous Internet access and multiplying devices (and thus access points) linking employees within an ever-more densely networked and mobile set of stakeholders. Societies collectively must balance the collective beneﬁ ts of openness with the systemic vulnerabilities that ﬂ ow from such openness. The Obama Administration’s Cyberspace Policy Review stated in 2009 that: “Threats to cyberspace pose one of the most serious economic and national security challenges of the twenty-ﬁ rst century for the United States and our allies” (p. 8, Goodyear et al.  2010 ). Accordingly, then, governments must address cybersecurity as both an internal challenge and one encompassing of all such levels within their jurisdiction.  How best to do so entails judgments pertaining to the contrasting prospects of open-source and proprietary systems reviewed in the previous chapter. In other words, due in large part to the collective attributes of open-sourced systems underpinning the notion of the cloud, whether a more online and open world is a more dangerous one is itself an inherently contested notion. Proponents of transparency and open sourcing espouse the collective resilience and intelligence of post- proprietary governance (i.e., open source) where theoretically, everyone is a potential defender and contributor to safeguarding against unforeseen weaknesses as well as more malicious threats. Skeptics worry that such openness augments vulnerabilities.  In his presentation of eight fundamental elements to workable and effective cloud computing systems, Wyld’s emphasis on universality and openness—along with security and privacy—underscores the competing forced at hand (   Wyld  2010a ,  b ). 1    The data breach involved the loss of an external memory stick within the federal department responsible for student loan processing (Human Resources and Skills Development Canada): ﬁ nancial and personal data on an estimated 500,000 citizens, holders of student loans, was said to be misplaced. One irony of this episode is reporting that the spectre of legal action against the government may prompt it toward wider usage of cloud systems—for which the federal govern-ment has proved trepid in exploring due to concerns about data privacy (Press  2013 ). Such themes in terms of personal privacy and the Government of Canada’s cautious temperament toward digital renewal and cloud systems speciﬁ cally are returned to later in this chapter as well as Chap.       8    , respectively.  5 Cybersecurity\\x0c61   The author offers two competing and somewhat contradictory predictions for the coming decade that further highlight the accumulating systemic stakes—both posi-tive and negative: on the one hand, the democratization of technology from more open, online, and interoperable infrastructure is said to promise tremendous beneﬁ t to societies, whereas on the other hand, the author predicts two or three “massive” security breaches each year likely to galvanize media attention and public scrutiny (Wyld  2010a ,  b ). Such pronouncements, while seemingly contradictory at times, underscore the duality of compounding opportunities and threats as cloud comput-ing systems and expanding online activity further augment the degrees of interde-pendence across critical electronic systems in and across both industry and government.  Such competing logics also replicate themselves in terms of online information ﬂ ows for new styles of openness in traditionally proprietary ﬁ elds such as journal-ism and learning. The most visible example is perhaps Wikipedia and its displace-ment of hard form encyclopedia resources in a manner that enables the validity and accuracy of posted information to be vetted by society at large. The power of such instantaneous and collective mobilization can be both informational much as it can serve as an important determinant of spontaneous and collectivized trust.  One such tragic example came in 2010 when a Polish aircraft, carrying the coun-try’s President and numerous dignitaries, crashed in Russia en route to a bilateral ceremony with ofﬁ cials from both countries. Given the historical sensitivities of relations between both countries, this incident carried at least the potential for sus-picion and conspiracy theories to arise, whereas any such risk was mitigated by the real-time online reporting of Wikipedia members that, in turn, provided a compre-hensive and highly credible source of facts and opinions themselves subject to con-stant scrutiny and revision. 2      The openness and learning that ensued can be partially credited as contributors to the thoughtful manner by which both countries addressed the cause and aftermath of this tragic accident. One could point to a somewhat analogous relationship between the Polish tragedy and Microsoft’s evolution in recent years—namely, the reduced scope for cynicism and outright conspiracy theorizing in an environment of collective openness. In the former case, the extensive and real-time reporting of what transpired (as well as the timely and sincere response by Russian authorities) mitigated what, in a pre-Internet era, may well have served as fertile ground for suspicion and accusation across at least portions of the impacted societies.  Consequently, participative openness can buttress the traditional mantra that secrecy breeds suspicion. Yet notwithstanding such examples, there remains much about the Internet and online activity that remains in the shadows—shielded inad-vertently or intentionally from public viewing and understanding.  The US Government’s efforts are emblematic in this regard. Much as 9–11 drove a fundamental restructuring of air transportation infrastructure and government’s security apparatus for addressing terrorist threats during the Bush Administrations, 2     Openness and Interdependence\\x0c62the arrival of President Obama in 2008 would signal a similarly important inﬂ ection point in terms of prioritizing cyber-efforts in both reactive and proactive manners.  The absence of a crystallizing event such as the 9–11 attacks nonetheless alters the political landscape—bringing less sharpened demands for clarity of action. By the same token, however, the accentuated emphasis on secrecy and covertness that gained traction in the previous decade remains a key variable (and a source of fric-tion between Obama’s campaign pledges for more institutional openness and the realities of governing that ensued). In short, the struggles and efforts of the Obama Administration are an important reference point (and source of inﬂ uence) for all democracies, most especially neighboring Canada, and as such, they are examined at some length in this chapter.      The Search for Hybrid Governance 3   Within the US and across much of the world, there is growing recognition that cybersecurity requires innovative responses that must be facilitated more than ordained by public sector authorities. Such is the imperative of hybrid governance models—which challenge governments to both organize and behave in new ways less constrained by machinery-laden models of bureaucracy and control and more outward and participative (and thus aligned with mobility).  Meaningful and effective hybrid governance must reconcile four competing and complex realities. Firstly, President Obama and other political and industry leaders around the world have sought to create attention and dialogue on the risks of cyber-security to an unprecedented degree—galvanizing awareness and action within and outside of government. Secondly, the internalizing of public sector action is closely interrelated with bureaucratic structures and mindsets emphasizing secrecy and hierarchical control. Thirdly, the private sector is a key player—as owner and opera-tor of major portions of critical telecommunication infrastructure and electronic online systems: while markets can generate innovation to mitigate cybersecurity risks, competitive and proprietary concerns often limit information sharing and con-certed action. Fourthly, consistent with the nature of online space and activity and many emerging cyber-threats (Cornish  2009 ), there may be merit (and indeed neces-sity) in looking to hybrid arrangements that include more organic and unconven-tional governance mechanisms and strategies (of the sort that are consistent with a Web 2.0 ethos and underpinning many of the threat movements requiring attention and response).  With respect to the ﬁ rst point, President Obama sought to instill a prism of lead-ership and accountability at the highest level:3    Signiﬁ cant portions of this section are largely drawn from the following article: Quigley, K., & Roy, J. (2011). Cyber-security and risk management in an interoperable world: An examination of Governmental Action in North America.  Social Sciences Computer Review, 30 (1), 83–94.  5 Cybersecurity\\x0c63  My administration will pursue a new, comprehensive approach to securing America’s digital infrastructure. This new approach starts at the top with this commitment from me: from now on, our digital infrastructure, the networks and computers we depend on every day, will be treated as they should be—as a strategic national asset. Protecting this infrastructure will be a national security priority. We will ensure these networks are secure, trustworthy and resilient. 4     Such executive branch backing can underpin new organizational capacities des-ignated as vehicles for more holistic coordination. Indeed, two important beneﬁ ts can emerge from hierarchical leadership and direction setting: ﬁ rstly, a willingness and ongoing efforts to both measure and report on progress in a public manner (and also via Congressional and Parliamentary bodies as the public’s ﬁ rst line of account-ability) and, secondly, in sparking and accelerating a public dialogue on a critical issue such as cybersecurity that otherwise remains poorly understood and thus poorly suited to social learning and collective intelligence, a basis for more enlight-ened governance and policy systems.     While the Obama Administration is ripe with tensions between traditional bureaucracy and new governance capacities (and related strains of secrecy versus openness    5 ), the executive leadership brought to this issue has nonetheless rendered it more visible and more widely examined in both technocratic and political realms. The Canadian case by contrast is notable for the absence of clear political commit-ment and open debate with respect to cyber-matters speciﬁ cally. The resulting mindset pertaining to cyber and other forms of critical infrastructure is a reinforce-ment of a secretive and hierarchist mindset of governmental authorities, most espe-cially those at the federal level (Quigley and Roy  2011 ).    A particular concern here is the absence of more open and robust mechanisms for sharing information between industry and government, a major issue given that the vast majority of critical infra-structure assets and systems are owned and operated by companies (Clemens and Crowley  2012 ). While the US has sought to heighten appreciation of the need to share information and create new hybrid capacities to do so (as described above), the lack of an open Canadian dialogue in this regard reinforces secrecy inside of government and covertness in its private sector dealings.  The absence of more robust action may be due to the lack of a crystallizing event (despite a growing catalogue of cyber-breaches in Canada, none have thus far resulted in widespread or highly visible damage) or the general decline of interest and prioritization in digital matters that has characterized the Harper Government. Widening concerns regarding such complacency were highlighted in June 2012 by 4    Obama, B. (2009).  Obama announces complete overhaul of cyber security (Part 1) , May 29th (  http://www.youtube.com/watch?v=dgDsXAykAm0    ).  5    The United States also reportedly launched its ﬁ rst major cyber-attack on another country in 2011, a coordinated effort with Israel aimed at destabilizing Iran’s nuclear development program. The action, reported in the New York Times and in a subsequent book, also sparked heightened debate and concern among lawmakers about leaks and the need for secrecy pertaining to national security measures (yet another example of widening tensions between openness—imposed or invited—and the traditional public sector culture of secrecy).   The Search for Hybrid Governance  \\x0c64the somewhat surprising release of an internal memo (through an access to informa-tion request of several months prior) prepared by the Canadian Deputy Minister (i.e., appointed Department Head) responsible for public safety for his Minister—lamenting Canada’s vulnerability to cyber-attacks (ibid.; Mayeda and Miller  2012 ).  An October 2012 report by the Auditor General further criticized federal govern-ment efforts, exposing systemic weaknesses and the absence of the sort of political leadership and public engagement of the sort on display in recent years in the US. Moreover, as noted in the introduction of this book, a 2011 related effort by the federal government to permit an expansion of online surveillance by policing and security authorities sparked a major online backlash leading to a government retreat, an episode suggesting a lack of political and societal learning and nuance. Indeed, the framing of the proposed legislation as an attempt to better protect children online from predators was widely viewed as a massive political simpliﬁ cation designed to thwart any political opposition to the measures, a miscalculation likely contributing to the Government’s trepid stance on cyber-security matters more gen-erally (and one that further underscores the absence of a wider political dialogue on such matters).  The Obama Administration’s 2009 Cyberspace Policy Review, by contrast, high-lights the need for a national dialogue involving government, industry, and the pub-lic at large—emphasizing the need for coordinated action across all levels of government as well as across sectors (Goodyear et al.  2010 ). At the same time, reﬂ ecting the largely bureaucratic ethos of government, leadership and responsibil-ity are centralized within the conﬁ nes of the White House and the new Presidential, cybersecurity appointee. Here we witness clashes between vertical and horizontal lines of accountability: government understanding that it cannot act alone but none-theless driven by conﬂ icting pressures to act unilaterally and collaboratively. Within governments, these pressures play out within and between speciﬁ c units and their leaders; across sectors they reﬂ ect government’s dual role of orchestrating pro-cesses for inter-sectoral coordination and dialogue on the one hand and regulating and policing wherever necessary on the other hand.  In terms of this latter point, the hierarchical orientation of government authori-ties and a public interest orientation that often necessitates a guardian role is one that may coexist uneasily with the more competitive and individualist tendencies of the marketplace and industry actors. The overarching challenge, then, lies in ﬁ nding innovative ways to expand government’s role in an intelligent, agile, and adaptive manner—balancing state and market capacities in recognition of the fact that it is unlikely to be governments themselves that create the tools and mechanisms neces-sary to ensure a safe and resilient digital infrastructure but instead (1) ideas stem-ming from innovation and experimentation within the marketplace and (2) an alignment of public and private interests via collaborative efforts between both sec-tors. A key challenge here is that government alone cannot initiate collective action within the marketplace nor shape behavior in those dimensions of civil society with individualist or egalitarian tendencies and values.  Growing calls for industry self-reporting and self-monitoring are thus important in mobilizing market-based assessments of risk—and reactions to such assessments. 5 Cybersecurity\\x0c65Accordingly, the Intelligence and National Security Alliance ( 2009 ) provided a thoughtful analysis of public–private partnering in a variety of contexts—with the aim of devising a suitable framework for sectoral collaboration speciﬁ cally in the cybersecurity realm. As a point of departure for high-level guidance, they propose two fundamental dimensions to such an undertaking:(cid:129)      An executive committee composed of representatives from individual, business and government organizations referred to here as a Cyber Security Panel, which represents the interests of businesses and individual users.  (cid:129)   A partner government organization responsible for some oversight, regulation and enforcement, focused on net security. Government is essential because only government has the authority and ability to fully investigate cyber incidents that may occur across networks and only government has the ability and legitimacy to regulate industry where private citizens’ interests are at risk (as with privacy). (p. 4, INSA  2009 )       This type of high-level collaboration—formalized in such a manner—is important in signalling the necessity of sectoral collaboration. Further, such a forum could bring to light the signiﬁ cant shared externalities of ﬁ rms and industries—transforming the “widespread agreement that this long-term trend of grabbing the economic gains from information technology advances and ignoring their security costs has reached a cri-sis” (Goldsmith and Hathaway  2010 ) into concrete proactive measures and better planning for emergency preparedness and responses to incidents when they occur.  Yet in order to proceed in such a manner, governments must pursue strategies that facilitate multi-organizational collaboration while at the same time account for the competitive context of markets. Public authorities must recognize the disincentives that will constrain industry’s willingness to share proprietary information (Langford and Roy  2009 ). It is unlikely industry will share information about their vulnerabili-ties: liability issues and concerns about brand and reputation are important vices here. Sector level forums can thus agree to certain levels of conﬁ dentiality provision-ing where essential and necessary, while also facilitating participation in more open mechanisms for public and private dialogue that are necessary to build trust and expand information sharing. Shaping the mindset of markets in terms of expectations and incentives is particularly important, especially as evidence points to a strength-ening correlation between cyber-vulnerabilities and a loss of shareholder value (Andoh-Baidoo et al.  2010 ).     This emphasis on transparency and openness can also be an important linkage to alternative governance formations which are more organic and communitarian in focus and orientation—and skeptical of industry and government capacities (espe-cially existing ones). Such actors may be more open to the formation of new com-munities, akin to the self-governance dynamic becoming so prevalent in an online, interconnected world (Shirky  2008 ). Consistent with embracing the growing reach and prowess of Web 2.0 and social networking sites outside of government (Eggers  2005 ; Williams  2012 ; Wyld  2007 ) and the more networked democratic ethos taking hold (Stoker  2005 ; Roy  2008 ,  2010 ), the imperative facing public sector authorities is to forge innovative mechanisms for collective outreach and engagement.  Such mobilization can then align governmental authority with new collaborative capacities via communities and movements devoted to fostering greater collective  The Search for Hybrid Governance  \\x0c66security online—as well as shared reactive response capacities for breaches and breakdowns when they occur. One like-minded suggestion—attempting in some manner to align and link governmental authority with a more grassroots, spontane-ous form of extended community—is offered by Irvine and Palmer ( 2010 ) in their proposed blueprint of a Cyber National Guard (in the United States although the authors acknowledge and endorse the need for an international capacity for this type of mechanism). Responding to the Obama Administration’s Cyber Space Policy review that calls for new processes over the midterm between the government and the private sector to “assist in preventing, detecting, and responding to cyber- incidents,” the notion of a Cyber National Guard is one of networked resilience through public funding and leadership coupled with private support and assis-tance—and driven by voluntary engagement and a communitarian-type ethos to both reactive and proactive forms of mobilization (ibid.).  The authors suggest, for example, such a body could greatly assist public aware-ness and education efforts, an approach that can to some degree marry the experi-mentalism of fatalists with an egalitarian-minded emphasis on shared preparation and building a culture of “cyber hygiene” (p. 59). Key here is government’s willing-ness and ability to share authority in a manner that acknowledges the necessity of beyond traditional state and bureaucratic capacities. The creation of a US Cyber Challenge—a nationwide talent search to mobilize and nurture a cadre of 10,000 young Americans with cybersecurity skills—is a useful example of this type of grassroots initiative encouraged by government but working outside of the strict conﬁ nes of public sector (Gupta  2010 ). Destabilized by recent breaches and attacks, a similarly inspired initiative in South Korea (labelled “the best of the best”) has sought to leverage a grassroots culture of hacking toward bolstering the country’s cyber-defenses against external threats, notably its northern neighbor (   Kwon  2012 ).  Looking to such alternative and more collaborative and open governance move-ments can assist and accompany industry and government efforts to foster new out-reach capacities more aligned with the networked realities of the Internet itself. Such governance experimentation is critically important in terms of both proactive preparation and mitigating the sorts of threats emerging in cyberspace. It is only by way of such hybrid strategies that governments can respond, both proactively and reactively, to the multifaceted risks of an evermore digitally and socially networked world. While straining the traditional governmental paradigm of bureaucracy and the traditional proprietary orientation of the marketplace, hybrid strategies carry the potential to better align a smarter and more strategic public sector role with the increasingly networked and diffuse realities of the mobility era.      Beyond Complacency: Employee and Public Engagement  An important element in the facilitation of new hybrid strategies for collective secu-rity (strategies that must invariably draw upon characteristics of adaptive gover-nance and openness discussed in the preceding chapters) is widened public 5 Cybersecurity\\x0c67awareness and engagement in order to foster collective learning and resilience while also providing a degree of oversight and accountability of public sector efforts to combat threats. Nevertheless, the systemic secrecy of a traditional bureaucratic mindset can stymie such openness, creating now-familiar tensions between machin-ery and mobility.  Moreover, the steady and interrelated expansion of cloud computing, social media, mobile smart devices, and wireless Internet access creates a set of conditions ripe for inadvertent and malicious exploitation by an increasingly online public that is worrisomely passive and ill informed in the main with respect to online security and personal behavior (Ponemon  2011a ,  b ). Even as openness and alternative own-ership models and mindsets drive the formation of novel and more participative governance schemes, the steady expansion of cloud platforms and mobile devices can also further augment the shared risks and consequences of cyber-insecurity. A 2012 US federal digital government strategy, for example, outlines the height-ened vulnerability:  Mobile devices have unique security challenges. Due to their portability, they are easy to misplace, potentially compromising any unencrypted sensitive data or applications stored locally…The rate of change of mobile operating systems, new update and notiﬁ cation capa-bilities from external hardware and software vendors, diversity of the devices themselves, and introduction of employee-owned devices (BYOD) also make security in the mobile space more challenging than in a traditional desktop environment and require new approaches to continuously monitor and manage devices and secure the data itself. 6     For public sector organizations pursuing mobility as an organizational mindset as well as technological strategy, an emphasis on employee awareness and respon-sibility is therefore central to fostering collective capacities for cybersecurity across infrastructure (including cloud systems and the myriad of personal devices deployed by public servants within and outside of the organization’s physical and virtual walls) and data processing. As a retired American Lieutenant General describes it,  Mobile users are looking for ease of access and speed of use, but are assuming security and privacy. This requires a very different “corporate” security approach. As organizations integrate new technologies and IT systems expand into the cloud, cyber-security must adapt to address the expectations of users. “The future of cyber-security is sustainable risk management,” said Lt. Gen. Raduege. “The tipping point of cyber will likely come when it blends in seamlessly with the agency’s broader business portfolio and becomes part of how the agency operates and delivers on its mission.” That calls for a new cultural approach that’s integrated into almost every aspect of public and private life he noted. “People will compare trade-offs and make tough choices based on data from a real-time view of the cyber landscape (p. 1, Raduege 2011).” 6    . The report provides a thoughtful and useful examination of the implications of mobility and security for public sector governance both internally and in terms of external outreach.   Beyond Complacency: Employee and Public Engagement\\x0c68   Importantly, while this call for sustainable risk management as a new organiza-tional ethos underscores individual choices and decisions, such an enlightened cul-ture must also emphasize responsibility. As the passage also implies, such enlightenment also implies a greater overlap and blending of formerly separate pub-lic and private realms, one consistent with the evolution of work patterns and orga-nizational governance examined in earlier chapters.  Cybersecurity thus reinforces a now-familiar set of tensions. A machinery-laden, bureaucratic orientation of government primarily treats public servants as special-ized workers to be assigned and overviewed within strict temporal and physical employment settings. By contrast, a more dispersed and multilayered mobile envi-ronment blurs such boundaries—creating new opportunities for empowerment but also a new imperative for framing and pursuing cybersecurity both individually and collectively through a shared set of expectations and responsibilities that become the basis for regularized learning and accountability. In other words, any effective and resilient security ethos requires proactive engagement and participation across all levels of organizations as well as across society at large.  Central to such an evolution are complex and interrelated matters of trust—as well as ﬂ uid viewpoints and behavioral values pertaining to privacy and the safe-guarding and usage and sharing of personal information. The emergence of online—and more recently mobile commerce and related forms of payment—bring together systemic conditions for cybersecurity and the public sector role examined in this chapter with the wider set of choices made by individuals as both consumers and citizens (and potentially as activists as well). These latter choices, within the shift-ing and interrelated realms of payments and privacy, constitute the central focus of the next chapter.        5 Cybersecurity\\x0c', 'Cybersecurity\\n\\n7\\n\\nKevvie Fowler\\n\\nCybersecurity can be defined as the body of technologies, processes and practices designed to \\nprotect networks, computers, programs and data from attack, damage or unauthorized access.1 \\nThe first use of the term occurred in 1994,2 when few organizations had an Internet presence \\nor were interconnected and data breaches did not capture newspaper headlines. As the years \\npassed,  interconnectivity  increased,  adoption  of  the  Internet  soared,  and  computers  became \\ncritical components of most businesses.\\n\\nToday,  cybersecurity  has  captured  the  attention  of  employees  from  the  back  office  to  the \\nboard  room.  Furthermore,  business  boundaries  are  quickly  eroding,  and  business  data  is \\naccessed  and  managed  across  corporate  as  well  as  employee-owned  devices  such  as  tablets \\nand smartphones, further complicating data protection.\\n\\nDespite  the  increased  importance  of  cybersecurity,  many  organizations  continue  to \\napproach  the  problem  as  a  technological  issue,  just  as  they  did  in  the  mid-1990s.  But  cyber-\\nsecurity  is  a  broader  matter  that  must  be  embedded  into  several  areas  of  an  organization  to \\nprotect it against a fundamental shift in the motivation and class of criminals that threaten it.\\n\\nAll organizations share the objective of understanding and managing cyberthreats, and risk \\nmanagement is the critical practice that can be used to accomplish this objective. This chapter \\nwill focus on how the practice of risk management applies within the domain of cybersecurity.\\n\\nCyber Risk Management Overview\\nCyber  risk  management  consists  of  foundational  elements  that  should  be  performed  by  all \\norganizations. An example of a foundational security element is how cyber risk oversight and \\naccountability will be structured within the organization. In addition to these foundational ele-\\nments there are principles that are used to identify, assess, and prioritize risk and the controls \\nthat can be used to reduce or eliminate it. This overview of cyber risk management will focus \\non the foundational elements of a cyber risk management system and serve as a prerequisite to \\nthe risk principles and controls we will look at later in this chapter. The first foundational ele-\\nment we’ll explore is leadership and governance.\\n\\nLeadership and Governance\\n\\nYears  ago,  cybersecurity  responsibility  stopped  at  the  director  or  vice  president  level \\nwithin  most  organizations.  Today,  cybersecurity  is  a  top  business  risk.  The  board  of  direc-\\ntors  is  accountable  to  ensure  that  appropriate  governance,  culture,  and  systems  have  been \\n\\n91\\n\\n.\\n\\nd\\ne\\nv\\nr\\ne\\ns\\ne\\nr\\n\\ns\\nt\\n\\nh\\ng\\ni\\nr\\n\\nl\\nl\\n\\nA\\n\\nl\\n\\n.\\ny\\ng\\no\\no\\nn\\nh\\nc\\ne\\nT\\n&\\ne\\nc\\nn\\ne\\nc\\nS\\n\\ni\\n\\ni\\n\\nr\\ne\\nv\\ne\\ns\\nE\\n\\nl\\n\\n.\\n\\n5\\n1\\n0\\n2\\n©\\n\\nt\\n\\nh\\ng\\ni\\nr\\ny\\np\\no\\nC\\n\\nGreen, Philip E. J.. Enterprise Risk Management : A Common Framework for the Entire Organization, Elsevier Science & Technology, 2015. ProQuest Ebook\\n         Central, http://ebookcentral.proquest.com/lib/ryerson/detail.action?docID=2146002.\\nCreated from ryerson on 2022-05-11 18:31:49.\\n\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n\\x0c92  ENTERPRISE RISK MANAGEMENT\\n\\nestablished  to  protect  the  organization  from  cybersecurity  risk.  The  2013  breach  at  a  lead-\\ning U.S. retailer shows that cybersecurity accountability resides at the top of an organization. \\nThe  retailer’s  CEO  resigned3  amid  recommendations  to  replace  several  board  members  for \\ntheir  perceived  poor  due  diligence  in  protecting  the  organization  from  cybersecurity  risk.4 \\nCorporate  directors  and  C-suite  executives  now  place  high  priority  on  cybersecurity  and  are \\nfocusing on the following key areas of their organization to ensure that cybersecurity is estab-\\nlished and governed appropriately.\\n\\nLeadership\\nResponsibility for cybersecurity should reside with senior executives. In most organizations the \\nboard of directors or an executive leadership committee is responsible for determining who in \\nthe organization will be responsible for information security. This position is often designated \\nchief  information  security  officer  (CISO)  or  an  equivalent  title  and  usually  reports  to  a  very \\nsenior position, such as to another C-Suite role within the organization. The CISO is essential in \\nleading, communicating, and influencing people at various levels across lines of business, often \\nin areas over which  the CISO has no direct authority. Having the CISO report into a lower level \\nor a technical area of the organization will reduce his or her influence across the various areas \\nof the business.\\n\\nCybersecurity  needs  to  maintain  top-level  visibility  within  an  organization.  The  CISO  or \\nequivalent security leader should ensure that cybersecurity successes and challenges are com-\\nmunicated  to  the  board  of  directors.  It  is  ultimately  the  responsibility  of  the  board  to  ensure \\nthat cybersecurity is effectively managed. This responsibility can only be managed when accu-\\nrate information flows to board members so that they are aware of the security success, failures \\nand weaknesses within the organization. This area of risk management should be a recurring \\ntopic at the board level, not discussed solely in response to individual cyber-related events.\\n\\nGovernance\\nA  proper  cybersecurity  framework  is  essential  in  ensuring  clear  accountability,  communica-\\ntion,  and  holistic  practice  within  an  organization.  This  framework  should  be  supported  by  a \\nsecurity policy, standards, and procedures. Figure 7–1 illustrates the hierarchy of cybersecurity \\nframework elements.\\n\\nCybersecurity is only as effective as the team devoted to its management. The team should \\nbe  devoted  to  managing  cybersecurity  risks  and  should  contain  a  range  of  subject  matter \\nexperts  as  well  as  effective  communicators  having  knowledge  of  practices  and  procedures \\n\\n.\\n\\nd\\ne\\nv\\nr\\ne\\ns\\ne\\nr\\n\\ns\\nt\\n\\nh\\ng\\ni\\nr\\n\\nl\\nl\\n\\nA\\n\\nl\\n\\n.\\ny\\ng\\no\\no\\nn\\nh\\nc\\ne\\nT\\n&\\ne\\nc\\nn\\ne\\nc\\nS\\n\\ni\\n\\ni\\n\\nr\\ne\\nv\\ne\\ns\\nE\\n\\nl\\n\\n.\\n\\n5\\n1\\n0\\n2\\n©\\n\\nt\\n\\nh\\ng\\ni\\nr\\ny\\np\\no\\nC\\n\\nFIGURE 7–1  Cybersecurity framework components.\\n\\nGreen, Philip E. J.. Enterprise Risk Management : A Common Framework for the Entire Organization, Elsevier Science & Technology, 2015. ProQuest Ebook\\n         Central, http://ebookcentral.proquest.com/lib/ryerson/detail.action?docID=2146002.\\nCreated from ryerson on 2022-05-11 18:31:49.\\n\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n\\x0cChapter 7 l Cybersecurity  93\\n\\nwithin other areas of the organization. This mixed skill set is essential in advising, influencing \\nand collaborating with stakeholders across the organization.\\n\\nLegal and Compliance\\n\\nThe threat of a cyberattack is a significant risk and the potential source of sizeable losses for \\nmany organizations. The importance and potential effects of a cyberattack are also well under-\\nstood  by  external  regulators,  legislative  bodies,  partners,  and  clients,  who  impose  require-\\nments to ensure that sensitive information is stored, managed, and transferred securely.\\n\\nMaintaining  a  compliance  requirements  register  is  critical  in  managing  the  security  and \\nprivacy  requirements  associated  with  the  data  you  store,  process,  and  transmit.  This  register \\nshould span regulatory, legislative, and corporate requirements set by your organization and \\nshould also include commercial requirements, or the requirements to which your organization \\nis  held  in  its  business  with  its  partners  and  clients.  Rightly  so,  your  partners  and  clients  will \\nexpect your organization to maintain a set level of security.\\n\\nThe complied register should include the different types of protected data within the orga-\\nnization,  the  specific  requirements  to  protect  and  manage  the  information,  and  notification \\nrequirements in the event of data loss or a suspected compromise.\\n\\nEnsuring that security requirements are embedded within third-party contracts is a necessary \\nbut  often  overlooked  method  of  protecting  an  organization  from  cyberattack.  Many  organiza-\\ntions  employ  third  parties  to  deliver  services  and  products.  In  outsourced  arrangements,  ele-\\nments of data management or processing are outsourced, but not the governance of the data and \\nsystems,  which  always  remains  with  the  outsourcing  organization.  Any  regulatory  and  legisla-\\ntive requirements that an organization faces will need to be governed by the organization, which \\nremains responsible for ensuring compliance with regulatory and legislative requirements.\\n\\nDespite the outsourcing of service delivery, the consequences associated with a cyber event \\nexperienced at a contracted third party can still directly affect your organization. For example \\nlet’s  consider  an  organization  that  maintains  a  customer  database  of  1  million  data  records, \\nbacked up by a third party. If the database was accessed by cybercriminals thanks to a lack of \\nbasic  security  practices  within  the  third  party  provider,  the  effect,  including  loss  of  business, \\nrecovery  costs,  and  damage  to  brand,  would  lie  with  the  organization.  If  there  was  a  contract \\nin place between the organization and the contracted third party, the costs associated with the \\nbreach would have been covered by the third party and, better yet, the breach might have been \\navoided all together had there been terms within the contract requiring the third party to imple-\\nment and maintain good industry security practices to protect the organization’s information.\\n\\nContract  security  terms  are  normally  contained  in  a  legal  service  agreement  defining  the \\nlevel of services that the organization will receive and the steps taken by the third-party vendor \\nor service provider to protect the information under its management. When evaluating service \\nproviders,  it  is  imperative  to  ensure  that  they  incorporate  and  comply  with  security  require-\\nments, including maintaining an adequate level of cybersecurity protection equal to or greater \\nthan that of the organization’s own industry good practices, including prompt notification in \\nthe event of a suspected or confirmed intrusion at the third party provider.\\n\\n.\\n\\nd\\ne\\nv\\nr\\ne\\ns\\ne\\nr\\n\\ns\\nt\\n\\nh\\ng\\ni\\nr\\n\\nl\\nl\\n\\nA\\n\\nl\\n\\n.\\ny\\ng\\no\\no\\nn\\nh\\nc\\ne\\nT\\n&\\ne\\nc\\nn\\ne\\nc\\nS\\n\\ni\\n\\ni\\n\\nr\\ne\\nv\\ne\\ns\\nE\\n\\nl\\n\\n.\\n\\n5\\n1\\n0\\n2\\n©\\n\\nt\\n\\nh\\ng\\ni\\nr\\ny\\np\\no\\nC\\n\\nGreen, Philip E. J.. Enterprise Risk Management : A Common Framework for the Entire Organization, Elsevier Science & Technology, 2015. ProQuest Ebook\\n         Central, http://ebookcentral.proquest.com/lib/ryerson/detail.action?docID=2146002.\\nCreated from ryerson on 2022-05-11 18:31:49.\\n\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n\\x0c94  ENTERPRISE RISK MANAGEMENT\\n\\nRisk Assessment\\nAs we saw in Chapter\\xa01, risk assessment is the process of identifying, analyzing, and prioritiz-\\ning risk to ensure that it is appropriately managed within an organization. Risks can be viewed \\nindividually as well as collectively; both views should be incorporated into a risk assessment to \\nensure that the proper level of risk to the organization is identified and managed. Risk assess-\\nments can be performed at many levels of an organization, so risks can be identified within a \\nspecific technological environment or application or, more broadly, at a project, business unit, \\nor  organizational  level.  A  risk  assessment  can  include  hundreds  of  risks,  but  they  cannot  all  \\nbe  appropriately  covered  in  this  chapter.  Our  focus  in  this  chapter  is  on  some  of  the  key \\nsources  of  cybersecurity  risk  that  are  applicable  to  most  organizations.  These  sources  of  risk \\nshould be evaluated for applicability to your organization and augmented with other risks your \\norganization faces as appropriate.\\n\\nSources of Risk\\n\\nCybercriminals,  regulatory  and  legislative  noncompliance,  and  errors  and  omissions  are  key \\nsources  of  cybersecurity  risk  affecting  most  organizations.  Each  risk  may  be  associated  with \\nmultiple threats, some of which may have catastrophic consequences. We will begin our look \\nat sources of risk with cybercriminals, the source most frequently discussed among businesses.\\n\\nCybercriminals\\nWhen one mentions the term cybersecurity, most people are likely to remember a recent news \\nstory about a “hacker” who digitally broke into an organization and stole sensitive information, \\nor they may think of the increased need to safeguard their organizations against them. In this \\nchapter,  we  will  demystify  the  term  “hacker”  and  refer  to  hackers  as  “cybercriminals,”  which \\nbetter describes who they are and what they do. There are four distinct types of cybercriminals \\nin the world today: petty criminals, hacktivists, organized criminals, and criminals sponsored \\nby a nation-state.\\n\\nPetty Criminals\\nPetty criminals are individuals or small groups of criminals who carry out cybercrime. Driven \\nby  financial  motivations,  petty  criminals  commit  computer  crimes  that  can  include  targeted \\nemail campaigns tricking users into divulging sensitive information and exploiting system vul-\\nnerabilities to gain unauthorized access to data. Some petty criminals who have special skills \\nalso develop computer threats such as malicious software, referred to as malware, that they sell \\nto other cybercriminal groups. A petty criminal may be a trusted internal employee of an orga-\\nnization or may be an outsider.\\n\\nMost  petty  criminals  lack  large  resources  and  thus  will  typically  look  for  the  path  of  least \\nresistance when committing their crimes. If an organization has superior risk controls, a petty \\ncriminal will normally move to another target having a lower level of security. Even when petty \\ncriminals possess specialized skills to write and sell malware, they look for a quick return on \\ntheir product.\\n\\n.\\n\\nd\\ne\\nv\\nr\\ne\\ns\\ne\\nr\\n\\ns\\nt\\n\\nh\\ng\\ni\\nr\\n\\nl\\nl\\n\\nA\\n\\nl\\n\\n.\\ny\\ng\\no\\no\\nn\\nh\\nc\\ne\\nT\\n&\\ne\\nc\\nn\\ne\\nc\\nS\\n\\ni\\n\\ni\\n\\nr\\ne\\nv\\ne\\ns\\nE\\n\\nl\\n\\n.\\n\\n5\\n1\\n0\\n2\\n©\\n\\nt\\n\\nh\\ng\\ni\\nr\\ny\\np\\no\\nC\\n\\nGreen, Philip E. J.. Enterprise Risk Management : A Common Framework for the Entire Organization, Elsevier Science & Technology, 2015. ProQuest Ebook\\n         Central, http://ebookcentral.proquest.com/lib/ryerson/detail.action?docID=2146002.\\nCreated from ryerson on 2022-05-11 18:31:49.\\n\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n\\x0cChapter 7 l Cybersecurity  95\\n\\nThe  story  surrounding  a  2013  cybersecurity  breach  of  a  leading  U.S.  retailer  includes  an \\nexample of a petty criminal who sold malware that he authored to a group of cybercriminals. \\nThe  malware  in  question  was  reportedly5  developed  by  a  17-year-old  petty  criminal  from \\nRussia, who sold it for $1,800 to a group of cybercriminals who breached the retailer network \\nand installed it across 1,800 store locations. The malware stole a reported 40 million credit card \\nnumbers and resulted in one of the largest data security breaches in recent years.\\n\\nOrganized Criminals\\nMuch  like  petty  criminals,  organized  criminals  carry  out  computer  crime  for  financial  gain. \\nOrganized  criminals  consist  of  large  groups  of  individuals  who  are  well  organized  and  well \\nfunded.  There  are  thousands  of  organized  criminal  groups  in  the  world.  Many  such  groups \\nare very knowledgeable and highly efficient in execution. Today, malware is a very successful \\nthreat used by organized criminals to conduct their crimes. This, however, was not the case in \\nthe early 2000’s when malware was designed to disrupt operations and spread quickly, com-\\nmonly resulting in saturated network connections and loss of business service availability. SQL \\nSlammer6 and Blaster7 are two examples of this. Malware evolved in the late 2000s and is now \\nstealthy and designed to infect, monitor activity, and steal data without detection. This shift in \\nmalware has made it a popular choice among organized criminals.\\n\\nDespite the growing popularity of covert malware, intrusive malware is undergoing a resur-\\ngence.  One  such  example  is  Cryptolocker,  which  unobtrusively  infects  a  computer,  scanning \\nall  local  folders  in  search  of  documents.  It  then  turns  to  the  network  and  repeats  the  search \\namong  network  files  and  folders.  Using  its  inventory  of  the  user’s  documents,  Cryptolocker \\nencrypts them, rendering them unusable. It then displays a message informing the user that he \\nor she must pay an online ransom, normally in the form of an cryptocurrency such as Bitcoin \\nor  LiteCoin.  After  being  paid,  the  criminal  group  will  send  the  individual  or  organization  a \\ndecryption key to decrypt the files and return them to their prior state.\\n\\nRansomware is usually a threat that is built once and then used multiple times. The orga-\\nnized  criminal  group  either  purchases  the  malware  or  develops  it  internally  before  setting  it \\nloose on the Internet, possibly infecting millions of systems around the world.\\n\\nPetty and organized criminals are financially motivated, but this motivation isn’t shared by \\nall cybercriminals. The next group of criminals we will look at carries out crimes in support of \\npolitical causes, rather than for financial gain.\\n\\nHacktivists\\nHacktivists  are  groups  of  criminals  who  unite  to  carry  out  cyberattacks  in  support  of  politi-\\ncal  causes.  Hacktivists  typically  target  entire  industries  but  sometimes  attack  specific  orga-\\nnizations  that  they  believe  don’t  align  with  their  political  views  or  practices.  Among  the \\nbest-known hacktivist groups is “Anonymous,” which has carried out hundreds of cyberattacks, \\nincluding Operation Payback,8 which included a series of distributed denial of service (DDOS) \\nattacks  that  disrupted  victims’  websites,  preventing  legitimate  users  from  accessing  them.  A \\nDDOS attack is launched from multiple computers running specialized software that generates \\na large amount of traffic directed to a website with the intent of overwhelming the system so \\n\\n.\\n\\nd\\ne\\nv\\nr\\ne\\ns\\ne\\nr\\n\\ns\\nt\\n\\nh\\ng\\ni\\nr\\n\\nl\\nl\\n\\nA\\n\\nl\\n\\n.\\ny\\ng\\no\\no\\nn\\nh\\nc\\ne\\nT\\n&\\ne\\nc\\nn\\ne\\nc\\nS\\n\\ni\\n\\ni\\n\\nr\\ne\\nv\\ne\\ns\\nE\\n\\nl\\n\\n.\\n\\n5\\n1\\n0\\n2\\n©\\n\\nt\\n\\nh\\ng\\ni\\nr\\ny\\np\\no\\nC\\n\\nGreen, Philip E. J.. Enterprise Risk Management : A Common Framework for the Entire Organization, Elsevier Science & Technology, 2015. ProQuest Ebook\\n         Central, http://ebookcentral.proquest.com/lib/ryerson/detail.action?docID=2146002.\\nCreated from ryerson on 2022-05-11 18:31:49.\\n\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n\\x0c96  ENTERPRISE RISK MANAGEMENT\\n\\nFIGURE 7–2  Stages of a hacktivist’s campaign.\\n\\nthat it stops responding to legitimate user requests. Hacktivists typically announce upcoming \\nattacks in advance, hoping to recruit fellow hacktivists and draw media attention to the politi-\\ncal cause they support. After recruiting, the operation begins, during which hacktivists perform \\nseveral types of reconnaissance to identify targets, as well as weaknesses that can be exploited \\nwithin  targeted  organizations.  The  attack  is  then  carried  out,  typically  including  the  theft  of \\nsensitive  information  or  disrupting  business  operations.  At  the  end  of  a  cyber-operation,  the \\nhacktivists disband until they are recruited for the next cybercampaign. In this writer’s expe-\\nrience  protecting  organizations,  hacktivists  tend  to  attack  in  waves,  and  the  attacks  continue \\nfor a period ranging from a few days to several weeks, sometimes long after a campaign was \\nreported to have ended. Figure 7–2 illustrates the stages of a hacktivist campaign.\\n\\nThe last group of cybercriminals we will look at are nation-state–sponsored criminals, who are \\n\\nnot financially motivated and who prefer to operate covertly before, during, and after an attack.\\n\\nNation-state–sponsored Criminals\\nNation-state–sponsored criminals are highly skilled individuals who are contracted by govern-\\nment departments to launch targeted and complex attacks against unsuspecting organizations \\nin support of a state agenda. Historically Nation-state sponsored attacks have been launched \\nat a number of organizations across industries including telecommunication providers, power \\nand utility organizations and technology manufactures to name a few. In some cases Nation-\\nstate  sponsored  attackers  carry  out  crimes  against  citizens  of  their  own  country.  In  the  past, \\nspies  would  infiltrate  foreign  governments  and  steal  sensitive  information,  such  as  military \\nplans. With increased reliance on computers, espionage has moved to the cyber realm, where \\nit is commonly executed from secret computer security labs and focuses on the identification \\nand covert extraction of sensitive digital information.\\n\\nIn many cases, governments employ security experts who can plan and execute Nation-state–\\nsponsored  attacks.  However,  some  governments  also  rely  on  external  mercenaries  who  have \\nspecialized skillsets and who are contracted to aid or execute cyberattacks. One such group of \\nmercenaries is known as the Elderwood Group,9 a group of cybercriminals who have conducted \\nmore than 300 cyberattacks over the past four years, including targeted attacks against U.S. mili-\\ntary defense contractors as well as against governments and large technology companies.\\n\\nConsidering  the  substantial  investment  in  cybersecurity  protection  by  governments,  mili-\\ntary  defense  and  large  technology  companies,  being  a  good  cybercriminal  is  not  enough  to \\nensure  a  successful  cyber-operation.  Nation-states  also  leverage  zero-day  vulnerabilities, \\nunknown weaknesses within software that provide criminals unauthorized access to any com-\\nputers running the vulnerable product. In many cases, the vendor of the vulnerable software \\nproduct is not aware that the vulnerability exists.\\n\\n.\\n\\nd\\ne\\nv\\nr\\ne\\ns\\ne\\nr\\n\\ns\\nt\\n\\nh\\ng\\ni\\nr\\n\\nl\\nl\\n\\nA\\n\\nl\\n\\n.\\ny\\ng\\no\\no\\nn\\nh\\nc\\ne\\nT\\n&\\ne\\nc\\nn\\ne\\nc\\nS\\n\\ni\\n\\ni\\n\\nr\\ne\\nv\\ne\\ns\\nE\\n\\nl\\n\\n.\\n\\n5\\n1\\n0\\n2\\n©\\n\\nt\\n\\nh\\ng\\ni\\nr\\ny\\np\\no\\nC\\n\\nGreen, Philip E. J.. Enterprise Risk Management : A Common Framework for the Entire Organization, Elsevier Science & Technology, 2015. ProQuest Ebook\\n         Central, http://ebookcentral.proquest.com/lib/ryerson/detail.action?docID=2146002.\\nCreated from ryerson on 2022-05-11 18:31:49.\\n\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n\\x0cChapter 7 l Cybersecurity  97\\n\\nThese zero-day vulnerabilities are often identified by cybersecurity experts within various \\ngovernment agencies, by independent security researchers, and also by criminals. Nation-state \\ncriminals are well funded and often exploit zero-day vulnerabilities in their attacks. These vul-\\nnerabilities are bought and sold within hidden online marketplaces that make up the under-\\nground economy for prices typically between $5,000 and $250,000 per vulnerability.\\n\\nThe Underground Economy\\nWhen  financially  motivated  criminals  launch  attacks  and  steal  information,  the  information \\nitself is of no monetary value and must be sold for financial reward. The one exception is ran-\\nsomware, which holds data hostage until a fee is paid to release it. When data needs to be con-\\nverted into currency, cybercriminals turn to the underground economy, where large collections \\nof websites sell illegal services and products ranging from drugs and weapons to contract killers \\nand cybermercenaries. Within the underground economy is also a thriving market for data sto-\\nlen during past cyberattacks. Highly sought after data within the underground economy at the \\ntime of this writing are stolen credit card numbers, personal information, healthcare data, and \\ncompromised social media and online user accounts and passwords.\\n\\nAll  criminal  vendors  within  the  underground  economy  advertise  freely  and  directly  com-\\npete with each other. Many vendors provide guarantees about the validity of the information \\nthey  provide,  such  as  credit  card  information.  If  you  are  sold  a  credit  card  number  that  has \\nbeen canceled by the bank, the vendor will provide a replacement number free of charge. In \\naddition to buying information, you can also lease the services of cybercriminals. One popu-\\nlar  service  that  is  frequently  leased  within  the  underground  economy  is  the  control  of  a  net-\\nwork of compromised computers to carry out activities of your choosing. The most common \\npurpose is to use the network of compromised computers to launch a DDOS attack against a \\ntarget organization. This service is so popular that vendors within the underground economy \\nfrequently  offer  discounts  for  a  repeat  lease.  For  all  cybercriminals’  blatant  advertising  and \\ntheir commerce of illegal activities, products, and services, it may be asked why law enforce-\\nment doesn’t just shut down such websites and trace the origins of the individuals involved in \\nthe illegal e-commerce. But this is easier said than done. The underground economy thrives on \\nthe invisible web, an area of the Internet specifically designed to protect the identity and loca-\\ntion of those who use it. The invisible web will be examined in more depth later in this chapter.\\nCybercriminals are just one source of risk for an organization. Some sources of cyber risk \\n\\nare not associated with illegal or malicious activity at all.\\n\\nNoncompliance with Cybersecurity Requirements\\nCybersecurity  requirements  can  be  found  embedded  within  several  sources,  including  legis-\\nlative  and  regulatory  standards,  corporate  standards,  and  commercial  contracts  which  your \\npartners and clients hold your organization to. Figure 7–3 illustrates some sources of cyberse-\\ncurity legal requirements.\\n\\nOne  example  of  a  cybersecurity  requirement  comes  from  a  private  regulator,  the  Payment \\nCard  Institute  (PCI)  Security  Standards  Council.  The  PCI  Security  Standards  Council  is  a  pri-\\nvate  regulator  formed  by  executives  of  major  credit  card  companies,  who  developed  data \\n\\n.\\n\\nd\\ne\\nv\\nr\\ne\\ns\\ne\\nr\\n\\ns\\nt\\n\\nh\\ng\\ni\\nr\\n\\nl\\nl\\n\\nA\\n\\nl\\n\\n.\\ny\\ng\\no\\no\\nn\\nh\\nc\\ne\\nT\\n&\\ne\\nc\\nn\\ne\\nc\\nS\\n\\ni\\n\\ni\\n\\nr\\ne\\nv\\ne\\ns\\nE\\n\\nl\\n\\n.\\n\\n5\\n1\\n0\\n2\\n©\\n\\nt\\n\\nh\\ng\\ni\\nr\\ny\\np\\no\\nC\\n\\nGreen, Philip E. J.. Enterprise Risk Management : A Common Framework for the Entire Organization, Elsevier Science & Technology, 2015. ProQuest Ebook\\n         Central, http://ebookcentral.proquest.com/lib/ryerson/detail.action?docID=2146002.\\nCreated from ryerson on 2022-05-11 18:31:49.\\n\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n\\x0c98  ENTERPRISE RISK MANAGEMENT\\n\\nFIGURE 7–3  Sources of cybersecurity legal requirements.\\n\\nsecurity  standards  (DSS)  and  enforce  them  as  regulatory  requirements  to  safeguard  payment \\ncard  information  and  reduce  the  losses  experienced  by  merchants  and  banks  at  the  hands  of \\ncybercriminals.\\n\\nIf an organization processes payment card information, it must remain in compliance with \\nPCI DSS requirements or suffer potential fines or the revocation of its ability to process credit \\ncard transactions. A recent data breach victim was fined US$13.3 million by the PCI Security \\nStandards Council for noncompliance with PCI-DSS.10\\n\\nCanadian Anti-Spam Legislation (CASL) serves as an example on the legislative side. CASL \\nprohibits the transmission of unsolicited communication, including emails and text messages, \\nto existing and potential customers. Failure to comply with the legislation can carry a fine of up \\nto  C$10  million  dollars  for  businesses.  Moreover,  if  an  organization  has  commercial  require-\\nments to comply with a base set of security practices and is found not to be in compliance with \\nthem, it may be subject to financial penalty, usually in the form of a reimbursement of service \\nfees or termination of the contract with the client.\\n\\nConsidering that in 2014 the reported average global cost of a cyber breach was US$3.5 mil-\\nlion,11 failure to comply with regulatory, legislative, and commercial security requirements can \\nincur a loss in excess of the loss incurred in an actual cyberattack.\\n\\nInformation  security  and  ensuring  customer  privacy  have  become  a  mandatory  cost  of \\ndoing  business.  Organizations  must  identify  cyber-related  regulatory  and  legislative  require-\\nments that apply to them and ensure that business operations are managed accordingly. Aside \\nfrom  cyberattacks  and  non-compliance  with  cybersecurity  requirements,  organizations  can \\nstill face substantial cyber risks due to mistakes made by employees.\\n\\nErrors and Omissions\\nEvery digital asset, such as a server, tablet, laptop, or thumb drive, contains data and requires \\nsome form of human interaction to benefit from it. This interaction is performed by a human \\nand  managed  through  processes  and  workflow,  with  each  area  serving  as  a  potential  area  of \\nvulnerability  that  can  be  unintentionally  or  intentionally  exploited.  Take,  for  example,  an \\nemployee who accidentally leaves behind a tablet or a USB thumb drive containing sensitive \\ndata in a coffee shop, or an employee who transfers sensitive information to the wrong client \\nby mistake. Errors and omissions caused by such mistakes and system glitches account for a \\nlarge proportion of data breaches reported each year.12\\n\\n.\\n\\nd\\ne\\nv\\nr\\ne\\ns\\ne\\nr\\n\\ns\\nt\\n\\nh\\ng\\ni\\nr\\n\\nl\\nl\\n\\nA\\n\\nl\\n\\n.\\ny\\ng\\no\\no\\nn\\nh\\nc\\ne\\nT\\n&\\ne\\nc\\nn\\ne\\nc\\nS\\n\\ni\\n\\ni\\n\\nr\\ne\\nv\\ne\\ns\\nE\\n\\nl\\n\\n.\\n\\n5\\n1\\n0\\n2\\n©\\n\\nt\\n\\nh\\ng\\ni\\nr\\ny\\np\\no\\nC\\n\\nGreen, Philip E. J.. Enterprise Risk Management : A Common Framework for the Entire Organization, Elsevier Science & Technology, 2015. ProQuest Ebook\\n         Central, http://ebookcentral.proquest.com/lib/ryerson/detail.action?docID=2146002.\\nCreated from ryerson on 2022-05-11 18:31:49.\\n\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n\\x0cChapter 7 l Cybersecurity  99\\n\\nTable 7–1  Common Events and Possible Consequences\\n\\nEvent\\n\\nLoss of service availability\\n\\nWeb application compromise\\n\\nElectronic financial fraud\\n\\nMalware/virus outbreak\\n\\nPhysical theft of an electronic asset\\n\\nUnintentional data disclosure\\n\\nIntellectual property theft\\n\\nPossible Consequences\\n\\nLoss of revenue\\nLoss of customer confidence\\nLoss of employee productivity\\nLoss of revenue\\nLoss of data integrity\\nLoss of customer confidence\\nLoss of revenue\\nLoss of data integrity\\nLoss of customer confidence\\nLoss of service availability\\nLoss of data integrity\\nLoss of employee productivity\\nFinancial loss\\nLoss of customer confidence\\nLoss of revenue\\nLoss of service availability\\nLoss of data integrity\\nLoss of employee productivity\\nLoss of competitive advantage\\nLoss of customer confidence\\n\\nEvents\\nOrganizations face many different sources of cybersecurity risk. Each source of risk is associ-\\nated with one or more events. For example, when considering a hacktivist DDOS attack on an \\norganization, the loss of service availability is the risk, the hacktivist group the source of risk, \\nand  the  DDOS  attack  the  event.  Each  risk  that  an  organization  faces  can  be  associated  with \\nseveral events. A list of some common events can be found in the table (Table 7–1).\\n\\nRisk Analysis and Prioritization\\n\\nWithin  cybersecurity,  the  risk  analysis  process  deviates  slightly  from  that  discussed  in \\nChapter\\xa01:\\n\\nIdentifying the value of assets\\n\\nl \\nl  Risk criteria definition\\nl \\nl  Determining the likelihood and consequence of identified threats\\n\\nIdentifying vulnerabilities and threats\\n\\n.\\n\\nd\\ne\\nv\\nr\\ne\\ns\\ne\\nr\\n\\ns\\nt\\n\\nh\\ng\\ni\\nr\\n\\nl\\nl\\n\\nA\\n\\nl\\n\\n.\\ny\\ng\\no\\no\\nn\\nh\\nc\\ne\\nT\\n&\\ne\\nc\\nn\\ne\\nc\\nS\\n\\ni\\n\\ni\\n\\nr\\ne\\nv\\ne\\ns\\nE\\n\\nl\\n\\n.\\n\\n5\\n1\\n0\\n2\\n©\\n\\nt\\n\\nh\\ng\\ni\\nr\\ny\\np\\no\\nC\\n\\nIdentifying Asset Value\\nDuring risk analysis, it is important to assign a monetary value to each asset to aid later priori-\\ntization. Assigning a value to an asset should be based on both tangible and intangible factors. \\nIf  an  organization  purchases  a  server  for  $10,000  and  spends  $20,000  to  hire  a  consultant  to \\n\\nGreen, Philip E. J.. Enterprise Risk Management : A Common Framework for the Entire Organization, Elsevier Science & Technology, 2015. ProQuest Ebook\\n         Central, http://ebookcentral.proquest.com/lib/ryerson/detail.action?docID=2146002.\\nCreated from ryerson on 2022-05-11 18:31:49.\\n\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n\\x0c100  ENTERPRISE RISK MANAGEMENT\\n\\ninstall and configure it and $50,000 a year to maintain the server, the approximate value of the \\nserver  would  be  $80,000  for  one  year  (assuming  the  cost  of  the  server  is  not  amortized  over \\nseveral  years).  Slightly  complicating  our  example,  if  the  organization  then  copies  intellectual \\nproperty to the server, the value of the server would likely increase to a value far greater than \\nthe prior value of a server over a one-year term.\\n\\nAssigning an asset value based on tangible properties is relatively straightforward, however, \\nintangible  properties  are  a  little  more  complex  to  identify.  It  is  good  practice  to  consult  the \\nasset owner when assigning values and when examining the intangible value properties.\\n\\nThe value of properties will differ depending on the asset under evaluation. The following list \\n\\ndescribes some of the common properties that can serve as a base when assigning asset values:\\n\\nl  Cost to develop\\nl  Cost to maintain and secure\\nl  Value of the asset to organization owners and users\\nl  Cost of replacement in the event of loss\\n\\nThe  properties  used  to  determine  the  values  should  be  defined  and  consistently  applied \\nto  all  assets.  Some  assets  may  have  additional  properties,  but  ensuring  consistency  will  aid \\nin  assigning  accurate  and  relative  values  across  all  assets.  Consistency  is  important  not  only \\nwhen assigning values to assets, but also when defining your risk criteria.\\n\\nRisk Criteria\\nAs covered in Chapter\\xa01 of this book, defining risk criteria ensures that risk can be compared \\nand aggregated effectively and consistently. Common practice within the industry is to define \\nscales inclusive of multiple rating levels to assess the likelihood and consequence of each risk. \\nScales can range from two to more than ten, with each level adding a layer of granularity as well \\nas more complexity. Each level within a criteria scale requires a clear definition and should be \\ndifferentiated from the other levels. Too many levels can result in criteria levels that are too dif-\\nficult to map, hindering the successful adoption of the risk criteria by others in the organiza-\\ntion. Many organizations use five or fewer levels to balance granularity and complexity.\\n\\nLIKELIHOOD\\nAs already discussed in this chapter, each of the four classes of cybercriminals have different \\nmotives  for  cyberattack,  ranging  from  financial  gain  to  espionage  to  raising  awareness  about \\na political cause. When evaluating the likelihood of experiencing a cyber event at the hands of \\nthese  criminals,  three  core  factors  should  be  considered  that  can  influence  the  likelihood  of \\nthe organization’s experiencing a cyberattack.\\n\\nThe data you manage is the strongest influence on your likelihood of suffering a cyberattack. \\nPetty  criminals,  organized  criminals,  and  nation-states  target  organizations  based  on  the  data \\nthey manage. An organization managing financial data will have a higher likelihood of experienc-\\ning a cyberattack by a criminal groups motivated by financial gain than that of another organiza-\\ntion that does manages neither financial data nor data that can be converted into financial gain.\\n\\nThe industry to which you belong also affects your likelihood of experiencing a cyberattack. \\nIf your organization is part of an industry frequently targeted by hacktivists or other criminal \\n\\n.\\n\\nd\\ne\\nv\\nr\\ne\\ns\\ne\\nr\\n\\ns\\nt\\n\\nh\\ng\\ni\\nr\\n\\nl\\nl\\n\\nA\\n\\nl\\n\\n.\\ny\\ng\\no\\no\\nn\\nh\\nc\\ne\\nT\\n&\\ne\\nc\\nn\\ne\\nc\\nS\\n\\ni\\n\\ni\\n\\nr\\ne\\nv\\ne\\ns\\nE\\n\\nl\\n\\n.\\n\\n5\\n1\\n0\\n2\\n©\\n\\nt\\n\\nh\\ng\\ni\\nr\\ny\\np\\no\\nC\\n\\nGreen, Philip E. J.. Enterprise Risk Management : A Common Framework for the Entire Organization, Elsevier Science & Technology, 2015. ProQuest Ebook\\n         Central, http://ebookcentral.proquest.com/lib/ryerson/detail.action?docID=2146002.\\nCreated from ryerson on 2022-05-11 18:31:49.\\n\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n\\x0cChapter 7 l Cybersecurity  101\\n\\ngroups,  you  can  expect  to  face  more  attacks  than  do  organizations  belonging  to  a  less  fre-\\nquently targeted industry.\\n\\ninfluencer \\n\\nThe  technology  you  use \\n\\nis  a  commonly  overlooked \\n\\nin  cyberattacks. \\nTechnological vulnerabilities are a common way criminals break into organizations. Each vul-\\nnerability identified in technology must be either patched or corrected via another risk control \\nto address the exposure. This corrective action is normally dependent on the details of the vul-\\nnerability, such as whether it is exposed to a material threats, whether external or internal to \\nan organization. Organizations who use technology commonly associated with a high number \\nof vulnerabilities face increased difficulties in identifying and mitigating these multiple expo-\\nsures in a timely manner and raises the likelihood of the vulnerabilities’ being identified and \\nexploited by a criminal.\\n\\nCONSEQUENCE\\nThe  “consequence”  is  an  event’s  expected  effect  on  an  organization  A  single  cybersecurity \\nevent can be associated with several consequences, and such a case, the “high-water mark,” or \\nmost significant consequence, should be used for the event. For example, if a targeted cyberat-\\ntack is associated with a loss of brand reputation that carries a consequence rated as “critical” \\nas  well  as  a  loss  of  service  availability  that  has  a  consequence  of  “high,”  the  threat’s  conse-\\nquence should be rated as “critical.” Table 7–2 illustrates a sample consequence matrix includ-\\ning qualitative and quantitative measures.\\n\\nOne  of  the  most  significant  cybersecurity  events  is  a  security  breach.  It  is  said  by  many \\nthat  thanks  to  the  sophistication  of  threats  and  the  persistence  of  criminals,  it  is  no  longer  a \\nquestion of whether an organization will be breached, but rather when it will detect the next \\nbreach. The covert nature and sophistication of threats make them hard to detect, with some \\nbreaches taking months or years to detect. Thousands of  organizations each  year  find  them-\\nselves grappling with a breach.\\n\\nThe  average  direct  and  indirect  costs  associated  with  a  breach  are  US$3.5  million.13  This \\nincludes  the  cost  to  perform  the  computer  forensic  investigation,  notification  of  the  people \\naffected, post-breach services such as providing credit monitoring to affected victims, and loss \\nof business.\\n\\nTable 7–2  Example of a Consequence Scale for Cyber Risks\\n\\nConsequence Consideration\\n\\nConsequence\\n\\nReputational Damage\\n\\nFinancial Loss (USD)\\n\\nOperational Effect\\n\\nIncidental\\nMinor\\n\\nModerate\\n\\nMajor\\nCritical\\n\\nLimited\\nLocal/regional\\nShort-term negative exposure\\nLocal/regional\\nMedium-term negative exposure\\nNational negative publicity\\nGlobal negative publicity\\nLong-term negative exposure\\n\\n<$500\\n$500–$1,000\\n\\n<9% degraded service\\n10–49% degraded service\\n\\n$1,000–$19,000\\n\\n>50% degraded service\\n\\n$20,000–$40,000\\n>$50,000\\n\\nComplete loss of service\\nComplete loss of service\\nLoss of employee productivity\\n\\n.\\n\\nd\\ne\\nv\\nr\\ne\\ns\\ne\\nr\\n\\ns\\nt\\n\\nh\\ng\\ni\\nr\\n\\nl\\nl\\n\\nA\\n\\nl\\n\\n.\\ny\\ng\\no\\no\\nn\\nh\\nc\\ne\\nT\\n&\\ne\\nc\\nn\\ne\\nc\\nS\\n\\ni\\n\\ni\\n\\nr\\ne\\nv\\ne\\ns\\nE\\n\\nl\\n\\n.\\n\\n5\\n1\\n0\\n2\\n©\\n\\nt\\n\\nh\\ng\\ni\\nr\\ny\\np\\no\\nC\\n\\nGreen, Philip E. J.. Enterprise Risk Management : A Common Framework for the Entire Organization, Elsevier Science & Technology, 2015. ProQuest Ebook\\n         Central, http://ebookcentral.proquest.com/lib/ryerson/detail.action?docID=2146002.\\nCreated from ryerson on 2022-05-11 18:31:49.\\n\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n\\x0c102  ENTERPRISE RISK MANAGEMENT\\n\\nA security breach can include several consequences spanning tangible properties such as \\nfinancial loss, operational effect, and employee safety, as well as nontangible properties such \\nas  strategic  effect  and  reputational  loss.  Take  the  example  of  an  organization  examining  the \\nconsequence  associated  with  a  compromised  server.  The  cost  to  rebuild  the  compromised \\nserver would be a tangible property, but replacing trade secrets disclosed in the cyberattack, \\nthe  value  of  loss  caused  by  degraded  brand  reputation,  and  loss  of  shareholder  confidence \\nstemming from the attack are intangible properties. Further complicating the scenario, in sev-\\neral past cyberattacks, the share prices of the breached organizations dropped sharply imme-\\ndiately after the breaches and remained degraded for a period of time, eventually recovering \\nto  prebreach  value.  Within  the  risk  analysis  process,  do  you  factor  in  the  loss  in  share  price \\nindefinitely, or just until it’s expected to recover? Unfortunately there is no simple answer. It \\nis  important  to  define  how  a  consequence  will  be  rated  and  consistently  applied  to  all  risk \\nevents. This consequence should include both tangible and intangible properties, and, much \\nas  with  the  value  assigned  to  assets,  the  asset  owners  should  be  involved  to  help  monetize \\nintangible  properties.  Another  good  source  that  can  be  used  when  monetizing  intangible \\nproperties is a business impact assessment (BIA). BIAs predict the consequences of the dis-\\nruption  of  business,  which  can  span  tangible  and  intangible  properties  applicable  within \\ncybersecurity events. BIAs are often completed in conjunction with business continuity plan-\\nning (BCP). BCP resources may thus also help determine the consequences of cybersecurity \\nevents.\\n\\nAn understanding of the consequence of cybersecurity events will allow you to effectively \\n\\nprioritize them.\\n\\nRisk Treatment\\nRisk treatment is used to minimize or eliminate identified risk. For example, if an organization \\nowns a server containing a technological vulnerability for which there is no associated patch, \\nthe organization could implement additional risk controls, such as by implementing an intru-\\nsion  prevention  system  to  frustrate  attempts  to  exploit  the  vulnerability.  Alternatively,  if  the \\nserver was not needed in production, the organization might measure the cost of removing it \\nto completely eliminate the risk.\\n\\nIn addition to the foundational cybersecurity practices we looked at earlier in this chapter, \\nwhich  make  up  the  broader  cyber  risk  management  system,  hundreds  of  potential  risk  con-\\ntrols can be used to further reduce or eliminate risk. In this chapter, we’ll look at some popular \\nrisk controls across three domains: business continuity, human elements, and operations and \\ntechnology.\\n\\nBusiness Continuity\\n\\nA key objective of every organization or business is to ensure the availability of operations. BCP \\nplays an important role in ensuring that operations can be restored efficiently and effectively in \\nthe event of an event such as a power outage, flood, or fire.\\n\\n.\\n\\nd\\ne\\nv\\nr\\ne\\ns\\ne\\nr\\n\\ns\\nt\\n\\nh\\ng\\ni\\nr\\n\\nl\\nl\\n\\nA\\n\\nl\\n\\n.\\ny\\ng\\no\\no\\nn\\nh\\nc\\ne\\nT\\n&\\ne\\nc\\nn\\ne\\nc\\nS\\n\\ni\\n\\ni\\n\\nr\\ne\\nv\\ne\\ns\\nE\\n\\nl\\n\\n.\\n\\n5\\n1\\n0\\n2\\n©\\n\\nt\\n\\nh\\ng\\ni\\nr\\ny\\np\\no\\nC\\n\\nGreen, Philip E. J.. Enterprise Risk Management : A Common Framework for the Entire Organization, Elsevier Science & Technology, 2015. ProQuest Ebook\\n         Central, http://ebookcentral.proquest.com/lib/ryerson/detail.action?docID=2146002.\\nCreated from ryerson on 2022-05-11 18:31:49.\\n\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n\\x0cChapter 7 l Cybersecurity  103\\n\\nFIGURE 7–4  Linkage between operational and security event response and recovery.\\n\\nMany  security  teams  are  also  leveraging  effective  BCP  to  prepare,  manage,  and  recover \\nbusiness  operations  in  the  event  of  a  cyberattack.  The  following  figure  illustrates  the  link-\\nage  between  cybersecurity  and  operational  risk,  events,  and  the  shared  benefit  of  BCP  \\n(Figure 7–4).\\n\\nWhen  an  event  is  identified,  it  may  involve  using  additional  personnel  and  transferring \\noperations, partly or fully, to another location or provider to manage. Data from the primary \\nlocation or from a backup is transferred to ensure that business operations are relocated effec-\\ntively during the test. The same regulatory and legislative security requirements managed by \\nan organization within their primary location of business apply to temporary data processing \\nfacilities. It is also imperative that the effectiveness of cybersecurity in a temporary operating \\nlocation  be  the  same  as  in  the  primary  location  and  that  cybersecurity  risk  continues  to  be \\nmanaged at a level approved by the management of the organization.\\n\\nMost  organizations  regularly  test  the  response  and  performance  of  continuity  and  recov-\\nery  plans  using  tabletop  exercises  specifically  designed  to  mimic  material  events  likely  to  be \\nexperienced.  Organizations  using  BCP  to  manage  cybersecurity  events  should  also  include \\ncybersecurity-related  events,  such  as  a  targeted  cyberattack  or  a  denial-of-service  attack, \\nto ensure that cyber events gain the same benefits from testing as other scenarios across the \\norganization.\\n\\nSecuring the Human Element\\n\\nSuccessful cyberattacks often include the psychological manipulation of the users of technol-\\nogy  so  that  they  perform  actions  and  circumvent  processes,  knowingly  or  unknowingly,  to \\naid  the  criminal.  This  practice  of  exploiting  people  to  perform  actions  desired  by  a  criminal \\nis commonly referred to as social engineering. Cybercriminals often look for the path of least \\nresistance and use social engineering techniques to trick a user into providing physical or logi-\\ncal access to a system or network. For example, a criminal may call up a help desk agent at an \\norganization,  pretend  to  be  a  member  of  a  project  team,  and  request  that  the  agent  verbally \\nprovide  the  password  of  another  team  member  who  is  on  vacation.  To  apply  pressure,  the \\ncriminal may add that the agent will get in trouble with his or her manager if he doesn’t supply \\nthe password and gain access to the files of the other team member to complete a critical proj-\\nect. The organization may have policies that prohibit the help desk agent from providing the \\n\\n.\\n\\nd\\ne\\nv\\nr\\ne\\ns\\ne\\nr\\n\\ns\\nt\\n\\nh\\ng\\ni\\nr\\n\\nl\\nl\\n\\nA\\n\\nl\\n\\n.\\ny\\ng\\no\\no\\nn\\nh\\nc\\ne\\nT\\n&\\ne\\nc\\nn\\ne\\nc\\nS\\n\\ni\\n\\ni\\n\\nr\\ne\\nv\\ne\\ns\\nE\\n\\nl\\n\\n.\\n\\n5\\n1\\n0\\n2\\n©\\n\\nt\\n\\nh\\ng\\ni\\nr\\ny\\np\\no\\nC\\n\\nGreen, Philip E. J.. Enterprise Risk Management : A Common Framework for the Entire Organization, Elsevier Science & Technology, 2015. ProQuest Ebook\\n         Central, http://ebookcentral.proquest.com/lib/ryerson/detail.action?docID=2146002.\\nCreated from ryerson on 2022-05-11 18:31:49.\\n\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n\\x0c104  ENTERPRISE RISK MANAGEMENT\\n\\nFIGURE 7–5  Human element of security.\\n\\npassword over the phone, but a smooth-talking criminal may be able to persuade the agent to \\nbreak protocol. Figure 7–5 illustrates how a cyberattack on the human element can circumvent \\nprocedural and technological risk controls deployed within an organization.\\n\\nSocial  engineering  may  seem  like  a  trivial  or  unlikely  method  of  attack,  but  it  remains  an \\neffective method used by criminals to gain unauthorized access to systems. Recent breaches, \\nincluding the breach of a leading retailer in 2013, were believed to be the result of criminals’ \\nhaving  used  social  engineering  techniques  to  entice  users  at  a  third  party14  to  unknowingly \\ninstall malware on their computer, granting the criminals remote system access.15\\n\\nMost software and hardware produced today includes a myriad of security features to help \\nprotect  it  from  cyberattack.  The  human  element  is  more  problematic  and  requires  users  to \\nchange  deeply  rooted  behavior.  They  must  be  trained  to  understand  the  risks  they  face  and \\nhow to respond to them.\\n\\nSecurity Awareness Training\\nSecurity awareness training should include general training on the cyberthreats applicable to \\nall employees and partners as well as targeted sessions for high-risk employee groups, focusing \\non the specific cyberthreats faced by individuals within key teams.\\n\\nSecurity training is an essential component of cybersecurity. It aims to ensure that employ-\\nees understand the cyber threats that they face, organization security policies and their role in \\ncybersecurity.\\n\\nBackground and Personnel Checks\\nEmployees are an essential line of defense in detecting and preventing cyberattacks. But they \\nalso  may  be  the  ones  conducting  the  attack,  and  organizations  should  ensure  that  the  right \\nemployees  or  subcontractors  are  hired  to  interact  with  systems,  data,  and  other  personnel. \\nBackground checks are a common method of prescreening to ensure that high-risk individu-\\nals are properly evaluated before joining the organization. For additional information on back-\\nground checks, refer to Chapter\\xa08, on human capital risk.\\n\\n.\\n\\nd\\ne\\nv\\nr\\ne\\ns\\ne\\nr\\n\\ns\\nt\\n\\nh\\ng\\ni\\nr\\n\\nl\\nl\\n\\nA\\n\\nl\\n\\n.\\ny\\ng\\no\\no\\nn\\nh\\nc\\ne\\nT\\n&\\ne\\nc\\nn\\ne\\nc\\nS\\n\\ni\\n\\ni\\n\\nr\\ne\\nv\\ne\\ns\\nE\\n\\nl\\n\\n.\\n\\n5\\n1\\n0\\n2\\n©\\n\\nt\\n\\nh\\ng\\ni\\nr\\ny\\np\\no\\nC\\n\\nGreen, Philip E. J.. Enterprise Risk Management : A Common Framework for the Entire Organization, Elsevier Science & Technology, 2015. ProQuest Ebook\\n         Central, http://ebookcentral.proquest.com/lib/ryerson/detail.action?docID=2146002.\\nCreated from ryerson on 2022-05-11 18:31:49.\\n\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n\\x0cChapter 7 l Cybersecurity  105\\n\\nOperations and Technology\\n\\nSince  the  dawn  of  cybersecurity,  technology  is  the  area  within  most  organizations  that  has \\nreceived  the  most  attention.  But,  as  we  have  discussed  throughout  this  chapter,  it  is  just  one \\npiece of a balanced and holistic approach to managing cybersecurity.\\n\\nTechnology\\nWhen the topic of cybersecurity emerged, there was a belief that the threat could be addressed \\nby  means  of  additional  technological  risk  controls,  such  as  firewalls  and  antivirus  software: \\nThe  more  layers  of  technology  controls,  the  greater  the  security.  This  view  has  become  out-\\ndated  and  is  no  longer  aligned  with  today’s  cyberthreats.  Previously,  IT  risk  controls  were \\ndesigned solely to detect threats based on signature-based detection strategies. When data was \\nsent to a computer or a file was opened on a computer, the data would be scanned to identify \\nknown threats. Now, there are more than 315,000 new threats discovered each day.16 Product \\nvendors cannot develop signatures fast enough, and system administrators cannot distribute \\nsignature files quickly enough to keep up. Some antivirus vendors themselves state that antivi-\\nrus software alone is not an effective measure against the cyberthreats of today.17\\n\\nSignature-based defense is a necessary form of cybersecurity but is not itself sufficient pro-\\ntection  for  an  organization.  Alternative  technological  risk  controls,  such  as  next-generation \\nfirewalls  and  unified  threat  management  devices  that  combine  antivirus,  firewall,  web  content \\nfiltering,  and  data  loss  prevention  provide  a  reasonable  degree  of  protection.  There  has  also \\nbeen a surge in the use of anomaly-based detection tools. These tools operate based on behav-\\niors rather than signatures. For example, if a computer is not normally in use between 1 a.m. and \\n4 a.m., and the software detects an unusually large number of connections with a computer in \\na foreign country, the software would then highlight the anomaly and alert the user or system \\nadministrator. All these controls generate security events that must be acknowledged, analyzed, \\nand  acted  on.  But  it  remains  a  challenge  to  prioritize  such  anomalies,  some  of  which  may  be \\ninnocuous.  Security  technology,  such  as  security  information  event  managers,  helps  organiza-\\ntions analyze large volumes of security data to help ensure that significant threats are focused on.\\n\\nOperations\\nDeploying technological risk controls is a start, but effectively configuring controls and actively \\nacting on the events reported by them are equally important steps. In late 2013, a U.S. retailer \\nreported a data security breach and on investigation learned that its risk controls had identi-\\nfied 60,000 events during the attack that were not properly acted on.18 If they had been acted \\nupon,  the  retailer  may  have  significantly  reduced  the  scope  and  effect  of  the  breach  it  expe-\\nrienced.  Organizations  looking  to  assess  the  effectiveness  of  their  controls  should  gauge  the \\ngovernance  of  the  control,  not  just  whether  the  control  has  been  implemented.  If  there  is  a \\ncontrol, who is supposed to operate it? Is there a process outlining how events should be quali-\\nfied and acted on? Do those tasked with following the process have the skills and knowledge to \\ndo so? These are just a few examples of questions that should be asked to help ensure that the \\nright people and process accompany a technological risk control.\\n\\n.\\n\\nd\\ne\\nv\\nr\\ne\\ns\\ne\\nr\\n\\ns\\nt\\n\\nh\\ng\\ni\\nr\\n\\nl\\nl\\n\\nA\\n\\nl\\n\\n.\\ny\\ng\\no\\no\\nn\\nh\\nc\\ne\\nT\\n&\\ne\\nc\\nn\\ne\\nc\\nS\\n\\ni\\n\\ni\\n\\nr\\ne\\nv\\ne\\ns\\nE\\n\\nl\\n\\n.\\n\\n5\\n1\\n0\\n2\\n©\\n\\nt\\n\\nh\\ng\\ni\\nr\\ny\\np\\no\\nC\\n\\nGreen, Philip E. J.. Enterprise Risk Management : A Common Framework for the Entire Organization, Elsevier Science & Technology, 2015. ProQuest Ebook\\n         Central, http://ebookcentral.proquest.com/lib/ryerson/detail.action?docID=2146002.\\nCreated from ryerson on 2022-05-11 18:31:49.\\n\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n\\x0c106  ENTERPRISE RISK MANAGEMENT\\n\\nTransferring Risk\\n\\nOrganizations may choose to transfer cyber risk to a third party, such as an insurer, rather than \\n(or as well as) implementing risk controls on their own. Cyber liability insurance enables orga-\\nnizations to establish coverage to offset the financial cost of a cybersecurity event. In addition \\nto financial support, many cyber liability providers will assist in the actual management of the \\nevent for the insured. The goals of cyber liability products are to reduce the effects of a cyber \\nevent such as a security breach and minimize the consequences experienced by the insured. \\nCyber  liability  insurance  can  provide  support  for  first-party  and  third-party  costs  associated \\nwith a cybersecurity event.\\n\\nFirst party coverage ensures that financial support is provided for direct costs such as the \\n\\ncost of forensics, notification and recovery of the environment.\\n\\nThird-party  coverage  covers  lawsuits  and  other  liabilities  that  the  organization  may  face \\n\\nassociated with the event.\\n\\nA  recent  example  of  an  organization  that  used  cyber  liability  insurance  to  offset  breach \\ncosts is a leading retailer that received a US$38 million payout from its cyber liability insurer to \\noffset the costs of its 2013 breach.19\\n\\nRisk Monitoring and Review\\nExternal Threat Monitoring\\n\\nOrganizations deploy risk controls to reduce risk within an environment. These controls can be \\nadministrative, such as a policy or procedures, or technological, such as a firewall or intrusion pre-\\nvention system. What all these controls have in common is that they are in place to protect against \\nknown  threats.  Known  threats  are  the  threats  prevalent  within  the  industry  that  are  likely  to  be \\nexperienced by a particular organization. Staying on the forefront of the emerging threats enables \\nan organization to anticipate and protect itself against such threats before they are experienced. \\nThis information is known as threat intelligence and requires identifying, extracting, normalizing, \\nand analyzing large volumes of data from the Internet in search of the relevant information.\\n\\nIt  is  not  uncommon  for  cybercriminals  to  collaborate  and  communicate  among  each  other \\nusing Internet blogs, chat rooms, and social media sites as they plan attacks against organizations, \\nor to boast about them afterward. Monitoring key Internet locations enables an organization to \\nidentify  a  planned  attack  scheduled  for  the  future  or,  in  some  cases,  to  identify  an  attack  that, \\nunknown to the organization, occurred but has yet to be detected. This requires the development \\nof robust and sophisticated data analysis systems to store and analyze large and dynamic sets of \\nInternet data. Because the Internet is made up of two segments, the visible and the invisible web, \\nintelligence should be extracted from both segments to ensure that emerging threats are clear.\\n\\nVisible Web\\n\\nThe visible web is comprised of millions of pages on the Internet. Domains such as .ca, .com, \\n.org,  .net,  and  .biz  are  merely  a  few  of  the  popular  ones,  each  containing  web  pages,  social \\n\\n.\\n\\nd\\ne\\nv\\nr\\ne\\ns\\ne\\nr\\n\\ns\\nt\\n\\nh\\ng\\ni\\nr\\n\\nl\\nl\\n\\nA\\n\\nl\\n\\n.\\ny\\ng\\no\\no\\nn\\nh\\nc\\ne\\nT\\n&\\ne\\nc\\nn\\ne\\nc\\nS\\n\\ni\\n\\ni\\n\\nr\\ne\\nv\\ne\\ns\\nE\\n\\nl\\n\\n.\\n\\n5\\n1\\n0\\n2\\n©\\n\\nt\\n\\nh\\ng\\ni\\nr\\ny\\np\\no\\nC\\n\\n\\n \\n \\n \\n \\n \\n\\x0cChapter 7 l Cybersecurity  107\\n\\nmedia  and  chat  rooms  that  may  contain  data  relevant  to  the  organization.  The  visible  web \\nmakes up about 4% of networked web pages on the Internet.20 Access within the visible web \\nis often monitored and mapped back to an IP address  of a computer. It  is  difficult to remain \\nanonymous within the visible web, making it a risky place for cybercriminals to plan or boast \\nabout  their  attacks.  The  exceptions  to  this  are  hacktivists,  who  seek  attention  in  support  of \\ntheir cause. In addition to keeping track of hacktivists, monitoring the visible web helps iden-\\ntify emerging cybersecurity research and trends that can be used to improve an organization’s \\nsecurity program.\\n\\nInvisible Web\\n\\nThe  other  96%  of  the  Internet  is  made  up  of  several  constellations  of  networks  that  form  the \\ninvisible web. The invisible web consists of databases and cannot be enumerated by popular \\nsearch  engines.  Many  of  these  database  require  credentials  to  access  their  content.  In  addi-\\ntion, the invisible web contains several networks of computers specially designed to mask the \\nlocation  and  identity  of  their  users  and  merchants  and  can  only  be  accessed  using  special-\\nized software. One popular invisible web network includes sites within the .onion domain. To \\naccess this network, users must first download The Onion Router (TOR), software available on \\nthe Internet. After installing it, a user can navigate areas such as the invisible wiki and browse \\nthe underground market discussed earlier in this chapter. Monitoring the invisible web helps \\nidentify past criminal cyberactivity against an organization that may not yet have been discov-\\nered. One example of this is associated with a large U.S. bank: One of the bank’s fraud analysts \\nwas able to monitor underground websites and illegally purchase a collection of compromised \\ncredit  card  numbers  that  belonging  to  his  institution.21  Use  of  the  suspect  cards  was  traced \\nback to a retailer and served as an indicator of a breach of which the retailer was unaware. This \\nis a great example of how external threat monitoring can be used to catch exposures missed by \\na proactive security program.\\n\\nWhether  an  organization  decides  to  take  on  intelligence  monitoring  itself,  or  whether  it \\n\\nhires a third party, it is important to include data from both the visible and invisible web.\\n\\nSecurity Metrics\\n\\nSecurity metrics enable an organization to monitor risk controls. The building blocks behind \\nsecurity  metrics  are  good  key  performance  indicators  (KPIs)  that  can  be  implemented  to \\nmeasure and track the effectiveness and failures of risk controls, as well as positive and nega-\\ntive  changes  in  breaches.  An  example  of  a  KPI  is  the  number  of  threats  blocked  by  risk  con-\\ntrols within an environment. This can confirm the effectiveness or maturity of a control within \\nthat  environment.  Another  example  is  the  tracking  of  breaches,  including  the  source  as  well \\nas the amount of elapsed time from cyber event detection to containment and recovery. KPIs \\nallow for the identification of opportunities to learn from past events and manage subsequent \\nevents.  Security  metrics  should  be  reviewed  on  a  recurring  basis  with  managers,  who  can \\nmake changes in response to the metrics and present the information to the company’s board \\nof directors so its members understand the state of security within the organization.\\n\\n.\\n\\nd\\ne\\nv\\nr\\ne\\ns\\ne\\nr\\n\\ns\\nt\\n\\nh\\ng\\ni\\nr\\n\\nl\\nl\\n\\nA\\n\\nl\\n\\n.\\ny\\ng\\no\\no\\nn\\nh\\nc\\ne\\nT\\n&\\ne\\nc\\nn\\ne\\nc\\nS\\n\\ni\\n\\ni\\n\\nr\\ne\\nv\\ne\\ns\\nE\\n\\nl\\n\\n.\\n\\n5\\n1\\n0\\n2\\n©\\n\\nt\\n\\nh\\ng\\ni\\nr\\n \\n \\n \\n \\n \\n \\n \\n \\n\\x0c108  ENTERPRISE RISK MANAGEMENT\\n\\nPostmortem Cybersecurity Event Reviews\\n\\nCybersecurity incidents can harm an organization and can also serve as a way to learn about \\nweaknesses within the security program and gaps in risk controls that require more attention. \\nIt  is  good  practice  to  perform  a  postmortem  review  after  each  material  cybersecurity  event \\nwithin an organization. This provides an opportunity to identify a  number  of  things:  the  risk \\ncontrols that helped prevent or limit the scope of the event, the response processes that were \\neffective, and the deficiencies of risk controls that, if remedied, could reduce the likelihood of \\nanother event in the future. The findings of postmortem cybersecurity event reviews should be \\nformally documented and put through the risk management process to ensure that all cyberse-\\ncurity risks are assessed and managed accordingly.\\n', 'computer law & security review 34 (2018) 908–911 \\n\\nAvailable online at www.sciencedirect.com \\n\\njournal homepage: www.elsevier.com/locate/CLSR \\n\\nAn approach to minimizing legal and reputational \\nrisk in Red Team hacking exercises \\n\\n∗\\nJoseph V. DeMarco \\n\\nDeVore & DeMarco, LLP, New York, NY, USA \\n\\na r t i c l e \\n\\ni n f o \\n\\na b s t r a c t \\n\\nArticle history: \\n\\nKeywords: \\nData protection \\nData security \\nCybercrime \\nCybersecurity \\nCyber-resilience \\nComputer intrusions \\nEthical hacking \\nNetwork and information security \\nPenetration Testing \\nRed Team \\n\\nRobust cyber-resilience depends on sound technical controls and testing of those controls \\nin combination with rigorous cyber-security policies and practices. Increasingly, corpora- \\ntions and other organizations are seeking to test all of these, using methods more sophis- \\nticated than mere network penetration testing or other technical audit operations. More \\nsophisticated organizations are also conducting so-called “Red Team” exercises, in which \\nthe organization tasks a small team of highly skilled and trained individuals to try to gain \\nunauthorized access to physical and logical company assets and information. While such \\noperations can have real value, they must be planned and conducted with great care in order \\nto avoid violating the law or creating undue risk and reputational harm to the organization. \\nThis article explores these sometimes tricky issues, and offers practical risk-based guidance \\nfor organizations contemplating these types of exercises. \\n\\n© 2018 Joseph V. DeMarco. Published by Elsevier Ltd. All rights reserved. \\n\\n1. \\n\\nIntroduction \\n\\nAs the amount and variety of data being stored has increased \\nexponentially over the years, so have the challenges in keep- \\ning it safe. As a result, information security professionals have \\nneeded constantly to re-invent how to proactively test and \\nassess the physical and technical vulnerabilities of company \\nsystems, so much so that the defenses themselves raise le- \\ngal and reputational risks. “Red Team” operations conduct in- \\nternal physical and logical testing to determine whether un- \\nknown vulnerabilities exist at a corporation,1 \\nwhich would \\npermit unauthorized access to company data and systems, of- \\n\\nten without any warning to internal security personnel. This \\narticle discusses the risks of trying to break into your own net- \\nwork and to hack your own data. \\n\\n2. \\n\\nThe Red Team operation \\n\\nRed Teaming is a form of “ethical hacking” which involves the \\nuse of techniques and methods similar to those of a crimi- \\nnal hacker or state-sponsored organizations to simulate a real \\ncyber-attack (often paired with a physical intrusion) so that \\nthe corporation can learn about weaknesses in their defenses. \\nThe theory is that by simulating an attack, the Corporation \\n\\n∗ Corresponding author: Partner, DeVore & DeMarco, LLP, \\n\\nNew York, NY, USA. \\n\\nE-mail address: jvd@devoredemarco.com \\nAlthough governmental entities and NGOs can also benefit from Red Team testing, this article focuses on the issues implicated when \\n\\n1 \\n\\na private corporation or similar private-sector entity conducts such operations. \\n\\nhttps://doi.org/10.1016/j.clsr.2018.05.033 \\n0267-3649/© 2018 Joseph V. DeMarco. Published by Elsevier Ltd. All rights reserved. \\n\\n\\x0ccomputer law & security review 34 (2018) 908–911 \\n\\n909 \\n\\ncan prompt appropriate changes and security improvements \\nbased on observed cyber-weaknesses. As readers of this publi- \\ncation are likely aware, one common example of ethical hack- \\ning is the penetration test, whereby a Company enlists a tech- \\nnology consultant to test certain points of vulnerability in the \\ncompany’s system at a certain period in time in coordination \\nwith the Company’s IT personnel. In contrast, Red Teaming \\ninvolves a more comprehensive cyber-security assessment of \\na company, often over a longer period of time and usually \\nwith little or no warning to employees within the company. \\nIndeed, knowledge of the exercise is sometimes limited only \\nto a handful of senior management – and in some cases, to \\nincrease the realism of the test, the CISO and head of phys- \\nical security (or their functional equivalents) are deliberately \\nexcluded from the “circle of trust” and have no knowledge of \\nthe exercise until it is concluded. \\n\\nTypically, the operation aims to identify both the cyber and \\nphysical vulnerabilities in a Company’s network and systems. \\nThe Red Team (which is carefully selected and operates un- \\nder strict supervision) often begins by gathering as much in- \\nformation as possible from publicly available sources about \\nthe “target” whether it is the corporation as a whole or a divi- \\nsion or even single facility of the Company. This “reconnais- \\nsance phase” can also include the collection of information on \\nCorporate personnel who will be targeted. Often, those em- \\nployees’ social media profiles are a rich source of data that \\ncan be used to learn who to target in order to gain access to \\ncompany facilities, systems, or confidential information. The \\nRed Team generally does not leverage knowledge of internal \\noperations, sources of information, Corporate network access; \\nrather, they seek to emulate access and availability of an ex- \\nternal attacker. Once potential weaknesses are identified, the \\nTeam then employs many of the same tools that a black hat \\nhacker would use to compromise company servers and net- \\nworks, including “social engineering”2 \\ntechniques that solicit \\ncritical information from employees under false pretenses. In \\naddition, physical intrusion testers may be tasked with sur- \\nreptitiously gaining access to areas in Company facilities to \\nidentify weaknesses in physical security or, place a device on \\nthe Company’s system to aid the hacking. For example, a tester \\nmay pose as a package delivery person or use a cloned build- \\ning access card to get access to a server room, or just to com- \\nputers that are unattended. They may even scatter “infected”\\nthumb drives in company offices in the hope that someone \\nmight plug them into a corporate computer.3 \\n\\nThe Team may or may not provide some limited informa- \\ntion to the company’s IT department in advance for certain \\nparts of the operation. Black Box testing is when the Com- \\npany provides no information prior to the start of testing to \\nthe Team about the company’s network and the Company’s \\nnetwork defense organization has no prior knowledge of the \\n\\n2 \\n\\n3 \\n\\nExamples  of  “social  engineering” include  sending  phishing \\nemails to Company employees or “pre-texting,” communicating \\nwith employees using a fabricated scenario to obtain information. \\nNaturally, the drives will not contain any actual malware; they \\ncan, however, be configured to “beacon home” to the Red Team op- \\nerations center with information about where the drive was con- \\nnected and, potentially, who connected it. Targeted remedial mea- \\nsures can then be considered by management. \\n\\ntest. Grey Box testing is when the Company provides partial \\ndetails of the target systems and the network defense orga- \\nnization may have some notice of the test. White Box test- \\ning is when a Company provides the Team with full and com- \\nplete details of the network, applications, and internal proce- \\ndures and when the Company’s network defense organization \\nknows about the test in advance. The recommendations below \\nare generally applicable to all of these scenarios. \\n\\n3. \\n\\nLegal risks \\n\\n3.1. \\n\\nAccess to sensitive information \\n\\nEven though the Company voluntarily authorizes 4 \\nthe hack- \\ning, it does not mean that the hacking is free of a variety of \\nstatutory and contractual legal risks. The Company’s systems \\nlikely contain a variety of personal information that is sub- \\nject to local and foreign national laws (and both federal and \\nstate laws in the United States). For example, in the U.S., un- \\nder federal and state data breach statutes, Companies who \\nhold personal information that is inadvertently exposed must \\nundertake an extensive investigation and expensive remedial \\nmeasures to inform affected individuals of the breach. Ad- \\nditionally, the exposure or deletion of data may give rise to \\ncauses of action in tort or could violate contractual provi- \\nsions between the Company and third parties. A properly con- \\nceived Red Team operation should, through knowledgeable le- \\ngal counsel, analyze these laws in advance, so as not to trigger \\na “false alarm” and needless data breach report by the Corpo- \\nration. \\n\\nRed Team operatives should, to the extent possible, avoid \\nviewing any electronic financial data, credit reports, employee \\nor applicant data, or health data. Unless otherwise stated in \\nwriting, data exfiltration relating to employees—whether cur- \\nrent, former, or prospective—of the Corporation should almost \\nalways be prohibited or only be conducted with prior approval \\nand appropriate documentation. Similarly, exfiltration of data \\noutside of the internal network should not be permitted. In ad- \\ndition, to maximize security, information compromised dur- \\ning a testing engagement should not traverse the internal \\nnetwork with risk of external exposure. Moreover, unless oth- \\nerwise  approved  in  advance,  testers  should  not  access  or \\nattempt to access customer data, sensitive employee infor- \\nmation, or systems housing information not owned by the \\nCompany. \\n\\nIn  terms  of  attack  technique  and  tradecraft,  malware \\nshould never be employed for any purpose during the exercise. \\nIn addition to implicating potential liability under local com- \\nputer crime laws, the malware may damage data or spread to \\nother systems in unpredictable ways that could give rise to \\na claim sounding in negligence, among other legal liabilities. \\n\\n4 \\n\\nAs will be discussed elsewhere, see infra, it is crucial that inter- \\nnal or external legal counsel versed in the issues discussed herein \\nbe closely involved in the conceptualization and execution of the \\nexercise. At the outset, counsel can guide the Corporation in the \\nproper methods of exercise authorization so as to ensure that it is \\nnot “ultra vires” while at the same time maintaining the parame- \\nters of desired secrecy. \\n\\n\\x0c910 \\n\\ncomputer law & security review 34 (2018) 908–911 \\n\\nInstead, as a general matter, Red Team testing efforts should \\nbe conducted with technologies, tools, and platforms that are \\nobtained from reputable sources and, in the event of Free and \\nOpen Source Software (FOSS), abide by all corporate use li- \\ncense agreements. Moreover, tools, technologies, and capabili- \\nties leveraged during testing should not be acquired from loca- \\ntions or sources considered un-reputable, or from sources that \\npose unintended risk to the system being tested. Crucially, the \\nRed Team should never use stolen hacking tools (e.g., leaked \\nNational Security Agency tools) or tools that violate corporate \\nuse agreements. Testers should also never purposefully desta- \\nbilize the confidentiality or availability of the Company’s pro- \\nprietary data and information. Finally, Red Team testing via \\nsocial engineering methods with e-mail based phishing at- \\ntacks should never include malicious software as part of the \\npayload. In sum, the “Physician’s Principle” – primum non nocere \\n– should be scrupulously respected: Testing should be done in \\na manner in which the user or system is not put at any addi- \\ntional risk. \\n\\nThe Team should be especially careful to avoid actions that \\ncould adversely affect the Company’s clients or other innocent \\nthird parties. The operation should avoid intercepting data \\nflows coming to or from or entering the networks of entities \\nother than the Company, including service providers. Failing \\nto take proper precaution can result in serious damage, in- \\ncluding the destruction of data, the exposure of personal in- \\nformation protected by statute, compromising of a power sys- \\ntem or other essential service. If the Red Team has reason to \\nbelieve that clients or other innocent third parties could be \\nforeseeably adversely affected, they should first consult legal \\ncounsel prior to taking the action in question. If the Team in- \\nadvertently causes harm to a client or other innocent third \\nparties, the Team should cease all activity and immediately \\ncontact the managers supervising the operation. \\n\\n3.2. \\n\\nLaw enforcement and physical safety \\n\\nBecause the Company’s employees are unaware of the Red \\nTeam operation, there is always a risk that an attempted phys- \\nical or cyber intrusion will be quickly escalated to law enforce- \\nment. The Company should carefully consider measures to \\nminimize the risk of this occurring or, in some cases, whether \\nprior notice to law enforcement about the operation is appro- \\npriate. \\n\\nPrior to commencing a specific kinetic or cyber operation, \\nthe Team should select Company personnel who can – in the \\nevent that the Red Team’s actions are detected by Company \\npersonnel or by clients – prevent the matter from being esca- \\nlated to law enforcement. In the case of cyber operations, the \\nteam should consider providing a list to select personnel of all \\nIP addresses that the operation will be directed from. In the \\ncase of physical penetration testing, the team should provide \\nphotographs and information about the tester’s true identity \\nand assumed identity to select personnel. The team should \\nalso inform select personnel once a specific kinetic or cyber \\noperation has been completed. This deconfliction will ensure \\ntesting efforts are not interrupted and unnecessary investiga- \\ntion and analysis is not conducted. \\n\\nIn addition to law enforcement involvement, physical in- \\ntrusion testing could potentially include the risk of a physical \\n\\nconfrontation and bodily injury. Although the goal of the ex- \\nercise is to breach the company’s physical security, a tester \\nshould never resort to breaking and entering or other extraor- \\ndinary measures that could result in property damage or a \\nphysical injury. During the testing lifecycle, if at any point a \\ntester is “discovered,” deception or social engineering is per- \\nmitted within the bounds of these guidelines, but a tester \\nshould never impersonate a police officer, other first respon- \\nders, clergy, public officials, lawyers, or doctors, and should be \\nmindful about not breaking any local laws. \\n\\nTesters should disclose testing activities and identities if \\nthe discoverer becomes hostile or asks for or seeks escala- \\ntion. At no point during a physical testing engagement should \\ntesters leverage security weakness that put the tester or any- \\none else at risk of injury. Safety is the top priority when con- \\nducting physical intrusion testing. In the event the facility in- \\nvolved employs armed guards, it is imperative to discuss im- \\npacts and response process with supervisors prior to test ex- \\necution. \\n\\nPhysical testing engagements should be pre-coordinated \\nwith supervisors, and include approval prior to test execution. \\nThis may include representation form Corporate security, lo- \\ncal physical security, or a direct liaison at the actual facility \\nbeing tested. Physical Intrusion testers should have a lanyard \\naround their neck (hidden from plain sight) that includes a \\n“safe passage” letter signed from physical security or respon- \\nsible site location representatives noting that this is an au- \\nthorized test. This letter should be accompanied with a di- \\nrect contact number and the physical security tester’s actual \\nemployee badge for de-confliction. The Team should always \\nensure that there will always be a Company representative—\\nideally the senior legal officer—who can be contacted during \\noperations and who can be given as a name to law enforce- \\nment or security personnel. \\n\\n4. \\n\\nImportant best practices \\n\\n4.1. \\n\\nDirecting and defining the scope of work \\n\\nAs a threshold matter, it is crucial that legal counsel be closely \\ninvolved in planning and supervising the Red Team exercise. \\nAs noted above, an array of disparate civil and criminal laws \\ncan be implicated in an exercise and a thorough knowledge \\nof the applicable legal framework governing the Company and \\nthe exercise is crucial. In addition to core legal compliance, the \\nuse of outside counsel can, depending on the circumstances, \\nbring the operation within the bound of counsel privilege. The \\nbenefits of this are outside the scope of this article, but they \\ncan be substantial. \\n\\nIn addition to the careful planning around the legal risks \\nabove, there are some more general principles that should \\ngovern the service agreement between the company and the \\nRed Team vendor. The Company should clearly delineate in \\nwritten Red Team Guidelines (RTGs) what information or sys- \\ntems are off-limits to testing, what testing devices are per- \\nmited and the acceptable methods of physical intrusion test- \\ning. Any limits on social engineering methods should also be \\nspelled out. Any changes in scope of testing or devices tested \\nmust be approved and included within a written Statement of \\n\\n\\x0ccomputer law & security review 34 (2018) 908–911 \\n\\n911 \\n\\nWork (SOW) prior to test execution. Red Team testers should \\nalways remain within the scope of testing defined in the RTGs \\nand SOW. \\n\\nRed Team testers should also abide by all Company poli- \\ncies that are affected by the operation and a Code of Conduct \\n(COC) and Memorandum of Agreement (MOA) signed by all of \\nthe individual Team testers who are not full-time Company \\nemployees. \\n\\n4.2. \\n\\nInformation flows during testing \\n\\nDocumentation and reporting are essential to a well-managed \\noperation. Red Team testers should document all their testing \\nanalysis and results including steps taken to achieve actions \\non objectives. These methods will enable re-testing or valida- \\ntion testing to occur with emulation of tester attack methods. \\nDuring Red Team activities, testers should provide periodic –\\nand in no event less than weekly – progress updates that de- \\nscribe in detail what has been discovered and what methods \\nwere used. \\n\\nResults of Red Team testing activities should be consoli- \\ndated in periodic reports and provide an overview of discov- \\nered vulnerabilities, weaknesses, exploitation success and re- \\nmediation guidance on how to address the risk. Any final re- \\nport should assess overall risk level of the system and the \\nrisk level of each vulnerability. As noted above, the Red Team \\nshould operate at the direction of counsel and all Red Team \\ndocumentation should be labelled “Privileged and Confidential: \\nPrepared at Counsel Direction.”\\n\\nDuring Red Team Testing activities, if a tester discovers, ex- \\nploits, or otherwise takes advantage of a weakness, risk, or \\nvulnerability considered to be critical in nature, it is the obliga- \\ntion of the tester to disclose immediately this information to \\ntrusted supervisors, regardless of impacts to the testing pro- \\ncess. These include the following as examples: \\n\\n• Discovered breaches. \\n• Evidence of attacker remanence (tools, directories, files, \\n\\nmalware, etc.). \\n\\n• Vulnerabilities with high exploitation probability. \\n• Vulnerabilities that are exploitable for full, untraceable ac- \\n\\nability, errors and omissions coverage, and cyber insurance \\npolicies. Errors and omissions coverage, for example, will gen- \\nerally cover many claims arising from negligence, but it will \\nnot cover disclosure of personal information or personal in- \\njuries. Cyber insurance may cover disclosure of personal in- \\nformation, but may not insulate Directors and Officers from \\nclaims of malfeasance. It is possible that certain aspects of the \\nscope of work are not insurable, in which case the Company \\nmay need to revisit the scope of work. \\n\\n4.4. \\n\\nProtecting company relationships \\n\\nAny  of  the  dangers  above  can  damage  relationships  with \\nclients, other third parties, employees, and the Company’s per- \\nception in the media. Prior to signing the vendor contract, the \\nCompany should identify any potential sources of employee \\nor third party data and build the exercise around that data as \\nmuch as possible. \\n\\nWith respect to its own employees, the Company should \\nrequest that the Red Team avoid engaging in “pretexting” of \\nreal persons or any misappropriation of the likenesses of other \\npeople. This prohibition includes using names or likenesses \\nof persons that the Team knows are known to the target or \\nwho are connected to the Company or making representa- \\ntions to the target that could uniquely identify the online per- \\nsonality as a particular person, especially from the target’s \\npersonal history. Similarly, unless otherwise approved in ad- \\nvance, Red Team testers should not be authorized to log into \\nthe Company’s systems utilizing an employee’s access creden- \\ntials. If the team acquires an employee’s credentials, the team \\nshould note that the credentials were successfully obtained \\nand proceed no further. If the Red Team includes leveraging \\nof employee credentials to determine extent of threat and im- \\npact, this must be done in a secure manner. Red Team testers \\nmust acknowledge and abide by these Guidelines; credentials \\nshould only be associated to business owned accounts; com- \\npromised credentials should only be used for the purposes of \\ntesting; and users should be alerted by the trusted agent at the \\ncompletion of the test to change their password(s). \\n\\ncess. \\n\\n5. \\n\\nConclusion \\n\\n• Vulnerabilities that could place lives, physical safety or \\n\\npublic welfare at risk. \\n\\n4.3. \\n\\nInsurance \\n\\nGiven the potential for damage to Company and third par- \\nties, it is important for appropriate officials to assess the risks \\nagainst the terms of Company insurance policies, including \\ngeneral commercial liability policies, director and officer li- \\n\\nAs the challenges to keeping data secure multiply, it is im- \\nportant for companies to subject their data systems to more \\nrigorous scrutiny. Red Team operations should be considered \\nalongside other penetration testing techniques with a realistic \\nassessment of the legal and reputational risks associated with \\nthose operations. If properly guided by management and legal \\ncounsel, they can significantly increase the cyber-resilience of \\nan organization. \\n\\n\\x0c', '2015 European Intelligence and Security Informatics Conference\\n2015 European Intelligence and Security Informatics Conference\\n\\nCritical Infrastruc\\nTheory for Resilie\\n\\ncture Protection: Towar\\nent Software-Intensive \\n\\nrds a Design \\nSystems  \\n\\nJyri Rajamäki and Rauno Pirinen \\n\\nLaurea \\n\\nUniversity of Applied Sciences, Espoo, Finland \\n\\nAbstract—Modern societies are highly depe\\ncritical  software-intensive  information  syst\\nsociety. Designing security for these informatio\\nparticularly challenging since the technologies \\nsystems.  Revolutionary  advances \\nin  hardw\\ninformation and human interface technologies\\nof  thinking  about  how  these  resilient  softwar\\n(SIS)  are  conceptualized,  built  and  evaluated\\nthis  area  is  to  develop  a  design  theory  (DT)  f\\nthat communities developing and operating dif\\ntechnologies  can  share  knowledge  and  best \\ncommon frame of reference. \\n\\nendent on different \\nems  that  support \\non systems has been \\nthat make up these \\nware,  networking, \\ns require new ways \\nre-intensive  systems \\nd.  Our  research  in \\nfor  resilient  SISs  so \\nfferent information \\npractices  using  a \\n\\nKeywords—critical \\n\\ninfrastructure  prot\\nintensive systems, cyber security, trust-building\\n\\ntection, \\ng, design theory \\n\\nsoftware-\\n\\nI.  INTRODUCTION \\n\\nThe main purpose for designing resilient \\nreturn  privacy  and  trust  in  digital  world  and\\ncompetitive  edge  in  security-related  busines\\ninfrastructures. The purpose, with regard to s\\nwhat is going on and what will happen in the \\nbe aware of the current level of security in th\\nto  design  or  build-in  security  and  resilienc\\nenvironment,  and  to define  trade-offs  for  se\\nlevels  versus  system’s  usability  [1].  The \\nmitigate  cyber  security  risks,  which  in  its \\nbusiness  continuity  and  operations  of  the  w\\ndesign  theory  proposal  is  based  on  the  co\\ninformation systems design theory by Gregor\\n\\nsystems is how to \\nd  to  gain  a  global \\nss,  such  as  critical \\necurity, is to know \\nnetwork(s), and to \\nhe network(s), how \\ncy  to  a  networked \\ncurity  and  privacy \\noverall  aim  is  to \\nturn  supports  the \\nwhole  society.  Our \\nore  components  of \\nr and Jones [2]. \\n\\nII. DESIGN THEORY CONSTRUCTS FOR R\\n\\nRESILIENT SISS \\n\\nResilient  Systems:  Resiliency  means  t\\ninfrastructure  is  able  to  adapt  to  changing \\ncase  of  information  security,  based  on  r\\nawareness and a priori risk analysis. \\n\\nthat  a  system  or \\nconditions,  in  the \\nrun-time  situation \\n\\nSituation  Awareness  involves  being  a\\nhappening around one to understand how in\\nand one’s own actions affect the goals and ob\\nand  in  the  near  future.  The  most  impo\\nsituational awareness  are  observations,  analy\\nand cyber-policy of the government.  \\n\\naware  of  what  is \\nnformation, events, \\nbjectives, both now \\nortant  enablers  of \\nlysis, visualization, \\n\\nSecurity  technologies  include  all  technic\\ncyber  security,  such  as  secure  system  archi\\nand  implementation,  as  well  as  tools  and  pl\\nsystem development and deployment. \\n\\ncal  means  towards \\nitectures,  protocols \\natforms  for  secure \\n\\nSecurity  management  and  governance  c\\n\\nand  organizational  aspects  of  information \\nareas \\n(1)  Security  policy  d\\nimplementation,  and  (2)  Information  sec\\n\\ninclude: \\n\\ncovers  the  human \\nsecurity.  Its  focus \\ndevelopment  and \\ncurity  investment, \\n\\nincentives,  and  trade-offs.  Inf\\nsystem  (ISMS)  means  continu\\nsystem  by  documented  and  s\\nprocedures and process to achie\\navailability  of  the  organizatio\\npreserve. \\n\\nformation  security  management \\nuously  managing  and  operating \\nsystematic  establishment  of  the \\neve confidentiality, integrity and \\non’s  information  assets  that  do \\n\\nFORM AND FUNCTION \\n\\nIII. PRINCIPLES OF F\\nTrustworthy  and  secure  tec\\nbasis to build on. As the securit\\ncybercrime  and  other  unaut\\nsolutions  and  management  o\\ndesign  and  constant  develop\\nsystematic  approaches  towar\\nsystems. Both the resilient syst\\nsystem  are  SISs.  Security  tec\\nbetween their platform and soft\\nis the main tool in and between \\nSoftware-intensive  systems\\nplatform  layer,  the  software  l\\nEvery  cyber-secure  system  co\\nresilient  system,  and  the  situat\\nthe main prerequisite towards c\\na  system  of  software-intensiv\\nlayers compose a physical netw\\nsoftware network and human la\\nas  shown  in  Fig.1.  Trust  (\\nsystematically built up at all lay\\n\\nchnologies  and  platforms  are  a \\nty risks continue to increase with \\nthorized  access, \\nthe  security \\nf  IT  security  need  systematic \\npment.  Fig.1  shows  the  new \\nds  resilient  software-intensive \\ntem and the situation awareness \\nchnologies  are  applied  in  and \\nftware layers. Trust management \\n\\nhuman layers. \\ns  consist  of  three  layers:  the \\nlayer  and  the  human  layer  [3]. \\nonsists  of  two  SISs:  the  proper \\ntional  awareness  system  that  is \\ncyber security. A complex SIS is \\ne  sub-systems,  which  platform \\nwork, software layers compose a \\nayers compose a social network, \\n(=  cyber  security)  should  be \\nyers. \\n\\nFig.1 Systematic approach towards\\n\\ns resilient software-intensive systems\\n', '2015 European Intelligence and Security Informatics Conference\\n\\nTerrorism and its Transition to Cyberspace  \\n\\nManuel José Gazapo Lapayese \\nChief Manager \\nInternational Security Observatory \\nMadrid, Spain \\nm.gazapo.lapayese@hotmail.com  \\n\\nAbstract—This  poster  discuss  the  results  of  research  carried \\nout  from  various  angles  on  the  links  and  relationships  existing \\nbetween  cyberspace  and  contemporary  terrorism.  In  order  to \\nunderstand  why  terrorism  is  spreading  increasingly  into  the \\nvirtual  world,  the  poster  is  structured  around  two  questions: \\nwhether  cyberspace \\nis  terrorism’s  new  battleground,  and \\nwhether  it  is  possible  to  differentiate  cyberterrorism  from \\nterrorism online. \\n\\nKeywords— Responses, resilience, cybersecurity, terrorism. \\n\\nI.  CYBERSPACE: TERRORISM’S NEW \\n\\nBATTLEGROUND \\n\\nA.  Cyberspace’s Complex Anatomy \\nOur  research  at  the  International  Security  Observatory  has \\nproven  cyberspace  to  be  a  field  for  action  lying  halfway \\nbetween the physical and virtual dimensions. As a consequence \\nof  this,  the  Web  exhibits  an  extremely  complex  anatomy:  it \\ncould be argued that cyberspace has a double nature, since it is \\nsimultaneously a virtual and a physical scenario. \\n\\nB.  Why has Terrorism Chosen to Act within this New \\n\\nDimension? \\n\\ntraits  of \\n\\ncyberspace \\n\\ncharacteristic \\n\\nThe \\n-immediacy, \\naccessibility    anonymity  and  asymmetry-  do  not  only  make  it \\ndifferent from traditional battlegrounds such as land, sea, air or \\nspace – they are also the reasons why terrorists are increasingly \\noften  drawn  to  it  for  their  operations.  Cyberspace  is  a \\nbattleground where terrorists can face their enemies as equals: \\nmere access to a digital platform allows any terrorists to attack \\ntheir enemies at no risk of being identified or neutralised. Thus, \\nwe can assert that cyberspace as a battleground is defined by its \\nhosting asymmetric conflicts in which terrorists are playing an \\nincreasingly larger part. \\n\\nC.  The Mutability of Cyberspace. From Web 1.0 to Web 2.0 \\nThe  Web,  which  started  out  in  the  1990s,  has  already \\nundergone two stages: the first was Web 1.0, where there were \\nno  search  engines,  no  explorers  and  no  participative \\ninteraction;  while  the  second,  the  Web  2.0  within  which  we \\noperate,  is  defined  by  interconnection  and  interaction,  social \\nnetworks  and  forums;  the  risks  and  vulnerabilities  within  it \\nhave increased by several orders of magnitude. The unchecked \\ngrowth of our dependence on the Internet is something real. \\nThe  cyberspace \\ninception  by \\nis  characterised  from \\nunstoppable  mutability,  so  it  carries  within  itself  the  seed  of \\n\\nits \\n\\n978-1-4799-8657-6/15 $31.00 © 2015 IEEE\\nDOI 10.1109/EISIC.2015.46\\n\\n178\\n\\ninsecurity: if extant threats in cyberspace are always ahead of \\ndefence  mechanisms  and  thus  early-warning  systems  fail  to \\nfulfil  their  goals,  it  is  easy  to  foresee  that  the  number  of \\nterrorists  seduced  by  the  Internet  will  be  increasing  by  the \\nhour.  \\n\\nII.  CYBERTERRORISM OR TERRORISM ONLINE? \\n\\nAs the poster shows, the nuances of the distinction between the \\nconcepts  of  ‘terrorism  operating  online’  and  ‘cyberterrorism’ \\nare  not  well  established,  and  they  vary  according  to  each \\nexpert.  For  example,  international  cybercrime  experts  like \\nLaura  Cowan  or  Fernando  Miró  claim  that  there  is  no  actual \\ndifference between terrorism online and cyberterrorism – they \\nare one and the same. All this brings us to the point that the use \\nof cyberspace by terrorists has the Web as a medium, which is \\na  perfectly  tailored  catalyst  for  successfully  carrying  out  their \\nmissions:  it  is  a  channel  used  by  terrorists  to  spread  their \\nthreats and influence over the whole planet. Thus, the existence \\nof  cyberterrorist  operations  does  not  imply  that  the  Web  is \\nunderstood in them as a goal in and of itself – but as a medium \\nthrough which to put even more pressure on their enemies. \\n\\nIII.  CONCLUSIONS \\n\\nAs  we  have  seen  above,  cyberspace  is  an  extremely  complex \\ndimension  that  is  beginning  to  offer  –  if  it  has  not  done  so \\nalready – very attractive conditions for the adoption of existing \\ndigital  platforms  by  an  increasingly  large  number  of  terrorist \\nmovements  and  organisations  in  order  to  carry  out  their  tasks \\nand  operations:  recruiting  and  indoctrinating  new  militants, \\ndiversifying  their  sources  of  income  and  spreading  their \\nmessages  and  threats.  Considering  the  arguments  given  in \\nresponse to the questions that have structured this poster, it can \\nterrorism  online  and \\nthat  while \\nultimately  be  argued \\ncyberterrorism  cannot  be  differentiated  from  one  another, \\ncyberspace  does  appear  to  be  terrorism’s  new  operational \\nbattleground.  Knowing  that  the  virtual  world  is  an  ever-\\nchanging  medium  and  that  terrorists  will  always  be  one  step \\nahead  of  security  improvements,  it  is  vital  to  understand  that \\nthe  surveillance  of  cyberspace  and  the  improvement  of \\ncybersecurity  and  early-warning  systems  merit  much  greater \\nattention  than  they  have  received  until  now.  Our  security  no \\nlonger depends on the protection we can grant ourselves at the \\nmaterial level. Virtual protection – cybersecurity – has become \\na  priority;  even  more  so  since  terrorism  is  guaranteed  to \\ncontinue to exist over the foreseeable future. \\n\\nAuthorized licensed use limited to: Ryerson University Library. Downloaded on May 18,2022 at 02:29:56 UTC from IEEE Xplore.  Restrictions apply. \\n\\n \\n \\n \\n \\n \\n \\n\\x0c'], 'Index': [22, 58, 159, 163, 192, 226, 229, 246, 444, 470, 474, 478, 513, 519, 541, 551, 554, 556, 570, 574, 589, 607, 629, 641, 645, 655, 689, 693, 715, 772, 775, 780, 786, 832, 849, 852, 893, 896, 897, 906, 922, 932, 951, 959, 963, 996, 1091, 1105, 1106, 1108, 1112, 1123, 1162, 1172, 1175, 1181, 1196, 1197, 1214, 1217, 1218, 1288, 1300, 1301]}\n"
     ]
    }
   ],
   "source": [
    "## Reinsert updated text back into the dataframe\n",
    "\n",
    "import glob\n",
    "\n",
    "new_my_dict = {'Code': [], 'Full text': []}\n",
    "\n",
    "non_retrievables = []\n",
    "\n",
    "os.chdir('C:\\\\Users\\\\bbhat\\\\Downloads\\\\MRP\\\\Final Files')\n",
    "os.getcwd()\n",
    "\n",
    "for i in glob.glob('*.txt'):\n",
    "    #print(i)\n",
    "    f = open(i, 'r', encoding='utf-8')\n",
    "    if str(i)[:4].isdigit():\n",
    "        new_my_dict['Code'].append(str(i)[:4])\n",
    "        new_my_dict['Full text'].append(f.read())\n",
    "\n",
    "new_my_dict['Index'] = list(my_df_without_references.index[my_df_without_references['Code'].isin(list(map(int,new_my_dict['Code'])))])\n",
    "            \n",
    "\n",
    "print(new_my_dict)\n",
    "#my_df_without_references.index[my_df_without_references['Code'].isin([124,27])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6G Networks: Is This an Evolution or a Revolution?\n",
      "\n",
      "The  lessons  learned  from  the  third \n",
      "\n",
      "industrial  revolution  taught  us \n",
      "that the transformation from mechani-\n",
      "cal  and  analog  technology  to  digital \n",
      "electronics  have  changed  the  world \n",
      "once  and  forever.  While  computers \n",
      "and  communication  networks  have \n",
      "become  the  new  oil  that  defines  the \n",
      "wealth  of  countries,  research  and \n",
      "industrial  communities  have  been \n",
      "the  driving  forces  that  have  made \n",
      "this transition possible. In the future, \n",
      "the  same  communities  and  stake-\n",
      "holders  are  required  to  enable  the \n",
      "transition to net-zero communication \n",
      "networks.  With  reference  to  mobile \n",
      "communications,  5G  is  an  evolution \n",
      "from  all  previous  networks  with  the \n",
      "adoption of new radio access technolo-\n",
      "gies,  multisliced  architecture,  cloud-\n",
      "native and automation, and so on. By \n",
      "definition, 5G is a network that adapts \n",
      "to user needs and dynamic changes in \n",
      "traffic, designed to serve a new class of \n",
      "users:  “machines.”  Therefore,  latency \n",
      "has  become  a  critical  metric  in  5G. \n",
      "Looking forward, 6G shall employ cell-\n",
      "less  access  networks,  integrated  non-\n",
      "terrestrial  networks, joint sensing and \n",
      "communications,  new  spectrums \n",
      "such as terahertz (THz) communica-\n",
      "tions,  switching  from  traditional \n",
      "channel-based  design  paradigms  to \n",
      "designing  channels  through  novel \n",
      "technologies  such  as  intelligent \n",
      "reconfigurable  surfaces,  open  inter-\n",
      "faces  that  interconnect  all  network \n",
      "\n",
      "Digital Object Identifier 10.1109/MVT.2021.3116995\n",
      "\n",
      "Date of current version: 2 December 2021\n",
      "\n",
      "functions,  end-to-end  orchestrators, \n",
      "and,  most  noticeably,  artificial  intelli-\n",
      "gence  (AI)  machines  that  govern  all \n",
      "functional  modules  and  operational \n",
      "services.  The  various  network  func-\n",
      "tions  generate  traces  of  various \n",
      "operations  that  are  ingested  into \n",
      "databases;  then  AI  will  leverage  this \n",
      "data  for  optimized  decisions  that  are \n",
      "reflected  into  network  status  transi-\n",
      "tions,  resource  utilization,  service \n",
      "enhancement,  and  ultimately  lead  to \n",
      "self-synthesizing networks. Built upon \n",
      "commercial  clouds,  6G  will  have  the \n",
      "flexibility to scale and restructure for \n",
      "more resilient response to traffic fluc-\n",
      "tuations  and  user  requirements.  To \n",
      "this  end,  cybersecurity  features  will \n",
      "become an embedded part of network \n",
      "functions  to  shield  the  network  ser-\n",
      "vices  not  only  from  external  threats \n",
      "but  also  from  hosting  domains.  From \n",
      "an  air  interface  perspective,  6G  will \n",
      "integrate  nonterrestrial  (space,  air, \n",
      "drone,  and  ocean)  communications \n",
      "technologies  to  connect  and  route \n",
      "new users such as drones and coastal \n",
      "trading  vessels.  Furthermore,  future \n",
      "wireless  networks  need  to  make  use \n",
      "of  a  spectrum  that  extends  into  the \n",
      "optical  spectrum  and  includes  the \n",
      "THz  range.  The  channel  becomes  a \n",
      "critical component due to the impact \n",
      "of blockages and random orientations \n",
      "at  these  frequencies.  Active  and  pas-\n",
      "sive  intelligent  reflecting  surfaces \n",
      "(IRSs) will become a new wireless sys-\n",
      "tem  element  that  will  help  overcome \n",
      "new  challenges  related  to  coverage \n",
      "and the propagation channel.\n",
      "\n",
      "The evolution of mobile networks \n",
      "could  be  defined  by  the  continu-\n",
      "ous  improvement  and  integration \n",
      "of  new  services  or  users.  However, \n",
      "if  6G  became  an  intelligent  network \n",
      "that identified requirements, adapted \n",
      "to  situations,  and  applied  self-con-\n",
      "figuration  for  sophisticated  actions \n",
      "without  human  intervention,  would \n",
      "this be considered an evolution of new \n",
      "network infrastructure? In fact, this is \n",
      "a  revolution!  The  question  that  we \n",
      "should ask is, “Is such a network vi-\n",
      "sion achievable in five to 10 years from \n",
      "now?”  The  answer  is  simple:  “It  is \n",
      "possible.” Considering the massive in-\n",
      "vestment and attention to AI, the mi-\n",
      "gration of networks to the cloud, the \n",
      "adoption of new service and integral \n",
      "components,  and  most  important-\n",
      "ly the  new  visions  for  a  network-\n",
      "over-the-cloud, all of those enablers \n",
      "will allow a new network generation \n",
      "that connect humans through smart \n",
      "machines to be built. A smart 6G net-\n",
      "work will open the space for ground-\n",
      "breaking advancements in technology \n",
      "and service management. 6G will \n",
      "provide  connectivity  to  new  verti-\n",
      "cals and management to life-sup-\n",
      "porting facilities at reduced power \n",
      "consumption  rates.  Therefore,  it  is \n",
      "the  time  to  think  about  standards \n",
      "for such networks, composed ele-\n",
      "ments,  key-performance  indicators, \n",
      "and changes that may be brought \n",
      "to  social  and  economic  domains. \n",
      "It  seems that this is not the time to \n",
      "think  about  evolution;  it  is  time  to \n",
      "be  bold  and  consider  revolutionary \n",
      "\n",
      "14 |||   \n",
      "\n",
      "IEEE VEHICULAR TECHNOLOGY MAGAZINE  |  DECEMBER 2021\n",
      "\n",
      "From the Guest editorsKlaus David, Anwer Al-Dulaimi, Harald Haas, and Rose Qingyang Hu \n",
      "\f",
      "steps to adapt to the rapidly chang-\n",
      "ing user demands.\n",
      "\n",
      "This is the fourth special issue of \n",
      "IEEE  Vehicular  Technology  Magazine \n",
      "dedicated  to  6G  technologies,  and \n",
      "the third issue in the 6G series with \n",
      "the IEEE Future Networks Initiative. \n",
      "The  special  issues  will  cover  differ-\n",
      "ent technical areas to help research \n",
      "and  industrial  communities  have  a \n",
      "better understanding of the state of \n",
      "the art for 6G communications. This \n",
      "special  issue  has  six  articles  that \n",
      "address  various  network  segments \n",
      "and technologies.\n",
      "\n",
      "The first article, “Slicing-Based \n",
      "Artificial  Intelligence  Service  Provi-\n",
      "sioning  on  the  Network  Edge,”  by  Li \n",
      "et al., addresses the AI service provi-\n",
      "sioning  to  support  6G  edge  network \n",
      "intelligence. The authors specify the \n",
      "features  and  requirements  for  AI  as \n",
      "well as the customized slicing for such \n",
      "services. The article also provides  a \n",
      "trace-driven  case  study  to  demon-\n",
      "strate  the  AI  service  performance \n",
      "requirements  via  flexibly  choosing \n",
      "resource pooling policies.\n",
      "\n",
      "In  the  second  article,  “Key  Tech-\n",
      "nologies  in  6G  Terahertz  Wireless \n",
      "Communication  Systems:  A  Survey,” \n",
      "Wang et al. study the interesting THz \n",
      "technologies and their potential in \n",
      "future  6G  wireless  communication \n",
      "systems.  The  authors  conducted  a \n",
      "survey for key technologies in 6G THz \n",
      "wireless communication systems, \n",
      "focusing  on  THz  channel  modeling, \n",
      "THz multibeam antenna design, THz \n",
      "front-end chip design, THz baseband \n",
      "signal processing, and THz resource \n",
      "management.  The  article  presents \n",
      "various performance analyses.\n",
      "\n",
      "In the third article, “Cooperative \n",
      "Multiterminal  Radar  and  Communi-\n",
      "cation:  A  New  Paradigm  for  6G  Mo-\n",
      "bile Networks,” Leyva et al. explore \n",
      "the new hitherto separate radar and \n",
      "communication systems toward their \n",
      "amalgam known as a joint radar and \n",
      "communication  system.  The  article \n",
      "proposes  to  integrate  a  radio  sensing \n",
      "component  into  6G  considering  an \n",
      "ultradense  network  scenario.  The  au-\n",
      "thors show that building such a system \n",
      "\n",
      "is  feasible  with  current  technologies \n",
      "and will support high-resolution appli-\n",
      "cations for next-generation networks.\n",
      "\n",
      "In the fourth article, “Intelligent Re-\n",
      "flecting  Surface-Aided  Vehicular  Net-\n",
      "works  Toward  6G:  Vision,  Proposal, \n",
      "and Future Directions,” Zhu et al. an-\n",
      "alyze  IRS,  considering the significant \n",
      "improvement in the power of needed \n",
      "signals at the receivers, especially that \n",
      "IRS  has  no  energy  cost  and  easy  de-\n",
      "ployment. The authors show how the \n",
      "IRS  can  improve  the  signal  transmis-\n",
      "sions  between  vehicles  and  roadside \n",
      "units. The article provides interesting \n",
      "analysis and also open the discussion \n",
      "for more complex scenarios that could \n",
      "be  studied  in  the  future,  such  as  the \n",
      "utilization of IRS resource in vehicular \n",
      "communication systems.\n",
      "\n",
      "In the fifth article, “Multicarrier- \n",
      "Division Duplex: A Duplexing Technique \n",
      "for the Shift to 6G Wireless Communi-\n",
      "cations,” Li et al. show the advantages \n",
      "of  multicarrier-division  duplex  (MDD) \n",
      "over  the  in-band  full-duplex  (IBFD) \n",
      "mode and the conventional half-duplex \n",
      "modes  of  frequency-division  duplex \n",
      "and  time-division  duplex  from  several \n",
      "essential  aspects,  including  self-inter-\n",
      "ference cancellation (SIC) techniques \n",
      "capability,  resource  integration,  and \n",
      "the support for high-mobility commu-\n",
      "nications. This article provides many \n",
      "numerical  results  that  show  that \n",
      "MDD  outperforms  IBFD  in  terms  of \n",
      "energy efficiency and SIC. The article \n",
      "also discusses some implementation \n",
      "challenges for MDD systems.\n",
      "\n",
      "The  last  article,  “Directional \n",
      "Terahertz  Communication  Systems \n",
      "for  6G:  Fact  Check:  A  Quantitative \n",
      "Look,”  by  Boulogeorgos  et  al.,  de-\n",
      "rives realistic values for the nee ded \n",
      "directivity  to  establish  ultrabroad-\n",
      "band  communication  links  at  THz \n",
      "frequencies  both  in  backhaul  and \n",
      "fronthaul  scenarios.  The  authors \n",
      "also  study  the  impact  of  misalign-\n",
      "ment  on  practical  link  distances, \n",
      "incorporating  reconfigurable  intel-\n",
      "ligent surfaces as a solution to over-\n",
      "come  blockage,  and  explored  the \n",
      "implications  on  the  physical  layer \n",
      "security of THz networks. The find-\n",
      "\n",
      "ings of this article are supported by \n",
      "a detailed analysis for performance.\n",
      "\n",
      "Author Information\n",
      "Klaus  David  (david@uni-kassel.de) \n",
      "is  a  full  professor  and  head  of  com-\n",
      "munication technology at Kassel Uni-\n",
      "versity,  Kassel,  34121,  Germany.  His \n",
      "research  interests  include  mobile \n",
      "networks,  applications,  context \n",
      "awareness, and artificial intelligence. \n",
      "He  has  12  years  of  industrial  experi-\n",
      "ence at companies including HP, Bell \n",
      "Northern  Research,  IMEC,  T-Mobile, \n",
      "and IHP, with five years of experience \n",
      "in  the United  Kingdom,  Belgium,  the \n",
      "United States, and Japan.\n",
      "\n",
      "Anwer  Al-Dulaimi  (anwer.al-dulai \n",
      "mi@exfo.com)  is  a  technical  product \n",
      "owner  in  the  Center  of  Excellence  at \n",
      "EXFO, Montréal, QC H4S 0A4, Canada. \n",
      "He  received  his  Ph.D.  degree  in  elec-\n",
      "tronic and computer engineering from \n",
      "Brunel  University,  London,  in  2012 \n",
      "after receiving B.Sc. and M.Sc. honors \n",
      "degrees  in  communication  engineer-\n",
      "ing.  His  research  interests  include  5G \n",
      "and  6G  networks,  cloud  computing, \n",
      "vehicle-to-everything  technology,  and \n",
      "the Internet of Things.\n",
      "\n",
      "Harald  Haas  (harald.haas@ieee \n",
      ".org)  is  a  distinguished  professor  at \n",
      "the University of Strathclyde, Glasgow, \n",
      "G1 1XW, United Kingdom. His research \n",
      "interests include optical wireless com-\n",
      "munications  and  spatial  modulation, \n",
      "which he introduced in 2006. He is the \n",
      "initiator  and  a  cofounder  of  pureLiFi \n",
      "and  director  of  the  Light  Fidelity \n",
      "Research and Development Center.\n",
      "\n",
      "Rose  Qingyang  Hu  (rose.hu@usu \n",
      ".edu) is a full professor in the Depart-\n",
      "ment of Electrical and Computer Engi-\n",
      "neering  at  Utah  State  University, \n",
      "Logan, Utah, 84322, USA, where she is \n",
      "the associate dean of research for the \n",
      "College  of  Engineering.  She  received \n",
      "her Ph.D. degree in electrical engineer-\n",
      "ing  from  the  University  of  Kansas, \n",
      "Lawrence. She has more than 10 years \n",
      "of R&D experience with Nortel, Black-\n",
      "berry, and Intel as a technical manag-\n",
      "er,  senior  research  scientist,  and \n",
      "senior wireless system architect.\n",
      "\n",
      "DECEMBER 2021  |  IEEE VEHICULAR TECHNOLOGY MAGAZINE \n",
      "\n",
      "||| 15 \n",
      "\n",
      " \n",
      " \n",
      "\f",
      "\n"
     ]
    }
   ],
   "source": [
    "# create dataframe for the full text without references\n",
    "for i, index in enumerate(new_my_dict['Index']):\n",
    "\n",
    "    new_text = new_my_dict['Full text'][i]\n",
    "    old = my_df_without_references['Full text without references'][index]\n",
    "    #print(old)\n",
    "    my_df_without_references.replace(to_replace = old, value = new_text, inplace = True)\n",
    "\n",
    "    #print(\"replaced\", index)\n",
    "    #my_df_without_references['Full text without references'][89]\n",
    "        \n",
    "print(my_df_without_references['Full text without references'][1108])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "## REMOVE SOME RECORDS MANUALLY AS RANDOM SYMBOLS DETECTED/NEW INFO COMES TO LIGHT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Code': ['0287', '0327', '0440', '0551', '0703', '0984', '1211', '1285'], 'Reason': [' extract only', ' removed ref - detect weird symbols', ' ref removed, other lang detected', ' remove manually', ' abstract only', ' not being read properly', ' file is not being read properly [REMOVE MANUALLY]', ' file is not being read properly [REMOVE MANUALLY]'], 'Index': Int64Index([273, 313, 425, 526, 665, 930, 1137, 1203], dtype='int64')}\n"
     ]
    }
   ],
   "source": [
    "#f = open(\"textish.txt\", \"a\", encoding='utf-8')\n",
    "import glob\n",
    "\n",
    "to_remove = {'Code': [], 'Reason': []}\n",
    "\n",
    "os.chdir('C:\\\\Users\\\\bbhat\\\\Downloads\\\\MRP\\\\Final Files\\\\Removed manually after checking text')\n",
    "os.getcwd()\n",
    "\n",
    "for i in glob.glob('*.txt'):\n",
    "    #print(i)\n",
    "    f = open(i, 'r', encoding='utf-8')\n",
    "    if str(i)[:4].isdigit():\n",
    "        to_remove['Code'].append(str(i)[:4])\n",
    "        to_remove['Reason'].append(str(i)[6:-4])\n",
    "\n",
    "to_remove['Index'] = my_df_without_references.index[my_df_without_references['Code'].isin(list(map(int,to_remove['Code'])))]\n",
    " \n",
    "        \n",
    "f.close()\n",
    "\n",
    "print(to_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No     1316\n",
       "Yes       8\n",
       "Name: remove manually, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop manual records from dataframe\n",
    "remove_manually = [\"No\"]*len(my_df_without_references)\n",
    "for i,index in enumerate(to_remove['Index']):\n",
    "\n",
    "    remove_manually[int(index)] = \"Yes\"\n",
    "    #my_df['Remove Manually'] =  np.where(my_df['Full text'].str.strip()=='', 'Yes', 'No')\n",
    "    #my_df_without_references['Remove Manually'] \n",
    "    #print(my_df_without_references['Code'][int(index)])\n",
    "    #print(\"dropped\", index)\n",
    "    #my_df_without_references['Full text without references'][89]\n",
    "        \n",
    "my_df_without_references['remove manually'] = remove_manually \n",
    "my_df_without_references['remove manually'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1324, 7)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#my_df_without_references.drop(index=270, inplace=True)``\n",
    "my_df_without_references.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Save Final dataframe removing blank records, non-english records, and some files not being read correctly\n",
    "\n",
    "my_df_without_references_clean = my_df_without_references[(my_df_without_references['blank'] != 'Yes')\\\n",
    "                         & (my_df_without_references['english lang'] == 'en')\\\n",
    "                         & (my_df_without_references['remove manually'] != 'Yes')].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# export data to a CSV file\n",
    "\n",
    "os.chdir('C:\\\\Users\\\\bbhat\\\\Downloads\\\\MRP\\\\Final Files')\n",
    "os.getcwd()\n",
    "\n",
    "my_df_without_references_clean.to_csv('Stage 2.3 - new papers full text without ref.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
